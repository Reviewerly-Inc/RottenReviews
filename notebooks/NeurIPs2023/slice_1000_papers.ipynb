{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "350c38b5-cccd-4cf8-a0af-5466ea0fd047",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8",
         "0.7494000000000001",
         "0.0416666667",
         "0.9411299229000001",
         "215",
         "162",
         "33.6037",
         "12.872",
         "15.9897",
         "14.4442",
         "13.2649",
         "0.09480000000000001",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1",
         "0.7788",
         "0.1071362434",
         "0.947173357",
         "215",
         "160",
         "32.9398",
         "13.0922",
         "15.3049",
         "14.1918",
         "12.6374",
         "0.069",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6",
         "0.7975",
         "0.0933876124",
         "0.8911411762",
         "215",
         "160",
         "60.5595",
         "7.72",
         "10.1878",
         "10.7063",
         "7.5081",
         "0.16010000000000002",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1",
         "0.8136",
         "0.1130384199",
         "0.8543175459000001",
         "215",
         "159",
         "24.6842",
         "14.3916",
         "17.9549",
         "16.1666",
         "14.582699999999999",
         "0.5533",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0",
         "0.8162",
         "0.0243987494",
         "0.946657896",
         "215",
         "159",
         "36.1512",
         "13.3014",
         "14.7013",
         "14.2653",
         "13.4733",
         "0.0671",
         "97",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0",
         "0.788",
         "0.15018518520000002",
         "0.9463365078",
         "215",
         "159",
         "41.9838",
         "11.8751",
         "12.2",
         "12.1617",
         "14.5053",
         "0.1376",
         "89",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1",
         "0.7687",
         "0.2258405483",
         "0.9238996506",
         "215",
         "158",
         "51.7726",
         "10.363",
         "13.4388",
         "13.0239",
         "10.8601",
         "0.08660000000000001",
         "34",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0",
         "0.7917000000000001",
         "0.0843567251",
         "0.8677315712",
         "215",
         "158",
         "53.0107",
         "9.3931",
         "11.5955",
         "11.6982",
         "9.6732",
         "0.2889",
         "95",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2",
         "0.7698",
         "0.1875",
         "0.8994294405000001",
         "235",
         "176",
         "38.6184",
         "11.5496",
         "13.3074",
         "13.0239",
         "13.0732",
         "0.157",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7",
         "0.6733",
         "0.2161904762",
         "0.8820936084000001",
         "235",
         "173",
         "36.9973",
         "10.9559",
         "13.2957",
         "12.7451",
         "11.1124",
         "0.1149",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6",
         "0.7925000000000001",
         "0.0643939394",
         "0.9252514839",
         "235",
         "161",
         "32.6263",
         "11.3975",
         "13.0251",
         "12.3198",
         "10.8339",
         "0.22690000000000002",
         "90",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper \\[1\\], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n\\[1\\] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0",
         "0.8056000000000001",
         "0.1709677419",
         "0.9168287516",
         "235",
         "158",
         "29.5424",
         "13.7997",
         "16.3372",
         "14.8897",
         "13.9196",
         "0.1695",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on \\[1\\], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n\\[1\\] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet\\[J\\]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8",
         "0.769",
         "0.0856869942",
         "0.8494880199",
         "230",
         "173",
         "47.6531",
         "10.0229",
         "12.4446",
         "12.1617",
         "10.673",
         "0.0376",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies \\[1\\]\\[2\\]\\[3\\]\\[4\\] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as \\[5\\]\\[6\\]\\[7\\], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n\\[1\\] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n\\[2\\] DINOv2: Learning Robust Visual Features without Supervision\n\n\\[3\\] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n\\[4\\] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n\\[5\\] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n\\[6\\] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n\\[7\\] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4",
         "0.7735000000000001",
         "0.0323340548",
         "0.8710070252000001",
         "230",
         "160",
         "28.8865",
         "13.6155",
         "16.716",
         "15.2184",
         "16.0264",
         "0.11520000000000001",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0",
         "0.6853",
         "0.1509199134",
         "0.845987916",
         "230",
         "160",
         "40.8168",
         "10.9426",
         "12.2591",
         "12.4048",
         "10.0477",
         "0.0917",
         "73",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch \\[e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $\\]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5",
         "0.7703",
         "0.125",
         "0.8415295482",
         "230",
         "146",
         "44.4485",
         "9.9623",
         "12.962",
         "12.2092",
         "10.5219",
         "0.2071",
         "85",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1",
         "0.808",
         "0.1030952381",
         "0.8639517426000001",
         "230",
         "139",
         "21.7635",
         "14.5932",
         "18.2728",
         "16.0526",
         "15.1145",
         "0.3007",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references \\[26\\] and \\[43\\]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3",
         "0.8097000000000001",
         "0.125577812",
         "0.9384059906000001",
         "216",
         "159",
         "37.8687",
         "11.8256",
         "14.7024",
         "13.9801",
         "12.3945",
         "0.5343",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB \\[1\\] and RIDRs \\[2\\]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in \\[3\\].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX \\[4\\] and struc2vec \\[3\\]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n\\[1\\] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels\\[J\\]. Advances in neural information processing systems, 2008, 21.\n\n\\[2\\] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy\\[C\\]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n\\[3\\] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs\\[C\\]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n\\[4\\] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity\\[C\\]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11",
         "0.7875000000000001",
         "0.1017504718",
         "0.9667627811",
         "216",
         "159",
         "35.5122",
         "11.9667",
         "15.5548",
         "14.2567",
         "13.0316",
         "0.1898",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0",
         "0.7567",
         "0.1625",
         "0.9054954052",
         "216",
         "158",
         "39.8721",
         "11.4906",
         "14.8403",
         "13.6629",
         "10.8156",
         "0.4877",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1",
         "0.7503000000000001",
         "-0.0170454545",
         "0.9454556108000001",
         "216",
         "158",
         "24.1342",
         "14.5718",
         "17.9758",
         "16.1143",
         "14.8295",
         "0.1213",
         "82",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5",
         "0.7613000000000001",
         "0.054166666700000005",
         "0.9666213393",
         "216",
         "161",
         "25.023",
         "13.7233",
         "18.3038",
         "15.5797",
         "13.6786",
         "0.7285",
         "91",
         "1",
         "0",
         "0",
         "2"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference \\[16\\] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0",
         "0.7991",
         "0.0583035701",
         "0.9081530571",
         "216",
         "153",
         "33.4658",
         "14.6366",
         "17.0915",
         "15.5328",
         "15.8075",
         "0.050100000000000006",
         "90",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, \\[4, 34, 45\\])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors \\[21\\], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  \\[13\\] and \\[24\\]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1",
         "0.778",
         "0.14054687500000002",
         "0.8547609448",
         "216",
         "148",
         "48.1605",
         "10.4415",
         "14.4641",
         "13.4159",
         "10.3417",
         "0.7608",
         "97",
         "2",
         "2",
         "0",
         "0"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1",
         "0.7458",
         "0.2506493506",
         "0.8731790781000001",
         "216",
         "144",
         "21.6953",
         "13.7338",
         "17.2493",
         "14.6837",
         "12.809",
         "0.0917",
         "98",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. \\[52\\]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $\\[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8",
         "0.7748",
         "0.0389152569",
         "0.8465107679",
         "216",
         "139",
         "46.5232",
         "10.574300000000001",
         "13.8801",
         "13.2279",
         "9.9498",
         "0.9305",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to \\[16\\] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0",
         "0.7532",
         "0.06302655680000001",
         "0.9268480539",
         "216",
         "138",
         "35.4205",
         "12.723700000000001",
         "16.3765",
         "14.9859",
         "12.7758",
         "0.31720000000000004",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9",
         "0.777",
         "0.1441088435",
         "0.9163020849",
         "216",
         "164",
         "20.9031",
         "15.1685",
         "17.6329",
         "16.1033",
         "16.3235",
         "0.1695",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10",
         "0.7563000000000001",
         "0.1606039794",
         "0.9120497704",
         "216",
         "162",
         "41.6487",
         "10.3267",
         "12.6316",
         "11.9208",
         "10.3715",
         "0.12",
         "98",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2",
         "0.8039000000000001",
         "0.0723484848",
         "0.9104201794000001",
         "216",
         "162",
         "36.7352",
         "13.4187",
         "15.654",
         "14.8367",
         "13.9859",
         "0.1507",
         "88",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0",
         "0.8072",
         "0.1367346939",
         "0.9023641944",
         "216",
         "154",
         "27.0804",
         "14.2534",
         "17.422",
         "15.9407",
         "15.3886",
         "0.1041",
         "104",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., \\[1,2,3\\]. \n\\[1\\] “Adaptive Active Learning for Image Classification”. 2013. \n\\[2\\] “Active Learning with Multi-label SVM Classification”. 2013. \n\\[3\\] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10",
         "0.7563000000000001",
         "0.0305428049",
         "0.8611335754",
         "216",
         "140",
         "40.9473",
         "10.7776",
         "14.0555",
         "12.9025",
         "11.2445",
         "0.49920000000000003",
         "91",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on \\[19\\], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past \\[46\\], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2",
         "0.7377",
         "0.0835497835",
         "0.9506004453",
         "220",
         "170",
         "34.147",
         "13.4538",
         "16.2734",
         "15.1863",
         "14.622",
         "0.2025",
         "71",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet \\[1\\], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n\\[1\\] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially \\[2\\], on the taxonomic structure lack proper citation and comparison.\n\n\\[2\\] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used \\[1\\] to extract such priors among categories.\n\n\\[1\\] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with \\[2\\] in detail?\n\n\\[2\\] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with \\[2\\] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16",
         "0.8414",
         "0.046051423300000005",
         "0.9489502907",
         "220",
         "160",
         "14.7073",
         "14.2945",
         "17.9453",
         "14.769",
         "14.6504",
         "0.6214000000000001",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n\\[1\\] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery\\[C\\]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n\\[2\\] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery\\[C\\]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n\\[3\\] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery\\[C\\]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n\\[4\\] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery\\[J\\]. arXiv preprint arXiv:2211.11727, 2022.\n\n\\[5\\] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery\\[J\\]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13",
         "0.727",
         "-0.044117647100000004",
         "0.9325020313000001",
         "220",
         "159",
         "28.9525",
         "12.6369",
         "15.7857",
         "14.0859",
         "14.4757",
         "0.1213",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3",
         "0.7317",
         "0.1063360882",
         "0.9010543823",
         "220",
         "158",
         "13.9079",
         "16.7021",
         "19.5385",
         "17.5059",
         "17.615",
         "0.1213",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0",
         "0.7436",
         "-0.0205645161",
         "0.9308603406",
         "215",
         "161",
         "38.0053",
         "11.8417",
         "13.3907",
         "13.196",
         "11.9742",
         "0.0364",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. \\[1\\].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n\\[1\\] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2",
         "0.7798",
         "0.120959596",
         "0.9181414247",
         "215",
         "161",
         "42.0814",
         "11.4702",
         "14.4848",
         "13.9306",
         "12.7929",
         "0.2025",
         "91",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4",
         "0.7577",
         "0.1165249433",
         "0.9456864595000001",
         "215",
         "159",
         "39.3595",
         "11.5787",
         "14.4812",
         "13.7657",
         "11.814",
         "0.1041",
         "110",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7",
         "0.7752",
         "0.1777777778",
         "0.9243376255",
         "215",
         "159",
         "46.1476",
         "10.3421",
         "11.7843",
         "12.1617",
         "11.2259",
         "0.06570000000000001",
         "98",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in \\[1\\]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n\\[1\\] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1",
         "0.779",
         "0.1302469136",
         "0.9419665337",
         "215",
         "158",
         "31.0458",
         "13.3759",
         "15.8751",
         "14.6258",
         "13.6881",
         "0.4867",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from \\[37\\] and \\[40\\] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of \\[37\\] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of \\[37\\] and \\[40\\].",
         "909",
         "5",
         "0",
         "0.7543000000000001",
         "0.12186849150000001",
         "0.9009177685",
         "230",
         "164",
         "50.8104",
         "11.8054",
         "14.8032",
         "13.8167",
         "12.9653",
         "0.1958",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8",
         "0.7494000000000001",
         "0.0836666667",
         "0.9435138106000001",
         "230",
         "161",
         "32.77",
         "13.1018",
         "15.9801",
         "14.7214",
         "12.6345",
         "0.5933",
         "89",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1",
         "0.7439",
         "0.2067708333",
         "0.9592400789000001",
         "230",
         "160",
         "32.6936",
         "12.9846",
         "16.1754",
         "14.8193",
         "12.0743",
         "0.8077000000000001",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in \\[1\\] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n\\[1\\] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1",
         "0.7637",
         "0.12499415",
         "0.9655532241",
         "230",
         "137",
         "26.589",
         "13.4723",
         "16.45",
         "14.7234",
         "13.0895",
         "0.1213",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper \\[27\\]). yes",
         "384",
         "1",
         "7",
         "0.7825000000000001",
         "0.1956845238",
         "0.9658693075",
         "230",
         "134",
         "33.9863",
         "12.6558",
         "15.5382",
         "14.4923",
         "13.5984",
         "0.4152",
         "89",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP \\[1\\].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n\\[1\\] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0",
         "0.795",
         "0.1399054207",
         "0.8918016553",
         "219",
         "160",
         "25.6579",
         "14.2719",
         "16.0499",
         "14.7643",
         "15.6239",
         "0.088",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning \\[1,2,3\\]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     \\[1\\] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     \\[2\\] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     \\[3\\] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3",
         "0.7529",
         "0.2095739348",
         "0.9313436151000001",
         "219",
         "158",
         "44.6358",
         "10.6951",
         "12.5033",
         "12.5085",
         "11.5333",
         "0.07200000000000001",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper \\[1\\]. \nPrevious work \\[1\\] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks \\[2\\] or perceptual adversarial attacks \\[3\\].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n\\[1\\] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n\\[2\\] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n\\[3\\] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning \\[4\\], which is a more practical setting. \n\n\\[4\\] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4",
         "0.7637",
         "0.2275595238",
         "0.8652505875000001",
         "219",
         "158",
         "36.728",
         "11.8353",
         "13.4182",
         "12.7451",
         "12.7455",
         "0.11",
         "87",
         "0",
         "2",
         "1",
         "0"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk \\[adversarial examples and poisoned samples\\] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1",
         "0.7872",
         "0.0666666667",
         "0.9156908989",
         "219",
         "157",
         "37.1925",
         "12.9906",
         "14.9234",
         "14.0682",
         "13.7299",
         "0.077",
         "81",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8720</td>\n",
       "      <td>15.9897</td>\n",
       "      <td>14.4442</td>\n",
       "      <td>13.2649</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0922</td>\n",
       "      <td>15.3049</td>\n",
       "      <td>14.1918</td>\n",
       "      <td>12.6374</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7200</td>\n",
       "      <td>10.1878</td>\n",
       "      <td>10.7063</td>\n",
       "      <td>7.5081</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3916</td>\n",
       "      <td>17.9549</td>\n",
       "      <td>16.1666</td>\n",
       "      <td>14.5827</td>\n",
       "      <td>0.5533</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.3014</td>\n",
       "      <td>14.7013</td>\n",
       "      <td>14.2653</td>\n",
       "      <td>13.4733</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0714</td>\n",
       "      <td>13.0114</td>\n",
       "      <td>12.5486</td>\n",
       "      <td>10.1760</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7042</td>\n",
       "      <td>14.5675</td>\n",
       "      <td>13.9100</td>\n",
       "      <td>11.9698</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.2691</td>\n",
       "      <td>13.9387</td>\n",
       "      <td>13.4543</td>\n",
       "      <td>11.2038</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9547</td>\n",
       "      <td>18.5308</td>\n",
       "      <td>16.4682</td>\n",
       "      <td>16.3810</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1560</td>\n",
       "      <td>17.2540</td>\n",
       "      <td>15.6161</td>\n",
       "      <td>13.6344</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1688368213177           1702411303415              6  ...   \n",
       "1      1688505633161           1702411303319              6  ...   \n",
       "2      1688552936677           1702411303221              6  ...   \n",
       "3      1688657604892           1702411303144              6  ...   \n",
       "4      1688617232745           1702411520565              6  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "15170  1688676041356           1702411081106              6  ...   \n",
       "15171  1688449656890           1702411268900              7  ...   \n",
       "15172  1688485585833           1702411268818              5  ...   \n",
       "15173  1688665406904           1702411268706              4  ...   \n",
       "15174  1688755793651           1702411268608              4  ...   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "0                   12.8720      15.9897     14.4442   \n",
       "1                   13.0922      15.3049     14.1918   \n",
       "2                    7.7200      10.1878     10.7063   \n",
       "3                   14.3916      17.9549     16.1666   \n",
       "4                   13.3014      14.7013     14.2653   \n",
       "...                     ...          ...         ...   \n",
       "15170               10.0714      13.0114     12.5486   \n",
       "15171               11.7042      14.5675     13.9100   \n",
       "15172               11.2691      13.9387     13.4543   \n",
       "15173               14.9547      18.5308     16.4682   \n",
       "15174               13.1560      17.2540     15.6161   \n",
       "\n",
       "       automated_readability_index politeness_score  hedge_C  hedge_D  \\\n",
       "0                          13.2649           0.0948       86        0   \n",
       "1                          12.6374           0.0690       94        0   \n",
       "2                           7.5081           0.1601       73        0   \n",
       "3                          14.5827           0.5533       90        0   \n",
       "4                          13.4733           0.0671       97        0   \n",
       "...                            ...              ...      ...      ...   \n",
       "15170                      10.1760           0.0667       94        0   \n",
       "15171                      11.9698           0.1450       93        0   \n",
       "15172                      11.2038           0.1508      107        0   \n",
       "15173                      16.3810           0.1249      107        0   \n",
       "15174                      13.6344           0.1932       98        0   \n",
       "\n",
       "       hedge_E  hedge_I  hedge_N  \n",
       "0            0        0        0  \n",
       "1            0        0        0  \n",
       "2            0        0        0  \n",
       "3            0        0        0  \n",
       "4            1        0        0  \n",
       "...        ...      ...      ...  \n",
       "15170        0        0        0  \n",
       "15171        1        1        0  \n",
       "15172        0        0        0  \n",
       "15173        0        0        0  \n",
       "15174        0        0        0  \n",
       "\n",
       "[15175 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "input_file = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v8.json'\n",
    "\n",
    "df = pd.read_json(input_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e33b87da-3c49-4347-b5d5-e0b51791fb8a",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8",
         "0.7494000000000001",
         "0.0416666667",
         "0.9411299229000001",
         "215",
         "162",
         "33.6037",
         "12.872",
         "15.9897",
         "14.4442",
         "13.2649",
         "0.09480000000000001",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1",
         "0.7788",
         "0.1071362434",
         "0.947173357",
         "215",
         "160",
         "32.9398",
         "13.0922",
         "15.3049",
         "14.1918",
         "12.6374",
         "0.069",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6",
         "0.7975",
         "0.0933876124",
         "0.8911411762",
         "215",
         "160",
         "60.5595",
         "7.72",
         "10.1878",
         "10.7063",
         "7.5081",
         "0.16010000000000002",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1",
         "0.8136",
         "0.1130384199",
         "0.8543175459000001",
         "215",
         "159",
         "24.6842",
         "14.3916",
         "17.9549",
         "16.1666",
         "14.582699999999999",
         "0.5533",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5",
         "0.7613000000000001",
         "0.054166666700000005",
         "0.9666213393",
         "216",
         "161",
         "25.023",
         "13.7233",
         "18.3038",
         "15.5797",
         "13.6786",
         "0.7285",
         "91",
         "1",
         "0",
         "0",
         "2"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference \\[16\\] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0",
         "0.7991",
         "0.0583035701",
         "0.9081530571",
         "216",
         "153",
         "33.4658",
         "14.6366",
         "17.0915",
         "15.5328",
         "15.8075",
         "0.050100000000000006",
         "90",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, \\[4, 34, 45\\])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors \\[21\\], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  \\[13\\] and \\[24\\]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1",
         "0.778",
         "0.14054687500000002",
         "0.8547609448",
         "216",
         "148",
         "48.1605",
         "10.4415",
         "14.4641",
         "13.4159",
         "10.3417",
         "0.7608",
         "97",
         "2",
         "2",
         "0",
         "0"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1",
         "0.7458",
         "0.2506493506",
         "0.8731790781000001",
         "216",
         "144",
         "21.6953",
         "13.7338",
         "17.2493",
         "14.6837",
         "12.809",
         "0.0917",
         "98",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. \\[52\\]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $\\[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8",
         "0.7748",
         "0.0389152569",
         "0.8465107679",
         "216",
         "139",
         "46.5232",
         "10.574300000000001",
         "13.8801",
         "13.2279",
         "9.9498",
         "0.9305",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to \\[16\\] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0",
         "0.7532",
         "0.06302655680000001",
         "0.9268480539",
         "216",
         "138",
         "35.4205",
         "12.723700000000001",
         "16.3765",
         "14.9859",
         "12.7758",
         "0.31720000000000004",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from \\[37\\] and \\[40\\] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of \\[37\\] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of \\[37\\] and \\[40\\].",
         "909",
         "5",
         "0",
         "0.7543000000000001",
         "0.12186849150000001",
         "0.9009177685",
         "230",
         "164",
         "50.8104",
         "11.8054",
         "14.8032",
         "13.8167",
         "12.9653",
         "0.1958",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8",
         "0.7494000000000001",
         "0.0836666667",
         "0.9435138106000001",
         "230",
         "161",
         "32.77",
         "13.1018",
         "15.9801",
         "14.7214",
         "12.6345",
         "0.5933",
         "89",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1",
         "0.7439",
         "0.2067708333",
         "0.9592400789000001",
         "230",
         "160",
         "32.6936",
         "12.9846",
         "16.1754",
         "14.8193",
         "12.0743",
         "0.8077000000000001",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in \\[1\\] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n\\[1\\] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1",
         "0.7637",
         "0.12499415",
         "0.9655532241",
         "230",
         "137",
         "26.589",
         "13.4723",
         "16.45",
         "14.7234",
         "13.0895",
         "0.1213",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper \\[27\\]). yes",
         "384",
         "1",
         "7",
         "0.7825000000000001",
         "0.1956845238",
         "0.9658693075",
         "230",
         "134",
         "33.9863",
         "12.6558",
         "15.5382",
         "14.4923",
         "13.5984",
         "0.4152",
         "89",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "88",
         "zfHCKDzzC8",
         "1026",
         "1682687320755",
         "['~Çağlar_Hızlı1', '~S._T._John1', '~Anne_Tuulikki_Juuti1', '~Tuure_Tapani_Saarinen1', '~Kirsi_Hannele_Pietiläinen1', '~Pekka_Marttinen1']",
         "Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions",
         "Deciding on an appropriate intervention requires a causal model of a treatment, the outcome, and potential mediators. Causal mediation analysis lets us distinguish between direct and indirect effects of the intervention, but has mostly been studied in a static setting. In healthcare, data come in the form of complex, irregularly sampled time-series, with dynamic interdependencies between a treatment, outcomes, and mediators across time. Existing approaches to dynamic causal mediation analysis are limited to regular measurement intervals, simple parametric models, and disregard long-range mediator--outcome interactions. To address these limitations, we propose a non-parametric mediator--outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. With this model, we estimate the direct and indirect effects of an external intervention on the outcome, showing how each of these affects the whole future trajectory. We demonstrate on semi-synthetic data that our method can accurately estimate direct and indirect effects. On real-world healthcare data, our model infers clinically  meaningful direct and indirect effect trajectories for blood glucose after a surgery.",
         "Reviewer_5ke6",
         "1688648659208",
         "1702410766548",
         "7",
         "4",
         "3",
         "3",
         "3",
         "This paper studies how to estimate the direct and indirect effctes of healthcare interventions. The general idea of this paper is to model the mediation process and outcome process jointly. More specifically, it considers the mediation process as a temporal point process conditioned on the past mediation, outcome and treatment data. It allows two causal paths: direct path models the direct effect of treatment and indirect path models the path treatment->mediation->outcome. The authors prove that under their three assumptions, the two effects can be represented by two terms in their non-paraametric temporal point process model. Experimental results shows the advantage of their proposed model. (1) The proposed model studies an interesting problem: how to distinguish indirect and direct effect, which is important in healthcare\n\n(2) The overall design of their causal model are reasonable. Althought their assumptions are not easy to verify on the data, they have tried their best to give convincing analysis to the data.\n\n(3) The motivation is clear and convincing. (1) Did you consider that in real world, the treatment may be correlated with the outcome, leading to bias in the model? Did you try to reduce the issue with IPTW or other method to debias?\n\n(2) Some recent related works about handling treatment effect and causal inference with non-parametric temporal point process model are missing. For example, \\[1\\] studies the treatment effect in healcare, too. \\[2\\] considers how to debias the neural temporal point process in the context of social media analysis. \\[3\\] studies how to sample the counterfactual sequences from temporal point process.\n\n\\[1\\] Gao, Tian, et al. Causal Inference for Event Pairs in Multivariate Point Processes. NeurIPS 2021\n\n\\[2\\] Zhang, Yizhou, et al. Counterfactual Neural Temporal Point Process for Estimating Causal Influence of Misinformation on Social Media. NeurIPS 2022.\n\n\\[3\\] Noorbakhsh, Kimia , and M. G. Rodriguez . Counterfactual Temporal Point Processes. NeurIPS 2022. Did you consider that in real world, the treatment may be correlated with the outcome, leading to bias in the model? \n\nDid you try to reduce the issue with IPTW or other method to debias? They have discussed.",
         "349",
         "6",
         "5",
         "0.7557",
         "0.1461538462",
         "0.8693915606",
         "228",
         "159",
         "47.3402",
         "10.2482",
         "12.3539",
         "12.2367",
         "11.0496",
         "0.1585",
         "99",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "89",
         "zfHCKDzzC8",
         "1026",
         "1682687320755",
         "['~Çağlar_Hızlı1', '~S._T._John1', '~Anne_Tuulikki_Juuti1', '~Tuure_Tapani_Saarinen1', '~Kirsi_Hannele_Pietiläinen1', '~Pekka_Marttinen1']",
         "Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions",
         "Deciding on an appropriate intervention requires a causal model of a treatment, the outcome, and potential mediators. Causal mediation analysis lets us distinguish between direct and indirect effects of the intervention, but has mostly been studied in a static setting. In healthcare, data come in the form of complex, irregularly sampled time-series, with dynamic interdependencies between a treatment, outcomes, and mediators across time. Existing approaches to dynamic causal mediation analysis are limited to regular measurement intervals, simple parametric models, and disregard long-range mediator--outcome interactions. To address these limitations, we propose a non-parametric mediator--outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. With this model, we estimate the direct and indirect effects of an external intervention on the outcome, showing how each of these affects the whole future trajectory. We demonstrate on semi-synthetic data that our method can accurately estimate direct and indirect effects. On real-world healthcare data, our model infers clinically  meaningful direct and indirect effect trajectories for blood glucose after a surgery.",
         "Reviewer_NnCo",
         "1688700561266",
         "1702410766318",
         "5",
         "4",
         "3",
         "4",
         "3",
         "The paper aims to estimate the direct and indirect treatment effects of healthcare interventions. The authors model the mediator as a point process and propose a non-parametric mediator–outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. The authors conduct experiments on a real-world RCT dataset and a semi-synthetic dataset. The experiments on the synthetic dataset show that the proposed model outperforms the baselines on the treatment effect estimation tasks. - The authors propose a new approach to model the direct and indirect effects of healthcare interventions.\n- The authors conduct experiments on both real-world and semi-synthetic datasets. The results demonstrate that the proposed model outperforms the baselines.\n- The implementation code is available.\n - Treatment A, as the confounder, affects both mediator M and outcome Y. M affects Y. \nThe confounding bias would make the estimation E\\[Y|A,M\\] inaccurate. Figure 5 shows the difference of diet density pre- and post-surgery, which demonstrates the existence of confounding bias. Without consideration of the confounders, the direct and indirect treatment effect estimation could be inaccurate.\n- The authors claim that (A1, A2, A3) might not hold in observational studies and they are not statistically testable. I have the concern that if the assumptions do not hold, can the proposed model be applied to real-world applications? How to evaluate the potential risk of the model.\n- A1，A2，A3 are very strong assumptions. In real-world settings, the no-unobserved confounder assumption may not hold, so it is necessary to conduct a sensitivity analysis of how sensitive or robust the proposed models are to the unobserved confounders. \n- Bariatric surgery could cause weight loss. Another mediator weight would significantly change after the surgery.\n- Some details are missing.  The authors just use diet and surgery to predict blood glucose. Is any detailed information about the diet, like nutrients including sugar, and starch? Are patients’ demographics (weights, age, height) used in the experiments? \n- It would be better if the authors display the factual prediction performance, like MSE for glucose prediction.\n- It is unclear what the variables m and o in Eq. (9) mean.\n See above. NA",
         "358",
         "0",
         "4",
         "0.7356",
         "0.15081313130000001",
         "0.9199216366",
         "228",
         "158",
         "43.4979",
         "10.5174",
         "13.5148",
         "12.7015",
         "11.1015",
         "0.12490000000000001",
         "98",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "90",
         "zfHCKDzzC8",
         "1026",
         "1682687320755",
         "['~Çağlar_Hızlı1', '~S._T._John1', '~Anne_Tuulikki_Juuti1', '~Tuure_Tapani_Saarinen1', '~Kirsi_Hannele_Pietiläinen1', '~Pekka_Marttinen1']",
         "Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions",
         "Deciding on an appropriate intervention requires a causal model of a treatment, the outcome, and potential mediators. Causal mediation analysis lets us distinguish between direct and indirect effects of the intervention, but has mostly been studied in a static setting. In healthcare, data come in the form of complex, irregularly sampled time-series, with dynamic interdependencies between a treatment, outcomes, and mediators across time. Existing approaches to dynamic causal mediation analysis are limited to regular measurement intervals, simple parametric models, and disregard long-range mediator--outcome interactions. To address these limitations, we propose a non-parametric mediator--outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. With this model, we estimate the direct and indirect effects of an external intervention on the outcome, showing how each of these affects the whole future trajectory. We demonstrate on semi-synthetic data that our method can accurately estimate direct and indirect effects. On real-world healthcare data, our model infers clinically  meaningful direct and indirect effect trajectories for blood glucose after a surgery.",
         "Reviewer_jr2N",
         "1688832247230",
         "1702410766216",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper defines direct and indirect effects in complex healthcare time-series as dynamic stochastic processes and theoretically provides causal assumptions for identifiability. This model allows for an external intervention influencing both mediator and outcome sequences simultaneously and captures time-delayed interactions among them. 1.\tThe authors proficiently present the estimated direct and indirect effects as longitudinal counterfactual trajectories, along with the requisite theoretical causal assumptions for their identification.\n2.\tThe method proposed is neat and articulated with good clarity. 1.\tThe method's scalability to larger datasets poses a concern. There exists many methods specifically designed for high-dimensional mediation analysis in time series \\[1\\]\\[2\\]\\[3\\]. It would be enlightening to observe how the proposed method compares to these in handling complex datasets.\n2.\tTo my understanding, Figure 1a may not accurately depict Zeng et al. 2021 \\[4\\]. It seems the original work allows for past mediators to have an influence on future outcomes.\n\nReferences\n\n\\[1\\] Chén, Oliver Y., et al. \"High-dimensional multivariate mediation with application to neuroimaging data.\" Biostatistics 19.2 (2018): 121-136.\n\n\\[2\\] Zhang, Haixiang, et al. \"Mediation analysis for survival data with high-dimensional mediators.\" Bioinformatics 37.21 (2021): 3815-3821.\n\n\\[3\\] Luo, Chengwen, et al. \"High-dimensional mediation analysis in survival models.\" PLoS computational biology 16.4 (2020): e1007768.\n\n\\[4\\] Zeng, Shuxi, et al. \"Causal mediation analysis for sparse and irregular longitudinal data.\" The Annals of Applied Statistics15.2 (2021): 747-767. 1.\tWhat advantage does the utilization of a marked point process offer in modeling mediators compared to the approach in \\[1\\], where the observed mediator is considered as drawn from a smooth underlying process?\n2.\tDoes the proposed method allow for modeling a high-dimensional observed mediator?\n3.\tIn line 119-120, the mediator process M considers the number of occurrences of the mediating event up until time $\\tau$ and the value of the mediator at time $\\tau$. I'm curious if the occurrence count alone is sufficient to model the process, or if the past values of the mediator should also be considered?\n4.\tRegarding line 146, how is the continuation of the outcome after the intervention at $t_a$ represented? Should it be an equal average over all timepoints post $t_a$, or should it be a weighted average giving more importance to timepoints closer to $t_a$?\n5.\tFor quick clarification, in line 159, $H_{\\leq \\tau}$ refers to the history up until time $\\tau$. Does this history include both mediator and outcome?\n\nReference\n\n\\[1\\] Zeng, Shuxi, et al. \"Causal mediation analysis for sparse and irregular longitudinal data.\" The Annals of Applied Statistics15.2 (2021): 747-767. Yes, the authors addressed their limitation, which involve untestable causal assumptions and scalability of the method to larger data sets.",
         "435",
         "15",
         "18",
         "0.7763",
         "0.0632716049",
         "0.9089412689",
         "228",
         "157",
         "32.1773",
         "11.7731",
         "14.3046",
         "12.8855",
         "12.0921",
         "0.1507",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "91",
         "zfHCKDzzC8",
         "1026",
         "1682687320755",
         "['~Çağlar_Hızlı1', '~S._T._John1', '~Anne_Tuulikki_Juuti1', '~Tuure_Tapani_Saarinen1', '~Kirsi_Hannele_Pietiläinen1', '~Pekka_Marttinen1']",
         "Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions",
         "Deciding on an appropriate intervention requires a causal model of a treatment, the outcome, and potential mediators. Causal mediation analysis lets us distinguish between direct and indirect effects of the intervention, but has mostly been studied in a static setting. In healthcare, data come in the form of complex, irregularly sampled time-series, with dynamic interdependencies between a treatment, outcomes, and mediators across time. Existing approaches to dynamic causal mediation analysis are limited to regular measurement intervals, simple parametric models, and disregard long-range mediator--outcome interactions. To address these limitations, we propose a non-parametric mediator--outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. With this model, we estimate the direct and indirect effects of an external intervention on the outcome, showing how each of these affects the whole future trajectory. We demonstrate on semi-synthetic data that our method can accurately estimate direct and indirect effects. On real-world healthcare data, our model infers clinically  meaningful direct and indirect effect trajectories for blood glucose after a surgery.",
         "Reviewer_bzqS",
         "1690408442130",
         "1702410766151",
         "7",
         "3",
         "4",
         "4",
         "2",
         "The paper's outstanding qualities lie in its well-articulated presentation and its precise experimental design. It amalgamates the earlier research findings of \\[Zeng et al., 2021\\] and \\[Hızlı et al., 2022\\] with the innovative notions put forth by \\[Robins et al., 2022\\] on indirect effects. The authors tackle pragmatic issues, such as the effects of surgery on a patient's blood sugar levels in relation to their diet, by formulating pertinent questions. For instance, they question whether optimal post-surgery mediation can entirely regulate blood sugar levels, or if there exist uncontrollable surgery-induced effects on blood sugar levels that resist management through mediation and diet adjustments.\n\nIn their methodological approach, the authors utilize non-parametric models of the temporal data-generating process. They employ a Marked Point Process (MPP) akin to \\[Hızlı et al., 2022\\] for meal intake (the mediating factor) and a non-parametric Gaussian Process (GP) for the outcome. The former is modeled as a combination of a counting process (number of meals) and a dosage process (carb intake per meal) using a non-parametric Poisson Process and the latter as a Gaussian process. The mediator model is trained to predict the mediator based on the intervention and the outcome model is trained with both the mediator and intervention given as input. This approach is put to the test in a series of synthetic experiments, validating its predictive strength against baseline models like Zeng et al., 2021. They further apply it in a real-world setting, successfully reproducing biological insights and potentially addressing the question of the degree to which surgery impacts diet changes.\n\nWhile at first glance, this paper might seem to bear similarities to \\[Hızlı et al., 2022\\], it stands out through its adept combination of the best methods for examining direct and indirect cause-and-effect relationships in a temporal setting. The paper, with its organized code and clear writing style, has the potential to become a valuable asset. However, I'm leaning towards accepting this paper on the condition that certain concerns regarding its originality and novelty are addressed, which I will detail in the following. 1. The paper is commendable for its realistic problem setup, which is articulated in Section 5.1 dealing with corner cases where the assumptions might falter: the existence of hidden confoundings and the violation of assumptions A.1 to A.3. Such validation is crucial in causal studies to confirm assumptions and identify any unnoticed confoundings that may influence our conclusions. Furthermore, the experiments and predictions are consistent with the clinically significant direct and indirect impacts of bariatric surgery on blood glucose levels.\n2. The approach to modeling the temporal dynamic is robust, anchoring its foundation on recent, proven work that adds to its credibility.\n3. The paper's eloquent presentation is worthy of note. The reading experience is enhanced by effective use of color-coding to differentiate between mediator and direct interventions. A minor suggestion would be to consider adaptations for grayscale printed versions of the paper. For instance, the caption of Figure (2) includes light and dark blue color coding, which could be made more distinguishable by slightly altering the arrow patterns. 1. The theoretical advancement of the study appears relatively marginal. While the exploration of direct vs. indirect causal effects in a temporal setting is engaging and the experiments provide valuable insights, I have some reservations about two of the claimed main contributions:\n* Dynamic causal mediation with a point process mediator: \\[Hızlı et al., 2022\\] have previously introduced point process mediator modeling. The novelty here is questionable, given that in the prior work, the treatment was the mediator itself.\n* A mediator-outcome model with an external intervention: The distinctiveness here is the training of two models: pre-intervention and post-intervention. However, the applied intervention is overly simplistic, offering limited theoretical innovation or insight. I have proposed, in the \"Questions\" section, the inclusion of the theory behind more complex interventions and experimentation on the simpler case. Yet, as it stands, this contribution mainly replicates the approach from \\[Hızlı et al., 2022\\], but uses two models to account for the intervention.\n2. Table 1 presents results suggesting that the direct causal impact of surgery outweighs its indirect effects. Although the insights from 5.1.3 and 5.1.2 align with existing studies, there seems to be no supportive evidence for this hypothesis. Perhaps incorporating relevant literature explanations into the discussion would be beneficial. While the coherence between findings in 5.1.2 and 5.1.3 lend some validation to the model, it would still be advantageous to have literature support for 5.1.4. 1. Even though the paper presents a succinct and coherent narrative, it's hard to ignore that the methodology could easily extend to cases where the intervention itself is also a point process. For instance, one might consider a patient's long-term history and periodic clinical treatments. In such scenarios, $NIE$ and $NDE$ could be defined at different time points. It might be beneficial to include the theory behind this in the appendix section. The theoretical framework in sections 2 and 3 would work if one defines $N_A: \\[0, T\\] \\to \\mathbb{N}$, and instead of developing two distinct models, a more comprehensive model could be formulated that includes the history of interventions. This approach could also minimize the chance of future incremental papers being published.\n2. What is the model's predictive power under model misspecification? Currently, the paper only presents results assessing predictive power in semi-synthetic scenarios where the model is appropriately specified. However, it would be beneficial to conduct experiments in scenarios reflective of real-world settings where model misspecification is common. Although the paper does incorporate a real-world setting, it is used merely for extracting qualitative observations. A comparative analysis of prediction power, similar to the semi-synthetic scenario but including model misspecification, is missing. 1. Like any causality-oriented study, this paper relies on certain assumptions for its model to function effectively. However, the authors have acknowledged this constraint adequately. They have also indicated possible real-world scenarios with hidden confounders where these assumptions might be compromised. This demonstrates a good understanding of the model's limitations.\n2. A further limitation of the method, as previously hinted, is its inability to handle more complex interventions. Currently, the model considers total effect, direct, and indirect effect only in relation to a unitary, binary intervention point process. It could potentially be enhanced by extending its capacity to accommodate non-binary scenarios (for different intervention styles, such as dosage treatments) or non-unitary processes (considering the entire electronic health record of a patient over a long period), which could provide a more comprehensive understanding.",
         "1078",
         "0",
         "9",
         "0.8145",
         "0.0773448773",
         "0.9028618336",
         "228",
         "138",
         "29.7694",
         "13.2838",
         "15.9072",
         "14.6213",
         "14.1134",
         "0.1932",
         "76",
         "0",
         "1",
         "1",
         "0"
        ],
        [
         "92",
         "zfCNwRQ569",
         "12252",
         "1683809116290",
         "['~Ruoyu_Li4', '~Qing_Li15', 'eli.yuzhang@gmail.com', '~Dan_Zhao2', '~Yong_Jiang3', '~Yong_Yang8']",
         "Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction",
         "Many security applications require unsupervised anomaly detection, as malicious data are extremely rare and often only unlabeled normal data are available for training (i.e., zero-positive). However, security operators are concerned about the high stakes of trusting black-box models due to their lack of interpretability. In this paper, we propose a post-hoc method to globally explain a black-box unsupervised anomaly detection model via rule extraction.\nFirst, we propose the concept of distribution decomposition rules that decompose the complex distribution of normal data into multiple compositional distributions. To find such rules, we design an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. By merging these two types of rules into a rule set, we can present the inferential process of the unsupervised black-box model in a human-understandable way, and build a surrogate rule-based model for online deployment at the same time. \nWe conduct comprehensive experiments on the explanation of four distinct unsupervised anomaly detection models on various real-world datasets. The evaluation shows that our method outperforms existing methods in terms of diverse metrics including fidelity, correctness and robustness.",
         "Reviewer_jw73",
         "1686820238350",
         "1702411372121",
         "5",
         "2",
         "2",
         "2",
         "3",
         "This paper proposes a rule-set extraction method for a black-box anomaly detection model that is trained with only normal or unlabeled data.\nThere are many methods to interpret the learned model, but, this paper claims that there are few methods designed for anomaly detection.\nThe proposed method first extracts rules that decompose the complex distribution of normal data into multiple simple distributions and then, in each simple distribution, the decision rules that approximate the decision boundary of the pre-trained model are estimated. \nBy merging such rules, the proposed method can obtain a surrogate rule-based model of the trained anomaly detector.\n - The problem tackled in this paper is important. There is a demand for interpretable anomaly detection in many industries, including security.\n- The proposed method is model-agnostic and thus can be applied in many applications.\n- The proposed method works well in the experiments. - There is no discussion or comparison regarding computational costs.\n- There are several unclear points about the methodology. This may be because I am a non-expert in this area (rule-based methods). I would like to wait for the author's additional explanation in the rebuttal. - This method is proposed as security-specific, but if I understand correctly, there is no security-specific part of the model. Is it better to present it as a more generic method since there are other areas of industry where rule sets are required?\n- The proposed method is mostly feature-by-feature processing, so can it be used for high dimensional data as well? The datasets with small feature sizes (30) were used in the experiments. Some discussion of the computational cost would be required.\n- Does Proposition 2 claim that the probabilities of the samples belonging to the same distribution $D_k$ are similar? If so, I think that the assumption is not satisfied, e.g., if $D$ is a Gaussian mixture distribution (i.e., $D_k$ is each Gaussian component). Please let me know if I have misunderstood.\n- In Eq. (4), although $I(N_l)$ and $I(N_r)$ depend on $N_l$ and $N_r$, it is unclear how $N_l$ and $N_r$ are used for caluculating the value of $I$. I also did not understand why the output of anomaly detection could be used to partition the distribution in Eq. (4).\n- In Eq. (8), It reads as the sum of a vector and scalar. Is the second term a vector?\n\nMinors\n- In section 1, this paper mentions one reason for using global explanatory methods is that forecasts are interpretable. However, I think that this property also be achieved by local explanation methods.\n- It is better to explain the meaning of each loss of Eq. (2) in Section 2.\n- In definition 3, $\\phi_k$ is not defined. Yes.",
         "452",
         "0",
         "4",
         "0.7453000000000001",
         "0.11203125",
         "0.9049289227",
         "215",
         "180",
         "50.0481",
         "9.7967",
         "12.6805",
         "12.3635",
         "9.2944",
         "0.2674",
         "99",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "93",
         "zfCNwRQ569",
         "12252",
         "1683809116290",
         "['~Ruoyu_Li4', '~Qing_Li15', 'eli.yuzhang@gmail.com', '~Dan_Zhao2', '~Yong_Jiang3', '~Yong_Yang8']",
         "Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction",
         "Many security applications require unsupervised anomaly detection, as malicious data are extremely rare and often only unlabeled normal data are available for training (i.e., zero-positive). However, security operators are concerned about the high stakes of trusting black-box models due to their lack of interpretability. In this paper, we propose a post-hoc method to globally explain a black-box unsupervised anomaly detection model via rule extraction.\nFirst, we propose the concept of distribution decomposition rules that decompose the complex distribution of normal data into multiple compositional distributions. To find such rules, we design an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. By merging these two types of rules into a rule set, we can present the inferential process of the unsupervised black-box model in a human-understandable way, and build a surrogate rule-based model for online deployment at the same time. \nWe conduct comprehensive experiments on the explanation of four distinct unsupervised anomaly detection models on various real-world datasets. The evaluation shows that our method outperforms existing methods in terms of diverse metrics including fidelity, correctness and robustness.",
         "Reviewer_AbmJ",
         "1687359474725",
         "1702411371993",
         "5",
         "5",
         "3",
         "2",
         "3",
         "The paper deals with the problem of \"explainable\" unsupervised machine learning (ML) for anomaly detection (AD), with a focus of network intrusion detection (NID). The paper argues that while abundant effort focused on providing _supervised_ ML techniques that are explainable, this is not the case for _unsupervised_ ML methods---which are abundant in NID due to the lack of fine-grained labelled data. The paper hence seeks to rectify such shortage by proposing a novel solution that simultaneously (i) provides \"human-understandable\" explanations; and (ii) allows to derive some \"rules\" that can be used to improve the detection performance of the unlderying network intrusion detection system (NIDS). The proposed method leverages the intuition of \"slicing\" the (training) data into segments that represent a given group of (network) activities, e.g., web or database traffic; and then derive specific rules that describe these activities in an \"humanly understandable way\" and which can be used (if violated) to identify anomalies. The method is rigorously described and its effectiveness is assessed through various experiments on two well-known NID datasets, showing some advantages over existing baselines (which are mostly tailored for supervised ML). + Evaluation on two NID datasets\n+ Ablation Study\n+ Rigorous description\n+ Some design choices \"make sense\"\n+ The method is rigorously described\n+ Some ideas are correlated with proofs (in the appendix)\n+ The paper tackles an open research problem (on the surface) for which limited research is available\n+ Evaluation considering various parameter settings\n+ The results show improvement over baselines\n\n\nThe paper addresses an intriguing research problem (\"explainable unsupervised machine learning\") which has high relevance in some real-world applications of ML (i.e., network intrusion detection). The proposed method is rigorously described: some intuitions are sensible, and for others there are proofs provided which increase the overall soundness of the proposed methodology. The evaluation (which is reproducible, since the code is disclosed and the datasets are publicly available) shows improvement over prior work (most of which, however, was not designed to work in the given setting).\n\nFinally, the main novelty of this paper resides in addressing an underexplored problem. ## High Level\n\n- Unconvincing motivation\n- Excessively optimistic assumptions\n- Flawed dataset and poor setup\n- Questionable metrics \n- Unclear \"understanding\" assessment\n\nDespite some strengths, the paper suffers from various issues which prevent me from recommending inclusion in NeurIPS'23 program. Specifically, though the paper seeks to address a \"real-world problem\" (i.e., how security operators deal with ML-NIDS that are not explainable), the proposed method relies on assumptions that can hardly be met in the real world---thereby decreasing the overall significance of the findings. \n\nAnother problem pertains the soundness of the experimental procedure, which casts doubts on the validity of the results and, hence, of the conclusions drawn from the paper. \n\nFinally, from a \"novelty\" perspective, the techniques used to address the problem tackled by this paper may be (somewhat) novel, but they can be redundant in light of some well-known considerations of the NID context.\n\n## Low Level\n\nI will provide an extensive description of the abovementioned weaknesses below. I will directly quote some statements made in the paper, and I will also attempt to provide suggestions and plenty of references to support my points.\n\n\n\n\n### Unconvincing motivation\n\nAlbeit I acknowledge that the goal of providing \"explainable ML\" is relevant, I do not see a strong incentive in providing \"explainable _unsupervised_ ML methods\". This is because practitioners are well-aware that such methods are bound to be inaccurate, since they assume a notion of \"normality\". In a sense, the \"explanation\" for a raised anomaly is that a given data-point deviates from such normality; even practitioners acknowledge this as a fact \\[D\\]. This of course leads to a huge amount of false positives, which must be manually triaged _regardless of the explanations_. \n\nIn light of this, I did not find a compelling argument (provided in the paper) in favor of focusing on unsupervised ML --- or, at least, not in the context assumed by this paper. Perhaps a potential avenue is using said explanations for \"attack attribution\" \\[H\\], but this is never made explicit.\n\n### Optimistic assumptions\n\nThe method makes some strong assumptions that are too optimistic in real settings. The problem is that the main contribution (allegedly) is addressed at real-world deployments of ML.\n\n> We consider the anomaly detection tolerant of noisy data, but their proportion in training dataset is small and we do not have any ground truth labels of the training data.\n\nThis is a bold assumption which almost trivialized the entire problem of anomaly detection. If one is confident of having a (large) training set containing \"certain\" benign samples, one can use it as basis for supervised ML by enriching it with malicious samples (e.g., \\[I\\]). Unfortunately, in reality, obtaining such a \"clean\" training set requires huge manual effort \\[D\\] (and so is determining the threshold which allows for a manageable amount of alerts in operational contexts). Do note that the experimental evaluation assumes a \"perfect\" labelling of the normal samples in the training data (there is no mention of \"noisy\" data).\n\nAlso, consider the following statement\n\n> For example, a server supports multiple services such as web, email and database. The representations of these services can be disparate and located in different regions in feature space with little transition between the regions, making it infeasible to find a uniform rule set to accurately estimate the original model\n\nIn theory, this is correct. In practice, however, addressing this problem is trivial: \"web\", \"email\" and \"database\" are all services that can be easily separated by looking at the source ports of the corresponding communications (potentially with an additional filter based on the IP address). Indeed, one must remember that these methods must be setup and deployed by network administrators---who are well aware of what services are running in their organization.\n\n(note that even though here I have criticized the specific example, the consideration above can be extended to any type of potential \"multimodality\" that arises from network data)\n\nIn light of this, I fail to see any practical reason in favor of the method proposed in the paper. Perhaps the authors can provide a clear use-case in which the \"multimodality\" of the data is truly problematic to model.\n\n### Flawed dataset (and poor experimental setup)\n\nThe proposed method is evaluated on two datasets for Network Intrusion Detection (NID), one being the CIC-IDS17. Unfortunately, this dataset is flawed \\[J, K\\]. Note that \\[J\\] came out in 2021, and it has already been well-received by the NID community, so it is concerning that this paper (which has been submitted to a top-venue such as NeurIPS) performs the experiments on the \"flawed\" variant of this dataset---especially given that a \"fixed\" version exists (provided in \\[J\\]). \n\nFurthermore, note that \\[J\\] clearly stated that some features in this dataset (both the original and fixed version) are redundant for NID purposes (this is especially the case for \"flow-based\" NID \\[I, L\\]): however, this paper does not provide any detail about whether precautions have been taken to clean the feature set from \"obvious\" features (note that this also entails the ToN-IoT dataset)\n\nFinally, it is unclear whether the experiments have been repeated a sufficient amount of times to derive statistically significant conclusions (as recommended in \\[B\\]). The paper states:\n\n> The datasets are randomly split by the ratio of 6:2:2 for training, validation and testing\n\nThe \"random split\" may bias the results. \n\nIn light of this, the experimental setup may not be sound, thereby questioning the overall results. I invite the authors to look into other datasets as well (the works referenced in this review provide plenty of suggestions).\n\n\n### Questionable evaluation metrics\n\nI was unable to find a link between the metrics used in the evaluation and the overarching goal of the paper.\n\nAccording to the Introduction:\n\n> we can present the inferential process of the black-box model in a human-understandable way, and build a surrogate rule-based model for online defense at the same time.\n\nHowever, there is nothing in the evaluation that allows one to measure whether the ```inferential process of the black-box model``` is presented in a ```human-understandable way```. This is because the evaluation appears to merely focus on the sheer detection performance of the \"surrogate\" model.\n\nTo re-quote a statement in the introduction (with which I fully agree!):\n\n> security operators tend to trust human-understandable rules rather than the unintuitive outputs such as labels and numeric values from the complex and incomprehensible models.\n\nThere is little in the evaluation that makes me believe that security operators would appreciate the explanations provided by the proposed method. \n\nI also have some concerns on the way these metrics are described:\n\n> Fidelity (FD), i.e., the ratio of input samples on which the predictions of original model and surrogate model agree over the total samples, which indicates the extent to which humans can trust the explanations\n\nI disagree: at best, FD denotes how much the surrogate and original models \"agree\". This says nothing about whether a human can \"trust\" the explanation in the general sense. Indeed, the quoted statement would be correct under the assumption that the original model's explanation are \"correct\". \n\n> Robustness (RB), i.e, the persistence to withstand small perturbations of the input that do not change the prediction of the model\n\nI am confused here: what is the ```model``` whose prediction should not change? I.e., is it the \"original\" or the \"surrogate\"?\n\n### Unclear method for \"understanding\"\n\nThis issue follows the previous one. The \"human-understandable way\" to interpret the rules generated by the proposed method is assessed in Section 6.3. However, there is a lack of details in this Section, and the \"conclusions\" appear to be drawn from purely subjective statements.\n\nConsider the following:\n\n> Such results are easy to be interpreted.\n\nHow is this determined?\n\n> These explanations are in line with how security experts recognize the attack data.\n\nNo reference is provided.\n\nPlus, there is a mismatch with Table 4 and the overall assumptions made in the paper. Specifically, the paper assumes an \"unsupervised\" AD task, wherein the specific attack is not known. In light of this, how can a human derive that, e.g., (taken from Table 4):\n\n> DDoS attacks use packets of small sizes to achieve\nasymmetric resource consumption on the victim side,\nand send packets at a high rate to flood the victim\n\n? At most, a human sees some rules (e.g., ```ps_mean > 101.68, iat_mean > 0.063, dur > 12.61```) which -- when not met -- trigger some anomalies. But from here to stating that these anomalies relate to \"DDoS attacks\" there is a long way. For instance, \"violation\" of these rules can very well be related to a port-scanning activity (which can very well be a benign event, e.g., a new host which scans the network after joining it).\n\n\n### Some bold statements in the Introduction\n\nBelow is a list of statements made in the Introduction for which I have serious concerns.\n\n\n> it requires no attack/malicious data during the training (i.e., zero-positive learning), which are typically much more sparse and difficult to obtain in contrast with benign data;\n\nActually, obtaining \"certain\" benign data can be even harder than acquiring malicious data (see \\[B\\]). As a matter of fact, real-world deployments of ML entail very coarse \"labelling\" schemes \\[A\\].\n\n> it does not fit any known threats, enabling better detection on unforeseen anomalies.\n\nBut this also means that some of the raised anomalies have nothing to do with attacks---leading to \"alert fatigue\" (see \\[C,D,E\\]).\n\n> being self-explained and accurate for high-stake security applications.\n\nPlease define \"accurate for high-stake security applications\". Even non-surrogate models have a huge margin of error \\[C\\].\n\n> Accuracy Loss (CH3). \\[...\\] In this case, though these methods can provide model explanation, they cannot meet the need of online deployment which requires high detection accuracy in security applications.\n\nI disagree. The \"surrogate\" model has a single objective: provide \"global\" explanations. Therefore, even though such surrogate model may have worse \"accuracy\", it is the \"larger\" model that is meant to be deployed, while the \"surrogate\" is only used for explanation tasks.\n\n> We observe that an important reason why simple surrogate models are ineffective is that they cannot learn well about the complex data distribution in high-dimensional space.\n\nOn what grounds is this \"observation\" made? Is it just an educated guess, does it derive from original experiments, or is it drawn from prior research?\n\n\n> The extracted rules outperform prior work in terms of diverse metrics including fidelity, robustness, true positive rate and true negative rate\n\nThis contradicts what was written at the beginning of the introduction: ```security operators tend to trust human-understandable rules rather than the unintuitive outputs such as labels and numeric values from the complex and incomprehensible models.```. In what way are the metrics mentioned above different from \"numeric values from the complex and incomprehensible models\"?\n\n> which meets the demand of improving human trust in black-box models and maintaining high detection accuracy for online deployment.\n\nThis is a self-claim: there is no evidence provided that ```fidelity, robustness, tpr, tnr``` meet the described ```demand``` (in terms of explainability).\n\n\n\n\n### Some additional issues:\n\nThe following is a list of miscellaneous issues I found in this submission; note that these issues are not necessarily \"minor\".\n\n* Some relevant works have not been considered. The extensive study carried out in \\[F\\] reveals, e.g., \\[G\\] -- which specifically focuses on providing \"explainable unsupervised models\".\n* ```furthur``` typo\n* I found the following statement to be misleading (and also unnecessary): ```we refer to adversarial attacks \\[44\\] and propose a method to approximate the optimal direction to explore the decision boundary```\n* ```Further, most of their true positive rates cannot meet the requirement of using their rules for online defense, as the sheer amount of attack data they miss can cause huge damages.``` please provide facts instead of writing vague statements such as \"can cause huge damages\". Even a single false negative can lead to \"huge damages\" \\[D\\].\n* I did not find any measure of the \"runtime\" used to train/test the proposed method. \n* Did the evaluation _really_ take place on a server having an RTX3090 with 8GB of VRAM? (given that the RTX3090 has 24GB of VRAM?)\n* Did the evaluation _really_ take place on a server having an Intel Xeon with only 8GB of RAM?\n* To my understanding, the method assumes that the data-points represent \"network flows\" (such is the data contained in the considered datasets). However, there is a huge variability in the ways such flows can be generated (see \\[I,M\\]). What would happen if the netflow generator is different? \n\n#### EXTERNAL REFERENCES\n\n\\[A\\]: Van Ede, Thijs, et al. \"Deepcase: Semi-supervised contextual analysis of security events.\" 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 2022.\n\n\\[B\\]: Apruzzese, Giovanni, Pavel Laskov, and Aliya Tastemirova. \"SoK: The impact of unlabelled data in cyberthreat detection.\" 2022 IEEE 7th European Symposium on Security and Privacy (EuroS&P). IEEE, 2022.\n\n\\[C\\]: Alahmadi, Bushra A., Louise Axon, and Ivan Martinovic. \"99% False Positives: A Qualitative Study of {SOC} Analysts' Perspectives on Security Alarms.\" 31st USENIX Security Symposium (USENIX Security 22). 2022.\n\n\\[D\\]: Apruzzese, Giovanni, et al. \"The role of machine learning in cybersecurity.\" Digital Threats: Research and Practice 4.1 (2023): 1-38.\n\n\\[E\\]: Hassan, Wajih Ul, et al. \"Nodoze: Combatting threat alert fatigue with automated provenance triage.\" network and distributed systems security symposium. 2019.\n\n\\[F\\]: Nadeem, Azqa, et al. \"Sok: Explainable machine learning for computer security applications.\" arXiv preprint arXiv:2208.10605 (2022) \\[to appear in EuroS&P'23\\]\n\n\\[G\\]: Wickramasinghe, Chathurika S., et al. \"Explainable unsupervised machine learning for cyber-physical systems.\" IEEE Access 9 (2021): 131824-131843.\n\n\\[H\\]: Nisioti, Antonia, et al. \"From intrusion detection to attacker attribution: A comprehensive survey of unsupervised methods.\" IEEE Communications Surveys & Tutorials 20.4 (2018): 3369-3388.\n\n\\[I\\]: Apruzzese, Giovanni, Luca Pajola, and Mauro Conti. \"The cross-evaluation of machine learning-based network intrusion detection systems.\" IEEE Transactions on Network and Service Management (2022).\n\n\\[J\\]: Liu, Lisa, et al. \"Error Prevalence in NIDS datasets: A Case Study on CIC-IDS-2017 and CSE-CIC-IDS-2018.\" 2022 IEEE Conference on Communications and Network Security (CNS). IEEE, 2022.\n\n\\[K\\]: Engelen, Gints, Vera Rimmer, and Wouter Joosen. \"Troubleshooting an intrusion detection dataset: the CICIDS2017 case study.\" 2021 IEEE Security and Privacy Workshops (SPW). IEEE, 2021.\n\n\\[L\\]: Arp, Daniel, et al. \"Dos and don'ts of machine learning in computer security.\" 31st USENIX Security Symposium (USENIX Security 22). 2022.\n\n\\[M\\]: Vormayr, Gernot, Joachim Fabini, and Tanja Zseby. \"Why are my flows different? a tutorial on flow exporters.\" IEEE Communications Surveys & Tutorials 22.3 (2020): 2064-2103. I thank the authors for submitting their paper to NeurIPS'23. Despite my stark criticism, I liked reading it. This is why I endorse the authors in answering the following questions to the best of their abilities: if provided with compelling evidence, I may be willing to raise my score.\n\n* Q1) Given that CIC-IDS17 is flaeed, how much time would it be necessary to re-do the experiments?\n* Q2) What is the runtime required to train/test the proposed method, and how does it compare to existing methods?\n* Q3) Are the details of the experimental platform correct?\n* Q4) What features have been used to train the models?\n* Q5) How was Table 4 derived?\n* Q6) Have the experiments been carried out multiple times to accout for bias?\n* Q7) Can the authors provide convincing evidence of the \"necessity\" of the proposed method _in practice_?\n* Q8) How is the \"robustness\" measured?\n* Q9) How long would it take to assess the efficacy of the proposed method under varying percentages of \"noisy\" data?\n* Q10) Does the method _require_ netflow data to work? And, if so, how would the resulting performance change if the flows are generated in a different way?\n\n\nPlease refer to the main review for additional information The \"limitations\" are discussed in the supplementary material. Unfortunately, they do not mention that, e.g., the proposed method relies on overly optimistic assumptions (for real deployments), nor that the \"understanding\" is likely drawn by subjective intuitions. Also, I see no reason for mentioning that the proposed method does not work well on images, unless this data-type becomes prevalent in NID (and I do not see this happening anytime soon).\n\n==========\n\n# Update after rebuttal\n\nI have increased my score from a 3 (Reject) to a 5 (Borderline Accept); I have also increased the scores for Contribution and Soundness (from a 2 to a 3). The improvements are due to the paper now being much more truthful as to what it does, as well as by accounting for a \"non-flawed\" version of the considered datasets. Ultimately, I do not see any clear reason for \"rejection\", but I also do not feel strong reasons to accept this---aside from tackling a highly practical area of application of ML, which could serve as inspiration for future work.",
         "3139",
         "7",
         "16",
         "0.8041",
         "0.0625262186",
         "0.8592364788",
         "215",
         "174",
         "40.1482",
         "12.0133",
         "15.0442",
         "14.088",
         "12.7434",
         "0.7396",
         "79",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "94",
         "zfCNwRQ569",
         "12252",
         "1683809116290",
         "['~Ruoyu_Li4', '~Qing_Li15', 'eli.yuzhang@gmail.com', '~Dan_Zhao2', '~Yong_Jiang3', '~Yong_Yang8']",
         "Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction",
         "Many security applications require unsupervised anomaly detection, as malicious data are extremely rare and often only unlabeled normal data are available for training (i.e., zero-positive). However, security operators are concerned about the high stakes of trusting black-box models due to their lack of interpretability. In this paper, we propose a post-hoc method to globally explain a black-box unsupervised anomaly detection model via rule extraction.\nFirst, we propose the concept of distribution decomposition rules that decompose the complex distribution of normal data into multiple compositional distributions. To find such rules, we design an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. By merging these two types of rules into a rule set, we can present the inferential process of the unsupervised black-box model in a human-understandable way, and build a surrogate rule-based model for online deployment at the same time. \nWe conduct comprehensive experiments on the explanation of four distinct unsupervised anomaly detection models on various real-world datasets. The evaluation shows that our method outperforms existing methods in terms of diverse metrics including fidelity, correctness and robustness.",
         "Reviewer_eS8h",
         "1687914682220",
         "1702411371900",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The authors propose and Distribution Decomposition Rules and Boundary\nInference Rules to make black boxes more interpretable.\n\nThey use Interior Clustering Tree IC-tree to find distribution\ndecomposition rules.  The IC-tree algorithm splits the data on a\nfeature value at each node recursively.  The feature value that\nmaximizes the gain in gini index before and after the split is chosen\nat each node.  Gini index is 2p(1-), where p be is the average output\nof the anomaly detection model f(x), which is the trained neural\nnetwork model.  The path to each leaf forms a distribution\ndecomposition rule and each leaf represents a data subset that is in\nthe same distribution.\n\nThe Compositional Boundary Exploration (CBE) algorithm finds a minimal\nhypercube that encloses the normal data in each distribution (leaf\nnode).  CBE uniformly samples data points on each hyperplane as initial\nexplores (centriods), then samples from a Gaussian distributions\npoints as auxiliary explorers near the centroids within some radius.\nThe samples are used to query the model to find samples with the\nlowest probability to be normal (negative examples), these are called\ncandidate explorers.  They use Fast Gradient Sign Method to perturb\nthe explorers.  Since the loss function is not known from the model,\nthey approximate the gradient by the gradient between the model\noutputs of an initial explorer and an auxiliary explorer with respect\nto the different in the samples.  The explores are perturbed until the\nf() indicates it is normal (less than threshold phi).  The\ncorresponding feature values forms the hyperplanes for the boundaries.\n\nThey evaluate 5 existing extraction methods with 4 black-box models and\n2 datasets.  In addition to TPR and TNR, they measure Fidelity (which\ncalculates agreement between the black-box model and their extracted\nrules) and Robustness (which estimates small input perturbations do not\nchange the model's output).  Their proposed method generally\noutperforms existing techniques.  Ablation studies were performed to\naccess the contribution of each component.\n\nI have read the authors' responses and commented on them. 1.  The proposed algorthms yield interpretables rules with high\n    fidelity of the black-box models.\n\n2.  Empirical results indicate the proposed algorithms generally\n    outperform existing ones.\n\n3.  The paper is generally well written. 1.  Some ideas could be clarified, see questions below. 1.  line 220: What is the reasoning for the initial vs auxiliary explorers?    \n\n2.  line 227: What is the reasoning for \"minimal probability of being normal\"?\n     Why not choose candidates that are close to the threshold $\\varphi$ and then\n     try to get to the other side of the threshold?\n\n3.  line 227: Does each of the dimension/feature have two candidate\n    explorers so that they yield two boundary (axis-parallel\n    hyperplane) in each dimension?  How do you guarantee one boundary\n    on each side in one dimension?\n\n4.  line 239: should f() be greater than $\\varphi$ instead of less than?  I think\n     you try to go from low f() to high f() to cross $\\varphi$.\n\n5.  line 323: \"directly using hypercubes as rules\", how are these\n    hypercubes found?  Are they from the IC-tree?  A hypercube can\n    be found for instances in each leaf by finding the \"min and max\" value\n    of each feature/dimension via a fitted Gaussian.  If that is not what you did, adding\n    it as a comparison would be interesting.\n\n6.  line 325: \"Though using the K-Means can reach similar results, it\n    cannot be expressed by axis-aligned rules with high interpretability\n    and deployability as the IC-Tree can achieve.\"\n\n    Using CBE, axis-aligned rules can be found with clusters found by\n    K-means.  If I understand correctly, the IC-tree can be ignored\n    after the boundary rules are extracted by CBE. Limitations of the proposed approach seem to be discussed as\ndirections in future work.",
         "609",
         "0",
         "5",
         "0.7587",
         "0.036250000000000004",
         "0.8613215685000001",
         "215",
         "167",
         "48.1562",
         "10.6315",
         "14.4656",
         "13.545",
         "11.6104",
         "0.23140000000000002",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "95",
         "zfCNwRQ569",
         "12252",
         "1683809116290",
         "['~Ruoyu_Li4', '~Qing_Li15', 'eli.yuzhang@gmail.com', '~Dan_Zhao2', '~Yong_Jiang3', '~Yong_Yang8']",
         "Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction",
         "Many security applications require unsupervised anomaly detection, as malicious data are extremely rare and often only unlabeled normal data are available for training (i.e., zero-positive). However, security operators are concerned about the high stakes of trusting black-box models due to their lack of interpretability. In this paper, we propose a post-hoc method to globally explain a black-box unsupervised anomaly detection model via rule extraction.\nFirst, we propose the concept of distribution decomposition rules that decompose the complex distribution of normal data into multiple compositional distributions. To find such rules, we design an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. By merging these two types of rules into a rule set, we can present the inferential process of the unsupervised black-box model in a human-understandable way, and build a surrogate rule-based model for online deployment at the same time. \nWe conduct comprehensive experiments on the explanation of four distinct unsupervised anomaly detection models on various real-world datasets. The evaluation shows that our method outperforms existing methods in terms of diverse metrics including fidelity, correctness and robustness.",
         "Reviewer_mhUf",
         "1688576570640",
         "1702411371797",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The paper presents a technique to build a decision tree (DT) that uses the predictions from any unsupervised anomaly detection algorithm to split at the nodes when constructing the DT. This is named as the Interior Clustering Tree. The DT will be used to extract interpretable rules. 1. The approach is useful for explainable anomaly detection and is an important problem domain. 1. Very similar to \\[1\\]. The difference is that in \\[1\\] the density is based on KDE, whereas, in the present work the density is based on the anomaly detector. So the technical novelty is less.\n\n2. Section 5: Lack of clarity; the procedure should be presented as algorithmic steps.\n\n3. We need more than just two datasets for empirical validity. These datasets also seem 'easy' since detection accuracy is very high for all anomaly detection algorithms. With easy datasets, the rules extracted would tend to be short and nicely interpretable. On the other hand, with harder datasets, the rules might be much more complex and difficult to interpret. I am interested in the types of rules extracted for the harder datasets.\n\nReferences:\n\n\\[1\\] Sarah Itani, Fabian Lecron, Philippe Fortemps, A one-class classification decision tree based on kernel density estimation, Applied Soft Computing, Volume 91, 2020 (https://arxiv.org/abs/1805.05021) 1. What is the order of computational complexity or the execution time of the algorithm? Is the also affected by the curse of dimensionality? N/A",
         "234",
         "4",
         "5",
         "0.7749",
         "0.1206190476",
         "0.8428279757",
         "215",
         "160",
         "44.1214",
         "10.7385",
         "15.4226",
         "14.0992",
         "10.5396",
         "0.08220000000000001",
         "91",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "96",
         "zdli6OxpWd",
         "24",
         "1681869011996",
         "['~Thomas_Steinke2', '~Alexander_Knop1']",
         "Counting Distinct Elements Under Person-Level Differential Privacy",
         "We study the problem of counting the number of distinct elements in a dataset subject to the constraint of differential privacy. \nWe consider the challenging setting of person-level DP (a.k.a. user-level DP) where each person may contribute an unbounded number of items and hence the sensitivity is unbounded.\n\nOur approach is to compute a bounded-sensitivity version of this query, which reduces to solving a max-flow problem. \nThe sensitivity bound is optimized to balance the noise we must add to privatize the answer against the error of the approximation of the bounded-sensitivity query to the true number of unique elements.",
         "Reviewer_BQdm",
         "1688543412766",
         "1702410725287",
         "7",
         "4",
         "3",
         "3",
         "3",
         "Suppose a data set consists of (user, item) pairs. The paper provides an estimate of the count of the number of distinct items that satisfies user level differential privacy. This differs from existing work in two ways. Existing work 1) considers item streams with item, not user, level differential privacy and 2) is highly concerned about computation costs and uses data sketches which have bounded size. \n\nIt solves the problem by generating lower bounds with bounded sensitivity by converting the distinct count to a max flow problem. The paper introduces a novel user-level privacy formulation of the distinct count problem. The main ideas are presented well, and it is technically sound. 1. The title could better describe the key feature of the problem, providing user level privacy. Since most distinct counting papers are about approx distinct counting and streaming/distributed algorithms, I think readers have an expectation that this paper would address this given the title and it's a bit of a let down when it doesn't.\n\n2. The related work section is somewhat inaccurate in its descriptions. E.g.\n* Desfointaine et al is a universal result about any distinct counting method which is mergeable. Changing the algorithm design can't get around this. But the results only imply that you can't merge many times and preserve both privacy and accuracy, not that you can't build a private sketch.\n* Smith et al doesn’t actually analyze the Flajolet-Martin (a.k.a. PCSA) sketch but their own tweak of the LogLog sketch (by Durand and Flajolet). (Though this inaccuracy is totally understandable given their title.)\n* Dickens et al is also a universal result for any order invariant sketch. \n* Both Smith et al and Dickens et al are pan private in the streaming setting as well\n* Note neither claim to provide privacy under merges. \n\n3. There is also some related work on private multiparty computation for distinct counts. e.g. \"Privacy-Preserving Secure Cardinality and Frequency Estimation\" Kreuter et al 2020\n\n4. The empirical results for the greedy algorithm are nice, but the bound is quite bad for this application since it only gives you an estimate of the correct order of magnitude. It's also not clear what to do in large scale distributed data settings. These are fairly minor weaknesses given the paper's scope though. 1. What is the distinction between maximal and maximum bipartite matching? A quick search seems to regard these descriptions as the same problem. Does the greedy algorithm generate the maximal matching that approximates the maximum matching? \n\n2. I'd be happy to increase the rating if the weaknesses 1 & especially 2 are addressed. yes",
         "435",
         "0",
         "8",
         "0.8072",
         "0.1689139515",
         "0.8877532482",
         "237",
         "160",
         "48.1302",
         "10.4934",
         "12.7891",
         "12.2616",
         "10.66",
         "0.0363",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "97",
         "zdli6OxpWd",
         "24",
         "1681869011996",
         "['~Thomas_Steinke2', '~Alexander_Knop1']",
         "Counting Distinct Elements Under Person-Level Differential Privacy",
         "We study the problem of counting the number of distinct elements in a dataset subject to the constraint of differential privacy. \nWe consider the challenging setting of person-level DP (a.k.a. user-level DP) where each person may contribute an unbounded number of items and hence the sensitivity is unbounded.\n\nOur approach is to compute a bounded-sensitivity version of this query, which reduces to solving a max-flow problem. \nThe sensitivity bound is optimized to balance the noise we must add to privatize the answer against the error of the approximation of the bounded-sensitivity query to the true number of unique elements.",
         "Reviewer_FDcy",
         "1688578520869",
         "1702410725195",
         "6",
         "4",
         "4",
         "3",
         "3",
         "The authors study the fundamental problem of counting the number of distinct elements in a dataset\nin a user-level DP setting, where a user can contribute an unbounded number of items. The main\ncontribution of the paper is an approach to obtain lower bounds through a bounded sensitivity\ncount and a bias-variance perspective. The authors give interesting algorithms to compute\nit quite efficiently, and show a linear time version which trades off efficiency with accuracy.\nThe algorithms are evaluated empirically and show good performance. \nThe problem is very natural and well motivated. The approach considered in the paper, in terms of\nbounded sensitivity, seems quite natural, and is connected to a big literature on Lipschitz extension.\nThe authors give rigorous bounds on the bounds achieved by their algorithms. The empirical results\nare also interesting, and show reasonable performance. The greedy algorithm is also shown to perform\nquite well. The presentation is quite good. The basic ideas in the paper, and the techniques used in the algorithms are fairly simple. The experiments section could be strengthened In line 51, what is the motivation for considering\nM_{\\ell,\\epsilon}(D) - \\frac{\\ell}{\\epsilon}\\log(1/2\\beta)?\n\nIs it assumed that there is a fixed \\ell_{max} for all the data (line 58)? It appears as an input in\nprocedure DPDISTINCTCOUNT, and in the bounds in Theorem 1.1.  This should be clarified\nearlier in that case. The algorithm needs to know \\ell_{max} in that case. Is there a way to specify it?\n\nLine 13 of algorithm 1 and line 10 of Algorithm 2: it might be helpful to make GEM consistent with\nthe name \"Generalized Exponential Mechanism\" used in Algorithm 3\n\nThe baseline sampling algorithm mentioned in lines 131-134 is not really related work, but just a\nbaseline, and could be in the experiments section.\n\nline 176: \"three\" should be \"four\"\n\nline 191: is the sampling done with replacement?\n\nWhat is the \\epsilon value in Fig 1? Does the \"Person Contribution Bound\" refer to \\ell_{max}?\nThe plots are quite interesting. Is there an explanation for why the gap between the algorithms\nand the true counts decreases as in the figure?\n\nTables 2 and 3 are not very easy to interpret. It might be easier to compare the counts as\nfractions or visually.\n\nHow do the results vary with \\epsilon?\n\nWhat is the motivation for considering \\epsilon=1 in the person contribution for the baseline? To some extent. There are no negative social impacts",
         "401",
         "0",
         "0",
         "0.7253000000000001",
         "0.1963888889",
         "0.9002891779000001",
         "237",
         "160",
         "51.7645",
         "9.4658",
         "12.8172",
         "12.3772",
         "9.6978",
         "0.0354",
         "105",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "98",
         "zdli6OxpWd",
         "24",
         "1681869011996",
         "['~Thomas_Steinke2', '~Alexander_Knop1']",
         "Counting Distinct Elements Under Person-Level Differential Privacy",
         "We study the problem of counting the number of distinct elements in a dataset subject to the constraint of differential privacy. \nWe consider the challenging setting of person-level DP (a.k.a. user-level DP) where each person may contribute an unbounded number of items and hence the sensitivity is unbounded.\n\nOur approach is to compute a bounded-sensitivity version of this query, which reduces to solving a max-flow problem. \nThe sensitivity bound is optimized to balance the noise we must add to privatize the answer against the error of the approximation of the bounded-sensitivity query to the true number of unique elements.",
         "Reviewer_REV6",
         "1688705858064",
         "1702410725052",
         "5",
         "3",
         "3",
         "3",
         "2",
         "Edit: Overall decision recommendation changed from borderline reject to borderline accept under the expectation that limitations and future work directions as discussed in the reviewer discussion are incorporated into the manuscript.\n\nThe manuscript studies the problem of approximating the number of unique items in a multiset under (user-level) differential privacy (DP). Unlike in prior work users can contribute arbitrarily many items to the multiset.\n\nThe authors propose to select for each user a subset of contributed items that maximises the total number of unique items. The maximisation problem is solved exactly in polynomial-time via bipartite maximum matching or alternatively a 2-approximation is found in linear-time via a greedy algorithm. S1) Non-trivial results: Sensitivity analysis of approximate DC(D;l) and application of generalized exponential mechanism is interesting.\n\nS2) Could be useful: Probability that noisy count is a lower bound can be calibrated and lower bound can be useful to check if certain thresholds are exceeded.\n\nS3) Improvement over naive baselines: Computing/approximating DC(D;l) seems clearly preferable to selecting l random items for each user. W1) Heavily biased estimator.\n\nA DP count would seem to prohibit deterministic lower/upper bounds. While a lower bound w.h.p. could still be useful, most settings would seem to call for an unbiased estimator (see also Q1a & Q1b).\n\nW2) Quality of solution unclear.\n\nApart from the poorly presented tables that do not clearly indicate the correct count, there is also no analysis of how much more utility could potentially be possible for this problem under a given DP regime. Thus, it is difficult to appreciate the solution in terms of how practically useful it is or how much utility is potentially lost due to the method (see also Q2a & Q2b).\n\nW3) Reproducibility\n\nWhile the datasets seem to be specified, the submission does not seem to provide code for experiments (see also Q3).\n\nW4) Minor: Some parts of the paper are hard to understand. Particularly, Section 3 could focus more on explanations related to the Generalized Exponential Mechanism (GEM) rather than well-known basics.\n\nIt would be better to move the basics of DP and basic Exponential/Laplace mechanism to the appendix and instead provide more explanations/intuitions on how the GEM is used in this work, why it is needed and some intuitions how it leads to better results.\n\nW5) Minor: Sensitivity analysis of DC(D;l) is missing.\n\nIt could be stated more explicitly why if a user is added that contributes X items DC(D;l) can increase by at most X, i.e., the added user cannot improve the solution for the previous users (e.g., due to optimal solution for previous users). That would also make it clearer why the sensitivity analysis for the approximation of DC(D;l) is non-trivial where an added user could potentially improve the solution for the previous users and removing a user could lead to less optimal solutions for the rest of users. Q1a) Presuming number of distinct items per user cannot be arbitrarily large, is it possible to derive an unbiased estimator using the proposed method or is there some strong indication that any unbiased estimator would be inherently impossible (presuming upper limit on items per user) or could not provide good enough accuracy in this setting?\n\nQ1b) Is there some indication that the released noisy counts correlate with the correct counts sufficiently to rank multiple noisy counts somewhat accurately?\n\nQ2a) What is correct count for each table and what is the achieved count with the proposed method? \n\nQ2b) Is there any strong indication that the proposed solution could not be easily improved upon?\n\nQ3) Do the authors plan to release the code that was used for the experiments? Some limitations do not seem to be mentioned (see Weaknesses W1) and there is generally no discussion of limitations in the abstract or an explicit paragraph in the main paper or appendix.",
         "633",
         "0",
         "2",
         "0.7837000000000001",
         "0.09051459290000001",
         "0.8110573888",
         "237",
         "158",
         "34.5201",
         "13.6697",
         "16.464",
         "15.1123",
         "13.8718",
         "0.0751",
         "94",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "99",
         "zdli6OxpWd",
         "24",
         "1681869011996",
         "['~Thomas_Steinke2', '~Alexander_Knop1']",
         "Counting Distinct Elements Under Person-Level Differential Privacy",
         "We study the problem of counting the number of distinct elements in a dataset subject to the constraint of differential privacy. \nWe consider the challenging setting of person-level DP (a.k.a. user-level DP) where each person may contribute an unbounded number of items and hence the sensitivity is unbounded.\n\nOur approach is to compute a bounded-sensitivity version of this query, which reduces to solving a max-flow problem. \nThe sensitivity bound is optimized to balance the noise we must add to privatize the answer against the error of the approximation of the bounded-sensitivity query to the true number of unique elements.",
         "Reviewer_fhMe",
         "1688827215012",
         "1702410724957",
         "5",
         "4",
         "3",
         "3",
         "3",
         "\nThis paper proposes an algorithm to count the maximum number of unique items one can get from considering from every individual in a dataset at most l items, while preserving differential privacy.  \n \n\nThe paper offers an (as far as I know) original contribution, which is simple and nice.  The explanation is clear.  The result may be significant to the extent one can cast applications needing to count the number of unique items into the relaxation considered in the current paper.\nThe paper performs an interesting empirical evaluation, even if it doesn't fully succeed to bring up a convincing application.\n \nThe paper also proposes a linear time algorithm, which is very nice, but which makes a second approximation, making it even more unclear how to determine whether it is suitable for a specific application.\n\n -- \nThe paper doesn't have a conclusions section, and doesn't mention limitations nor societal impact.\n\n",
         "148",
         "0",
         "0",
         "0.8147000000000001",
         "0.29150000000000004",
         "0.8922281861",
         "237",
         "157",
         "29.5567",
         "14.3537",
         "16.8354",
         "15.5328",
         "13.3838",
         "0.1262",
         "109",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "105",
         "zXckveawHa",
         "13137",
         "1683817138834",
         "['~Licong_Lin2', '~Mufang_Ying1', '~Suvrojit_Ghosh1', '~Koulik_Khamaru1', '~Cun-Hui_Zhang1']",
         "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
         "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a  single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator.",
         "Reviewer_KiDv",
         "1688244003510",
         "1702411416192",
         "5",
         "3",
         "3",
         "3",
         "2",
         "The paper studies the statistical limits of some adaptive linear models.\n\nThe paper defines the notion of $(k,d)$-adaptivity (Definition 2.1), and then it proves, under some conditions and for a $(k,d)$-adaptive model and failure probability $\\delta$, that\n- (Theorem 3.1) the estimation error of the adaptive components is bounded by $k\\log(n/\\delta)$ if the non-adaptive component has zero mean,\n- (Theorem 3.2) and similar results hold if the mean of the non-adaptive component is not zero;\n- (Theorem 3.4) moreover, there exists an estimator (TALE) that enjoys asymptotic normality.\n\nThe experiments present an interesting phenomenon: The TALE estimator coincides well with the normal distribution.\n\n The paper is written clearly and the presentation is smooth and relatively easy to follow.\n\n\n\n\n I have a major concern about whether the paper is technically solid and I wish to read the response from the authors:\n- Regarding Theorems 3.1 and 3.2, could the authors justify how the proof techniques differ from prior works? It appears to me that the two results are basic extensions of prior proofs (so, correct me if I am wrong).\n- Theorem 3.4 holds only for a single adaptive coordinate. Could the authors elaborate on the difficulty of extending the results for general $(k,d)$-adaptivity?\n\n\nMinor:\n- the same symbol $\\sigma$ is used to represent sigma field, variance of a random variable, and singular values. In my humble opinion, this might be confusing.\n\n\n**NOTE**: I am not an expert on statistics in general and on this particular line of research, so it is not for me to say whether the paper is significant or novel. - From the paper it is a bit hard for me to understand what \"adaptivity\" precisely means. The definition of $(k,d)$-adaptivity only specifies that the adaptive components $x_i^{ad}$ depend on the sigma field $F_{i-1}$. Would it be much simpler and clearer to say \"dependency\" instead of \"adaptivity\"?\n The authors discussed future works and limitations at the end of the paper.",
         "323",
         "0",
         "0",
         "0.7519",
         "0.024492296900000002",
         "0.9158651829000001",
         "215",
         "163",
         "46.992",
         "10.4431",
         "13.1077",
         "12.7854",
         "10.5187",
         "0.2025",
         "70",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "106",
         "zXckveawHa",
         "13137",
         "1683817138834",
         "['~Licong_Lin2', '~Mufang_Ying1', '~Suvrojit_Ghosh1', '~Koulik_Khamaru1', '~Cun-Hui_Zhang1']",
         "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
         "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a  single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator.",
         "Reviewer_tdeW",
         "1688575664641",
         "1702411416081",
         "6",
         "2",
         "3",
         "2",
         "3",
         "In \"Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference\" the authors consider the problem of estimating a low-dimensional signal in a high-dimensional linear model where data collection is allowed to be adaptive. The notion of adaptivity employed in this paper restricts itself to k components, meaning that the k first (wlog) covariates are allowed to be adaptive while the remaining are assumed i.i.d. This is in contrast to prior work where all components are allowed to be adaptive which yields very detrimental minimax lower bounds even in the case where only one component is to be estimated. Based on this new notion of adaptivity, the authors propose a scheme to estimate the low-dimensional signal yielding beneficial scaling guarantees, both in mean square error and asymptotic normality.     1. Originality: the authors study a novel scenario and provide a novel scheme with reasonable guarantees. The work has sufficient novelty.\n2. Quality: the paper is technically sound and the results are appropriately stated.\n3. Clarity: The main results of the paper and some intuition on how they are established are clear. The example provided could be a bit clearer. I expand on this in the Questions section.\n4. Significance: This may be to my own ignorance but the significance of the considered model is not entirely clear to me. I again will expand on this in the Questions section. I merge this with the Questions section. 1. Regarding Example 2.1.: Based on how the filtration is defined and the dimensionality of the quantities one can infer that A_i is considered to be the first coordinate of the covariates in the linear model. I don't see the loss of generality in instead defining x_i to include the treatment assignment as x_1i. This makes the mapping to the linear model more obvious.\n2. Regarding significance of the model. The underlying assumption is that variable selection is not necessary in this case, i.e. the low-dimensional coordinates to be estimated are known prior, and they are the only ones that are affected by adaptive covariates while the remaining are i.i.d.. Can the authors expand on the treatment assignment example to provide with a situation in which this would be the case?  -",
         "367",
         "0",
         "7",
         "0.7175",
         "0.15476475280000002",
         "0.9478315115",
         "215",
         "160",
         "42.3663",
         "11.6798",
         "15.8239",
         "14.348700000000001",
         "11.4631",
         "0.1953",
         "88",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "107",
         "zXckveawHa",
         "13137",
         "1683817138834",
         "['~Licong_Lin2', '~Mufang_Ying1', '~Suvrojit_Ghosh1', '~Koulik_Khamaru1', '~Cun-Hui_Zhang1']",
         "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
         "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a  single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator.",
         "Reviewer_Pp5b",
         "1688638134668",
         "1702411415993",
         "7",
         "3",
         "3",
         "3",
         "3",
         "This paper considers the issue of adaptive data collection in a linear regression model. To summarize the main idea, let us focus on the leading example in the paper (that is, Example 2.1, treatment assignment). In this example, a patient is treated based on effectiveness of the previous treatments as well as a small number of covariates. When the treatment is assigned adaptively in an unknown way, the treatment effect can be estimated via OLS only at a rate $\\sqrt{d/n}$, where $d$ is the dimension of the entire covariate vector (not the dimension of the covariates used for treatment assignment) and $n$ is the sample size. This result is shown by previous work in Khamaru et al. \\[21\\] and a simplified version is given as Proposition 2.2 in the paper. One of the main results in the paper is that the centered OLS estimator of the treatment effect attains a better rate of convergence, that is, $\\sqrt{k/n}$, where $k-1$ is the dimension of the covariates used for treatment assignment. The inference problem is further studied for the case that $k=1$. That is, the treatment assignment mechanism does not depend on the covariates but on the effectiveness of the previous treatments. The paper proposes an adaptive estimator called Two-stage Adaptive Linear Estimating Equation (TALE) Estimator. The adaptive weights are constructed in a particular fashion to develop asymptotic normality (see Theorem 3.4). Numerical experiments show potential usefulness of the proposed TALE estimator.          - This paper considers a highly important problem in the literature: adaptive data collection (e.g., bandits) is increasingly important in a number of fields. \n- The paper clarifies the important open question in the literature, that is, \"Can we obtain a good estimator for a low-dimensional parameter component in linear models when the degree of adaptivity is given?\".\n- The proposed TALE estimator has desirable theoretical properties and shows promising numerical results. - The non-adaptive component $x_i^{\\mathrm{nad}}$ is assumed to be independent of the adaptive component $x_i^{\\mathrm{ad}}$ (see lines 84-85). This seems quite strong in the sense that if this is the case, we could just drop the non-adaptive component $x_i^{\\mathrm{nad}}$ in the regression model and then we automatically obtain the $\\sqrt{k/n}$ rate, provided that the variance of the new regression error, which now includes the omitted part $\\theta^\\top x_i^{\\mathrm{nad}}$, is bounded by a constant that is independent of $d$. Using the scenario in Example 2.1 with $k=1$ (that is, the treatment assignment mechanism depends only on the effectiveness of the previous treatments), it might be preferable to consider the difference-in-means estimator (that is, to include only the intercept term and a treatment indicator) instead of estimating the treatment effect via regression adjustment. It would be useful to carefully discuss the issue of independence between the adaptive and nonadaptive components.  - Line 191: it seems that the conditional variance $\\sigma^2$ is a constant, meaning that it does not depend on $(x_i, \\mathcal{F}_{i-1})$. This is a restrictive assumption and could be commented in line 198.\n- The centered OLS is a proposed solution in the paper. I am wondering whether this estimator is the same as one that includes the intercept term. In other words, since it is conventional to use the intercept term in regression models, I am curious whether the standard practice already solves the research question raised in the paper (without fully realizing the importance of including the constant term in the regression model). \n- The centered OLS algorithm on page 6 is not fully implementable in an online fashion. This is because computation of the sample means requires access to the full dataset. It might be useful to add some remarks regarding how to carry out online estimation for the centered OLS.\n- Lots of notations are used before section 2.3. It might be better to move the notations section to improve readability of the paper.\n- The TALE estimator is highly related to the concurrent work \\[2\\] entitled \"Adaptive Linear Estimating Equations\". It would be useful to clarify the differences between this work and the current paper.\n\n  The numerical results are promising but there is no theoretical result in the paper that implies that the TALE estimator should perform strictly better than W-decorrelation. It might be helpful to fully discuss what numerical results are predicted by asymptotic theory and what are not.",
         "716",
         "2",
         "0",
         "0.7338",
         "0.1007646339",
         "0.8543957472",
         "215",
         "159",
         "40.1381",
         "12.4078",
         "16.4693",
         "15.0458",
         "13.2002",
         "0.25520000000000004",
         "91",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "108",
         "zXckveawHa",
         "13137",
         "1683817138834",
         "['~Licong_Lin2', '~Mufang_Ying1', '~Suvrojit_Ghosh1', '~Koulik_Khamaru1', '~Cun-Hui_Zhang1']",
         "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
         "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a  single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator.",
         "Reviewer_1ej5",
         "1688657571188",
         "1702411415905",
         "5",
         "3",
         "3",
         "3",
         "3",
         "The paper introduces a new data collection assumption that captures the partially adaptive data and then derives a bound for scaled MSE of order $k\\log n$, where $k$ is the number of entries that are collected adaptively.  Finally they also introduce a novel estimator for single coordinate inference which has  an asymptotic normality property. The paper is clearly structured and well-written. The theorems seem solid, and the assumptions are general. The authors also provide a concrete example of $\\textit{treatment assignment}$ to showcase the power of their theorems.  1. The numerical section is focused on the performance of TALE, missing out the numerical verifications for Theorem 3.1 and 3.2, which are the main theorems of the paper. \n\n2. There still seem to be some fundamental limitations for the definition of $(k,d)$-adaptivity. For example, $(k,d)$-adaptivity requires a fixed number of entries in covariates $x$ are adaptively collected, which ignore the important scenario when such the number and indices of such entries may vary. \n\n3. While the example of $\\textit{treatment assignment}$  is very helpful, no comparison has been made against the state-of-the-art statistical tools and no numerical experiments are provided.\n\n4. Typo in line 106.\n\n It is not very clear to me what is the technical difficulty to generalize the original bound involving $d$ (Lemma 16 of Lattimore and Szepesvari) to the bound of order $k$, and how the proof in this paper solves it.  See 2. in Weakness section.",
         "237",
         "0",
         "6",
         "0.7498",
         "0.070452233",
         "0.8740479946",
         "215",
         "159",
         "41.8702",
         "11.6248",
         "15.2102",
         "14.2443",
         "12.1742",
         "0.0999",
         "92",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "109",
         "zXckveawHa",
         "13137",
         "1683817138834",
         "['~Licong_Lin2', '~Mufang_Ying1', '~Suvrojit_Ghosh1', '~Koulik_Khamaru1', '~Cun-Hui_Zhang1']",
         "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
         "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a  single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator.",
         "Reviewer_nCuW",
         "1688959965227",
         "1702411415819",
         "7",
         "1",
         "3",
         "3",
         "3",
         "As I have communicated with the area chair, I will not be reviewing due to a conflict of interest. Submitting default ratings intended to be ignored below. NA NA NA NA",
         "31",
         "0",
         "1",
         "0.8387",
         "-0.125",
         "0.7032735348",
         "215",
         "155",
         "62.6241",
         "7.0916",
         "10.5849",
         "10.5042",
         "4.5518",
         "0.07390000000000001",
         "31",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "110",
         "zXckveawHa",
         "13137",
         "1683817138834",
         "['~Licong_Lin2', '~Mufang_Ying1', '~Suvrojit_Ghosh1', '~Koulik_Khamaru1', '~Cun-Hui_Zhang1']",
         "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
         "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a  single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator.",
         "Reviewer_4hmk",
         "1690011754139",
         "1702411415696",
         "5",
         "3",
         "3",
         "3",
         "2",
         "This paper investigates degree of adaptivity in data impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models.  The main result is giving an error bound of a low-dimensional component that does not have diension dependence. They propose an estimator TALE. For a special case when there is a single adaptive coordinate and non-adaptive components have zero mean, this estimator is asymptotically normal.\n\nThe manuscript is easy to read through and the technical content of the paper appears to be correct albeit some typos:\n\nLine 69: Adaptive\nLine 478 in the appendix: $X_{\\mathrm{ad}}$ Theoretical results:\n- The authors define (k,d)-adaptivity to quantify the level of adaptivity along with a concrete example. Using this idea, they can get the upper bound depending on $k$ in stead of full dimension $d$. These results could bridge the gap between iid and arbitrarily adaptive data collection.\n\nExperiments:\n- Compared to other methods like OLS, estimation errors for TALE are in good accordance with a norm distribution.\n Theoretical results:\n- The main result in this paper demonstrates the advantages of utilizing the $(k,d)$-adaptivity structure, yielding a scaled-MSE bound in the order of $k\\log(n)$ instead of $d\\log(n). While this is a positive outcome, it's worth considering that the result is based on a different norm, which makes it less convincing.\n\nExperiments:\n- In the introduction,  the paper aims to obtain an estimator with performance dependent on the degree of adaptivity. Besides, the main results highlight that having $k$ in the upper bound. Therefore, I believe it would be better for the authors to experiment with different levels of adaptivity.\n Numerical experiments:\n- The authors highlight that TALE exhibits shorter confidence intervals (CIs) compared to W-decorrelation, suggesting better estimation performance. However, it's noteworthy that OLS achieves much shorter CIs than TALE, especially in the higher-dimensional scenario where $d=50$. CI of TALE is about 50% longer than that of OLS. It would be helpful if the authors address this observation to provide a comprehensive evaluation of the methods. Also, given that, how could the authors conclude that TALE outperforms OLS in terms of estimation performance? \n- From Figure 2, we can see that OLS is indeed downwardly biased. However, we can also observe that the magnitude of errors might be the same. The main results show a tighter bound (from $d=50$ to $k=1\"), but the practical benefit is not evident. Additional analysis or insights would help demonstrate its significance. In addition to the limitations mentioned earlier, the authors noted that they did not provide asymptotic normality guarantees when the adaptive component has more than one dimension.",
         "431",
         "0",
         "0",
         "0.8105",
         "0.14041879840000002",
         "0.9205298424",
         "215",
         "143",
         "36.7949",
         "12.7177",
         "16.1442",
         "14.9213",
         "13.7196",
         "0.1631",
         "90",
         "0",
         "1",
         "1",
         "0"
        ],
        [
         "120",
         "zUYfbdNl1m",
         "10353",
         "1683782302705",
         "['~Yunho_Jin1', '~Chun-Feng_Wu1', '~David_Brooks1', '~Gu-Yeon_Wei1']",
         "$S^3$: Increasing GPU Utilization during Generative Inference for Higher Throughput",
         "Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose $S^3$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49× throughput over those systems that assume the worst case for the output sequence length.",
         "Reviewer_RWv5",
         "1687622971457",
         "1702411280974",
         "5",
         "4",
         "4",
         "3",
         "2",
         "This work builds an LLM inference platform, called S^3, around a sequence length predictor.\nThe sequence length predictor is used to\n1. batch LLM generations\n2. pre-allocate kv cache (where all seq have similar predicted seq len)\nS^3 also has a method for handling seq len prediction errors. They do pipelined generation. They unpad shorter seq to ignore wasting compute. LLM inference is becoming a larger and larger part of the total compute used within large organizations. Decrease inference costs is an extremely impactful line of work.\n\nThe analysis of overheads is good. \nFor kv cache pre-allocation, the authors note that pre-allocation limits seq len, not pre-allocating kv cache slows generation. An obvious baseline is pre-allocating for S tokens at a time (eg S=64) and freeing kv cache mem of generations which have finished (this frees mem for the really long generations). This simple baseline would decrease the kv cache concat overhead by a factor of S and eliminates the overhead of the S^3 algo.\n\nThe work uses a sequence length predictor to build an LLM inference platform. This is great systems research, I'm not sure it's positioned well for NeurIPS.\nThe work doesn't show how much of the benefit comes from pipelining vs kv cache preallocation vs seq len batching vs unpading. I'm not sure how much improvement each method is or if we're introducing other overheads by including methods such as seq len prediction.\n\nThere are great works on improving LLM inference. Why only compare to ORCA?\n\n The authors note: \"More GPUs shard the model into finer pieces and leave more space for storing the KV cache, allowing us to increase the batch size. \" - line 280\nThe method also pipelines generations; kv caches for all generations must be stored in mem, this in turn lowers the possible batch size. Is it possible to quantify the trade off?\n\nWill the code be made public? People can easily benchmark the implementation helping the authors identify shortcomings and improve the overall performance over time.\n Requires training a seq len predictor which hopefully generalizes to different data distributions.",
         "348",
         "0",
         "0",
         "0.8049000000000001",
         "0.1427721088",
         "0.8489073515000001",
         "215",
         "171",
         "54.5437",
         "9.2331",
         "12.0094",
         "12.1617",
         "9.7344",
         "0.09380000000000001",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "121",
         "zUYfbdNl1m",
         "10353",
         "1683782302705",
         "['~Yunho_Jin1', '~Chun-Feng_Wu1', '~David_Brooks1', '~Gu-Yeon_Wei1']",
         "$S^3$: Increasing GPU Utilization during Generative Inference for Higher Throughput",
         "Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose $S^3$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49× throughput over those systems that assume the worst case for the output sequence length.",
         "Reviewer_s4gr",
         "1688352334723",
         "1702411280886",
         "6",
         "3",
         "3",
         "3",
         "2",
         "The paper proposes a scheme that increases the throughput during inference on Transformer large language models (LLM). Typically, LLMs require large amounts of memory, for model parameters and for the KV (key/value) cache. The KV cache size depends of the output sequence length, which is not known when inference starts. Some implementations allocate memory for the KV cache in small increments, causing large latency, while others preallocate for up to the maximum output sequence length, causing potential memory waste. The authors propose a method, called S3 (scheduling sequences with speculation), that predicts the output length, and allocates the KV cache accordingly. The predictor is a fine-tuned Distilbert model (66M parameters) with small size and fast prediction time. A scheduler batches requests according to a greedy strategy. A supervisor is in charge of checking GPU utilization and handling mispredictions, while at the same time training the predictor in the background. An experimental analysis shows the flexibility of S3 in offering a trade-off between latency and throughput. Transformers are memory and compute intensive. Designing schemes that make better use of memory, thus increasing the latency and/or throughput is an important topic. The proposed solution is simple, and the predictor ran as part of S3 adds negligible overhead. The experimental results show improvements, generating by up to 6.49 times more sequences compared to other existing system. The system will need more analysis in the future, based on real traces (which are not available for research community now), and considering realistic service level objectives. 1. Could you add to the experimental section results for the case when no KV caching is used? N/A",
         "269",
         "0",
         "2",
         "0.8018000000000001",
         "0.09642857140000001",
         "0.8625138402",
         "215",
         "162",
         "40.0692",
         "11.8472",
         "15.9443",
         "14.5546",
         "13.1176",
         "0.3513",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "122",
         "zUYfbdNl1m",
         "10353",
         "1683782302705",
         "['~Yunho_Jin1', '~Chun-Feng_Wu1', '~David_Brooks1', '~Gu-Yeon_Wei1']",
         "$S^3$: Increasing GPU Utilization during Generative Inference for Higher Throughput",
         "Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose $S^3$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49× throughput over those systems that assume the worst case for the output sequence length.",
         "Reviewer_1WaJ",
         "1688518280236",
         "1702411280781",
         "7",
         "4",
         "3",
         "4",
         "3",
         "The paper tackles the problem of predicting the number of generated tokens for transformers in text generation tasks. This will help with better memory allocation and batch size management. The previous systems either used dynamic memory allocation (Hugging Face) which incurs inference overhead, or preallocated memory for over-estimated output length, limiting the batch size. This paper's prediction of output length achieves a larger batch size, thus increasing the throughput. Experiments show a 6.49x improvement in throughput. The predictor is get by training a Distilbert model. 1. The idea is simple but effective.\n2. The paper is clear, well-written, and easy to read.\n3. The evaluation is clear and convincing. It contains various settings, including different models, different hardware setups, online/offline with clear information presented (latency breakdown, batch size). 1. It has not been discussed that different models can generate outputs with different lengths.\n2. The evaluation does not contain different request patterns.\n3. Missing the evaluation of throughput in term of token/s. 1. Figure 1: is it get from generating with 60 token context length? This is not a long context.\n2. line 71: \"6.49× more sequences\" is vague, because sequences can have different lengths.\n3. line 212: \"The supervisor shifts the rows below the blank one so that all rows are stored contiguously.\". How much time overhead does this step cause?\n4. Why are you measuring the throughput as sequence/s, not token/s? Sequences have different lengths, which makes sequence/s hard to interpret. I can understand that you want to count how many requests can be served, but maybe also add plots for token/s.\n5. When you are using the Alpaca dataset, how did you setup the request distribution (coming time, etc)? \n6. How does your method compare to this one \"Fast Distributed Inference Serving for Large Language Models\" that was released recently?\n\nminor:\nline 47: typo before \"since most of the HBM is used to...\"\nline 307: \\[31, 39\\] are not focus on throughput. To accurately predict the output length, the distribution of the test trace should be similar to the data used to train the predictor. Also, different models will generate answers with different lengths, which requires the training data to reflect a similar behavior to the model used in the generation.",
         "374",
         "1",
         "10",
         "0.7841",
         "0.07876447880000001",
         "0.9079014063",
         "215",
         "160",
         "52.368",
         "9.1589",
         "11.6827",
         "12.2547",
         "10.0543",
         "0.1879",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "123",
         "zUYfbdNl1m",
         "10353",
         "1683782302705",
         "['~Yunho_Jin1', '~Chun-Feng_Wu1', '~David_Brooks1', '~Gu-Yeon_Wei1']",
         "$S^3$: Increasing GPU Utilization during Generative Inference for Higher Throughput",
         "Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose $S^3$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49× throughput over those systems that assume the worst case for the output sequence length.",
         "Reviewer_945f",
         "1689427120375",
         "1702411280702",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a new solution to the challenges of GPU underutilization and increasing batch size in the generation task of Large Language Models (LLMs), rooted in the memory-intensive requirement to retain the K and V values of prior tokens. To tackle these issues, the paper proposes an efficient framework named S^3, which uses a fine-tuned Distillbert model as a predictor to forecast the output sequence length based on an input prompt. This predictive model guides query generation scheduling and manages mispredictions by halting sequences exceeding allocated memory and doubling their assigned memory. The proposed approach increases the maximum configurable batch size in both online and offline scenarios and improves throughput, reporting a throughput increase of up to 6.49 times. Although this paper offers improvements in handling memory allocation for LLM inference, there are some concerns about evaluation and ablation of the proposed techniques. - This paper tackles the vital challenge of predicting output sequence length through a unique DistillBERT-based co-optimization of the system and algorithm. This approach effectively addresses the limitations of existing frameworks, namely HF-Transformer and FasterTransformer, leading to improved throughput while meeting SLO latency.\n\n- While larger models typically yield better performance, as the space for K, V caches reduce, effective memory allocation management becomes increasingly essential. The S^3 framework notably elevates the maximum throughput, particularly in larger models.\n\n- The S^3 framework optimizes the latency-throughput trade-off by adjusting memory allocation, leaving the model architecture intact and thereby maintaining model perplexity. Operating independently and focusing on performance enhancement, the framework doesn't impact the accuracy of existing LLM models.\n\n - While a major contribution of the paper is the prediction of output sequence length, the effectiveness of this proposed predictor isn't thoroughly evaluated. Tables 2 and 3 show a significant difference between the batch size predictions of S^3 and Oracle. The reasons behind this discrepancy need to be explained.\n\n- The effectiveness of the predictor appears to vary greatly with the fine-tuning dataset, with accuracies ranging from 65.6% to 98.6%. The paper proposes online learning, but this isn't evaluated. Additionally, the paper lacks an ablation study on the choice of predictor models and sizes.\n\n- The paper only compares the latency-throughput trade-off between vanilla systems and S^3 and doesn't compare average throughput and latency in specific tasks. This is crucial, as output sequence length prediction accuracy, which seems to be task-dependent, would likely impact this.\n\n- While S^3 meets the SLO limit, its implementation generally results in an increase in end-to-end latency. The paper doesn't adequately address how much each proposed technique contributes to this overhead.\n\n- The paper introduces a supervisor component to handle mispredictions, but the description of this technique is unclear. The supervisor appears to allocate double the memory when a previous allocation isn't sufficient. However, in typical scenarios with scarce memory, this could lead to problems if the predictor misestimates the batch size. More detailed explanations of various scenarios would be useful.\n - The figure captions could use more detail. For instance, is Figure 1 (left) showing an online scenario, and how many GPUs were used? Similarly, does Figure 1 (right) represent an offline scenario, and how large is the model size?\n\n- The term \"number of iterations\" requires clarification. It's evaluated in the sections assessing performance, but isn't clearly defined. \n\n- In Section 4.1, it's mentioned that \"Oracle exceeds the SLO for GPT-J, LLAMA 13B, and GPT-NEOX when it chooses the maximum batch size\". It's unclear why Oracle would select a batch size that violates the SLO.\n\n- Both Figures 4 (a) and (b) claim a maximum performance improvement of 6.49x. How can this be, especially when Figure 4 (b) pertains to \"Generated sequences under latency SLO\"? Is the data in Figure 4 (b) based on a scenario of maximum throughput?\n\n- The application of S^3 seems to yield less throughput improvement as the model size decreases. Is there still a significant performance improvement when applying S^3 to smaller models like GPT-3 small, which has around 125M parameters?\n\n- Regarding throughput-related performance metrics, it's unclear how Oracle's (ideal predictor and scheduler) performance was measured. The scheduling might have been done under an entirely ideal scenario, or it might be based on the assumption that the predictor makes no errors in predicting input sequences. The authors properly stated the limitations of the proposed methods.",
         "720",
         "0",
         "0",
         "0.8011",
         "0.1725472657",
         "0.9081500173",
         "215",
         "150",
         "32.9158",
         "12.8442",
         "16.3555",
         "14.7234",
         "13.8414",
         "0.0751",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "124",
         "zUYfbdNl1m",
         "10353",
         "1683782302705",
         "['~Yunho_Jin1', '~Chun-Feng_Wu1', '~David_Brooks1', '~Gu-Yeon_Wei1']",
         "$S^3$: Increasing GPU Utilization during Generative Inference for Higher Throughput",
         "Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose $S^3$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49× throughput over those systems that assume the worst case for the output sequence length.",
         "Reviewer_CH64",
         "1690272267536",
         "1702411280615",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposes a simple yet effective systematic solution to increase GPU usage and throughput during inference. The authors first make an interesting observation that the existing large language models are bounded by memory and the inefficiency is caused by the lack of awareness of the sequence length. Accordingly, the authors first fine-tune a small model DistillBert to predict the sequence length. Based on it, the authors accordingly schedule the generation of queries and deal with mispredictions. The authors conduct experiments with models from 6 billion to 175 billion parameters to evaluate the effectiveness of the proposed system. ++ The paper solves a practical problem, personally, I think improving the GPU utilization can benefit the community and the deployment of different applications.\n\n++ The proposed solution is simple yet effective. Predicting the output sequence length first is a simple and intuitive way to schedule the network and better utilize the GPU. Although incorporating a new model introduces additional lags, the authors show that such overhead is negligible in Figure 6.\n\n++ The results look promising; the proposed method allows for larger inference batch size and during the inference, e.g., 32 -> 256 for LLaMA-13B and 4 -> 32 for LLaMA-32B, and hence achieves higher throughput.\n -- Subsection Length-aware sequence scheduler in Section 3 is not very intuitive to the readers, especially the ones that are not directly working on the same topic. It would be better to illustrate more on how the bin packing problem is solved and the batching technique in ORCA (with an Algorithm or diagram or more descriptions).\n\n-- The authors only evaluate the proposed method on NVIDIA A100 GPU. However, it seems the design is not dependent on the architecture of A100 GPU. It would be better to also evaluate the proposed method on other GPU architectures.\n\n-- Minor: Distilbert in L169 and Distil-bert in L155 See weakness. N/A",
         "313",
         "0",
         "1",
         "0.755",
         "0.172521645",
         "0.92848593",
         "215",
         "140",
         "41.3375",
         "11.9507",
         "14.5207",
         "13.8615",
         "12.3396",
         "0.1262",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "146",
         "zPYeYv6YYs",
         "9388",
         "1683768267322",
         "['~Anastasios_Nikolas_Angelopoulos1', '~Emmanuel_Candes1', '~Ryan_Tibshirani1']",
         "Conformal PID Control for Time Series Prediction",
         "We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use  algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in\nofficial CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules at [this link](http://github.com/aangelopoulos/conformal-time-series).",
         "Reviewer_H9oS",
         "1688476408213",
         "1702411228694",
         "6",
         "4",
         "4",
         "4",
         "3",
         "The paper proposes an adaptation to existing adaptive conformal prediction in two novel ways: (i) by tracking the quantile via online regression over the running sum of the errors; and (ii) by incorporating a second model to anticipate the quantile in the next instant (\"scorecasting\"). The authors include theoretical guarantees for the resulting method, as well as comparisons against a benchmark in the field (ACI, which is shown to be a a special case of the proposed algorithm) over many different datasets.  - Clear: the paper is well-written and very clear regarding its contributions.\n- Limitations: the discussions on the method's limitations are very helpful.\n- Theoretical results: the mathematical proofs are easy to follow and the notation is clear.\n- Empirical results: the empirical studies are extensive and cover several different datasets. The experiments in the supplementary material are also very thorough.\n- Code: the code is well-organized and readable (but please include the `environments.yml` file, all the necessary datasets, and instructions on how to reproduce figures in the paper! See below). - Theoretical guarantees: the guarantees of the proposed method are only asymptotic. Unfortunately, no finite-sample results are included. None of the theoretical developments in the paper showcase advantages that the proposed method has over leading alternatives. \n- Baselines: there are many recent proposals in the field (even in your related works section), but the only baseline is ACI. SPCI (Xu and Xie, 2022) also obtained asymptotic longitudinal coverage of time series without creating infinitely-wide intervals; can you underline in what ways your proposal is better? \n- Experimental results: Can you include more details on how the hyperparameters were chosen for the examples in the main paper (for example, $r_t$)? Having too many hyper parameters can be overwhelming to the end-user (I appreciate the discussion in appendices C and D!). It would be great to include at least one example of adaptive learning in the proposed algorithm. \n- Scalability: all the time series considered, both in the main text and in the supplementary material (SM), are small, with the largest ones comprising around 3000 data points. In scenarios where new data arrives every second, for example, it is not clear if the method would work as-is or if any modifications would be needed. A discussion about this and an experiment with a very long time series would be great.\n- References: the authors point out the field of online calibration, and mention connections to game theory and online learning, but never explicitly discuss the connection to their work. It would be nice to better understand what tools from the field you are using or building upon.\n- Relationship to control theory: seems slightly out-of-place. Either explain the connection better (perhaps in the SM) or develop it in another paper? As it is, it's hard for the CP audience understand what the PID is, or why this connection is relevant.\n- Reproducibility: adding the proposed method's pseudocode would help a lot, either to the main text or to the SM if space is lacking. Trying to reproduce the results following the README.md, I was instructed to install the dependencies listed on `environment.yml`, but no such file was provided and I had to track them down one by one. There also seems to be a dataset missing (`datasets/preds_cases.csv`) and not all plots from the paper were generated.\n- Minor writing suggestion: on one hand, the relation to control theory seems currently very incipient and more of a curiosity, but it is presented prominently in a section of its own. On the other hand, the interesting Proposition 3 is cramped in the final section. You might consider adding an independent section for extensions and incorporate the control theory analogy into the final discussion section.\n- Other minor suggestions: I don't see the point of including the zoom in the figures; it oftentimes hides parts of the figure and the underlying patterns are clear from the whole graph. Besides the many plots, adding a table with a summary of the results among all datasets could help a reader to draw conclusions faster. The meaning of sublinear function is given in line 164, but the term is used before in lines 55 and 67, so we suggest bringing the definition up. Display (5) has a floating \\cdot in the last inequality and inconsistent usage (c \\cdot h(t) vs -ch(t)). Figure 1 caption says prediction sets are in purple, but it is actually in orange.\n- Typos: line 115: $(1-\\alpha)$ should be $\\tau$; line 139: the em-dash is confusing.; line 151: \"an particular\" should be \"a particular; proof of proposition 2: $C$ should be $c$; display under line 192: the second $\\text{err}_i$ should be $\\text{err}_t$; line 201: \"can made\" should be \"can be made\"; line 295: \"saturation function as in 2\" should be \"saturation function that satisfies (5)\" or \"saturation function as in Proposition 2\"line 301: missing \\mathrm for err_i.; the bibliography is not printed in the SM and the references do not match the main text, so it ca be confusing. - Why is asymptotic coverage the best one can hope for in the adversarial setting? Is this a formal result? It would be helpful to develop this idea a bit more in the text.\n- What are advantages of using the scorecaster in the conformal prediction setup vs adapting the model instead?\n- Any guidance on how should one pick $r_t$ and the learning rate? How was this decided for the figures in the main paper? The paper seems to imply trial and error. The impact on figures in the appendix is extremely large!\n- When do you expect ACI to be better than Quantile+Integrator+Scorecaster?\n- What are advantages and disadvantages of your proposal vs SPCI, given both achieve coverage of time series without creating infinitely-wide intervals? How does the empirical performance compares? In what ways is your proposal better?\n- Can you explain what you mean by \"Our algorithms may not be universally useful on time series different from those we used for evaluation\" (line 283)? When should it be useful?\n- There is a method called \"Trail\" in the appendix plots, but no explanation. What is it? Yes.",
         "1028",
         "0",
         "2",
         "0.7619",
         "0.13668450810000002",
         "0.9132441878",
         "215",
         "161",
         "46.5201",
         "11.0797",
         "13.8167",
         "13.2765",
         "11.0765",
         "0.8059000000000001",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "147",
         "zPYeYv6YYs",
         "9388",
         "1683768267322",
         "['~Anastasios_Nikolas_Angelopoulos1', '~Emmanuel_Candes1', '~Ryan_Tibshirani1']",
         "Conformal PID Control for Time Series Prediction",
         "We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use  algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in\nofficial CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules at [this link](http://github.com/aangelopoulos/conformal-time-series).",
         "Reviewer_bvK1",
         "1688795897428",
         "1702411228611",
         "7",
         "4",
         "3",
         "3",
         "3",
         "The paper tackles the problem of conformal UQ under distribution shifts. This is a very realistic setting where the upstream prediction model cannot be frequently updated, and we still want to certify some level of safety. The paper cleverly fames the problem as a PID control problem, and provides a practical algorithm that they show is effective on synthetic and real datasets. - The setting addressed is impactful and practical. A major hindrance of using CP in ML systems deployment is that the exchangeability assumption is often violated. This work provides a practical adaptation while still maintaining some guarantees of the method. \n\n- The PID framing of the problem & solution is clever and insightful. (very Big Brain, if i may use gen-z lingo.) The two Gibbs & Candes paper from 2021 and 2022 for CP under distribution shifts was able to circumvent the exchangeability assumption and achieve some guarantees by transforming the distribution shift into a online optimization problem for a single parameter $\\alpha^*$, which they prove is similar to a P controller.  This work takes the idea a step further, and introduces the integrater (I) and forecasting (D) algorithms, completing the picture (fig 2 <- such a nice figure). \n\n- The method can utilize time-series modeling approaches to adapt to seasonality. \n\n- The experiment section is well-presented. It walks you through part-by-part of the PID controller and shows the impact of each. The examples chosen are clear and convincing. \n\n  1. The paper did not define some concepts it used in its writing. For example: \n- line 29, exchangeability \n- line 25, sharpest\n- line 83, burn-in period\n- line 137 (not really a definition just... what are you trying to say here?) \"the quantile tracker proceeds agnostically and performs the same updates in any case.\"\n\nI think explaining them, even just in the appendix, will help with clarity. \n\n2. The paper only compared to ACI & ablations of its own method. A common choice of algorithm for the scenario introduced by the authors would be Enbpi and SPCI from Xu & Xie (references 29 and 30 in the paper). - Can you elaborate on the reason why Enbpi and SPCI from Xu & Xie are not good baselines for comparing your model? Many have used previous timesteps as covariate X, similar to your scorecasting approach.    The authors provided a good address of limitations in their discussion section. ",
         "399",
         "0",
         "2",
         "0.81",
         "0.16757054670000002",
         "0.8758778572",
         "215",
         "157",
         "49.3747",
         "10.3474",
         "14.0042",
         "13.1604",
         "10.0256",
         "0.1217",
         "105",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "148",
         "zPYeYv6YYs",
         "9388",
         "1683768267322",
         "['~Anastasios_Nikolas_Angelopoulos1', '~Emmanuel_Candes1', '~Ryan_Tibshirani1']",
         "Conformal PID Control for Time Series Prediction",
         "We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use  algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in\nofficial CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules at [this link](http://github.com/aangelopoulos/conformal-time-series).",
         "Reviewer_aXqf",
         "1688856338561",
         "1702411228514",
         "6",
         "4",
         "2",
         "3",
         "3",
         "This paper examines the issue of how to parameterize conformal prediction in the time series setting. It argues that standard conformal inference methods would not provide valid inferences in the sequential setting, which lacks exchangeability. To resolve this, the paper suggests using online quantile tracking, integrating errors for stabilizing coverage, and utilizing scorecasting in the presence of systematic trends. The authors establish the corresponding theoretical properties, such as asymptotic coverage and conduct several experiments to justify their approach. 1. A new method for conformal prediction in the in the time series setting with a clear presentation of the details and background.\n2. The authors show the proposed method has a major practical benefit, that unlike ACI (Gibbs and Candes, 2021), no infinite sets are produced.\n3. The authors demonstrate the practical utility of their methods with an extensive series of experiments on a wide range of real-time series data sets. 1. Although this paper present a general theorem that their method achieves asymptotic coverage, there is insufficient discussion on the coverage guarantees such as the lower bounds and upper bounds on coverage.\n2. The authors also explicitly avoid addressing the choice of automatic algorithms for the\ntwo parameter $C_{sat}$ and $K_I$ in the nonlinear saturation function.\n3. In the sequential setting (7), the authors didn’t show how to select the learning rate\n$\\eta$, what factors might affect the selection of the learning rate $\\eta$, and what impact this\nselection have on the performance of the method. 1. How the specific selection of the function $r_t$ and $\\hat{q}_t$ influence the\noverall performance of the proposed method in conformal prediction for time series?\n2. In the context of time series conformal prediction, how does this new method compare\nwith other popular methods in terms of robustness, and computational efficiency?\n3. How does a non-constant threshold function $h$ help with tolerating a greater degree of\ncoverage error throughout the sequence? 1. Despite demonstrating strong results across various experiments, the authors acknowledge\npotential limitations, including the challenge of proving asymptotic coverage, potential\ninapplicability to different time series, and limitations in scorecasting.\n2. The methods they develop are specific to cases where response $y_t$ is revealed at each time\npoint. However, there are many settings in which we receive the response in a delayed\nfashion or in large batches.",
         "384",
         "0",
         "11",
         "0.7674000000000001",
         "0.092883197",
         "0.9308227897",
         "215",
         "156",
         "29.7984",
         "15.0653",
         "18.35",
         "16.4503",
         "17.1128",
         "0.09870000000000001",
         "96",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "149",
         "zPYeYv6YYs",
         "9388",
         "1683768267322",
         "['~Anastasios_Nikolas_Angelopoulos1', '~Emmanuel_Candes1', '~Ryan_Tibshirani1']",
         "Conformal PID Control for Time Series Prediction",
         "We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use  algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in\nofficial CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules at [this link](http://github.com/aangelopoulos/conformal-time-series).",
         "Reviewer_Cw13",
         "1689077138643",
         "1702411228432",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper aims to provide asymptotically valid conformal prediction (CP) regions for the time series prediction problem. Similar to the adaptive conformal inference (ACI) framework \\[11\\], the main idea is to choose the appropriate quantile of the non-conformity scores (or equivalently tuning the miscoverage rate $\\alpha$) at each time step to fulfill the required error rate. The framework performs an online quantile update while taking into account the sum of coverage errors overtime to stabilize the coverage better. They provided theoretical analysis that guarantees the asymptotic coverage of the predictions made by their framework. Numerical experiments on real datasets show that their method brings more stable and efficient prediction sets than ACI.  In general, I liked the idea of designing a PID-like framework. Thanks to this structure, the prediction regions turn out to be more stable and efficient. Moreover, it ensures that their framework never outputs infinite size prediction sets, which is a big advantage over ACI. Also, they provided many numerical experiments in the paper and the Appendix to illustrate the power of their proposed framework highlighting the effect of each block and different choices of hyperparameters.  1. The related work section is not well-written in general. Also, it does not represent the works in the intersection of conformal prediction and time series prediction in a fair manner. Indeed many good papers are missing, such as \n\t- Foygel Barber, R., Candes, E. J., Ramdas, A., and Tibshirani, R. J. Conformal prediction beyond exchangeability. arXiv preprint arXiv:2202.13415, 2022,\n\t- Sun, S. and Yu, R. Copula conformal prediction for multi-step time series forecasting. ArXiv, abs/2212.03281, 2022,\nto mention a few. \n\n2. The comparisons are limited to ACI. Though it is a natural baseline to compare with, many other CP frameworks are designed for the time series prediction problem. It is interesting to see how they behave compared to the methods proposed in this paper. \n\n3. The scorecasting block seems unnecessary and, to some extent, redundant. Accounting for a wrong choice of learning model (e.g., a model that does not account for the seasonality effect) can not be a part of the design of a CP framework. This point is also mentioned in the paper in lines 286-288. However, it seems that the authors tried to put this block to force the similarity of their framework and the (well-known) PID controller.  \n\n4. There are numerous design choices (such as the saturation function) and hyperparameters in the framework, and it's worth noting that several of them may not be immediately intuitive for people in the Machine Learning or Conformal Prediction community when it comes to making appropriate choices.\n\n5. Generally speaking, I am still unsure to what extent it is worth exploring frameworks with an asymptotic coverage property, while the popularity of conformal prediction lies in its ability to provide a finite-sample guarantee.\n\n6. Minor Comments:\n\t- There are some typos in Equation 5. \n\n\t- Line115: There is a typo in the definition of the pinball loss (\\tau should be replaced with \\alpha). \n\n\t- Line 178: The equation reference should be (10) instead of (11).  \n\n\t- In the proof of Proposition 2., the capital C has to be replaced with the small c. \n\n\t- Bringing the extensions of the proposed method (e.g., conformal risk control and Proposition 3. or conditional coverage) into the discussion section is unappealing.\n\t- In order to facilitate the comparisons for the readers,  it is a good idea to report the Avg. size of the prediction sets and Avg. coverage in the figures like what you have in the Appendix figures.  Isn't it a good idea to provide a concrete explanation of why the proposed framework never returns infinite sets while this can happen in ACI?  The authors fairly mention the limitations of the proposed framework in the discussion section. ",
         "631",
         "1",
         "6",
         "0.7803",
         "0.1765963203",
         "0.9080626369",
         "215",
         "154",
         "48.5159",
         "10.1773",
         "13.0601",
         "12.8256",
         "10.4846",
         "0.8092",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "167",
         "zMNUNd9zs1",
         "12836",
         "1683814821296",
         "['~Manu_Srinath_Halvagal1', '~Axel_Laborieux1', '~Friedemann_Zenke1']",
         "Implicit variance regularization in non-contrastive SSL",
         "Non-contrastive SSL methods like BYOL and SimSiam rely on asymmetric predictor networks to avoid representational collapse without negative samples. Yet, how predictor networks facilitate stable learning is not fully understood. While previous theoretical analyses assumed Euclidean losses, most practical implementations rely on cosine similarity. To gain further theoretical insight into non-contrastive SSL, we analytically study learning dynamics in conjunction with Euclidean and cosine similarity in the eigenspace of closed-form linear predictor networks. We show that both avoid collapse through implicit variance regularization albeit through different dynamical mechanisms. Moreover, we find that the eigenvalues act as effective learning rate multipliers and propose a family of isotropic loss functions (IsoLoss) that equalize convergence rates across eigenmodes. Empirically, IsoLoss speeds up the initial learning dynamics and increases robustness, thereby allowing us to dispense with the EMA target network typically used with non-contrastive methods. Our analysis sheds light on the variance regularization mechanisms of non-contrastive SSL and lays the theoretical grounds for crafting novel loss functions that shape the learning dynamics of the predictor's spectrum.",
         "Reviewer_qXm9",
         "1688723244466",
         "1702411401619",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This article builds on the theory of non-constrastive (nc) self-supervised learning (SSL), with methods such as BYOL or SimSiam. Contrary to the existing litterature, they study directly the cosine similarity loss used rather than a Euclidian loss on the eigenspace, using NTK dynamics. They show that collapse is avoided in this case with implicit variance reduction. With their analysis, they find an undesirable anisotropy which they fix with a new family of losses that outperforms the state-of-the-art, especially without needing an Exponiential Moving Average (EMA) target network. The theory provides strong results in the linear framework, explaining the eigenvalues dynamics of both euclidian and cosine losses with and without projectors and stop gradients. The use of the NTK dynamics and the analysis of the cosine similarity is novel to me.\n\nThe findings that the eigenvalues affect learning as a learning rate provide a good justification for the new IsoLosses, which gives state-of-the-art results. In particular, the removal of the EMA and the increased dimensionality of the losses ensures their consistency. One of the main claims of the article is the analysis of the cosine similarity loss. However in that case, if the dynamics are quite different as claimed by the authors, I find the use of the result of Tian et al. that the predictor eigenspace aligns with the one of the correlation matrix of the representations surprising since it was established with a Euclidian loss. I would have hoped atleast a comment on this, if not an analysis of the alignment as done in Tian et al.\n\nI was awaiting an analysis of the eigenvalues similar to Figure 2 for a real network, and not only a comparison with other losses. As such, the analysis of the IsoLoss feels a bit disconnected from the theoretical analysis. Why do the dimensionality increase? Is it because small eigenvalues do not collapse due to their low learning rates ? Do the eigenvalues evolve during training similarly to the linear case, for BYOL/SimSiam and IsoLoss ? (and their euclidian counterparts)\n\nTwo important notions in the theory of NC-SSL are the EMA and the weight decay. Since an important improvement of the method is the removal of the need of the EMA of the target network, I would find natural to mention the effect of the EMA in the dynamic. \nSimilarly, the results of Wang et al. indicate the importance of the role of weight decay to collapse unwanted eigenvalues. I am surprised that the role of weight decay is not mentioned anywhere, especially despite its use in the implementation.\n\nThe formulation of the Isoloss (in particular the cosine similarity one) is very hard to interpret. However, it is logical due to the way it was found.\n\nThis is an interesting theoretical article despite some flaws and questions raised, and I am ready to raise my score if my questions are answered. If would define $\\hat z = U z$ a bit more clearly maybe before Lemma 1.\n\nEquation 3: There is a dimensional issue with the diagonal matrix on the right with the product \"$zD$\" if I am not mistaken. Shouldn't $D$ be on the left?\n\nDefinition 1: I find the different notations often a bit unclear, but most importantly is the sudden usage of the time $t$ index which is not consistent. It is present at line 114 but not at line 111, and appears only on part of the variables. Similarly for lemma 2, where $\\hat z_t$ loses the time index again. The use of bold variables is also often inconsistent.\n\nTable 2: I would have expected the inclusion of DirectCopy and of SimSiam in the comparison. The authors address adequately the limits of the theory they established, although they do not talk about the effect of EMA and weight decay in their theory or their hypothesis of DirectPred which was established with an Euclidian loss.",
         "645",
         "0",
         "0",
         "0.7264",
         "0.1082552864",
         "0.8838762641000001",
         "215",
         "158",
         "47.3283",
         "11.3489",
         "14.4065",
         "13.8167",
         "11.0938",
         "0.1507",
         "77",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "168",
         "zMNUNd9zs1",
         "12836",
         "1683814821296",
         "['~Manu_Srinath_Halvagal1', '~Axel_Laborieux1', '~Friedemann_Zenke1']",
         "Implicit variance regularization in non-contrastive SSL",
         "Non-contrastive SSL methods like BYOL and SimSiam rely on asymmetric predictor networks to avoid representational collapse without negative samples. Yet, how predictor networks facilitate stable learning is not fully understood. While previous theoretical analyses assumed Euclidean losses, most practical implementations rely on cosine similarity. To gain further theoretical insight into non-contrastive SSL, we analytically study learning dynamics in conjunction with Euclidean and cosine similarity in the eigenspace of closed-form linear predictor networks. We show that both avoid collapse through implicit variance regularization albeit through different dynamical mechanisms. Moreover, we find that the eigenvalues act as effective learning rate multipliers and propose a family of isotropic loss functions (IsoLoss) that equalize convergence rates across eigenmodes. Empirically, IsoLoss speeds up the initial learning dynamics and increases robustness, thereby allowing us to dispense with the EMA target network typically used with non-contrastive methods. Our analysis sheds light on the variance regularization mechanisms of non-contrastive SSL and lays the theoretical grounds for crafting novel loss functions that shape the learning dynamics of the predictor's spectrum.",
         "Reviewer_qE19",
         "1688785070942",
         "1702411401519",
         "7",
         "3",
         "3",
         "2",
         "4",
         "The learning dynamics of non-contrastive self-supervised learning is an important problem to understand how these methods avoid collapse without using negative samples. In this paper, the authors provide a rigorous analysis of this problem on a simple linear network with Gaussian inputs, especially the difference between Euclidean and cosine loss functions. It is demonstrated that both losses have implicit regularization effects on the variance of representation, and the role of predictor and stop-grad operations are thoroughly investigated. Based on these insights, the authors propose an isotropic loss to equalize the convergence rate and lead to a better performance in various settings.   The theoretical analysis in this paper is novel and clearly improves the understanding of how loss function, stop grad and projector affect the performance of non-contrastive self-supervise learning. Based on the mathematical understanding, the authors propose a new loss function that could beat the baseline method on different datasets, which illustrates the validity and power of the proposed theory in practice. The major weakness of this paper is the strong assumptions that require the network to be linear and the input to be iid Gaussian. For real-world datasets and practical network structures, it is not clear if those insights are still valid.   1. In Table 1, it is predicted that $L_{noPred}$ converges slower than $L$, however, in Figure 2 there is an eigenvalue in $L$ that converge much slower, there seems to be a discrepancy between theory and experiments.\n\n2. In theorem 1 and 2, the dynamics are taken to be the expectation of original dynamics over the distribution of augmentation. It seems that after taking expectations, it is essentially equivalent to inputting the original images without augmentations, which may lose an essential part of contrastive learning.\n\n3. In Theorem 2, it is assumed that the eigenvalues are of comparable magnitude, is this assumption required only on the initial value, or on the whole trajectory? In the latter case, it seems not appropriate to draw conclusions on the behavior of eigenvalues. No certain limits.",
         "335",
         "0",
         "4",
         "0.7689",
         "0.0830021645",
         "0.850540638",
         "215",
         "157",
         "31.2776",
         "14.8412",
         "17.9296",
         "16.3515",
         "16.2635",
         "0.1041",
         "96",
         "0",
         "1",
         "1",
         "0"
        ],
        [
         "169",
         "zMNUNd9zs1",
         "12836",
         "1683814821296",
         "['~Manu_Srinath_Halvagal1', '~Axel_Laborieux1', '~Friedemann_Zenke1']",
         "Implicit variance regularization in non-contrastive SSL",
         "Non-contrastive SSL methods like BYOL and SimSiam rely on asymmetric predictor networks to avoid representational collapse without negative samples. Yet, how predictor networks facilitate stable learning is not fully understood. While previous theoretical analyses assumed Euclidean losses, most practical implementations rely on cosine similarity. To gain further theoretical insight into non-contrastive SSL, we analytically study learning dynamics in conjunction with Euclidean and cosine similarity in the eigenspace of closed-form linear predictor networks. We show that both avoid collapse through implicit variance regularization albeit through different dynamical mechanisms. Moreover, we find that the eigenvalues act as effective learning rate multipliers and propose a family of isotropic loss functions (IsoLoss) that equalize convergence rates across eigenmodes. Empirically, IsoLoss speeds up the initial learning dynamics and increases robustness, thereby allowing us to dispense with the EMA target network typically used with non-contrastive methods. Our analysis sheds light on the variance regularization mechanisms of non-contrastive SSL and lays the theoretical grounds for crafting novel loss functions that shape the learning dynamics of the predictor's spectrum.",
         "Reviewer_ZNsZ",
         "1688911231025",
         "1702411401390",
         "5",
         "3",
         "2",
         "2",
         "2",
         "This work analyzes the learning dynamics of non-contrastive SSL approaches such as BYOL and Simsiam. Based on the proposed theory, the authors analyze the how the stop-grad and predictor module affect the learning dynamics. Importantly, the authors design a theoretically inspired loss and gain improvement on classification tasks. 1. This work provides solid analysis and discussion on the learning dynamics of non-contrastive SSL algorithm, which contributes to our understanding of the algorithm. Especially, they consider the widely used cosine similarity loss, while existing works only discuss Euclidean loss. They also propose an isotropic loss which is inspired by the theory.\n2. The simulation experiments helps understanding the proposed theory. 1. Lack of basic introduction to the used techniques, e.g., the neural tangent kernal (NTK).\n\n2. Lack of awareness of dividing the article into paragraphs. The preliminary, theoretical analysis and the simulation experiment are all mixed in chapter 2, which might be confusing for readers.\n\n3. The accuracy for the baseline model (BYOL) is too low. In the well-known SSL repository, solo-learn \\[1\\], the top-1 accuracy of BYOL (R-18, 1000ep) is 92.58 on CIFAR-10, and 70.46 on CIFAR-100. However, in this paper the baseline is only 89.4 and 61.1. I am afraid that this experiment cannot justify the effectiveness of the proposed isotropic loss. \n\n4. This paper mainly provides theory to understand how non-contrastive SSL algorithms work (4 pages), and the design of the isotropic loss is inspired by the theory (only half a page). I think the title of this paper is not accurate enough. 1. What does \"Gaussian i.i.d inputs\" in line 133 refer to specifically? To what extent does this setting fit the real-world scenario?\n\nOthers:\nLine 68: Replace z^{(1/2)} with z^{(1)}, z^{(2)} to avoid ambiguity\nLine 146: typo: \"lammata\"\n$\\ell_{iso}$ first appears in Fig 2. and Tab 1., which is before where it is defined.\n\nIf the author solves my concerns, then I would be willing to raise the rating.\n\n\\[1\\] https://github.com/vturrisi/solo-learn See weaknesses",
         "327",
         "3",
         "8",
         "0.7599",
         "0.004545454500000001",
         "0.8799060583",
         "215",
         "156",
         "49.0657",
         "9.3169",
         "12.1332",
         "11.6982",
         "9.9182",
         "0.1932",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "187",
         "zGRWp7yRqd",
         "7870",
         "1683736339659",
         "['~Lorenzo_Beretta1', '~Vincent_Cohen-Addad1', '~Silvio_Lattanzi1', '~Nikos_Parotsidis1']",
         "Multi-Swap k-Means++",
         "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often the practitioners' choice algorithm for optimizing the popular $k$-means clustering objective and is known to give an $O(\\log k)$-approximation in expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML 2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local-search steps obtained through the $k$-means++ sampling distribution to yield a $c$-approximation to the $k$-means clustering problem, where $c$ is a large absolute constant. Here we generalize and extend their local-search algorithm by considering larger and more sophisticated local-search neighborhoods hence allowing to  swap multiple centers at the same time. Our algorithm achieves a $9 + \\varepsilon$ approximation ratio, which is the best possible for local search. Importantly we show that our algorithm is practical, namely easy to implement and fast enough to run on a variety of classic datasets, and outputs solutions of better cost.",
         "Reviewer_coFq",
         "1687690310563",
         "1702411134520",
         "8",
         "3",
         "3",
         "4",
         "4",
         "This paper studies local-search algorithms for k-means clustering. The goal here is to obtain a local-search algorithm which (1) give a close to 9-approximation ratio (which is best possible for local search algorithms) and (2) is practical. In the past literature, there has been many local search algorithms developed for the k-means problem, but all of them either have a relatively big approximation ratio or have a prohibitive running time in practice due to the complexity of the local moves at each step. \n\nIn this paper, the authors give a simple local search algorithm which is practical and guarantees a 10.48-approximation. They also give a more complex local search which matches the approximation lower bound of 9, but with a significantly faster running time than in Kanungo et al. \\[2004\\]. However, this algorithm is significantly more complex and is unlikely to be used in practice. They also give experiments that show that their first algorithm and a slight variant of it perform well in practice.\n In my opinion, the strengths are as follows.\n1) The paper is clearly written.\n2) The first algorithm is a nice result since it combines practicality with an almost best possible theoretical guarantee. As far as I know (not being an expert), this is the first time the D^2-sampling is used and analyzed in combination with multi-swap local search. Overall, the techniques in the paper are nice. I do not see an obvious weakness in this work, the results are tight or close. Overall, I think this is a nice paper that fits well in the context of NeurIPS.  It is unclear to me if the approximation ratio of 10.48 is tight for the algorithm. As well as the 26.64 for the single swap version.\n\nIn experiment section, I do not see any discussion on the running time of the compared algorithms? Maybe it would be nice just to mention it. Yes.",
         "317",
         "1",
         "2",
         "0.752",
         "0.1347374847",
         "0.9587702751",
         "216",
         "170",
         "56.5081",
         "9.3152",
         "12.0182",
         "11.9792",
         "9.2278",
         "0.2025",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "188",
         "zGRWp7yRqd",
         "7870",
         "1683736339659",
         "['~Lorenzo_Beretta1', '~Vincent_Cohen-Addad1', '~Silvio_Lattanzi1', '~Nikos_Parotsidis1']",
         "Multi-Swap k-Means++",
         "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often the practitioners' choice algorithm for optimizing the popular $k$-means clustering objective and is known to give an $O(\\log k)$-approximation in expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML 2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local-search steps obtained through the $k$-means++ sampling distribution to yield a $c$-approximation to the $k$-means clustering problem, where $c$ is a large absolute constant. Here we generalize and extend their local-search algorithm by considering larger and more sophisticated local-search neighborhoods hence allowing to  swap multiple centers at the same time. Our algorithm achieves a $9 + \\varepsilon$ approximation ratio, which is the best possible for local search. Importantly we show that our algorithm is practical, namely easy to implement and fast enough to run on a variety of classic datasets, and outputs solutions of better cost.",
         "Reviewer_2sgw",
         "1688308249660",
         "1702411134425",
         "3",
         "4",
         "2",
         "2",
         "2",
         "This paper studies the standard $k$-means problem. Given a $k$-means instance $(P,k)$, the goal is to find a set $C$ of centers with size at most $k$ such that the sum of the squared  distances from $P$ to $C$ is minimized. For the $k$-means problem, Lattanzi and Sohler (ICML 2019) proposed an elegant combination of the local search and the $k$-means++ seeding methods. Instead of enumerating all the swap pairs constructed between the data points and the current centers, they showed that $k$-means++ sampling can be used for sampling a data point to serve as the candidate center for swapping in such that a $509$-approximation can be achieved in expectation in time $O(ndk^2loglogk)$. This paper extends the single-swap strategy to multi-swap strategy. In a single local search step, this paper shows that using $k$-means++ to sample $t$ data points induces a good $t$-swap for the local search process such that the clustering cost can be reduced significantly by at least a $\\Omega(1-1/k)$ fraction with certain probability. After $O(k^{t-1})$ local search steps, an improved approximation can be achieved related to the swap size $t$, where the total running time can be bounded by $\\tilde{O}(ndk^{2t})$. When $t$ is large enough, the approximation could be smaller than 10.48. By combining the techniques from Cohen Addad et al. (NeurIPS 2021), the papers shows that by using more local search steps (with exponential dependence on $\\epsilon$), the approximation guarantee can nearly match the lower bound of the $9+\\epsilon$ of the standard multi-swap local search method. The strengths of this paper can be summarized as follows:\n1. This paper proposes a fast multi-swap local search method for solving the standard $k$-means problem, which runs in linear time in the data size. The approximation ratio significantly improves the previous one with linear running time in the data size (i.e., 509-approximation)\n2. This paper gives another multi-swap local search method which better approximates the optimal clustering centers during the local search swaps using a subroutine called APX-CENTERS, where an improved approximation guarantee, i.e., $9+\\epsilon$, can be obtained with running time exponentially dependent on $poly(\\epsilon^{-1})$. The approximation ratio matches the approximation lower bound of local search methods for the $k$-means problem and significantly improves the running time of previous work based on direct enumeration of swap pairs constructed between the whole dataset and the current centers opened.\n3. In experiments, this paper proposes a heuristic method which avoids the exhaustive searching process for determining which subset of the sampled set of data points should be swapped in. The experiments show that the multi-swap local search method achieves better performance on clustering quality with fixed local search iterations compared with single-swap local search methods. 1. Although the authors show that sampling-based multi-swap local search can improve the approximation to a very small constant and even matches the lower bound of local search methods, the core idea behind is to use the successive $k$-means++ sampling strategy to construct candidate set of centers for swapping in, which is an extension of the sampling-based local search method (denoted as LS++ method )proposed by Lattanzi and Sohler. The claimed improvement in ratio seems to be minor as LS++ already guarantees constant approximation (in \\[1\\] the authors claimed that they did not attempt to optimize the constants and this paper verifies that LS++ can yield approximation ratio smaller than 26.4). The key idea behind the analysis for multi-swap local search method is as follows: (1) the authors further divide the optimal clusters into different groups according to their current clustering cost (i.e., $cost(P_h^*,C) \\ge \\delta ALG/k$ or $cost(P_h^*,C) < \\delta ALG/k$) (2) the authors give weights for swap pairs such that each current center can be used for at most $(1+1/t)$ times when performing a summation of all bad swap pairs. The analysis for probability lower bound that induces a good swap is similar to that of LS++ method.\n\n2. Some theoretical details is unclear to me. During the construction of ideal weighted multi-swaps, this paper partitions the optimal clustering centers and current clustering centers based on $\\tilde{O}=${\n$o_i \\ | \\ cost(O_i^*,C) \\ge \\delta ALG/k$} and $\\tilde{C}=$ $C\\backslash$ {$C\\[o_i\\] \\ | \\ o_i \\in O^* \\backslash \\tilde{O}$}. Then, in the construction of ideal multi-swaps, each swap is consist of $In$ and $Out$ such that $In \\subseteq \\tilde{O}$ and $Out \\subseteq \\tilde{C}$. If my understanding is not wrong, some of the optimal centers in $\\tilde{O}$ is not used for construction of ideal multi-swaps. If not all optimal centers is used at least once for constructing ideal multi-swaps, then the bound for summation of clustering cost for all \"bad'\" optimal clusters may not hold in Lemma 11. The ideal multi-swaps construction considers the two caes: (1) for each center $c_i \\in \\tilde{C}$ that is neither busy nor lonely, form $In$ with the optimal centers captured by $c_i$ (multi-swap) and borrow $|In|-1$ lonely centers from $L$ (2) for each center in $\\tilde{C}$ that is busy, form single swap using each of optimal centers captured by $c_i$ and the lonely centers in $L$. However, there may exist some case that for some optimal clusering center $o_i^* \\in \\tilde{O}$, the current center $c_j$ that captures $o_i^*$ is not in $\\tilde{C}$ and hence $o_i^*$ will no longer be used for constructing ideal multi-swaps. Here is an example where $o_i^*, o_2^*, o_3^*$ is the optimal clustering centers, and $c_1$, $c_2$, $c_3$ is the current centers with swap size $p=2$. In this instances, it holds that $c_1$ captures $o_1^*$ and $o_2^*$, $c_3$ captures $o_3^*$, $cost(O_1^*,C) \\ge \\delta ALG/k$, $cost(O_2^*,C)<\\delta ALG/k$ and $cost(O_3^*,C) \\ge \\delta ALG/k$. Hence, we have $\\tilde{O}=${$o_1^*,o_3^*$} and  $\\tilde{C} =${$c_2,c_3$}. During the construction of ideal multi-swaps, since $c_1$ is not in $\\tilde{C}$, $o_1^*$ will never be used during the construction. \n\n3. Another main weakness of this paper is the experiments. (1) As a local search algorithm, it’s important to validate the performance of the proposed algorithm within a certain time limitation, which is not presented in the experimental results. This paper mainly compares the experimental performances with fixed local search steps. It is unfair since multi-swap local search method takes more time than single-swap local search methods (i.e., the LS++ method). (2) In experiments, the maximum local search step is set to be 50, which is much smaller than the theoretical bounds (100000kloglogk) for obtaining good performance for LS++ algorithm. For this setting, even single-swap local search method may not converge to a good local optimal solution. The authors should present more evaluation for larger local search steps (i.e., several hundreds or thousands of local search steps) and fixed running time that is large enough for each algorithm to reach the convergence. (3) The size of the tested datasets is rather small (i.e., no larger than 500,000). However, in the recent results for clustering algorithms, instances of size over 1 million \\[1\\] or even 100 million \\[2\\] have been considered. Since multi-swap local search is much slower than the single-swap local search method (even with heuristic acceleration by avoiding the enumeration of all subsets of data points for swapping in), it is unclear that whether the proposed algorithm can scale well on large-scale datasets compared with single-swap local search method.\n\n\\[1\\] Ren J, Hua K, Cao Y. Global Optimal K-Medoids Clustering of One Million Samples\\[J\\]. Advances in Neural Information Processing Systems, 2022, 35: 982-994.\n\\[2\\] Matsui Y, Ogaki K, Yamasaki T, et al. Pqk-means: Billion-scale clustering for product-quantized codes\\[C\\]//Proceedings of the 25th ACM international conference on Multimedia. 2017: 1725-1733. 1. During the construction of ideal multi-swaps, can the construction process described in the paper guarantee that all the optimal centers in $\\tilde{O}$ is used at least once for constructing ideal multi-swaps (see the example of weakness 2). If some of the optimal clustering centers   are not used for constructing ideal multi-swaps, will the bound for summation of clustering cost for all \"bad'\" optimal clusters in Lemma 11 still hold?\n\n2. In Lemma 2, this paper shows that if the current clustering cost for some optimal cluster $O_i^*$ is larger than $(2+3\\delta)$ times its optimal clustering cost, the clustering cost of data points close to $o_i^*$ should take a large fraction (related to $\\delta$) of the whole clustering cost induced by $O_i^*$. Hence, in each local search step, the success probability for performing a good swap should be related to parameter $\\delta$, for example $\\Omega(1/\\delta)$. However, the running time of the proposed multi-swap local search algorithm is independent of $\\delta$. I think there should be at least an $\\frac{1}{\\delta}$ term in the running time, or does it mean that $\\delta$ is a constant given as the input, please explain.\n\n3. In previous multi-swap local search approximation schemes, the approximation ratio is given as a function related to the swap size $t$ (i.e., in \\[1\\], the approximation is given as $(3+2/t)^2$). However, in this paper, the approximation ratio is determined by an inequality related to $\\eta$ and $t$. Can the author provide the approximation ratio in the form similar to that of \\[1\\] such that one could figure out how large that swap size is enough for obtaining an approximation guarantee of 10.48.\n\n4. Why are all the instances in the experimental setting small? In the recent results for clustering algorithms, instances of size over 1 million \\[2\\] or even 100 million \\[3\\] have been considered. How does the proposed multi-swap local search method scale on large datasets?\n\n5. What are the performances of different local search algorithms within a certain time limitation (large enough for reaching the convergence)?\n\n\\[1\\] Kanungo T, Mount D M, Netanyahu N S, et al. A local search approximation algorithm for k-means clustering\\[C\\]//Proceedings of the eighteenth annual symposium on Computational geometry. 2002: 10-18.\n\n\\[2\\] Ren J, Hua K, Cao Y. Global Optimal K-Medoids Clustering of One Million Samples\\[J\\]. Advances in Neural Information Processing Systems, 2022, 35: 982-994.\n\n\\[3\\] Matsui Y, Ogaki K, Yamasaki T, et al. Pqk-means: Billion-scale clustering for product-quantized codes\\[C\\]//Proceedings of the 25th ACM international conference on Multimedia. 2017: 1725-1733.\n\n Since this is a theoretical paper, I don't think there is potential negative societal impact of this work. ",
         "1673",
         "12",
         "17",
         "0.7364",
         "0.07503741500000001",
         "0.9632872939",
         "216",
         "163",
         "45.3028",
         "12.5335",
         "15.416",
         "14.2216",
         "15.5248",
         "0.12560000000000002",
         "77",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "189",
         "zGRWp7yRqd",
         "7870",
         "1683736339659",
         "['~Lorenzo_Beretta1', '~Vincent_Cohen-Addad1', '~Silvio_Lattanzi1', '~Nikos_Parotsidis1']",
         "Multi-Swap k-Means++",
         "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often the practitioners' choice algorithm for optimizing the popular $k$-means clustering objective and is known to give an $O(\\log k)$-approximation in expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML 2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local-search steps obtained through the $k$-means++ sampling distribution to yield a $c$-approximation to the $k$-means clustering problem, where $c$ is a large absolute constant. Here we generalize and extend their local-search algorithm by considering larger and more sophisticated local-search neighborhoods hence allowing to  swap multiple centers at the same time. Our algorithm achieves a $9 + \\varepsilon$ approximation ratio, which is the best possible for local search. Importantly we show that our algorithm is practical, namely easy to implement and fast enough to run on a variety of classic datasets, and outputs solutions of better cost.",
         "Reviewer_FVuS",
         "1688323930331",
         "1702411134345",
         "7",
         "4",
         "4",
         "3",
         "4",
         "This paper proposes a new k-means algorithm: multi-swap local search (MSLS) which combines local search and k-means++, to achieve a constant approximation guarantee with efficient time complexity. Specifically, the local search framework includes a step that selects alternative centers for optimizing the cost function, and this paper selects those centers using the $ D^2 $-sample from k-means++  (without updating costs). \n\nThe authors prove that the random candidate centers obtained in this way lead to an improvement over the cost. By iterating on this step, MSLS will return a constant approximation result.\n\nThe author also leverage ideas from coreset and  dimensionality reducion to propose a more efficent $ 9+\\varepsilon $-approximation algorithm within the local search framework. - The paper is well written. All sources of motivations and techniques involved in this work are clearly presented, making it easy to follow the key ideas of the algoirthm and the related works. It does make a novel contribution to the classic problem.\n- The idea behind the MSLS algorithm is natural and the proofs are very clear. Although the author refer techniques from the previous work, the approximation analysis is non-trivial and results in very tight ratios.\n- The MSLS algorithm is simple and easy to implement. The experiments are comprehensive. This work is valuable in both theory and practice. - the time complexity is $ \\tilde{O} (nd k^p) $, which grows exponentially w.r.t. $p$. - Both k-means++ and local search are not limited to the Euclidean space. Can thm3 be generalized to the metric space? I notice that the analysis are influenced by \\[1\\] and there exists mean computing ($ \\mu(\\cdot) $) that prevents such generalization. However, \\[2\\] gives a constant approximation for k-means in the metric space. Therefore, I am interested in what the current analysis method lacks for the generalization and whether such limitation can be overcomed? \n\n\n\n\\[1\\] A Local Search Approximation Algorithm for k-Means Clustering\n\n\n\\[2\\] Simpler Analyses of Local Search Algorithms for Facility Location -     ",
         "327",
         "4",
         "1",
         "0.7551",
         "0.021745217100000002",
         "0.9559942484",
         "216",
         "163",
         "40.4488",
         "11.5303",
         "13.5381",
         "13.106",
         "11.824300000000001",
         "0.18580000000000002",
         "89",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "190",
         "zGRWp7yRqd",
         "7870",
         "1683736339659",
         "['~Lorenzo_Beretta1', '~Vincent_Cohen-Addad1', '~Silvio_Lattanzi1', '~Nikos_Parotsidis1']",
         "Multi-Swap k-Means++",
         "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often the practitioners' choice algorithm for optimizing the popular $k$-means clustering objective and is known to give an $O(\\log k)$-approximation in expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML 2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local-search steps obtained through the $k$-means++ sampling distribution to yield a $c$-approximation to the $k$-means clustering problem, where $c$ is a large absolute constant. Here we generalize and extend their local-search algorithm by considering larger and more sophisticated local-search neighborhoods hence allowing to  swap multiple centers at the same time. Our algorithm achieves a $9 + \\varepsilon$ approximation ratio, which is the best possible for local search. Importantly we show that our algorithm is practical, namely easy to implement and fast enough to run on a variety of classic datasets, and outputs solutions of better cost.",
         "Reviewer_swvB",
         "1688615495908",
         "1702411134252",
         "7",
         "4",
         "3",
         "3",
         "4",
         "The following results are given in the paper: \n1. A tighter analysis of the local search algorithm of Lattanzi and Sohler. The paper shows a constant approximation guarantee for their algorithm.\n2. The paper extends the approach of Lattanzi and Sohler to multi-swap local search (where more than one point is swapped in every iteration). Using this approach, an approximation guarantee of 10.48 is obtained.\n3. The paper also gives a (9+\\eps) approximation. Such a 9-approximation algorithm using local search is already known (https://www.sciencedirect.com/science/article/pii/S0925772104000215). The algorithm given in this paper has a slight running time advantage.\n\nThe algorithm is a local search algorithm. The justification of the title is that the swap-in points in the local search strategy are obtained by D^2 sampling (i.e., the sampling strategy used in k-means++). 1. Knowing a better analysis for an already published algorithm is good.\n2. Extension to multi-swap and its analysis giving better approximation guarantee is interesting.\n3. Matching the best possible approximation (possible using local search) using a slightly better running time is also interesting.\n4. The experimental section shows that the local search iterations do better than Lloyd's. This is interesting and can be of practical use. It would have been better if the running time comparison was also given to make the tradeoffs more visible. 1. The paper looks good from the point of view of extensions to the Lattanzi and Sohler work. However, from the point of view of developments in local search algorithms (which is essentially what the paper is), the improvement over (https://www.sciencedirect.com/science/article/pii/S0925772104000215) seems incremental. Even the proof techniques are similar.\n2. There are some discrepancies in the experimental section. For example, Figure 2 says \"first row...\", but there is none. I did not find the running time for the local search iterations (even MSLS-G). - Some of the other queries are mentioned above within the other fields. This work is mostly theoretical. There are no negative societal impacts.",
         "323",
         "2",
         "8",
         "0.7202000000000001",
         "0.1995614035",
         "0.9197740555",
         "216",
         "159",
         "48.1718",
         "9.2987",
         "10.7768",
         "11.4144",
         "10.5444",
         "0.0845",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "201",
         "zDbsSscmuj",
         "10291",
         "1683781343548",
         "['~Lin_Guan1', '~Karthik_Valmeekam1', '~Sarath_Sreedharan1', '~Subbarao_Kambhampati1']",
         "Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning",
         "There is a growing interest in applying pre-trained large language models (LLMs) to planning problems. However, methods that use LLMs directly as planners are currently impractical due to several factors, including limited correctness of plans, strong reliance on feedback from interactions with simulators or even the actual environment, and the inefficiency in utilizing human feedback. In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners. To address the fact that LLMs may not generate a fully functional PDDL model initially, we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans. For users who lack a background in PDDL, we show that LLMs can translate PDDL into natural language and effectively encode corrective feedback back to the underlying domain model. Our framework not only enjoys the correctness guarantee offered by the external planners but also reduces human involvement by allowing users to correct domain models at the beginning, rather than inspecting and correcting (through interactive prompting) every generated plan as in previous work. On two IPC domains and a Household domain that is more complicated than commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be leveraged to produce high-quality PDDL models for over 40 actions, and the corrected PDDL models are then used to successfully solve 48 challenging planning tasks. Resources, including the source code, are released at: https://guansuns.github.io/pages/llm-dm.",
         "Reviewer_iFiN",
         "1688658497528",
         "1702411277915",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper proposed to apply GPT LLMs to perform PDDL model construction from natural language description and correction with feedbacks, and then use classic planners or LLM planners to construct plans from the PDDL models. Experiments were conducted in the synthetic domains to verify the proposal and found that GPT-4 can construct PPDL models with less errors and classic PDDL planner outperforms LLM planners with the constructed PPDL models. 1. This is a new exploration of using LLMs to construct PDDL models (or symbolic world models for AI planning)\n2. Experiments are conducted to compare the performance of LLM planner and classic PDDL planner on the constructed PDDL models, and find that classic planner works better on PDDL model extracted by LLMs. 1. No theoretical framework is proposed to link the underlying probability models of token sequences of  LLMs to the domain and action models described by formal action description languages and its formal handling (e.g. planning, validation, correction and son). Without such a theoretical formal characterization, it is difficult to evaluate the validity and applicability/boundary of this kind of approach built on top of the LLMs, prompt-engineering, chains of feedback correction and planning and so on. \n2. A few experiments are given but without a systematic handling of metrics and the underlying hypotheses to be verified, and explanation to guide the application of the proposal and future research. The experimental methodology is ad-hoc. 1. Please explain the underlying models of LLMs on generating the PDDL domains and the feedback-correction mechanism; at least, explain or discuss your intuition. \n2. Have you deployed the plans to real-world fetch manipulator? If you did, how does it work? \n3. As your scenario is with fetch manipulator, have you try to use the LLMs to generate continuous parameters for the action operators? If not, please discuss the missing steps and future work is needed. \n4. What will be the solution to connect PDDL plans to real world execution? PDDL stream might be something you want to look at; explore how LLMs approach can be further extended to work with the full stack of task-and-motion planning systems like PDDL stream (https://github.com/caelan/pddlstream). \n5. Please discuss the difference between GPT-4 and GPT-3.5 rendering different results in Table 1. This will be helpful guide  readers in choosing the right LLMs to apply your proposal. NA",
         "387",
         "1",
         "9",
         "0.7518",
         "0.0847170686",
         "0.8813825846000001",
         "215",
         "159",
         "42.5378",
         "12.3862",
         "14.7624",
         "13.7764",
         "13.9716",
         "0.2908",
         "90",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 4465
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8720</td>\n",
       "      <td>15.9897</td>\n",
       "      <td>14.4442</td>\n",
       "      <td>13.2649</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0922</td>\n",
       "      <td>15.3049</td>\n",
       "      <td>14.1918</td>\n",
       "      <td>12.6374</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7200</td>\n",
       "      <td>10.1878</td>\n",
       "      <td>10.7063</td>\n",
       "      <td>7.5081</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3916</td>\n",
       "      <td>17.9549</td>\n",
       "      <td>16.1666</td>\n",
       "      <td>14.5827</td>\n",
       "      <td>0.5533</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>zsOOqjaj2z</td>\n",
       "      <td>5668</td>\n",
       "      <td>1683686700553</td>\n",
       "      <td>[~Yuanyuan_Wang5, ~Xi_Geng1, ~Wei_Huang8, ~Biw...</td>\n",
       "      <td>Generator Identification for Linear SDEs with ...</td>\n",
       "      <td>In this paper, we present conditions for ident...</td>\n",
       "      <td>Reviewer_Huoq</td>\n",
       "      <td>1688427159321</td>\n",
       "      <td>1702411021240</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7233</td>\n",
       "      <td>18.3038</td>\n",
       "      <td>15.5797</td>\n",
       "      <td>13.6786</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0714</td>\n",
       "      <td>13.0114</td>\n",
       "      <td>12.5486</td>\n",
       "      <td>10.1760</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7042</td>\n",
       "      <td>14.5675</td>\n",
       "      <td>13.9100</td>\n",
       "      <td>11.9698</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.2691</td>\n",
       "      <td>13.9387</td>\n",
       "      <td>13.4543</td>\n",
       "      <td>11.2038</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9547</td>\n",
       "      <td>18.5308</td>\n",
       "      <td>16.4682</td>\n",
       "      <td>16.3810</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1560</td>\n",
       "      <td>17.2540</td>\n",
       "      <td>15.6161</td>\n",
       "      <td>13.6344</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4465 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "21       zsOOqjaj2z               5668             1683686700553   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "21     [~Yuanyuan_Wang5, ~Xi_Geng1, ~Wei_Huang8, ~Biw...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "21     Generator Identification for Linear SDEs with ...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "21     In this paper, we present conditions for ident...  Reviewer_Huoq   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1688368213177           1702411303415              6  ...   \n",
       "1      1688505633161           1702411303319              6  ...   \n",
       "2      1688552936677           1702411303221              6  ...   \n",
       "3      1688657604892           1702411303144              6  ...   \n",
       "21     1688427159321           1702411021240              7  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "15170  1688676041356           1702411081106              6  ...   \n",
       "15171  1688449656890           1702411268900              7  ...   \n",
       "15172  1688485585833           1702411268818              5  ...   \n",
       "15173  1688665406904           1702411268706              4  ...   \n",
       "15174  1688755793651           1702411268608              4  ...   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "0                   12.8720      15.9897     14.4442   \n",
       "1                   13.0922      15.3049     14.1918   \n",
       "2                    7.7200      10.1878     10.7063   \n",
       "3                   14.3916      17.9549     16.1666   \n",
       "21                  13.7233      18.3038     15.5797   \n",
       "...                     ...          ...         ...   \n",
       "15170               10.0714      13.0114     12.5486   \n",
       "15171               11.7042      14.5675     13.9100   \n",
       "15172               11.2691      13.9387     13.4543   \n",
       "15173               14.9547      18.5308     16.4682   \n",
       "15174               13.1560      17.2540     15.6161   \n",
       "\n",
       "       automated_readability_index politeness_score  hedge_C  hedge_D  \\\n",
       "0                          13.2649           0.0948       86        0   \n",
       "1                          12.6374           0.0690       94        0   \n",
       "2                           7.5081           0.1601       73        0   \n",
       "3                          14.5827           0.5533       90        0   \n",
       "21                         13.6786           0.7285       91        1   \n",
       "...                            ...              ...      ...      ...   \n",
       "15170                      10.1760           0.0667       94        0   \n",
       "15171                      11.9698           0.1450       93        0   \n",
       "15172                      11.2038           0.1508      107        0   \n",
       "15173                      16.3810           0.1249      107        0   \n",
       "15174                      13.6344           0.1932       98        0   \n",
       "\n",
       "       hedge_E  hedge_I  hedge_N  \n",
       "0            0        0        0  \n",
       "1            0        0        0  \n",
       "2            0        0        0  \n",
       "3            0        0        0  \n",
       "21           0        0        2  \n",
       "...        ...      ...      ...  \n",
       "15170        0        0        0  \n",
       "15171        1        1        0  \n",
       "15172        0        0        0  \n",
       "15173        0        0        0  \n",
       "15174        0        0        0  \n",
       "\n",
       "[4465 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Randomly select 1000 unique submission_number values\n",
    "selected_submission_numbers = random.sample(df['submission_number'].unique().tolist(), 1000)\n",
    "\n",
    "# Filter rows with the selected submission_number values\n",
    "df_1000 = df[df['submission_number'].isin(selected_submission_numbers)]\n",
    "\n",
    "# Display the new dataframe\n",
    "df_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000.to_json('/home/ali/Review_Quality_Benchmark/data/processed/neurips2023_1000_papers.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
