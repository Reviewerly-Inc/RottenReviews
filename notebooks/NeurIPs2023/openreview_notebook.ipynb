{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V0 - V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openreview-py numpy pandas nltk transformers tqdm torch\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install pylats taaled spacy convokit\n",
    "\n",
    "# English models\n",
    "# %python -m spacy download en_core_web_sm\n",
    "# %python -m spacy download en_core_web_trf\n",
    "# # Spanish models (used as fallback)\n",
    "# %python -m spacy download es_core_news_sm\n",
    "# %python -m spacy download es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available?  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is GPU available? \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ali/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "/home/ali/Review_Quality_Benchmark/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotnine has not been installed.\n",
      "To enable advanced data visualization features, please install plotnine.\n",
      "Attempting to load spacy model: en_core_web_sm\n",
      "Successfully loaded spacy model: en_core_web_sm\n",
      "Attempting to load spacy model: en_core_web_trf\n",
      "Successfully loaded spacy model: en_core_web_trf\n",
      "Attempting to load spacy model: es_core_news_sm\n",
      "Successfully loaded spacy model: es_core_news_sm\n",
      "Attempting to load spacy model: es_dep_news_trf\n",
      "Successfully loaded spacy model: es_dep_news_trf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "import csv\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "from taaled import ld\n",
    "from pylats import lats\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ICLR 2024\n",
    "# file_path = '/home/ali/Review_Quality_Benchmark/data/raw/OpenReview/ICLR2024/ICLR2024_submissions.pkl'\n",
    "\n",
    "# NEURIPS 2023\n",
    "file_path = '/home/ali/Review_Quality_Benchmark/data/raw/OpenReview/neurips2023/neurips2023_submissions.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as pkl_file:\n",
    "    data = pickle.load(pkl_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to JSON file at: /home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v0.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Replace 'your_file.pkl' with the path to your .pkl file\n",
    "file_path = '/home/ali/Review_Quality_Benchmark/data/raw/OpenReview/neurips2023/neurips2023_submissions.pkl'\n",
    "output_json_path = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v0.json'\n",
    "\n",
    "# Load the .pkl file\n",
    "with open(file_path, 'rb') as pkl_file:\n",
    "    data = pickle.load(pkl_file)\n",
    "\n",
    "# Extract the required fields for each submission\n",
    "extracted_data = []\n",
    "for submission in data:\n",
    "    extracted_data.append({\n",
    "        'number': submission.number if hasattr(submission, 'number') else np.nan,\n",
    "        'id': submission.id if hasattr(submission, 'id') else np.nan,\n",
    "        'content.paperhash': submission.content['paperhash']['value'] if 'paperhash' in submission.content and 'value' in submission.content['paperhash'] else np.nan,\n",
    "        'content.authorids': submission.content['authorids']['value'] if 'authorids' in submission.content and 'value' in submission.content['authorids'] else np.nan,\n",
    "        'cdate': submission.cdate if hasattr(submission, 'cdate') else np.nan,\n",
    "        'content.title': submission.content['title']['value'] if 'title' in submission.content and 'value' in submission.content['title'] else np.nan,\n",
    "        'content.abstract': submission.content['abstract']['value'] if 'abstract' in submission.content and 'value' in submission.content['abstract'] else np.nan,\n",
    "        # 'content.TLDR': submission.content['TLDR']['value'] if 'TLDR' in submission.content and 'value' in submission.content['TLDR'] else np.nan,\n",
    "    })\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Save the DataFrame to a JSON file\n",
    "df.to_json(output_json_path, orient='records', indent=4)\n",
    "\n",
    "print(f\"DataFrame saved to JSON file at: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content.paperhash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content.authorids",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "content.title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content.abstract",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a8b7b4ce-637f-4d27-a041-2a1cccece2bd",
       "rows": [
        [
         "0",
         "10819",
         "zyhxRc9bew",
         "sun|what_is_flagged_in_uncertainty_quantification_latent_density_models_for_uncertainty_categorization",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "1683789038840",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark."
        ],
        [
         "1",
         "15594",
         "zyZkaqNnpa",
         "puli|dont_blame_dataset_shift_shortcut_learning_due_to_gradients_and_cross_entropy",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "1683835167534",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks."
        ],
        [
         "2",
         "327",
         "zuXyQsXVLF",
         "xu|enhancing_adversarial_contrastive_learning_via_adversarial_invariant_regularization",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "1682066194522",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR."
        ],
        [
         "3",
         "801",
         "ztqf6bzuqQ",
         "shi|hybrid_distillation_connecting_masked_autoencoders_with_contrastive_learners",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "1682507396411",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks."
        ],
        [
         "4",
         "7411",
         "ztDxO15N7f",
         "scholkemper|an_optimizationbased_approach_to_node_role_discovery_in_networks_approximating_equitable_partitions",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "1683729208530",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way."
        ],
        [
         "5",
         "5668",
         "zsOOqjaj2z",
         "wang|generator_identification_for_linear_sdes_with_additive_and_multiplicative_noise",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "1683686700553",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings."
        ],
        [
         "6",
         "8399",
         "zrUEHZ6s9C",
         "zhang|algorithm_selection_for_deep_active_learning_with_imbalanced_datasets",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "1683746518064",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR."
        ],
        [
         "7",
         "2448",
         "zrLxHYvIFL",
         "wang|discover_and_align_taxonomic_context_priors_for_openworld_semisupervised_learning",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "1683361520146",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA."
        ],
        [
         "8",
         "11147",
         "zrCmeqV3Sz",
         "xia|learning_invariant_representations_of_graph_neural_networks_via_cluster_generalization",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "1683793236823",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance."
        ],
        [
         "9",
         "813",
         "zqyVjCjhYD",
         "bianchi|the_expressive_power_of_pooling_in_graph_neural_networks",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "1682515100473",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test."
        ],
        [
         "10",
         "2649",
         "zqOcW3R9rd",
         "wei|shared_adversarial_unlearning_backdoor_mitigation_by_unlearning_shared_adversarial_examples",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "1683428990794",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore)."
        ],
        [
         "11",
         "8789",
         "zq4vFneRiA",
         "dai|the_crucial_role_of_normalization_in_sharpnessaware_minimization",
         "['~Yan_Dai1', '~Kwangjun_Ahn2', '~Suvrit_Sra1']",
         "1683754773269",
         "The Crucial Role of Normalization in Sharpness-Aware Minimization",
         "Sharpness-Aware Minimization (SAM) is a recently proposed gradient-based optimizer (Foret et al., ICLR 2021) that greatly improves the prediction performance of deep neural networks. Consequently, there has been a surge of interest in explaining its empirical success. We focus, in particular, on understanding ***the role played by normalization***, a key component of the SAM updates. We theoretically and empirically study the effect of normalization in SAM for both convex and non-convex functions, revealing two key roles played by normalization: i) it helps in stabilizing the algorithm; and ii) it enables the algorithm to drift along a continuum (manifold) of minima -- a property identified by recent theoretical works that is the key to better performance. We further argue that these two properties of normalization make SAM robust against the choice of hyper-parameters, supporting the practicality of SAM. Our conclusions are backed by various experiments."
        ],
        [
         "12",
         "8250",
         "zpVCITHknd",
         "wang|towards_personalized_federated_learning_via_heterogeneous_model_reassembly",
         "['~Jiaqi_Wang4', '~Xingyi_Yang1', '~Suhan_Cui1', '~Liwei_Che1', '~Lingjuan_Lyu1', '~Dongkuan_Xu2', '~Fenglong_Ma1']",
         "1683743540260",
         "Towards Personalized Federated Learning via Heterogeneous Model Reassembly",
         "This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. To track this problem, we propose a novel framework called pFedHR, which leverages heterogeneous model reassembly to achieve personalized federated learning. In particular, we approach the problem of heterogeneous model personalization as a model-matching optimization task on the server side. Moreover, pFedHR automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention. Furthermore, our proposed heterogeneous model reassembly technique mitigates the adverse impact introduced by using public data with different distributions from the client data to a certain extent. Experimental results demonstrate that pFedHR outperforms baselines on three datasets under both IID and Non-IID settings. Additionally, pFedHR effectively reduces the adverse impact of using different public data and dynamically generates diverse personalized models in an automated manner."
        ],
        [
         "13",
         "5115",
         "znudaK78u8",
         "hwang|active_learning_for_semantic_segmentation_with_multiclass_label_query",
         "['~Sehyun_Hwang1', '~Sohyun_Lee1', '~Hoyoung_Kim1', '~Minhyeon_Oh1', '~Jungseul_Ok2', '~Suha_Kwak3']",
         "1683654851515",
         "Active Learning for Semantic Segmentation with Multi-class Label Query",
         "This paper proposes a new active learning method for semantic segmentation. The core of our method lies in a new annotation query design. It samples informative local image regions ($\\textit{e.g.}$, superpixels), and for each of such regions, asks an oracle for a multi-hot vector indicating all classes existing in the region. This multi-class labeling strategy is substantially more efficient than existing ones like segmentation, polygon, and even dominant class labeling in terms of annotation time per click. However, it introduces the class ambiguity issue in training as it assigns partial labels ($\\textit{i.e.}$, a set of candidate classes) to individual pixels. We thus propose a new algorithm for learning semantic segmentation while disambiguating the partial labels in two stages. In the first stage, it trains a segmentation model directly with the partial labels through two new loss functions motivated by partial label learning and multiple instance learning. In the second stage, it disambiguates the partial labels by generating pixel-wise pseudo labels, which are used for supervised learning of the model. Equipped with a new acquisition function dedicated to the multi-class labeling, our method outperforms previous work on Cityscapes and PASCAL VOC 2012 while spending less annotation cost. Our code and results are available at [https://github.com/sehyun03/MulActSeg](https://github.com/sehyun03/MulActSeg)."
        ],
        [
         "14",
         "2253",
         "znY173SCxu",
         "kim|timereversed_dissipation_induces_duality_between_minimizing_gradient_norm_and_function_value",
         "['~Jaeyeon_Kim2', '~Asuman_E._Ozdaglar1', '~Chanwoo_Park2', '~Ernest_K._Ryu1']",
         "1683313199054",
         "Time-Reversed Dissipation Induces Duality Between Minimizing Gradient Norm and Function Value",
         "In convex optimization, first-order optimization methods efficiently minimizing function values have been a central subject study since Nesterov's seminal work of 1983. Recently, however, Kim and Fessler's OGM-G and Lee et al.'s FISTA-G have been presented as alternatives that efficiently minimize the gradient magnitude instead. In this paper, we present H-duality, which represents a surprising one-to-one correspondence between methods efficiently minimizing function values and methods efficiently minimizing gradient magnitude. In continuous-time formulations, H-duality corresponds to reversing the time dependence of the dissipation/friction term. To the best of our knowledge, H-duality is different from Lagrange/Fenchel duality and is distinct from any previously known duality or symmetry relations. Using H-duality, we obtain a clearer understanding of the symmetry between Nesterov's method and OGM-G, derive a new class of methods efficiently reducing gradient magnitudes of smooth convex functions, and find a new composite minimization method that is simpler and faster than FISTA-G."
        ],
        [
         "15",
         "4945",
         "znW5jNIOED",
         "zhang|optimizing_over_trained_gnns_via_symmetry_breaking",
         "['~Shiqiang_Zhang1', '~Juan_S_Campos1', '~Christian_Wolfgang_Feldmann1', '~David_Walz1', '~Frederik_Sandfort1', '~Miriam_Mathea1', '~Calvin_Tsay1', '~Ruth_Misener1']",
         "1683646917954",
         "Optimizing over trained GNNs via symmetry breaking",
         "Optimization over trained machine learning models has applications including: verification, minimizing neural acquisition functions, and integrating a trained surrogate into a larger decision-making problem. This paper formulates and solves optimization problems constrained by trained graph neural networks (GNNs). To circumvent the symmetry issue caused by graph isomorphism, we propose two types of symmetry-breaking constraints: one indexing a node 0 and one indexing the remaining nodes by lexicographically ordering their neighbor sets. To guarantee that adding these constraints will not remove all symmetric solutions, we construct a graph indexing algorithm and prove that the resulting graph indexing satisfies the proposed symmetry-breaking constraints. For the classical GNN architectures considered in this paper, optimizing over a GNN with a fixed graph is equivalent to optimizing over a dense neural network. Thus, we study the case where the input graph is not fixed, implying that each edge is a decision variable, and develop two mixed-integer optimization formulations. To test our symmetry-breaking strategies and optimization formulations, we consider an application in molecular design."
        ],
        [
         "16",
         "9206",
         "zn5ihqknGj",
         "xiao|an_alternating_optimization_method_for_bilevel_problems_under_the_polyakojasiewicz_condition",
         "['~Quan_Xiao1', '~Songtao_Lu1', '~Tianyi_Chen5']",
         "1683764248024",
         "An Alternating Optimization Method for Bilevel Problems under the Polyak-Łojasiewicz Condition",
         "Bilevel optimization has recently regained interest owing to its applications in emerging machine learning fields such as hyperparameter optimization, meta-learning, and reinforcement learning. Recent results have shown that simple alternating (implicit) gradient-based algorithms can match the convergence rate of single-level gradient descent (GD) when addressing bilevel problems with a strongly convex lower-level objective. However, it remains unclear whether this result can be generalized to bilevel problems beyond this basic setting. In this paper, we first introduce a stationary metric for the considered bilevel problems, which generalizes the existing metric, for a nonconvex lower-level objective that satisfies the Polyak-Łojasiewicz (PL) condition. We then propose a Generalized ALternating mEthod for bilevel opTimization (GALET) tailored to BLO with convex PL LL problem and establish that GALET achieves an $\\epsilon$-stationary point for the considered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations, which matches the iteration complexity of GD for single-level smooth nonconvex problems."
        ],
        [
         "17",
         "13421",
         "zmWNe1V6jg",
         "rui|scalable_fair_influence_maximization",
         "['~Xiaobin_Rui2', '~Zhixiao_Wang2', '~Jiayu_Zhao2', '~Lichao_Sun1', '~Wei_Chen10']",
         "1683819112745",
         "Scalable Fair Influence Maximization",
         "Given a graph $G$, a community structure $\\mathcal{C}$, and a budget $k$, the fair influence maximization problem aims to select a seed set $S$ ($|S|\\leq k$) that maximizes the influence spread while narrowing the influence gap between different communities. While various fairness notions exist, the welfare fairness notion, which balances fairness level and influence spread, has shown promising effectiveness. However, the lack of efficient algorithms for optimizing the welfare fairness objective function restricts its application to small-scale networks with only a few hundred nodes. In this paper, we adopt the objective function of welfare fairness to maximize the exponentially weighted summation over the influenced fraction of all communities. We first introduce an unbiased estimator for the fractional power of the arithmetic mean. Then, by adapting the reverse influence sampling (RIS) approach, we convert the optimization problem to a weighted maximum coverage problem. We also analyze the number of reverse reachable sets needed to approximate the fair influence at a high probability. Further, we present an efficient algorithm that guarantees $1-1/e - \\varepsilon$ approximation."
        ],
        [
         "18",
         "10441",
         "zkfyOkBVpz",
         "sheybani|curriculum_learning_with_infant_egocentric_videos",
         "['~Saber_Sheybani1', '~Himanshu_Hansaria1', '~Justin_Newell_Wood1', '~Linda_B._Smith1', '~Zoran_Tiganj1']",
         "1683783734526",
         "Curriculum Learning With Infant Egocentric Videos",
         "Infants possess a remarkable ability to rapidly learn and process visual inputs. As an infant's mobility increases, so does the variety and dynamics of their visual inputs. Is this change in the properties of the visual inputs beneficial or even critical for the proper development of the visual system? To address this question, we used video recordings from infants wearing head-mounted cameras to train a variety of self-supervised learning models. Critically, we separated the infant data by age group and evaluated the importance of training with a curriculum aligned with developmental order. We found that initiating learning with the data from the youngest age group provided the strongest learning signal and led to the best learning outcomes in terms of downstream task performance. We then showed that the benefits of the data from the youngest age group are due to the slowness and simplicity of the visual experience. The results provide strong empirical evidence for the importance of the properties of the early infant experience and developmental progression in training. More broadly, our approach and findings take a noteworthy step towards reverse engineering the learning mechanisms in newborn brains using image-computable models from artificial intelligence."
        ],
        [
         "19",
         "8270",
         "zjpjsJeVJZ",
         "tsepenekas|comparing_apples_to_oranges_learning_similarity_functions_for_data_produced_by_different_distributions",
         "['~Leonidas_Tsepenekas1', '~Ivan_Brugere1', '~Freddy_Lecue1', '~Daniele_Magazzeni1']",
         "1683743963779",
         "Comparing Apples to Oranges: Learning Similarity Functions for Data Produced by Different Distributions",
         "Similarity functions measure how comparable pairs of elements are, and play a key role in a wide variety of applications, e.g., notions of Individual Fairness abiding by the seminal paradigm of Dwork et al., as well as Clustering problems. However, access to an accurate similarity function should not always be considered guaranteed, and this point was even raised by Dwork et al. For instance, it is reasonable to assume that when the elements to be compared are produced by different distributions, or in other words belong to different ``demographic'' groups, knowledge of their true similarity might be very difficult to obtain. In this work, we present an efficient sampling framework that learns these across-groups similarity functions, using only a limited amount of experts' feedback. We show analytical results with rigorous theoretical bounds, and empirically validate our algorithms via a large suite of experiments."
        ],
        [
         "20",
         "1026",
         "zfHCKDzzC8",
         "hzl|temporal_causal_mediation_through_a_point_process_direct_and_indirect_effects_of_healthcare_interventions",
         "['~Çağlar_Hızlı1', '~S._T._John1', '~Anne_Tuulikki_Juuti1', '~Tuure_Tapani_Saarinen1', '~Kirsi_Hannele_Pietiläinen1', '~Pekka_Marttinen1']",
         "1682687320755",
         "Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions",
         "Deciding on an appropriate intervention requires a causal model of a treatment, the outcome, and potential mediators. Causal mediation analysis lets us distinguish between direct and indirect effects of the intervention, but has mostly been studied in a static setting. In healthcare, data come in the form of complex, irregularly sampled time-series, with dynamic interdependencies between a treatment, outcomes, and mediators across time. Existing approaches to dynamic causal mediation analysis are limited to regular measurement intervals, simple parametric models, and disregard long-range mediator--outcome interactions. To address these limitations, we propose a non-parametric mediator--outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. With this model, we estimate the direct and indirect effects of an external intervention on the outcome, showing how each of these affects the whole future trajectory. We demonstrate on semi-synthetic data that our method can accurately estimate direct and indirect effects. On real-world healthcare data, our model infers clinically  meaningful direct and indirect effect trajectories for blood glucose after a surgery."
        ],
        [
         "21",
         "12252",
         "zfCNwRQ569",
         "li|interpreting_unsupervised_anomaly_detection_in_security_via_rule_extraction",
         "['~Ruoyu_Li4', '~Qing_Li15', 'eli.yuzhang@gmail.com', '~Dan_Zhao2', '~Yong_Jiang3', '~Yong_Yang8']",
         "1683809116290",
         "Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction",
         "Many security applications require unsupervised anomaly detection, as malicious data are extremely rare and often only unlabeled normal data are available for training (i.e., zero-positive). However, security operators are concerned about the high stakes of trusting black-box models due to their lack of interpretability. In this paper, we propose a post-hoc method to globally explain a black-box unsupervised anomaly detection model via rule extraction.\nFirst, we propose the concept of distribution decomposition rules that decompose the complex distribution of normal data into multiple compositional distributions. To find such rules, we design an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. By merging these two types of rules into a rule set, we can present the inferential process of the unsupervised black-box model in a human-understandable way, and build a surrogate rule-based model for online deployment at the same time. \nWe conduct comprehensive experiments on the explanation of four distinct unsupervised anomaly detection models on various real-world datasets. The evaluation shows that our method outperforms existing methods in terms of diverse metrics including fidelity, correctness and robustness."
        ],
        [
         "22",
         "24",
         "zdli6OxpWd",
         "steinke|counting_distinct_elements_under_personlevel_differential_privacy",
         "['~Thomas_Steinke2', '~Alexander_Knop1']",
         "1681869011996",
         "Counting Distinct Elements Under Person-Level Differential Privacy",
         "We study the problem of counting the number of distinct elements in a dataset subject to the constraint of differential privacy. \nWe consider the challenging setting of person-level DP (a.k.a. user-level DP) where each person may contribute an unbounded number of items and hence the sensitivity is unbounded.\n\nOur approach is to compute a bounded-sensitivity version of this query, which reduces to solving a max-flow problem. \nThe sensitivity bound is optimized to balance the noise we must add to privatize the answer against the error of the approximation of the bounded-sensitivity query to the true number of unique elements."
        ],
        [
         "23",
         "14663",
         "zaQ7wV9NOg",
         "liu|optimistic_natural_policy_gradient_a_simple_efficient_policy_optimization_framework_for_online_rl",
         "['~Qinghua_Liu1', '~Gellért_Weisz2', '~András_György2', '~Chi_Jin1', '~Csaba_Szepesvari1']",
         "1683828212146",
         "Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework  for Online RL",
         "While policy optimization algorithms have played an important role in recent empirical success of Reinforcement Learning (RL), the existing theoretical understanding of policy optimization remains rather limited---they are either restricted to tabular MDPs or suffer from highly suboptimal sample complexity, especial in online RL where exploration is necessary. This paper proposes a simple efficient policy optimization framework---Optimistic NPG for online RL. Optimistic NPG can be viewed as simply combining of the classic natural policy gradient (NPG) algorithm [Kakade, 2001]  with optimistic policy evaluation subroutines to encourage exploration. For $d$-dimensional linear MDPs, Optimistic NPG is computationally efficient, and learns an $\\epsilon$-optimal policy within  $\\tilde{\\mathcal{O}}(d^2/\\epsilon^3)$ samples, which is the first computationally efficient algorithm whose sample complexity has the optimal dimension dependence $\\tilde{\\Theta}(d^2)$. It also improves over state-of-the-art results of policy optimization algorithms [Zanette et al., 2021] by a factor of $d$. For general function approximation that subsumes linear MDPs, Optimistic NPG, to our best knowledge, is also the first policy optimization algorithm that achieves the polynomial sample complexity for learning near-optimal policies."
        ],
        [
         "24",
         "13137",
         "zXckveawHa",
         "lin|statistical_limits_of_adaptive_linear_models_lowdimensional_estimation_and_inference",
         "['~Licong_Lin2', '~Mufang_Ying1', '~Suvrojit_Ghosh1', '~Koulik_Khamaru1', '~Cun-Hui_Zhang1']",
         "1683817138834",
         "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
         "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a  single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator."
        ],
        [
         "25",
         "10346",
         "zWxKYyW9ik",
         "wang|universality_and_limitations_of_prompt_tuning",
         "['~Yihan_Wang2', '~Jatin_Chauhan3', '~Wei_Wang13', '~Cho-Jui_Hsieh1']",
         "1683782196307",
         "Universality and Limitations of Prompt Tuning",
         "Despite the demonstrated empirical efficacy of prompt tuning to adapt a pretrained language model for a new task, the theoretical underpinnings of the difference between \"tuning parameters before the input\" against \"the tuning of model weights\" are limited. We thus take one of the first steps to understand the role of soft-prompt tuning for transformer-based architectures. By considering a general purpose architecture, we analyze prompt tuning from the lens of both: universal approximation and limitations with finite-depth fixed-weight pretrained transformers for continuous-valued functions. Our universality result guarantees the existence of a strong transformer with a prompt to approximate any sequence-to-sequence function in the set of Lipschitz functions. The limitations of prompt tuning for limited-depth transformers are first proved by constructing a set of datasets, that cannot be memorized by a prompt of any length for a given single encoder layer. We also provide a lower bound on the required number of tunable prompt parameters and compare the result with the number of parameters required for a low-rank update (based on LoRA) for a single-layer setting. We finally extend our analysis to multi-layer settings by providing sufficient conditions under which the transformer can at best learn datasets from invertible functions only. Our theoretical claims are also corroborated by empirical results."
        ],
        [
         "26",
         "5119",
         "zW1uVN6Mbv",
         "sturma|unpaired_multidomain_causal_representation_learning",
         "['~Nils_Sturma1', '~Chandler_Squires1', '~Mathias_Drton2', '~Caroline_Uhler1']",
         "1683655335197",
         "Unpaired Multi-Domain Causal Representation Learning",
         "The goal of causal representation learning is to find a representation of data that consists of causally related latent variables. We consider a setup where one has access to data from multiple domains that potentially share a causal representation. Crucially, observations in different domains are assumed to be unpaired, that is, we only observe the marginal distribution in each domain but not their joint distribution. In this paper, we give sufficient conditions for identifiability of the joint distribution and the shared causal graph in a linear setup. Identifiability holds if we can uniquely recover the joint distribution and the shared causal representation from the marginal distributions in each domain. We transform our results into a practical method to recover the shared latent causal graph."
        ],
        [
         "27",
         "10353",
         "zUYfbdNl1m",
         "jin|s^3_increasing_gpu_utilization_during_generative_inference_for_higher_throughput",
         "['~Yunho_Jin1', '~Chun-Feng_Wu1', '~David_Brooks1', '~Gu-Yeon_Wei1']",
         "1683782302705",
         "$S^3$: Increasing GPU Utilization during Generative Inference for Higher Throughput",
         "Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose $S^3$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49× throughput over those systems that assume the worst case for the output sequence length."
        ],
        [
         "28",
         "12494",
         "zTSlm4nmlH",
         "zhou|beta_diffusion",
         "['~Mingyuan_Zhou1', '~Tianqi_Chen2', '~Zhendong_Wang1', '~Huangjie_Zheng1']",
         "1683811747193",
         "Beta Diffusion",
         "We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization. Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them."
        ],
        [
         "29",
         "9772",
         "zR6V9fPRBn",
         "zheng|exploiting_negative_samples_a_catalyst_for_cohort_discovery_in_healthcare_analytics",
         "['~Kaiping_Zheng1', '~Horng-Ruey_Chua1', '~Melanie_Herschel1', '~H._Jagadish1', '~Beng_Chin_Ooi1', '~James_Wei_Luen_Yip2']",
         "1683774104431",
         "Exploiting Negative Samples: A Catalyst for Cohort Discovery in Healthcare Analytics",
         "Healthcare analytics, particularly binary diagnosis or prognosis problems, present unique challenges due to the inherent asymmetry between positive and negative samples. While positive samples, representing patients who develop a disease, are defined through rigorous medical criteria, negative samples are defined in an open-ended manner, resulting in a vast potential set. Despite this fundamental asymmetry, previous research has underexplored the role of negative samples, possibly due to the enormous challenge of investigating an infinitely large negative sample space. To bridge this gap, we propose an approach to facilitate cohort discovery within negative samples, which could yield valuable insights into the studied disease, as well as its comorbidity and complications. We measure each sample’s contribution using data Shapley values and construct the Negative Sample Shapley Field to model the distribution of all negative samples. Then we transform this field via manifold learning, preserving the data structure information while imposing an isotropy constraint in data Shapley values. Within this transformed space, we identify cohorts of medical interest through density-based clustering. We empirically evaluate the effectiveness of our approach on our hospital’s electronic medical records. The medical insights revealed in the discovered cohorts are validated by clinicians, which affirms the medical value of our proposal in unveiling meaningful insights consistent with existing domain knowledge, thereby bolstering medical research and well-informed clinical decision-making."
        ],
        [
         "30",
         "3702",
         "zQTi3pziFp",
         "xu|sounding_bodies_modeling_3d_spatial_sound_of_humans_using_body_pose_and_audio",
         "['~Xudong_XU1', '~Dejan_Markovic1', 'jasandakly@meta.com', 'toddkeebler@meta.com', '~Steven_Krenn1', '~Alexander_Richard1']",
         "1683568608068",
         "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and Audio",
         "While 3D human body modeling has received much attention in computer vision, modeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by body motion and speech, has fallen short in the community. To close this gap, we present a model that can generate accurate 3D spatial audio for full human bodies. The system consumes, as input, audio signals from headset microphones and body pose, and produces, as output, a 3D sound field surrounding the transmitter's body, from which spatial audio can be rendered at any arbitrary position in the 3D space. We collect a first-of-its-kind multimodal dataset of human bodies, recorded with multiple cameras and a spherical array of 345 microphones. In an empirical evaluation, we demonstrate that our model can produce accurate body-induced sound fields when trained with a suitable loss. Dataset and code are available online."
        ],
        [
         "31",
         "4269",
         "zQOYGDc9pu",
         "chen|optimized_covariance_design_for_ab_test_on_social_network_under_interference",
         "['~Qianyi_Chen2', '~Bo_Li29', '~LU_DENG1', '~Yong_Wang11']",
         "1683616915036",
         "Optimized Covariance Design for AB Test on Social Network under Interference",
         "Online A/B tests have become increasingly popular and important for social platforms. However, accurately estimating the global average treatment effect (GATE) has proven to be challenging due to network interference, which violates the Stable Unit Treatment Value Assumption (SUTVA) and poses great challenge to experimental design. Existing network experimental design research was mostly based on the unbiased Horvitz-Thompson (HT) estimator with substantial data trimming to ensure unbiasedness at the price of high resultant estimation variance. In this paper, we strive to balance the bias and variance in designing randomized network experiments.  Under a potential outcome model with 1-hop interference, we derive the bias and variance of the standard HT estimator and reveal their relation to the network topological structure and the covariance of the treatment assignment vector. We then propose to formulate the experimental design problem as to optimize the covariance matrix of the treatment assignment vector to achieve the bias and variance balance by minimizing the mean squared error (MSE) of the estimator. An efficient projected gradient descent algorithm is presented to the implement of the desired randomization scheme. Finally, we carry out extensive  simulation studies to demonstrate the advantages of our proposed method over other existing methods in many settings, with different levels of model misspecification."
        ],
        [
         "32",
         "11005",
         "zQ4yraDiRe",
         "jeong|multiscale_diffusion_denoised_smoothing",
         "['~Jongheon_Jeong1', '~Jinwoo_Shin1']",
         "1683791397574",
         "Multi-scale Diffusion Denoised Smoothing",
         "Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple \"denoise-and-classify\" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we present scalable methods to address the current trade-off between certified robustness and accuracy in denoised smoothing. Our key idea is to \"selectively\" apply smoothing among multiple noise scales, coined multi-scale smoothing, which can be efficiently implemented with a single diffusion model. This approach also suggests a new objective to compare the collective robustness of multi-scale smoothed classifiers, and questions which representation of diffusion model would maximize the objective. To address this, we propose to further fine-tune diffusion model (a) to perform consistent denoising whenever the original image is recoverable, but (b) to generate rather diverse outputs otherwise. Our experiments show that the proposed multi-scale smoothing scheme, combined with diffusion fine-tuning, not only allows strong certified robustness at high noise scales but also maintains accuracy close to non-smoothed classifiers. Code is available at https://github.com/jh-jeong/smoothing-multiscale."
        ],
        [
         "33",
         "9388",
         "zPYeYv6YYs",
         "angelopoulos|conformal_pid_control_for_time_series_prediction",
         "['~Anastasios_Nikolas_Angelopoulos1', '~Emmanuel_Candes1', '~Ryan_Tibshirani1']",
         "1683768267322",
         "Conformal PID Control for Time Series Prediction",
         "We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use  algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in\nofficial CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules at [this link](http://github.com/aangelopoulos/conformal-time-series)."
        ],
        [
         "34",
         "10567",
         "zOCIKYVaF5",
         "li|residual_alignment_uncovering_the_mechanisms_of_residual_networks",
         "['~Jianing_Li3', '~Vardan_Papyan1']",
         "1683785502007",
         "Residual Alignment: Uncovering the Mechanisms of Residual Networks",
         "The ResNet architecture has been widely adopted in deep learning due to its significant boost to performance through the use of simple skip connections, yet the underlying mechanisms leading to its success remain largely unknown. In this paper, we conduct a thorough empirical study of the ResNet architecture in classification tasks by linearizing its constituent residual blocks using Residual Jacobians and measuring their singular value decompositions. Our measurements ([code](https://colab.research.google.com/drive/1yKjEg2yF616tnZFAfuN0aQ-E9v3JmyjN?usp=sharing)) reveal a process called Residual Alignment (RA) characterized by four properties:\n- **(RA1):** intermediate representations of a given input are *equispaced* on a *line*, embedded in high dimensional space, as observed by Gai and Zhang [2021];\n- **(RA2):** top left and right singular vectors of Residual Jacobians align with each other and across different depths;\n- **(RA3):** Residual Jacobians are at most rank $C$ for fully-connected ResNets, where $C$ is the number of classes; and\n- **(RA4):** top singular values of Residual Jacobians scale inversely with depth.\n\nRA consistently occurs in models that generalize well, in both fully-connected and convolutional architectures, across various depths and widths, for varying numbers of classes, on all tested benchmark datasets, but ceases to occur once the skip connections are removed. It also provably occurs in a novel mathematical model we propose. This phenomenon reveals a strong alignment between residual branches of a ResNet (RA2+4), imparting a highly rigid geometric structure to the intermediate representations as they progress *linearly* through the network (RA1) up to the final layer, where they undergo Neural Collapse."
        ],
        [
         "35",
         "11082",
         "zO2dAQfvHf",
         "white|stabilized_neural_differential_equations_for_learning_dynamics_with_explicit_constraints",
         "['~Alistair_White1', '~Niki_Kilbertus1', 'maximilian.gelbrecht@tum.de', '~Niklas_Boers1']",
         "1683792253262",
         "Stabilized Neural Differential Equations for Learning Dynamics with Explicit Constraints",
         "Many successful methods to learn dynamical systems from data have recently been introduced. However, ensuring that the inferred dynamics preserve known constraints, such as conservation laws or restrictions on the allowed system states, remains challenging. We propose stabilized neural differential equations (SNDEs), a method to enforce arbitrary manifold constraints for neural differential equations. Our approach is based on a stabilization term that, when added to the original dynamics, renders the constraint manifold provably asymptotically stable. Due to its simplicity, our method is compatible with all common neural differential equation (NDE) models and broadly applicable. In extensive empirical evaluations, we demonstrate that SNDEs outperform existing methods while broadening the types of constraints that can be incorporated into NDE training."
        ],
        [
         "36",
         "14484",
         "zNA7u7wtIN",
         "kim|pflow_a_fast_and_dataefficient_zeroshot_tts_through_speech_prompting",
         "['~Sungwon_Kim2', '~Kevin_J._Shih1', '~Rohan_Badlani1', '~Joao_Felipe_Santos2', '~Evelina_Bakhturina1', '~Mikyas_T._Desta1', '~Rafael_Valle1', '~Sungroh_Yoon1', '~Bryan_Catanzaro1']",
         "1683826945702",
         "P-Flow: A Fast and Data-Efficient Zero-Shot TTS through Speech Prompting",
         "While recent large-scale neural codec language models have shown significant improvement in zero-shot TTS by training on thousands of hours of data, they suffer from drawbacks such as a lack of robustness, slow sampling speed similar to previous autoregressive TTS methods, and reliance on pre-trained neural codec representations. Our work proposes P-Flow, a fast and data-efficient zero-shot TTS model that uses speech prompts for speaker adaptation. P-Flow comprises a speech-prompted text encoder for speaker adaptation and a flow matching generative decoder for high-quality and fast speech synthesis. Our speech-prompted text encoder uses speech prompts and text input to generate speaker-conditional text representation. The flow matching generative decoder uses the speaker-conditional output to synthesize high-quality personalized speech significantly faster than in real-time. Unlike the neural codec language models, we specifically train P-Flow on LibriTTS dataset using a continuous mel-representation. Through our training method using continuous speech prompts, P-Flow matches the speaker similarity performance of the large-scale zero-shot TTS models with two orders of magnitude less training data and has more than 20$\\times$ faster sampling speed. Our results show that P-Flow has better pronunciation and is preferred in human likeness and speaker similarity to its recent state-of-the-art counterparts, thus defining P-Flow as an attractive and desirable alternative. We provide audio samples on our demo page: [https://research.nvidia.com/labs/adlr/projects/pflow](https://research.nvidia.com/labs/adlr/projects/pflow)"
        ],
        [
         "37",
         "8897",
         "zMeemcUeXL",
         "liu|famo_fast_adaptive_multitask_optimization",
         "['~Bo_Liu13', '~Yihao_Feng1', '~Peter_Stone1', '~qiang_liu4']",
         "1683756653507",
         "FAMO: Fast Adaptive Multitask Optimization",
         "One of the grand enduring goals of AI is to create generalist agents that can learn multiple different tasks from diverse data via multitask learning (MTL). However, in practice, applying gradient descent (GD) on the average loss across all tasks may yield poor multitask performance due to severe under-optimization of certain tasks. Previous approaches that manipulate task gradients for a more balanced loss decrease require storing and computing all task gradients ($\\mathcal{O}(k)$ space and time where $k$ is the number of tasks), limiting their use in large-scale scenarios. In this work, we introduce Fast Adaptive Multitask Optimization (FAMO), a dynamic weighting method that decreases task losses in a balanced way using $\\mathcal{O}(1)$ space and time. We conduct an extensive set of experiments covering multi-task supervised and reinforcement learning problems. Our results indicate that FAMO achieves comparable or superior performance to state-of-the-art gradient manipulation techniques while offering significant improvements in space and computational efficiency. Code is available at \\url{https://github.com/Cranial-XIX/FAMO}."
        ],
        [
         "38",
         "12836",
         "zMNUNd9zs1",
         "halvagal|implicit_variance_regularization_in_noncontrastive_ssl",
         "['~Manu_Srinath_Halvagal1', '~Axel_Laborieux1', '~Friedemann_Zenke1']",
         "1683814821296",
         "Implicit variance regularization in non-contrastive SSL",
         "Non-contrastive SSL methods like BYOL and SimSiam rely on asymmetric predictor networks to avoid representational collapse without negative samples. Yet, how predictor networks facilitate stable learning is not fully understood. While previous theoretical analyses assumed Euclidean losses, most practical implementations rely on cosine similarity. To gain further theoretical insight into non-contrastive SSL, we analytically study learning dynamics in conjunction with Euclidean and cosine similarity in the eigenspace of closed-form linear predictor networks. We show that both avoid collapse through implicit variance regularization albeit through different dynamical mechanisms. Moreover, we find that the eigenvalues act as effective learning rate multipliers and propose a family of isotropic loss functions (IsoLoss) that equalize convergence rates across eigenmodes. Empirically, IsoLoss speeds up the initial learning dynamics and increases robustness, thereby allowing us to dispense with the EMA target network typically used with non-contrastive methods. Our analysis sheds light on the variance regularization mechanisms of non-contrastive SSL and lays the theoretical grounds for crafting novel loss functions that shape the learning dynamics of the predictor's spectrum."
        ],
        [
         "39",
         "2943",
         "zKjSmbYFZe",
         "xian|efficient_postprocessing_for_equal_opportunity_in_fair_multiclass_classification",
         "['~Ruicheng_Xian1', '~Han_Zhao1']",
         "1683498350258",
         "Efficient Post-Processing for Equal Opportunity in Fair Multi-Class Classification",
         "Fairness in machine learning is of growing concern as more instances of biased model behavior are documented while their adoption continues to rise.  The majority of studies have focused on binary classification settings, despite the fact that many real-world problems are inherently multi-class.  This paper considers fairness in multi-class classification under the notion of parity of true positive rates—an extension of binary class equalized odds—which ensures equal opportunity to qualified individuals regardless of their demographics.  We focus on algorithm design and provide a post-processing method that derives fair classifiers from pre-trained score functions.  The method is developed by analyzing the representation of the optimal fair classifier, and is efficient in both sample and time complexity, as it is implemented by linear programs on finite samples.  We demonstrate its effectiveness at reducing disparity on benchmark datasets, particularly under large numbers of classes, where existing methods fall short."
        ],
        [
         "40",
         "569",
         "zJMutieTgh",
         "huang|inference_attacks_against_face_recognition_model_without_classification_layers",
         "['~Yuanqing_Huang1', '~Yinggui_Wang1', '~Le_Yang6', '~Rui_Lv2', '~Lei_Wang30', '~Tao_Wei5']",
         "1682341133193",
         "Inference Attacks Against Face Recognition Model without Classification Layers",
         "Face recognition (FR) has been applied to nearly every aspect of daily life, but it is always accompanied by the underlying risk of leaking private information. At present, almost all attack models against FR rely heavily on the presence of a classification layer. However, in practice, the FR model can obtain complex feature embedding of the input via the model backbone, and then compare it with the target for inference, which does not explicitly involve the outputs of the classification layer adopting logit or other losses. In this work, we advocate a novel inference attack composed of two stages for practical FR models without a classification layer. The first stage is the membership inference attack. Specifically, We analyze the distances between the intermediate features and batch normalization (BN) parameters. The results indicate that this distance is a critical metric for membership inference. We thus design a simple but effective attack model that can determine whether a face image is from the training data set or not. The second stage is the model inversion attack, where sensitive private data is reconstructed using a pre-trained generative adversarial network (GAN) guided by the attack model in the first stage. To the best of our knowledge, the proposed attack model is the very first in the literature developed for FR models without a classification layer. We illustrate the application of the proposed attack model in the establishment of privacy-preserving FR techniques."
        ],
        [
         "41",
         "3416",
         "zIEaOZ0saA",
         "brand|new_complexitytheoretic_frontiers_of_tractability_for_neural_network_training",
         "['~Cornelius_Brand1', '~Robert_Ganian1', '~Mathis_Rocton1']",
         "1683548215755",
         "New Complexity-Theoretic Frontiers of Tractability for Neural Network Training",
         "In spite of the fundamental role of neural networks in contemporary machine learning research, our understanding of the computational complexity of optimally training neural networks remains limited even when dealing with the simplest kinds of activation functions. Indeed, while there has been a number of very recent results that establish ever-tighter lower bounds for the problem under linear and ReLU activation functions, little progress has been made towards the identification of novel polynomial-time tractable network architectures. In this article we obtain novel algorithmic upper bounds for training linear- and ReLU-activated neural networks to optimality which push the boundaries of tractability for these problems beyond the previous state of the art."
        ],
        [
         "42",
         "2628",
         "zGdH4tKtOW",
         "shen|optimal_treatment_regimes_for_proximal_causal_learning",
         "['~Tao_Shen6', '~Yifan_Cui1']",
         "1683424852457",
         "Optimal Treatment Regimes for Proximal Causal Learning",
         "A common concern when a policymaker draws causal inferences from and makes decisions based on observational data is that the measured covariates are insufficiently rich to account for all sources of confounding, i.e., the standard no confoundedness assumption fails to hold. The recently proposed proximal causal inference framework shows that proxy variables that abound in real-life scenarios can be leveraged to identify causal effects and therefore facilitate decision-making. Building upon this line of work, we propose a novel optimal individualized treatment regime based on so-called outcome and treatment confounding bridges. We then show that the value function of this new optimal treatment regime is superior to that of existing ones in the literature. Theoretical guarantees, including identification, superiority, excess value bound, and consistency of the estimated regime, are established. Furthermore, we demonstrate the proposed optimal regime via numerical experiments and a real data application."
        ],
        [
         "43",
         "7870",
         "zGRWp7yRqd",
         "beretta|multiswap_kmeans",
         "['~Lorenzo_Beretta1', '~Vincent_Cohen-Addad1', '~Silvio_Lattanzi1', '~Nikos_Parotsidis1']",
         "1683736339659",
         "Multi-Swap k-Means++",
         "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often the practitioners' choice algorithm for optimizing the popular $k$-means clustering objective and is known to give an $O(\\log k)$-approximation in expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML 2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local-search steps obtained through the $k$-means++ sampling distribution to yield a $c$-approximation to the $k$-means clustering problem, where $c$ is a large absolute constant. Here we generalize and extend their local-search algorithm by considering larger and more sophisticated local-search neighborhoods hence allowing to  swap multiple centers at the same time. Our algorithm achieves a $9 + \\varepsilon$ approximation ratio, which is the best possible for local search. Importantly we show that our algorithm is practical, namely easy to implement and fast enough to run on a variety of classic datasets, and outputs solutions of better cost."
        ],
        [
         "44",
         "14705",
         "zEoP4vzFKy",
         "peychev|automated_classification_of_model_errors_on_imagenet",
         "['~Momchil_Peychev1', '~Mark_Niklas_Mueller2', '~Marc_Fischer1', '~Martin_Vechev1']",
         "1683828576628",
         "Automated Classification of Model Errors on ImageNet",
         "While the ImageNet dataset has been driving computer vision research over the past decade, significant label noise and ambiguity have made top-1 accuracy an insufficient measure of further progress. To address this, new label-sets and evaluation protocols have been proposed for ImageNet showing that state-of-the-art models already achieve over 95% accuracy and shifting the focus on investigating why the remaining errors persist.\n\nRecent work in this direction employed a panel of experts to manually categorize all remaining classification errors for two selected models. However, this process is time-consuming, prone to inconsistencies, and requires trained experts, making it unsuitable for regular model evaluation thus limiting its utility. To overcome these limitations, we propose the first automated error classification framework, a valuable tool to study how modeling choices affect error distributions. We use our framework to comprehensively evaluate the error distribution of over 900 models. Perhaps surprisingly, we find that across model architectures, scales, and pre-training corpora, top-1 accuracy is a strong predictor for the *portion* of all error types. In particular, we observe that the portion of severe errors drops significantly with top-1 accuracy indicating that, while it underreports a model's true performance, it remains a valuable performance metric.\n\nWe release all our code at https://github.com/eth-sri/automated-error-analysis."
        ],
        [
         "45",
         "8945",
         "zEm6hF97Pz",
         "choquettechoo|amplified_banded_matrix_factorization_a_unified_approach_to_private_training",
         "['~Christopher_A._Choquette-Choo1', '~Arun_Ganesh1', '~Ryan_McKenna2', '~Hugh_Brendan_McMahan1', '~J_Keith_Rush1', '~Abhradeep_Guha_Thakurta1', '~Zheng_Xu2']",
         "1683757865397",
         "(Amplified) Banded Matrix Factorization: A unified approach to private training",
         "Matrix factorization (MF) mechanisms for differential privacy (DP) have substantially improved the state-of-the-art in privacy-utility-computation tradeoffs for ML applications in a variety of scenarios, but in both the centralized and federated settings there remain instances where either MF cannot be easily applied, or other algorithms provide better tradeoffs (typically, as $\\epsilon$ becomes small).\nIn this work, we show how MF can subsume prior state-of-the-art algorithms in both federated and centralized training settings, across all privacy budgets. The key technique throughout is the construction of MF mechanisms with banded matrices (lower-triangular matrices with at most $\\hat{b}$ nonzero bands including the main diagonal). For cross-device federated learning (FL), this enables multiple-participations with a relaxed device participation schema compatible with practical FL infrastructure (as demonstrated by a production deployment).  In the centralized setting, we prove that banded matrices enjoy the same privacy amplification results as the ubiquitous DP-SGD algorithm, but can provide strictly better performance  in most scenarios---this lets us always at least match DP-SGD, and often outperform it"
        ],
        [
         "46",
         "10291",
         "zDbsSscmuj",
         "guan|leveraging_pretrained_large_language_models_to_construct_and_utilize_world_models_for_modelbased_task_planning",
         "['~Lin_Guan1', '~Karthik_Valmeekam1', '~Sarath_Sreedharan1', '~Subbarao_Kambhampati1']",
         "1683781343548",
         "Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning",
         "There is a growing interest in applying pre-trained large language models (LLMs) to planning problems. However, methods that use LLMs directly as planners are currently impractical due to several factors, including limited correctness of plans, strong reliance on feedback from interactions with simulators or even the actual environment, and the inefficiency in utilizing human feedback. In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners. To address the fact that LLMs may not generate a fully functional PDDL model initially, we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans. For users who lack a background in PDDL, we show that LLMs can translate PDDL into natural language and effectively encode corrective feedback back to the underlying domain model. Our framework not only enjoys the correctness guarantee offered by the external planners but also reduces human involvement by allowing users to correct domain models at the beginning, rather than inspecting and correcting (through interactive prompting) every generated plan as in previous work. On two IPC domains and a Household domain that is more complicated than commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be leveraged to produce high-quality PDDL models for over 40 actions, and the corrected PDDL models are then used to successfully solve 48 challenging planning tasks. Resources, including the source code, are released at: https://guansuns.github.io/pages/llm-dm."
        ],
        [
         "47",
         "278",
         "zD6lXmTPPh",
         "alfano|a_novel_framework_for_policy_mirror_descent_with_general_parameterization_and_linear_convergence",
         "['~Carlo_Alfano1', '~Rui_Yuan1', '~Patrick_Rebeschini1']",
         "1682032528993",
         "A Novel Framework for Policy Mirror Descent with General Parameterization and Linear Convergence",
         "Modern policy optimization methods in reinforcement learning, such as TRPO and PPO, owe their success to the use of parameterized policies. However, while theoretical guarantees have been established for this class of algorithms, especially in the tabular setting, the use of general parameterization schemes remains mostly unjustified. In this work, we introduce a novel framework for policy optimization based on mirror descent that naturally accommodates general parameterizations. The policy class induced by our scheme recovers known classes, e.g., softmax, and generates new ones depending on the choice of mirror map. Using our framework, we obtain the first result that guarantees linear convergence for a policy-gradient-based method involving general parameterization. To demonstrate the ability of our framework to accommodate general parameterization schemes, we provide its sample complexity when using shallow neural networks, show that it represents an improvement upon the previous best results, and empirically validate the effectiveness of our theoretical claims on classic control tasks."
        ],
        [
         "48",
         "5206",
         "zCFfv49MjE",
         "reid|quasimonte_carlo_graph_random_features",
         "['~Isaac_Reid3', '~Krzysztof_Marcin_Choromanski1', '~Adrian_Weller1']",
         "1683659388911",
         "Quasi-Monte Carlo Graph Random Features",
         "We present a novel mechanism to improve the accuracy of the recently-introduced class of graph random features (GRFs). Our method induces negative correlations between the lengths of the algorithm's random walks by imposing antithetic termination: a procedure to sample more diverse random walks which may be of independent interest. It has a trivial drop-in implementation. We derive strong theoretical guarantees on the properties of these quasi-Monte Carlo GRFs (q-GRFs), proving that they yield lower-variance estimators of the $2$-regularised Laplacian kernel under mild conditions. Remarkably, our results hold for any graph topology. We demonstrate empirical accuracy improvements on a variety of tasks including a new practical application: time-efficient approximation of the graph diffusion process. To our knowledge, q-GRFs constitute the first rigorously studied quasi-Monte Carlo scheme for kernels defined on combinatorial objects, inviting new research on correlations between graph random walks."
        ],
        [
         "49",
         "6594",
         "zAXg8dW8ZO",
         "tran|onelineofcode_data_mollification_improves_optimization_of_likelihoodbased_generative_models",
         "['~Ba-Hien_Tran2', '~Giulio_Franzese1', '~Pietro_Michiardi1', '~Maurizio_Filippone1']",
         "1683712170474",
         "One-Line-of-Code Data Mollification Improves Optimization of Likelihood-based Generative Models",
         "Generative Models (GMs) have attracted considerable attention due to their tremendous success in various domains, such as computer vision where they are capable to generate impressive realistic-looking images. Likelihood-based GMs are attractive due to the possibility to generate new data by a single model evaluation. However, they typically achieve lower sample quality compared to state-of-the-art score-based Diffusion Models (DMs). This paper provides a significant step in the direction of addressing this limitation. The idea is to borrow one of the strengths of score-based DMs, which is the ability to perform accurate density estimation in low-density regions and to address manifold overfitting by means of data mollification. We propose a view of data mollification within likelihood-based GMs as a continuation method, whereby the optimization objective smoothly transitions from simple-to-optimize to the original target. Crucially, data mollification can be implemented by adding one line of code in the optimization loop, and we demonstrate that this provides a boost in generation quality of likelihood-based GMs, without computational overheads. We report results on real-world image data sets and UCI benchmarks with popular likelihood-based GMs, including variants of variational autoencoders and normalizing flows, showing large improvements in FID score and density estimation."
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3395
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>id</th>\n",
       "      <th>content.paperhash</th>\n",
       "      <th>content.authorids</th>\n",
       "      <th>cdate</th>\n",
       "      <th>content.title</th>\n",
       "      <th>content.abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10819</td>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>sun|what_is_flagged_in_uncertainty_quantificat...</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15594</td>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>puli|dont_blame_dataset_shift_shortcut_learnin...</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>327</td>\n",
       "      <td>zuXyQsXVLF</td>\n",
       "      <td>xu|enhancing_adversarial_contrastive_learning_...</td>\n",
       "      <td>[~Xilie_Xu1, ~Jingfeng_Zhang1, ~Feng_Liu2, ~Ma...</td>\n",
       "      <td>1682066194522</td>\n",
       "      <td>Enhancing Adversarial Contrastive Learning via...</td>\n",
       "      <td>Adversarial contrastive learning (ACL) is a te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801</td>\n",
       "      <td>ztqf6bzuqQ</td>\n",
       "      <td>shi|hybrid_distillation_connecting_masked_auto...</td>\n",
       "      <td>[~Bowen_Shi2, ~XIAOPENG_ZHANG7, ~Yaoming_Wang1...</td>\n",
       "      <td>1682507396411</td>\n",
       "      <td>Hybrid Distillation: Connecting Masked Autoenc...</td>\n",
       "      <td>Representation learning has been evolving from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7411</td>\n",
       "      <td>ztDxO15N7f</td>\n",
       "      <td>scholkemper|an_optimizationbased_approach_to_n...</td>\n",
       "      <td>[~Michael_Scholkemper1, ~Michael_T_Schaub1]</td>\n",
       "      <td>1683729208530</td>\n",
       "      <td>An Optimization-based Approach To Node Role Di...</td>\n",
       "      <td>Similar to community detection, partitioning t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>12557</td>\n",
       "      <td>05P1U0jk8r</td>\n",
       "      <td>sakos|exploiting_hidden_structures_in_nonconve...</td>\n",
       "      <td>[~Iosif_Sakos1, ~Emmanouil-Vasileios_Vlatakis-...</td>\n",
       "      <td>1683812282551</td>\n",
       "      <td>Exploiting hidden structures in non-convex gam...</td>\n",
       "      <td>A wide array of modern machine learning applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>12654</td>\n",
       "      <td>02Uc0G2Cym</td>\n",
       "      <td>mianjy|robustness_guarantees_for_adversarially...</td>\n",
       "      <td>[~Poorya_Mianjy1, ~Raman_Arora1]</td>\n",
       "      <td>1683813240757</td>\n",
       "      <td>Robustness Guarantees for Adversarially Traine...</td>\n",
       "      <td>We study robust adversarial training of two-la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>1581</td>\n",
       "      <td>01GQK1gwe3</td>\n",
       "      <td>holl|can_neural_networks_improve_classical_opt...</td>\n",
       "      <td>[~Philipp_Holl1, ~Nils_Thuerey1]</td>\n",
       "      <td>1683105912880</td>\n",
       "      <td>Can Neural Networks Improve Classical Optimiza...</td>\n",
       "      <td>Finding the values of model parameters from da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>6838</td>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>hu|complexity_matters_rethinking_the_latent_sp...</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3394</th>\n",
       "      <td>10107</td>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>ghadiri|finite_population_regression_adjustmen...</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3395 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number          id                                  content.paperhash  \\\n",
       "0      10819  zyhxRc9bew  sun|what_is_flagged_in_uncertainty_quantificat...   \n",
       "1      15594  zyZkaqNnpa  puli|dont_blame_dataset_shift_shortcut_learnin...   \n",
       "2        327  zuXyQsXVLF  xu|enhancing_adversarial_contrastive_learning_...   \n",
       "3        801  ztqf6bzuqQ  shi|hybrid_distillation_connecting_masked_auto...   \n",
       "4       7411  ztDxO15N7f  scholkemper|an_optimizationbased_approach_to_n...   \n",
       "...      ...         ...                                                ...   \n",
       "3390   12557  05P1U0jk8r  sakos|exploiting_hidden_structures_in_nonconve...   \n",
       "3391   12654  02Uc0G2Cym  mianjy|robustness_guarantees_for_adversarially...   \n",
       "3392    1581  01GQK1gwe3  holl|can_neural_networks_improve_classical_opt...   \n",
       "3393    6838  00EKYYu3fD  hu|complexity_matters_rethinking_the_latent_sp...   \n",
       "3394   10107  009LK0vLcY  ghadiri|finite_population_regression_adjustmen...   \n",
       "\n",
       "                                      content.authorids          cdate  \\\n",
       "0     [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...  1683789038840   \n",
       "1     [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...  1683835167534   \n",
       "2     [~Xilie_Xu1, ~Jingfeng_Zhang1, ~Feng_Liu2, ~Ma...  1682066194522   \n",
       "3     [~Bowen_Shi2, ~XIAOPENG_ZHANG7, ~Yaoming_Wang1...  1682507396411   \n",
       "4           [~Michael_Scholkemper1, ~Michael_T_Schaub1]  1683729208530   \n",
       "...                                                 ...            ...   \n",
       "3390  [~Iosif_Sakos1, ~Emmanouil-Vasileios_Vlatakis-...  1683812282551   \n",
       "3391                   [~Poorya_Mianjy1, ~Raman_Arora1]  1683813240757   \n",
       "3392                   [~Philipp_Holl1, ~Nils_Thuerey1]  1683105912880   \n",
       "3393  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...  1683719044332   \n",
       "3394  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...  1683778565991   \n",
       "\n",
       "                                          content.title  \\\n",
       "0     What is Flagged in Uncertainty Quantification?...   \n",
       "1     Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "2     Enhancing Adversarial Contrastive Learning via...   \n",
       "3     Hybrid Distillation: Connecting Masked Autoenc...   \n",
       "4     An Optimization-based Approach To Node Role Di...   \n",
       "...                                                 ...   \n",
       "3390  Exploiting hidden structures in non-convex gam...   \n",
       "3391  Robustness Guarantees for Adversarially Traine...   \n",
       "3392  Can Neural Networks Improve Classical Optimiza...   \n",
       "3393  Complexity Matters: Rethinking the Latent Spac...   \n",
       "3394  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                       content.abstract  \n",
       "0     Uncertainty quantification (UQ) is essential f...  \n",
       "1     Common explanations for shortcut learning assu...  \n",
       "2     Adversarial contrastive learning (ACL) is a te...  \n",
       "3     Representation learning has been evolving from...  \n",
       "4     Similar to community detection, partitioning t...  \n",
       "...                                                 ...  \n",
       "3390  A wide array of modern machine learning applic...  \n",
       "3391  We study robust adversarial training of two-la...  \n",
       "3392  Finding the values of model parameters from da...  \n",
       "3393  In generative modeling, numerous successful ap...  \n",
       "3394  The design and analysis of randomized experime...  \n",
       "\n",
       "[3395 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file as a pandas DataFrame\n",
    "df_json = pd.read_json('/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v0.json')\n",
    "\n",
    "# Display the header of the first 5 samples\n",
    "df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the dataframe: (3395, 7)\n",
      "Number of NaN values in each column:\n",
      "number               0\n",
      "id                   0\n",
      "content.paperhash    0\n",
      "content.authorids    0\n",
      "cdate                0\n",
      "content.title        0\n",
      "content.abstract     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of the dataframe\n",
    "print(f\"Dimensions of the dataframe: {df.shape}\")\n",
    "\n",
    "# Count the number of NaN values in each column\n",
    "print(\"Number of NaN values in each column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 4\n",
      "max: 14\n",
      "mean: 6.455670103092784\n",
      "median: 6.0\n",
      "std: 0.905242195033333\n",
      "percentiles: [6. 6. 7. 8. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "# number of review, comments, and meta-reviews for each submission\n",
    "# 3395 is the number of submissions\n",
    "num_of_reviews = [len(data[i].details['directReplies']) for i in range(3395)]\n",
    "print('min:', min(num_of_reviews))\n",
    "print('max:', max(num_of_reviews))\n",
    "print('mean:', np.mean(num_of_reviews))\n",
    "print('median:', np.median(num_of_reviews))\n",
    "print('std:', np.std(num_of_reviews))\n",
    "print('percentiles:', np.percentile(num_of_reviews, [25, 50, 75, 90, 95, 99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Author_Rebuttal', 'Decision', 'Official_Comment', 'Official_Review'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_types = set()\n",
    "for i in range(3395):\n",
    "    for j in range(len(data[i].details['directReplies'])):\n",
    "        comment_types.add(data[i].details['directReplies'][j]['invitations'][0].split('/')[-1])\n",
    "\n",
    "comment_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with reviews saved to JSON file at: /home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v1.json\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each submission in the data\n",
    "new_rows = []\n",
    "for submission in data:\n",
    "    submission_id = submission.id\n",
    "    submission_number = submission.number\n",
    "    submission_title = submission.content['title']['value'] if 'title' in submission.content and 'value' in submission.content['title'] else None\n",
    "    submission_abstract = submission.content['abstract']['value'] if 'abstract' in submission.content and 'value' in submission.content['abstract'] else None\n",
    "    submission_authors = submission.content['authorids']['value'] if 'authorids' in submission.content and 'value' in submission.content['authorids'] else np.nan\n",
    "    submission_creation_date = submission.cdate if hasattr(submission, 'cdate') else np.nan\n",
    "\n",
    "    # Check if 'directReplies' exists in details\n",
    "    if 'directReplies' in submission.details:\n",
    "        for reply in submission.details['directReplies']:\n",
    "            # Check if the invitation is 'Official_Review'\n",
    "            if reply['invitations'][0].split('/')[-1] == 'Official_Review':\n",
    "                # Extract features from the review\n",
    "                reviewer = reply['signatures'][0].split('/')[-1]  # if 'signatures' in reply and len(reply['signatures']) > 0 else None\n",
    "                \n",
    "                #'tcdate', 'cdate', 'tmdate', 'mdate'\n",
    "                review_tcdate = reply['tcdate'] if 'tcdate' in reply else None\n",
    "                review_cdate = reply['cdate'] if 'cdate' in reply else None\n",
    "                review_tmdate = reply['tmdate'] if 'tmdate' in reply else None\n",
    "                review_mdate = reply['mdate'] if 'mdate' in reply else None\n",
    "                \n",
    "                review_rating = int(reply['content']['rating']['value'].split(':')[0]) if 'rating' in reply['content'] and 'value' in reply['content']['rating'] else None\n",
    "                review_confidence = int(reply['content']['confidence']['value'].split(':')[0]) if 'confidence' in reply['content'] and 'value' in reply['content']['confidence'] else None\n",
    "                review_soundness = int(reply['content']['soundness']['value'].split(' ')[0]) if 'soundness' in reply['content'] and 'value' in reply['content']['soundness'] else None\n",
    "                review_presentation = int(reply['content']['presentation']['value'].split(' ')[0]) if 'presentation' in reply['content'] and 'value' in reply['content']['presentation'] else None\n",
    "                review_contribution = int(reply['content']['contribution']['value'].split(' ')[0]) if 'contribution' in reply['content'] and 'value' in reply['content']['contribution'] else None\n",
    "                \n",
    "                review_summary = reply['content']['summary']['value'] if 'summary' in reply['content'] and 'value' in reply['content']['summary'] else None\n",
    "                review_strengths = reply['content']['strengths']['value'] if 'strengths' in reply['content'] and 'value' in reply['content']['strengths'] else None\n",
    "                review_weaknesses = reply['content']['weaknesses']['value'] if 'weaknesses' in reply['content'] and 'value' in reply['content']['weaknesses'] else None\n",
    "                review_questions = reply['content']['questions']['value'] if 'questions' in reply['content'] and 'value' in reply['content']['questions'] else None\n",
    "                review_limitations = reply['content']['limitations']['value'] if 'limitations' in reply['content'] and 'value' in reply['content']['limitations'] else None\n",
    "                \n",
    "                # Create a new row with the extracted features\n",
    "                new_row = {\n",
    "                    'submission_id': submission_id,\n",
    "                    'submission_number': submission_number,\n",
    "                    'submission_creation_date': submission_creation_date,\n",
    "                    'submission_authors': submission_authors,\n",
    "                    \n",
    "                    'submission_title': submission_title,\n",
    "                    'submission_abstract': submission_abstract,\n",
    "                    \n",
    "                    'reviewer': reviewer,\n",
    "                    'review_tcdate': review_tcdate,\n",
    "                    'review_cdate': review_cdate,\n",
    "                    'review_tmdate': review_tmdate,\n",
    "                    'review_mdate': review_mdate,\n",
    "                    \n",
    "                    'review_summary': review_summary,\n",
    "                    'review_strengths': review_strengths,\n",
    "                    'review_weaknesses': review_weaknesses,\n",
    "                    'review_questions': review_questions,\n",
    "                    'review_limitations': review_limitations,\n",
    "                    \n",
    "                    'review_rating': review_rating,\n",
    "                    'review_confidence': review_confidence,\n",
    "                    'review_soundness': review_soundness,\n",
    "                    'review_presentation': review_presentation,\n",
    "                    'review_contribution': review_contribution\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "\n",
    "# Create a new DataFrame from the new rows\n",
    "df_reviews = pd.DataFrame(new_rows)\n",
    "\n",
    "# Save the updated DataFrame to a JSON file\n",
    "output_json_path = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v1.json'\n",
    "df_reviews.to_json(output_json_path, orient='records', indent=4)\n",
    "\n",
    "print(f\"Updated DataFrame with reviews saved to JSON file at: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_strengths",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_weaknesses",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_questions",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_limitations",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4e0f5b89-dc00-4555-a200-c8ac1634ab37",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes.",
         "1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n",
         "1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n",
         "1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n",
         "Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "6",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure. ",
         "In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow.",
         "See questions.",
         "* In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n",
         "Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "6",
         "4",
         "3",
         "3",
         "4"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models.",
         "The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful.",
         "I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\".",
         "1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term?",
         "Yes.",
         "6",
         "4",
         "3",
         "3",
         "2"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models.",
         "To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses)",
         "There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n",
         "- Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n",
         "Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "6",
         "4",
         "2",
         "3",
         "3"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions.",
         "This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning.",
         "The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n",
         "The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "6",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method.",
         "-This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand.",
         "-Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not.",
         "-How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective?",
         "Please see the weaknesses part.",
         "5",
         "3",
         "4",
         "4",
         "4"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets.",
         "* The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements",
         "* I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm.",
         "* The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one?",
         "Not explicitly discussed",
         "6",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks.",
         "* Experiments show good results for their methods.",
         "* The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots.",
         "* How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick?",
         "The authors adequately addressed the limitations.",
         "6",
         "3",
         "3",
         "2",
         "3"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness. ",
         "The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term.",
         "The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8.",
         "See \"Weaknesses\" part.",
         "N.A.",
         "8",
         "4",
         "3",
         "3",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released.",
         "1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n",
         "1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet.",
         "Shown as Weaknesses.",
         "Shown as Weaknesses.",
         "6",
         "4",
         "3",
         "3",
         "3"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines.",
         "1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n",
         "I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n",
         "1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n",
         "The authors have discussed the limitations.",
         "6",
         "4",
         "3",
         "3",
         "3"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100.",
         "- Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations.",
         "- The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021",
         "- It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES).",
         "- There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "4",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach.",
         "The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models.",
         "1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022.",
         "See weakness.",
         "The authors have included discussion on the limited gain over Distill-CLIP.",
         "4",
         "4",
         "3",
         "2",
         "3"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes.",
         "The findings on the relationship between diversity and architecture are interesting",
         "1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners",
         "See above",
         "None",
         "5",
         "5",
         "1",
         "1",
         "2"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties.",
         "* Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written",
         "* When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n",
         "* How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n",
         "* Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "4",
         "3",
         "2",
         "2",
         "2"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n",
         "- The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant.",
         "- The paper has some minor typo errors.\n",
         "1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)?",
         "- Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "5",
         "5",
         "3",
         "3",
         "2"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy.",
         "The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive.",
         "- Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method.",
         "-",
         "-",
         "6",
         "5",
         "4",
         "3",
         "3"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner.",
         "(+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks. ",
         "(-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022.",
         "(-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n",
         "The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "5",
         "3",
         "3",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks.",
         "- The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method.",
         "- Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper.",
         "Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n",
         "No potential negative societal impact.",
         "5",
         "3",
         "2",
         "3",
         "3"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs.",
         "* The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative.",
         "* Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method.",
         "* Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$?",
         "Limitations are sufficiently discussed.",
         "6",
         "4",
         "3",
         "3",
         "2"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model. ",
         "The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery.",
         "The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.  ",
         "1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6).",
         "Yes.",
         "6",
         "3",
         "3",
         "4",
         "3"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n",
         "I think this paper is theoretically sound. ",
         "1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available?",
         "1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes.",
         "1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "7",
         "1",
         "3",
         "2",
         "3"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases. ",
         "The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail. ",
         "My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).  ",
         "How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)? ",
         "Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "4",
         "2",
         "3",
         "2",
         "2"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community.",
         "This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process.",
         "This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24].",
         "Why is this article relevant to the machine learning community?",
         "This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "4",
         "1",
         "3",
         "2",
         "2"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data.",
         "- The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution.",
         "- The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear.",
         "What are the situations where the derived conditions for identifying linear SDEs so useful in practice?",
         "N/A",
         "5",
         "2",
         "2",
         "3",
         "2"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations.",
         "In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial. ",
         "It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community.",
         "- l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined?",
         "Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "4",
         "3",
         "2",
         "3",
         "3"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results.",
         "The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely.",
         "The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper.",
         "You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4.",
         "The authors discuss the limitations of their work. ",
         "7",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n",
         "1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution.",
         "1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting.",
         "1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness. ",
         "See Weaknesses.",
         "7",
         "3",
         "4",
         "4",
         "4"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting.",
         "1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting.",
         "1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table.",
         "1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?",
         "N/A",
         "6",
         "3",
         "3",
         "3",
         "2"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art.",
         "Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods.",
         "I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n",
         "1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n",
         "No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "6",
         "2",
         "3",
         "3",
         "3"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy. ",
         "* Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof.",
         "* The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n",
         "* For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1?",
         "The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "5",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms. ",
         "The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported. ",
         "The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n",
         "Please see the weaknesses above.",
         "N/A",
         "3",
         "3",
         "2",
         "1",
         "2"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n",
         "* This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n",
         "a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n",
         "Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors.",
         "Limitations are discussed in the paper.",
         "5",
         "3",
         "2",
         "3",
         "3"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art.",
         "1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material.",
         "1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section.",
         "1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.",
         "In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "6",
         "3",
         "3",
         "3",
         "2"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions. ",
         "1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced.",
         "1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class.",
         "1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced. ",
         "The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "5",
         "4",
         "2",
         "2",
         "2"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. ",
         "1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow.",
         "The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value. ",
         "Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing?",
         "The authors addressed the limitations. ",
         "5",
         "3",
         "3",
         "2",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges.",
         "+ Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow.",
         "- The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs.",
         "Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs? ",
         "The reviewer does not see potential negative social impact of the work.",
         "4",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score. ",
         "- The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n",
         "- **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu.",
         "- The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios?",
         "The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "6",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism.",
         "Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n",
         "No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently. ",
         "1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n",
         "N/A",
         "7",
         "4",
         "3",
         "3",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective.",
         "1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n",
         "1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n",
         "It would be beneficial to answer the questions in weakness.",
         "N/A",
         "7",
         "5",
         "3",
         "3",
         "4"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence.",
         "- The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors.",
         "- The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability.",
         "- In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022.",
         "The authors have discussed the limitation and potential negative societal impact.",
         "7",
         "5",
         "4",
         "3",
         "4"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated.",
         "The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n",
         "The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating.",
         "I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n",
         "The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "6",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries.",
         "1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n",
         "1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n",
         "\n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket.",
         "The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "7",
         "4",
         "4",
         "4",
         "3"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings.",
         "1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided.",
         "1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.  ",
         "1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved.",
         "- ",
         "6",
         "5",
         "3",
         "3",
         "2"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs.",
         "**Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators.",
         "- Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020.",
         "- I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results?",
         "The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "6",
         "4",
         "3",
         "4",
         "3"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n",
         "1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n",
         "1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n",
         "Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]).",
         "yes",
         "4",
         "4",
         "2",
         "2",
         "2"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model.",
         "- Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n",
         "- Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n",
         "Refer to the weaknesses mentioned above.",
         "Refer to the weaknesses mentioned above.",
         "6",
         "5",
         "3",
         "3",
         "2"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label.",
         "- This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read.",
         "- Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022.",
         "- Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n",
         "The authors have discussed the limitations.",
         "4",
         "4",
         "3",
         "3",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model. ",
         "1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method. ",
         "1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021.",
         "Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022",
         "After the part of conclusion, the authors discussed the limitation of this work. ",
         "3",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n",
         "The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n",
         "\n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n",
         "*  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n",
         "* Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "5",
         "3",
         "3",
         "2",
         "2"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>...</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_strengths</th>\n",
       "      <th>review_weaknesses</th>\n",
       "      <th>review_questions</th>\n",
       "      <th>review_limitations</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>1. This paper focuses on samples that remain s...</td>\n",
       "      <td>1. Why are the uncertain samples of the model ...</td>\n",
       "      <td>1. Checking some details in the paper, such as...</td>\n",
       "      <td>Is DAUC a model-agnostic approach that can be ...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>...</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>In my opinion, this categorization process of ...</td>\n",
       "      <td>See questions.</td>\n",
       "      <td>* In my opinion, at a high level, this method ...</td>\n",
       "      <td>Yes, the limitations have been listed by the a...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>...</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>The paper is very well written overall, I enjo...</td>\n",
       "      <td>I find it quite difficult to judge the technic...</td>\n",
       "      <td>1. Can the proposed method be applied to datas...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>...</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>To my knowledge, paper presents a novel approa...</td>\n",
       "      <td>There are some weaknesses that could further i...</td>\n",
       "      <td>- Table 1: Could you ellaborate why other rela...</td>\n",
       "      <td>Some of the assumptions and limitations of pro...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>This paper analyzes shortcut learning theoreti...</td>\n",
       "      <td>The theory itself has limited applicability du...</td>\n",
       "      <td>It seems that this paper forcus on a theoretic...</td>\n",
       "      <td>The theory itself has limited applicability du...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>The strengths of this paper are :\\n- It is a s...</td>\n",
       "      <td>The main weakness is that most of the paper is...</td>\n",
       "      <td>l.146 the link between the ideal $P_z$ and a l...</td>\n",
       "      <td>The conclusion is a list of limitations that i...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>...</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>The main strength of this paper is a finite sa...</td>\n",
       "      <td>The paper has a few minor issues, but I believ...</td>\n",
       "      <td>- Can you address my comment on conditional ve...</td>\n",
       "      <td>yes</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>- The main strength of the paper is that it pr...</td>\n",
       "      <td>- To my reading of the paper, the most importa...</td>\n",
       "      <td>- Is there any chance to obtain lower bounds f...</td>\n",
       "      <td>One important limitation that is not mentioned...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>The paper demonstrates several strengths that ...</td>\n",
       "      <td>While  the paper demonstrates strengths, there...</td>\n",
       "      <td>1.  I would like to request the authors to add...</td>\n",
       "      <td>It would be valuable for the authors to provid...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>...</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>To the best of my knowledge, using leverage sc...</td>\n",
       "      <td>The idea of the paper is overall good, but the...</td>\n",
       "      <td>* How is the random vector in Key Challenge 2 ...</td>\n",
       "      <td>I was unable to find a discussion by the autho...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate  ...  \\\n",
       "0      1688368213177  1688368213177  1702411303415  ...   \n",
       "1      1688505633161  1688505633161  1702411303319  ...   \n",
       "2      1688552936677  1688552936677  1702411303221  ...   \n",
       "3      1688657604892  1688657604892  1702411303144  ...   \n",
       "4      1688617232745  1688617232745  1702411520565  ...   \n",
       "...              ...            ...            ...  ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  ...   \n",
       "15171  1688449656890  1688449656890  1702411268900  ...   \n",
       "15172  1688485585833  1688485585833  1702411268818  ...   \n",
       "15173  1688665406904  1688665406904  1702411268706  ...   \n",
       "15174  1688755793651  1688755793651  1702411268608  ...   \n",
       "\n",
       "                                          review_summary  \\\n",
       "0      This paper proposes a model-agnostic framework...   \n",
       "1      In this paper, the authors present a unique ap...   \n",
       "2      I have read the other reviews and all rebuttal...   \n",
       "3      Paper introduces a framework to detect and cat...   \n",
       "4      This paper theoretecally and empirically showe...   \n",
       "...                                                  ...   \n",
       "15170  This paper proposes an asymmetric training sch...   \n",
       "15171  In this paper, authors present regression adju...   \n",
       "15172  This paper focuses on estimation of individual...   \n",
       "15173  This paper explores the design and analysis of...   \n",
       "15174  The paper addresses the problem of ATE and ITE...   \n",
       "\n",
       "                                        review_strengths  \\\n",
       "0      1. This paper focuses on samples that remain s...   \n",
       "1      In my opinion, this categorization process of ...   \n",
       "2      The paper is very well written overall, I enjo...   \n",
       "3      To my knowledge, paper presents a novel approa...   \n",
       "4      This paper analyzes shortcut learning theoreti...   \n",
       "...                                                  ...   \n",
       "15170  The strengths of this paper are :\\n- It is a s...   \n",
       "15171  The main strength of this paper is a finite sa...   \n",
       "15172  - The main strength of the paper is that it pr...   \n",
       "15173  The paper demonstrates several strengths that ...   \n",
       "15174  To the best of my knowledge, using leverage sc...   \n",
       "\n",
       "                                       review_weaknesses  \\\n",
       "0      1. Why are the uncertain samples of the model ...   \n",
       "1                                         See questions.   \n",
       "2      I find it quite difficult to judge the technic...   \n",
       "3      There are some weaknesses that could further i...   \n",
       "4      The theory itself has limited applicability du...   \n",
       "...                                                  ...   \n",
       "15170  The main weakness is that most of the paper is...   \n",
       "15171  The paper has a few minor issues, but I believ...   \n",
       "15172  - To my reading of the paper, the most importa...   \n",
       "15173  While  the paper demonstrates strengths, there...   \n",
       "15174  The idea of the paper is overall good, but the...   \n",
       "\n",
       "                                        review_questions  \\\n",
       "0      1. Checking some details in the paper, such as...   \n",
       "1      * In my opinion, at a high level, this method ...   \n",
       "2      1. Can the proposed method be applied to datas...   \n",
       "3      - Table 1: Could you ellaborate why other rela...   \n",
       "4      It seems that this paper forcus on a theoretic...   \n",
       "...                                                  ...   \n",
       "15170  l.146 the link between the ideal $P_z$ and a l...   \n",
       "15171  - Can you address my comment on conditional ve...   \n",
       "15172  - Is there any chance to obtain lower bounds f...   \n",
       "15173  1.  I would like to request the authors to add...   \n",
       "15174  * How is the random vector in Key Challenge 2 ...   \n",
       "\n",
       "                                      review_limitations review_rating  \\\n",
       "0      Is DAUC a model-agnostic approach that can be ...             6   \n",
       "1      Yes, the limitations have been listed by the a...             6   \n",
       "2                                                   Yes.             6   \n",
       "3      Some of the assumptions and limitations of pro...             6   \n",
       "4      The theory itself has limited applicability du...             6   \n",
       "...                                                  ...           ...   \n",
       "15170  The conclusion is a list of limitations that i...             6   \n",
       "15171                                                yes             7   \n",
       "15172  One important limitation that is not mentioned...             5   \n",
       "15173  It would be valuable for the authors to provid...             4   \n",
       "15174  I was unable to find a discussion by the autho...             4   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      3                 3                    3   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 3                    3   \n",
       "3                      4                 2                    3   \n",
       "4                      3                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "15170                  4                 3                    3   \n",
       "15171                  5                 3                    3   \n",
       "15172                  3                 2                    2   \n",
       "15173                  3                 2                    1   \n",
       "15174                  3                 3                    2   \n",
       "\n",
       "       review_contribution  \n",
       "0                        3  \n",
       "1                        4  \n",
       "2                        2  \n",
       "3                        3  \n",
       "4                        3  \n",
       "...                    ...  \n",
       "15170                    3  \n",
       "15171                    3  \n",
       "15172                    2  \n",
       "15173                    3  \n",
       "15174                    2  \n",
       "\n",
       "[15175 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file as a pandas DataFrame\n",
    "df_reviews = pd.read_json('/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v1.json')\n",
    "\n",
    "# Display the header of the first 5 samples\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame with 'total_review' column saved to JSON file at: /home/ali/Review_Quality_Benchmark/data/processed/openreview_ICLR2024_total_review.json\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the specified columns into a single column named 'total_review'\n",
    "df_reviews['total_review'] = df_reviews[['review_summary', 'review_strengths', 'review_weaknesses', 'review_questions', 'review_limitations']].apply(\n",
    "    lambda row: ' '.join(row.dropna()), axis=1\n",
    ")\n",
    "\n",
    "# Drop the original columns to reduce redundancy\n",
    "df_reviews = df_reviews.drop(columns=['review_summary', 'review_strengths', 'review_weaknesses', 'review_questions', 'review_limitations'])\n",
    "# Create a new column 'length_words' to count the number of words in the 'total_review' column\n",
    "df_reviews['length_words'] = df_reviews['total_review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "# Save the new DataFrame to a different JSON file\n",
    "new_output_json_path = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_ICLR2024_total_review.json'\n",
    "df_reviews.to_json(new_output_json_path, orient='records', indent=4)\n",
    "\n",
    "print(f\"New DataFrame with 'total_review' column saved to JSON file at: {new_output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dc4701bd-a01e-4e00-92a9-ddadc4d3482c",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>review_mdate</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate   review_mdate  \\\n",
       "0      1688368213177  1688368213177  1702411303415  1702411303415   \n",
       "1      1688505633161  1688505633161  1702411303319  1702411303319   \n",
       "2      1688552936677  1688552936677  1702411303221  1702411303221   \n",
       "3      1688657604892  1688657604892  1702411303144  1702411303144   \n",
       "4      1688617232745  1688617232745  1702411520565  1702411520565   \n",
       "...              ...            ...            ...            ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  1702411081106   \n",
       "15171  1688449656890  1688449656890  1702411268900  1702411268900   \n",
       "15172  1688485585833  1688485585833  1702411268818  1702411268818   \n",
       "15173  1688665406904  1688665406904  1702411268706  1702411268706   \n",
       "15174  1688755793651  1688755793651  1702411268608  1702411268608   \n",
       "\n",
       "       review_rating  review_confidence  review_soundness  \\\n",
       "0                  6                  3                 3   \n",
       "1                  6                  4                 3   \n",
       "2                  6                  4                 3   \n",
       "3                  6                  4                 2   \n",
       "4                  6                  3                 3   \n",
       "...              ...                ...               ...   \n",
       "15170              6                  4                 3   \n",
       "15171              7                  5                 3   \n",
       "15172              5                  3                 2   \n",
       "15173              4                  3                 2   \n",
       "15174              4                  3                 3   \n",
       "\n",
       "       review_presentation  review_contribution  \\\n",
       "0                        3                    3   \n",
       "1                        3                    4   \n",
       "2                        3                    2   \n",
       "3                        3                    3   \n",
       "4                        3                    3   \n",
       "...                    ...                  ...   \n",
       "15170                    3                    3   \n",
       "15171                    3                    3   \n",
       "15172                    2                    2   \n",
       "15173                    1                    3   \n",
       "15174                    2                    2   \n",
       "\n",
       "                                            total_review  length_words  \n",
       "0      This paper proposes a model-agnostic framework...           225  \n",
       "1      In this paper, the authors present a unique ap...           513  \n",
       "2      I have read the other reviews and all rebuttal...           650  \n",
       "3      Paper introduces a framework to detect and cat...           453  \n",
       "4      This paper theoretecally and empirically showe...           307  \n",
       "...                                                  ...           ...  \n",
       "15170  This paper proposes an asymmetric training sch...           574  \n",
       "15171  In this paper, authors present regression adju...          1063  \n",
       "15172  This paper focuses on estimation of individual...           519  \n",
       "15173  This paper explores the design and analysis of...          1546  \n",
       "15174  The paper addresses the problem of ATE and ITE...           358  \n",
       "\n",
       "[15175 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2e1a90c0-8134-47f0-b914-cfe20fab4bb4",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>review_mdate</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate   review_mdate  \\\n",
       "0      1688368213177  1688368213177  1702411303415  1702411303415   \n",
       "1      1688505633161  1688505633161  1702411303319  1702411303319   \n",
       "2      1688552936677  1688552936677  1702411303221  1702411303221   \n",
       "3      1688657604892  1688657604892  1702411303144  1702411303144   \n",
       "4      1688617232745  1688617232745  1702411520565  1702411520565   \n",
       "...              ...            ...            ...            ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  1702411081106   \n",
       "15171  1688449656890  1688449656890  1702411268900  1702411268900   \n",
       "15172  1688485585833  1688485585833  1702411268818  1702411268818   \n",
       "15173  1688665406904  1688665406904  1702411268706  1702411268706   \n",
       "15174  1688755793651  1688755793651  1702411268608  1702411268608   \n",
       "\n",
       "       review_rating  review_confidence  review_soundness  \\\n",
       "0                  6                  3                 3   \n",
       "1                  6                  4                 3   \n",
       "2                  6                  4                 3   \n",
       "3                  6                  4                 2   \n",
       "4                  6                  3                 3   \n",
       "...              ...                ...               ...   \n",
       "15170              6                  4                 3   \n",
       "15171              7                  5                 3   \n",
       "15172              5                  3                 2   \n",
       "15173              4                  3                 2   \n",
       "15174              4                  3                 3   \n",
       "\n",
       "       review_presentation  review_contribution  \\\n",
       "0                        3                    3   \n",
       "1                        3                    4   \n",
       "2                        3                    2   \n",
       "3                        3                    3   \n",
       "4                        3                    3   \n",
       "...                    ...                  ...   \n",
       "15170                    3                    3   \n",
       "15171                    3                    3   \n",
       "15172                    2                    2   \n",
       "15173                    1                    3   \n",
       "15174                    2                    2   \n",
       "\n",
       "                                            total_review  length_words  \\\n",
       "0      This paper proposes a model-agnostic framework...           225   \n",
       "1      In this paper, the authors present a unique ap...           513   \n",
       "2      I have read the other reviews and all rebuttal...           650   \n",
       "3      Paper introduces a framework to detect and cat...           453   \n",
       "4      This paper theoretecally and empirically showe...           307   \n",
       "...                                                  ...           ...   \n",
       "15170  This paper proposes an asymmetric training sch...           574   \n",
       "15171  In this paper, authors present regression adju...          1063   \n",
       "15172  This paper focuses on estimation of individual...           519   \n",
       "15173  This paper explores the design and analysis of...          1546   \n",
       "15174  The paper addresses the problem of ATE and ITE...           358   \n",
       "\n",
       "       citation_count  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "15170               0  \n",
       "15171               1  \n",
       "15172               3  \n",
       "15173               3  \n",
       "15174               0  \n",
       "\n",
       "[15175 rows x 19 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def count_citations(text):\n",
    "    citation_patterns = [\n",
    "        r'\\[\\d+(?:,\\s*\\d+)*\\]',                         # [1], [1, 2, 3]\n",
    "        r'\\([A-Za-z]+ et al\\.,\\s*\\d{4}\\)',               # (Smith et al., 2020)\n",
    "        r'\\(\\d{4}[a-z]?\\)',                              # (2020), (2020a)\n",
    "        r'\\[[A-Za-z]+\\d{4}[a-z]?\\]',                     # [Smith2020], [Johnson2021a]\n",
    "        r'\\b(?:doi:|arxiv:|https?://[^\\s]+)',             # DOI, arXiv, URLs\n",
    "    ]\n",
    "    pattern = '|'.join(citation_patterns)\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)\n",
    "\n",
    "\n",
    "# Apply the count_citations function to the 'total_review' column and create a new column 'citation_count'\n",
    "df_reviews['citation_count'] = df_reviews['total_review'].apply(count_citations)\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 14:15:26.522604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746728126.544830 3911350 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746728126.551650 3911350 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746728126.571549 3911350 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746728126.571568 3911350 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746728126.571570 3911350 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746728126.571572 3911350 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 14:15:26.578010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Processing reviews: 100%|██████████| 15175/15175 [18:33<00:00, 13.63it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "64ea5b0a-213a-414b-bf6e-cae37c062a2e",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>review_mdate</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate   review_mdate  \\\n",
       "0      1688368213177  1688368213177  1702411303415  1702411303415   \n",
       "1      1688505633161  1688505633161  1702411303319  1702411303319   \n",
       "2      1688552936677  1688552936677  1702411303221  1702411303221   \n",
       "3      1688657604892  1688657604892  1702411303144  1702411303144   \n",
       "4      1688617232745  1688617232745  1702411520565  1702411520565   \n",
       "...              ...            ...            ...            ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  1702411081106   \n",
       "15171  1688449656890  1688449656890  1702411268900  1702411268900   \n",
       "15172  1688485585833  1688485585833  1702411268818  1702411268818   \n",
       "15173  1688665406904  1688665406904  1702411268706  1702411268706   \n",
       "15174  1688755793651  1688755793651  1702411268608  1702411268608   \n",
       "\n",
       "       review_rating  review_confidence  review_soundness  \\\n",
       "0                  6                  3                 3   \n",
       "1                  6                  4                 3   \n",
       "2                  6                  4                 3   \n",
       "3                  6                  4                 2   \n",
       "4                  6                  3                 3   \n",
       "...              ...                ...               ...   \n",
       "15170              6                  4                 3   \n",
       "15171              7                  5                 3   \n",
       "15172              5                  3                 2   \n",
       "15173              4                  3                 2   \n",
       "15174              4                  3                 3   \n",
       "\n",
       "       review_presentation  review_contribution  \\\n",
       "0                        3                    3   \n",
       "1                        3                    4   \n",
       "2                        3                    2   \n",
       "3                        3                    3   \n",
       "4                        3                    3   \n",
       "...                    ...                  ...   \n",
       "15170                    3                    3   \n",
       "15171                    3                    3   \n",
       "15172                    2                    2   \n",
       "15173                    1                    3   \n",
       "15174                    2                    2   \n",
       "\n",
       "                                            total_review  length_words  \\\n",
       "0      This paper proposes a model-agnostic framework...           225   \n",
       "1      In this paper, the authors present a unique ap...           513   \n",
       "2      I have read the other reviews and all rebuttal...           650   \n",
       "3      Paper introduces a framework to detect and cat...           453   \n",
       "4      This paper theoretecally and empirically showe...           307   \n",
       "...                                                  ...           ...   \n",
       "15170  This paper proposes an asymmetric training sch...           574   \n",
       "15171  In this paper, authors present regression adju...          1063   \n",
       "15172  This paper focuses on estimation of individual...           519   \n",
       "15173  This paper explores the design and analysis of...          1546   \n",
       "15174  The paper addresses the problem of ATE and ITE...           358   \n",
       "\n",
       "       citation_count  question_count  \n",
       "0                   0               8  \n",
       "1                   0               1  \n",
       "2                   0               6  \n",
       "3                   0               1  \n",
       "4                   0               0  \n",
       "...               ...             ...  \n",
       "15170               0               3  \n",
       "15171               1               1  \n",
       "15172               3               2  \n",
       "15173               3               9  \n",
       "15174               0               0  \n",
       "\n",
       "[15175 rows x 20 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def count_questions(review_text):\n",
    "    \n",
    "    if review_text:\n",
    "        question_count = 0\n",
    "\n",
    "        sentences = sent_tokenize(review_text)\n",
    "        for sent in sentences:\n",
    "            inputs = tokenizer(\n",
    "                sent,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=64,\n",
    "                padding=True\n",
    "            ).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                predicted = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "                # Label 0 = question\n",
    "                if predicted == 0:\n",
    "                    question_count += 1\n",
    "\n",
    "    return question_count\n",
    "\n",
    "\n",
    "df_reviews['question_count'] = [\n",
    "    count_questions(row['total_review']) for row in tqdm(df_reviews.to_dict('records'), desc=\"Processing reviews\")\n",
    "]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "78ea15a4-454f-4641-8de8-514ba1fca365",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>review_mdate</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate   review_mdate  \\\n",
       "0      1688368213177  1688368213177  1702411303415  1702411303415   \n",
       "1      1688505633161  1688505633161  1702411303319  1702411303319   \n",
       "2      1688552936677  1688552936677  1702411303221  1702411303221   \n",
       "3      1688657604892  1688657604892  1702411303144  1702411303144   \n",
       "4      1688617232745  1688617232745  1702411520565  1702411520565   \n",
       "...              ...            ...            ...            ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  1702411081106   \n",
       "15171  1688449656890  1688449656890  1702411268900  1702411268900   \n",
       "15172  1688485585833  1688485585833  1702411268818  1702411268818   \n",
       "15173  1688665406904  1688665406904  1702411268706  1702411268706   \n",
       "15174  1688755793651  1688755793651  1702411268608  1702411268608   \n",
       "\n",
       "       review_rating  review_confidence  review_soundness  \\\n",
       "0                  6                  3                 3   \n",
       "1                  6                  4                 3   \n",
       "2                  6                  4                 3   \n",
       "3                  6                  4                 2   \n",
       "4                  6                  3                 3   \n",
       "...              ...                ...               ...   \n",
       "15170              6                  4                 3   \n",
       "15171              7                  5                 3   \n",
       "15172              5                  3                 2   \n",
       "15173              4                  3                 2   \n",
       "15174              4                  3                 3   \n",
       "\n",
       "       review_presentation  review_contribution  \\\n",
       "0                        3                    3   \n",
       "1                        3                    4   \n",
       "2                        3                    2   \n",
       "3                        3                    3   \n",
       "4                        3                    3   \n",
       "...                    ...                  ...   \n",
       "15170                    3                    3   \n",
       "15171                    3                    3   \n",
       "15172                    2                    2   \n",
       "15173                    1                    3   \n",
       "15174                    2                    2   \n",
       "\n",
       "                                            total_review  length_words  \\\n",
       "0      This paper proposes a model-agnostic framework...           225   \n",
       "1      In this paper, the authors present a unique ap...           513   \n",
       "2      I have read the other reviews and all rebuttal...           650   \n",
       "3      Paper introduces a framework to detect and cat...           453   \n",
       "4      This paper theoretecally and empirically showe...           307   \n",
       "...                                                  ...           ...   \n",
       "15170  This paper proposes an asymmetric training sch...           574   \n",
       "15171  In this paper, authors present regression adju...          1063   \n",
       "15172  This paper focuses on estimation of individual...           519   \n",
       "15173  This paper explores the design and analysis of...          1546   \n",
       "15174  The paper addresses the problem of ATE and ITE...           358   \n",
       "\n",
       "       citation_count  question_count  \n",
       "0                   0               8  \n",
       "1                   0               1  \n",
       "2                   0               6  \n",
       "3                   0               1  \n",
       "4                   0               0  \n",
       "...               ...             ...  \n",
       "15170               0               3  \n",
       "15171               1               1  \n",
       "15172               3               2  \n",
       "15173               3               9  \n",
       "15174               0               0  \n",
       "\n",
       "[15175 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdate and tcdate equal: 15175\n",
      "cdate and tcdate not equal: 0\n",
      "tmdate and mdate equal: 15175\n",
      "tmdate and mdate not equal: 0\n"
     ]
    }
   ],
   "source": [
    "# Count rows where cdate and tcdate are equal or not equal\n",
    "cdate_tcdate_equal = (df_reviews['review_cdate'] == df_reviews['review_tcdate']).sum()\n",
    "cdate_tcdate_not_equal = (df_reviews['review_cdate'] != df_reviews['review_tcdate']).sum()\n",
    "\n",
    "# Count rows where tmdate and mdate are equal or not equal\n",
    "tmdate_mdate_equal = (df_reviews['review_tmdate'] == df_reviews['review_mdate']).sum()\n",
    "tmdate_mdate_not_equal = (df_reviews['review_tmdate'] != df_reviews['review_mdate']).sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"cdate and tcdate equal: {cdate_tcdate_equal}\")\n",
    "print(f\"cdate and tcdate not equal: {cdate_tcdate_not_equal}\")\n",
    "print(f\"tmdate and mdate equal: {tmdate_mdate_equal}\")\n",
    "print(f\"tmdate and mdate not equal: {tmdate_mdate_not_equal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "63af6ad9-0eb3-474f-a1f7-3913890fb747",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  \\\n",
       "0      1688368213177           1702411303415              6   \n",
       "1      1688505633161           1702411303319              6   \n",
       "2      1688552936677           1702411303221              6   \n",
       "3      1688657604892           1702411303144              6   \n",
       "4      1688617232745           1702411520565              6   \n",
       "...              ...                     ...            ...   \n",
       "15170  1688676041356           1702411081106              6   \n",
       "15171  1688449656890           1702411268900              7   \n",
       "15172  1688485585833           1702411268818              5   \n",
       "15173  1688665406904           1702411268706              4   \n",
       "15174  1688755793651           1702411268608              4   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      3                 3                    3   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 3                    3   \n",
       "3                      4                 2                    3   \n",
       "4                      3                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "15170                  4                 3                    3   \n",
       "15171                  5                 3                    3   \n",
       "15172                  3                 2                    2   \n",
       "15173                  3                 2                    1   \n",
       "15174                  3                 3                    2   \n",
       "\n",
       "       review_contribution                                       total_review  \\\n",
       "0                        3  This paper proposes a model-agnostic framework...   \n",
       "1                        4  In this paper, the authors present a unique ap...   \n",
       "2                        2  I have read the other reviews and all rebuttal...   \n",
       "3                        3  Paper introduces a framework to detect and cat...   \n",
       "4                        3  This paper theoretecally and empirically showe...   \n",
       "...                    ...                                                ...   \n",
       "15170                    3  This paper proposes an asymmetric training sch...   \n",
       "15171                    3  In this paper, authors present regression adju...   \n",
       "15172                    2  This paper focuses on estimation of individual...   \n",
       "15173                    3  This paper explores the design and analysis of...   \n",
       "15174                    2  The paper addresses the problem of ATE and ITE...   \n",
       "\n",
       "       length_words  citation_count  question_count  \n",
       "0               225               0               8  \n",
       "1               513               0               1  \n",
       "2               650               0               6  \n",
       "3               453               0               1  \n",
       "4               307               0               0  \n",
       "...             ...             ...             ...  \n",
       "15170           574               0               3  \n",
       "15171          1063               1               1  \n",
       "15172           519               3               2  \n",
       "15173          1546               3               9  \n",
       "15174           358               0               0  \n",
       "\n",
       "[15175 rows x 18 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'tcdate' and 'tmdate' columns\n",
    "df_reviews = df_reviews.drop(columns=['review_tcdate', 'review_tmdate'])\n",
    "\n",
    "# Rename 'cdate' to 'creation_date' and 'mdate' to 'last_modification_date'\n",
    "df_reviews = df_reviews.rename(columns={'review_cdate': 'creation_date', 'review_mdate': 'last_modification_date'})\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to a different JSON file\n",
    "out = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v2.json'\n",
    "df_reviews.to_json(out, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4 - V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy\n",
    "\n",
    "# English models\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_trf\n",
    "# # Spanish models (used as fallback)\n",
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e84aa45e-9447-4d9d-ae8d-9a418bb87ef9",
       "rows": [
        [
         "0",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_eS3u",
         "1698243150596",
         "1699636093263",
         "6",
         "2",
         "3",
         "2",
         "3",
         "This work proposes LSTNet, a self-supervised method to establish reliable 3D dense correspondences irrespective of the input point clouds’ rotational orientation.\n\nSpecifically, LSTNet learns to formulate SO(3)-invariant local shape transform for each point in a dynamic, input-dependent manner. Each point-wise local shape transform can map the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor, which is passed to the decoder to reconstruct the shape and pose of the input point cloud. \n\nThe proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish dense point-wise correspondences via nearest point pairs between cross-reconstructed point clouds. The self- and cross-reconstruction training strategy is simple yet effective. \n\nLSTNet demonstrates state-of-the-art performance on 3D semantic matching when evaluated on the KeypointNet dataset and part segmentation label transfer when evaluated on the ShapeNet dataset. The performance of aligned shape pairs under the setting of I/I shows that other methods, such as CPAE, are much better than LSTNet. The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.\n\nLack of limitations.",
         "191",
         "0",
         "0"
        ],
        [
         "1",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_jP4i",
         "1698652503617",
         "1699636093190",
         "5",
         "4",
         "3",
         "3",
         "2",
         "1) This paper proposes a self-supervised method to find semantically corresponding points for a point cloud pair;\n\n2）The main idea is to decouple a point cloud feature learning process into a SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms;\n\n3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method. 1) This paper is generally well-written;\n\n2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant\npoint-wise local shape transforms seems to be novel;\n\n3) Experimental results are good. 1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset. \n\n2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation. \n\n3) The running time and GPU memory cost is blurry for me;\n\n4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation\nfrom Rotated, Noisy, and Decimated Point Cloud Data]. Please refer to the weaknesses.",
         "215",
         "0",
         "0"
        ],
        [
         "2",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_wiS9",
         "1698706547448",
         "1699636093122",
         "3",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces LSTNet, which leverages an SO(3)-equivariant encoder-decoder architecture(Vector Neuron Networks, VNNs) and proposes a novel function called local shape transform to further transform the learned features. The proposed method is validated on both the 3D keypoint transfer and part segmentation label transformer tasks. 1. The idea of cross-reconstruction for generating inter-object correspondences in a self-supervised way is interesting;\n\n2. The overall writing is good and the methodology part is well-organized and easy to follow. 1. The novelty of this work seems insufficient for ICLR. The whole pipeline heavily relies on VNNs and the main contribution I personally consider is the local shape transform and the self-supervised mechanism for correspondences.\n\n2. Regarding the local shape transform:\n   2.1. From 3.1.1, the SO(3)-invariant output is $\\mathbf{V}\\mathbf{U}^T \\in \\mathbb{R}^{C \\times C}$, while in 3.1.2, the obtained SO(3)-invariant features $\\mathbf{V} \\in \\mathbb{R}^{C^\\prime \\times 3 \\times N}$ have a different shape;\n\n   2.2 The authors claimed that the local shape transform transforms the global features to local ones. Regarding this, I have two questions. \n\n      2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer. \n\n      2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the \"global\" features by such a mechanism, the features turn to \"local\"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so)\n\n3. Regarding the experiments:\n    3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments;\n\n     3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.\n\n    3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.\n\n   3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?\n\n4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.\n---------------------------------------------\n[1]. Zohaib et al. SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data, ICCV 2023;\n\n[2]. Dent et al. PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors, ECCV 2018\n\n[3]. Ao et al. SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration, CVPR 2021\n\n[4]. Wang et al. You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors, ACM MM 2022\n\n[5]. Yu et al. Rotation-Invariant Transformer for Point Cloud Matching, CVPR 2023 See weaknesses.",
         "570",
         "7",
         "10"
        ],
        [
         "3",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_a6Ps",
         "1698768293694",
         "1699636092942",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper attempts to register point cloud properties to their templates without precise correspondences and exact shape matching. To achieve this, the authors trained a local shape transform (LST) network that produces SO(3) invariant correspondences. The training is self-supervised. The experimental results on ShapeNet look nice. - Valid motivation. Unlike the abused topic, vanilla point cloud registration, the motivation stands and could potentially benefit practical usages.\n- The SO(3)-invariant network design intrinsically ensures robustness against rotations.\n- The joint usage of a global descriptor and a local descriptor makes sense and may help with classification and recognition directly.\n- The self-supervision scheme looks plausible by self and cross-reconstruction. My major concern is with the experimental setup. While the experiments on ShapeNet is common in the community and shows good result, I am in general doubtful whether such an approach could be really applied to the real world. \nIn motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. [Scan2CAD, CVPR 2019]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases. \n\nThe authors also take groundtruth keypoints and semantic segmentations from datasets for the experiments. In the real-world, however, obtaining such accurate high-level semantic information already requires a deep understanding of the point cloud, and its segmentation backbone may already be SO(3) invariant. This impairs the strength that the authors proposed. Following my points in the \"weaknesses\" section, I am curious about several relevant problems in the practical setup (i.e., scan to model). \n1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity? \n2. Will the network still be functional if the density distributions are different across input and output? \n3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?\n4. Would non-gt and/or biased key points and semantic parts be transferred properly?\n\nIt would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.",
         "412",
         "0",
         "5"
        ],
        [
         "4",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_Frem",
         "1699350072271",
         "1699636092872",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a method of learning dense 3D correspondence between shapes in a self-supervised manner. Specifically, it is built on an existing SO(3)-equivariant representation. The input point clouds are independently encoded to SO(3)-equivariant global shape descriptor Z and dynamic SO(3)-invariant point-wise local shape transforms. Then the network is trained via penalizing errors in self- and cross- reconstructions via the decoder. The experiment validates the effectiveness of the proposed method. 1. The paper is in general well organized and easy to follow. \n2. The proposed method is straightforward and shown to be effective on the test data. 1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method. \n2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.\n3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?\n4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design. Please refer to the Weaknees part.",
         "290",
         "0",
         "7"
        ],
        [
         "5",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_xDut",
         "1698437142685",
         "1699636121514",
         "8",
         "5",
         "4",
         "4",
         "3",
         "This paper is about multilingual federated prompt tuning for low-resource languages, bringing together federated learning and prompt-tuning techniques. This approach leverages parameter-efficient fine-tuning which preserves user privacy, and additionally, the authors introduce language distance in order to highlight the strengths of the proposed paradigm. The results show that the technique is parameter efficient and computationally beneficial, reducing by 99% the number of trainable parameters while increasing the performance on downstream tasks (XNLI, NC) of ~7% accuracy. This paper makes a contribution to the federated learning field showing how federated learning can be used to enhance the performance of language models while preserving user privacy. The experiments are well-designed and the results are convincing - added to extensive analyses in order to leverage the capabilities of the proposed paradigm, but also its limitations. Although the paper is generally well-structured, the title mentions `low-resource` languages. However, the two tasks leveraged are primarily on high-resource languages, rather than low-resourced language. I would suggest to the authors to include more tasks - there are many low-resource language datasets (for instance on African languages MasakhaNEWS, Masakhaner (1.0 and 2.0 - which have been cited by the way but not used), MasakhaPOS; Indic languages: https://github.com/AI4Bharat/indicnlp_catalog; etc) and tasks.\n\nThis is rather a highly recommended suggestion, that does not take away the contribution of the paper. Including them would strengthen the paper and be more in accordance with the title. The Aggregation formula is a bit confusing. Did you mean h_{global, t+1} = \\sum_{k=1}^{m} h_{k, t}? Because the `t+1` on the last term does not make sense to me.",
         "262",
         "1",
         "0"
        ],
        [
         "6",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_E7Lk",
         "1698484432194",
         "1700794322411",
         "1",
         "5",
         "1",
         "2",
         "2",
         "The paper introduces a finetuning paradigm that combines federated learning (FL) with prompt tuning for multilingual finetuning on certain, with the goal to preserve the privacy of the local data used for the finetuning job. The results show better performance in certain classification tasks, such as New Classification and XNLI. - Federated learning have recently gained good traction, the paper is a good application of it in the tasks of finetuning LLM. The paper chooses to use prompt tuning instead of full tuning to save costs, as well as to avoid overfitting on small data.\n- The method produces better performance on the 2 classification tasks compared to baselines - The proposed is a very trivial combination of federated learning and prompt tuning, which both are established methodology in their own realm. There is no novelty, such as modification or adjustment to the method that may have give a better results. In other words, people with an objective to do federated learning for privacy purpose can easily come up with prompt tuning as a solution to reduce costs.\n- Though it may have implicitly inferred by the concept of FL, the paper did not mention why and how federated learning helps with privacy and in which case one should use FL for their application.\n- The purpose of the task of multilingual finetuning in this case, is not warranted use case of privacy preservation.\n- There is no reported evidence that privacy is actually preserved. Such as whether the final model memorize the local data.\n- There are better parameter-efficient finetuning methods, such as LORA/QLora, that the authors should conduct experiments on and do comparision with prompt tuning.\n- The results show prompt tuning are much worse than full-federated tuning, thus casting doubt if the cost-saving is worth it.\n- Other generative and knowledge-based tasks, such as QA, translations and summarizations should be performed.\n\n**I have read the author responses and I advocate for a strong reject, below are reasons:**\n\n* I mentioned the paper has fundamental problems with originality, novelty, where the paper uses an unrelated existing and non-novel method designed for a different problem (fed-learning) to solve a low-resource \"privacy\" problem that does not make sense or exist yet, in which the method itself much worse than standard training. \n* Instead of addressing the scientific issue, the authors distracted away by pressing that they are helping the low-resource communities, or improving inequality as a societal issue. These multiple responses are lengthy, wordy, unnecessary, and filled with many \"politically correct\" (I don't know better word) things to avoid the scientific issue. Agree that we should help those under-represented communities, but after reading these, I shouldn't feel like rejecting the paper is an action against those communities.\n* The problem of \"a low-resource community who wants to shut down their internet and border\" is unfounded. We train LLM on public data we can find. If they wants to protect their secret data, they can download a public pre-trained model and fine-tune on their own. \n* The real problem is how to improve low-resource with the limited data we have, which the paper fails to suggest a better solution than trivial.\n* Less communication doens't mean more privacy, because we transfer model weights, not the data. And less parameters doesn't mean less private information be leaked. This misconception leads to wrong approach.\n* The author claims to be the first to target the low-resource problem and many other things, but there have been many works in previous years about this. Please be careful with this kind of \"we are first\" statements.\n* Overall, none of the responses has helped resolve the issues stated in the review. - Citation formet incorrect, \\citep{} be used to produce something like (Abc, et al., 2023) and not Abc, et al., 2023 everywhere.\n- Many grammatical errors, such as \"Throughout the fine-tuning...\"\"",
         "646",
         "0",
         "0"
        ],
        [
         "7",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_AG4r",
         "1698731849876",
         "1700723834276",
         "3",
         "4",
         "4",
         "1",
         "3",
         "The paper proposes a Multilingual Federated Prompt Tuning paradigm, where lightweight multilingual prompts are encoded and on regional devices in different languages and aggregated by averaging the prompt embeddings. The goal is fine-tuning multilingual large language models on resource-constraint devices in a privacy-preserving way. The paper evaluates this approach via the XNLI task, ablated into data efficiency, \"language distance\", and communication cost, against \"monolingual\" training (baseline). The innovation lies in that the paper somehow mashes federated learning, multi-lingual (low resource) language models, and Parameter-Efficient Fine-Tuning in one paper. The fact that they managed to come up with a storyline for a system that bolsters the benefit of each approach is commendable. - poor presentation: the citations are not separable enough from the main text, e.g., without any parenthesis, rendering the submission unreadable. Against the tradition and ease of reading, abbreviations are not defined in advance, e.g., NLI, PFL, PLM.\n- claims unverifiable: no code release.\n- conflating existing metrics with innovation: language distance is not a new concept.\n- conceptual weakness: the contrived baseline was bound to give the proposed approach an edge due to lack of federated learning. Also, what the paper refers to as prompts are just classifier model input, which are different from decoders-style LLM prompts as commonly acknowledged. Finally, the approach has absolutely nothing to do with privacy which the abstract and the main body consistently bolsters. \n- evaluation weakness: only two tasks (new classification and XNLI) was used in evaluation. In section 5.4.1 \n\n>  In both the NC and XNLI tasks, despite the total number of\nparameters exceeding 278 million, the trainable parameters are only around 1.2 million, accounting\nfor less than 0.5% of the total.\n\nCould the authors clarify which part of the model is being fine-tuned?",
         "293",
         "0",
         "0"
        ],
        [
         "8",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_LsRx",
         "1698767055794",
         "1700887244625",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The paper applies federated learning on multilingual scenarios to efficiently parameter-efficient prompt fine-tuning in a manner that preserves user privacy. The idea is to utilize a single global encoder that accumulates the information via federated prompt averaging. Thus, it learns the language patterns without knowing about the user information. They evaluated the experiment on NC and XNLI datasets and found performance improvement over the baseline. - The method is very practical since it is simple and efficient, and it is an appropriate method for training multilingual model.\n- Good analysis on the data efficiency and distance measurement, showing the effectiveness of the proposed method. - In terms of novelty, the proposed idea is not new, and it is only a further investigation of the multilingual setting.\n- Lack of clarity. The paper does not provide enough information about how the prompts are constructed or look like and hyperparameters for all settings. I suggest adding the information to the paper or appendix. Questions:\n- Do you have any findings on why multilingual centralized learning is far worse than federated learning in Table 2?\n- How did you tune the training and parameter averaging?\n\nSuggestions:\n- Figure number is missing on Page 2\n\n\"As depicted in Figure , \"\n\n- Missing Figure/Table \n\n\"This translates to over 99% reduction in the communication overhead shown in 3\"\n\n- Typo\n\n\"Finetuning accuracy across different lanugages on the NC task.\"",
         "234",
         "0",
         "0"
        ],
        [
         "9",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_agCZ",
         "1698322956814",
         "1699636820093",
         "5",
         "3",
         "2",
         "2",
         "2",
         "To tackle Multi-Domain Text Classification (MDTC) task, one mainstream of proposed techniques is to extract the features via the shared and private extractors to capture the domain-invariant and domain-specific knowledge, respectively. However, as the number of domains increases, the count of their private extractors will also rapidly surge.  \nThe author proposed a novel approach Stochastic Adversarial Network (SAN) to avoid the unaffordable explosion of parameters when encountering the newly emerged domains. Specifically, the author modeled the domain-specific feature extractors as a multivariate Gaussian distribution. Furthermore, some tricks, such as domain label smoothing and robust pseudo-label regularization techniques, are utilized to improve the overall performance.\nExtensive experiments on two benchmarks demonstrate the superiority of the proposed method compared with the state-of-the-art baselines. 1.\tThis paper proposes a novel approach, called Stochastic Adversarial Network, to reduce the computational cost while meeting a large amount of domains.\n2.\tThis paper originally employs Gaussian distribution to generate private extractors in order to circumvent the extensive parameters found in previous works. \n3.\tThis paper conducts numerous experiments to show the effectiveness of the proposed scheme. Moreover, the parameter sensitivity and ablation study demonstrate the rationale of parameter selection and the necessity of each modules, respectively. 1.\tThe motivation is trivial. It is hard to say that the model size is the bottleneck of the training process according to Table.1 and 9. 342.91M is absolutely fine in current period. Further, inference process may gain nothing in the aspect of computational acceleration as we only choose one private extractor from the Domain Discriminator D. \n2.\tThe baselines are outdated and improvements on two benchmarks are limited. According to Table 2,3 and 4, it can hardly convince me that the proposed model exactly outperforms the SOTA models. It is worth noting that the author points out this limitation in Appendix E. \n3.\tThe writing and organization need to be improved. \na)\tThe emphasis in writing has been misplaced. As the author highlights the role of multivariate Gaussian distribution in Abstract, you are supposed to tell more story of it instead of the regularization term, which is the idea of others.\nb)\tThe effectiveness is not the focus of this article, efficiency is. Therefore, moving D. 5 to the main body of the article perhaps make your contribution more prominent. \nc)\tSome tools can be utilized effectively to optimize sentence structure and composition. 1.\tThe aim of equation (3) is to ensure that the shared Feature Extractor F_s exactly extract the domain-invariant features. Thus the author maximum this loss to let the discriminator D be confused about the features coming from F_s. Here is the question: discriminator D may lack of capabilities to recognize the difference among domains as this loss function does not involve any domain knowledge.\nThere may exists another adversarial network in equation (3), i.e. domain-specific extractor enhances the capabilities of discriminator D and domain-invariant extractor still confuse the discriminator D. \n2.\tAs a classic NLP task, this method inevitably needs to be compared with chatgpt. Currently, chatgpt has shown remarkable zero-shot capabilities. Therefore, you need to convince the reviewers why your method should be used instead of chatgpt or highlight the scenarios in which your method has significant advantages.",
         "534",
         "0",
         "5"
        ],
        [
         "10",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_NpVu",
         "1698685251472",
         "1699636819980",
         "1",
         "4",
         "1",
         "3",
         "1",
         "The paper presents a new model for MDTC, built on the previous shared-private feature extraction architecture. The innovation includes 1) modelling the parameter of domain-specific feature extractors as a Gaussian random variable, and for each domain, the parameter is drawn from the distribution. This is why the model is called stochastic adversarial network, or SAN, 2)  domain label smoothing 3) pseudo labelling regularization.  The authors show some empirical successes on some datasets. The paper demonstrates that the authors are well aware of the challenges in MDTC and are familiar with various tools in deep learning (such as reparametrization trick, label smoothing, pseudo labelling etc). I have some concerns about this work.\n\n1. Assuming the design of proposed model is sensible (in fact I have doubts on this; see 2), the work heuristically puts together a bunch of well-known techniques to improve performance. Works of primarily such a nature, although potentially valuable in practice, do not possess enough novelty that justifies a publication in ICLR. \n\n2. I have doubts on the proposed approach in the \"stochastic\" part. Let us track the parameter $W_1$ of the domain-specific feature extractor for domain 1. In the beginning it is drawn from the prescribed Gaussian, say, its value is $W_1^{(0)}$, and after the first iteration, the Gaussian parameter gets updated (using the reparametrization trick)  -- well, whether Gaussian parameter is updated or not is not critical here. Then in the next iteration, $W_1$  is drawn again, let us call it $W_1^{(1)}$. If this understanding is correct, then $W_1^{(0)}$ and $W_1^{(1)}$ can be very different. That is, along the training process, $W_1$ will randomly hop everywhere as long as the Gaussian variance is not vanishing. How would such a scheme work at all? Bringing the parameter $W_2$ of the second domain-specific extractor into the picture would show an even more absurd picture: at each iteration $t$, $W_1^{(t)}$ and  $W_2^{(t)}$ are random variables following the same Gaussian distribution. How would $W_1$ and $W_2$ track their respective domain specific features?  If this structure were to work, it would have to be the case where the Gaussian variance is very small (which might be the case as shown in Figure 3 of the appendix). In that case, all domain-specific extractors are more or less the same, i.e, all equal to the Gaussian mean, only subject to some tiny *domain-nonspecific* random perturbation. That would defeat the entire purpose of having domain specific feature extractors. -- I could misunderstood the paper and I am willing to hear the authors' defence on this. In your defence, please also show the initial and final values of the Gaussian mean vector $\\mu$ (say, in terms of its L1-norm divided by its dimension), I would like compare it with $\\sigma$. See weakness 2.\n\nAdditional question: The authors say that the conventional shared-private adversarial scheme will have \"exponential increase\" in model parameters as new domains emerge? Why is it exponential?",
         "484",
         "0",
         "3"
        ],
        [
         "11",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_bAwA",
         "1698806204960",
         "1699636819830",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper tackles the multi-domain text classification (MDTC) problem, and tries to minimize the amount the learning parameters by introducing a stochastic feature extractor (domain feature). The model is effective in handling the benchmark datasets and outperform the other baseline models. Additional multi-source UDA experiment is also conducted as a simple model extension. The proposed model performs strong in the benchmark dataset, with minimized learning parameters. The design of using both shared/private feature extractor is interesting and effective in merging the domain in the latent space. The proposed method is straightforward and easy to understand. 1. Though the proposal seems to be effective and achieving strong performance, the model itself still uses a relative old adversarial backbone, with the discriminator approach for removing the domain invariant feature. The two-feature-extractor approach is interesting, but that is mainly to deal with parameter increase in the MDTC problem. It would be great to see other design improvement in the model.\n2. The performance gain in using the proposed model is marginal on the Amazon review/FDU-MTL datasets. Also, it would be great to have some analysis on adjusting the setting between the two feature extractors. 1. This might be somewhat irrelevant, but would the model perform well in multi domain classification in other domain type(s), e.g., images?",
         "213",
         "0",
         "3"
        ],
        [
         "12",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_skmj",
         "1698632081062",
         "1701140370231",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper studies multi-modal generalization in neural networks such as transformer-based models and recurrent networks. To do so, the authors propose Genertic COG, a modular benchmark with multi-modal splits to test for 3 types of generalization: 1) distractor (generalization to different noise distribution), 2) systemic compositional (generalization to new permutation of task structures) and 3) productive compositional (generalization to tasks of greater complexity) generalization. Experiments conducted by the authors showed that while cross-attention based transformers (e.g. CrossAttn and Perceiver) outperform other models and perform well on distractor and systemic compositional generalization, they fail at productive generalization when the depth of the task tree goes to out-of-distribution (>3). Representational analysis is done to show that cross-attention based transformers (e.g. CrossAttn and Perceiver) superior performance on distractor generalization might be due to their ability to better retain task-relevant (e.g. stimulus and response) information at the penultimate layer. +The paper studies a timely and critical question about the generalization capability of multimodal transformer-based models\n\n+The proposed benchmark dataset uncovers a limitation of current multimodal transformer-based models: productive generalization which can facilitate the development of more generalizable transformers/LLMs. \n\n+The paper is generally well-written and easy to follow -While the paper’s studies show that certain designs (e.g. cross-attention) seem to confer multi-modal generalization, there are still some key questions that can be more thoroughly studied to uncover the reasons why this is the case.\n\n-Similarly, important discussions such as why the (cross-attention) transformers might fail at productive generalization is lacking. What is the key architectural difference between dual stream transformer and transformers with cross attn that can explain their generalization performance? Is it only the lack of a cross attention between the different modalities?\n\nPossible typo:\n“Finally, we included a Perceiver-like model (Jaegle et al., 2021), an architecture designed to generically process multimodal inputs (Fig. 2f).”:  (Fig. 2f) > (Fig. 2e).\n\n\n==Post-Rebuttal==\nI appreciate the authors' response and decided to keep my score.",
         "318",
         "1",
         "3"
        ],
        [
         "13",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_a4Su",
         "1699400405601",
         "1699636123172",
         "3",
         "3",
         "1",
         "2",
         "2",
         "This paper proposes a new benchmark for assessing various forms of generalization in a multimodal setting named gCOG. The dataset includes several different splits intended to measure different aspects of generalization. The paper also compares several different model architectures on the dataset. * The paper introduces a new dataset, gCOG. While the dataset is conceptually similar to those from prior work, such as gSCAN, it supports different types of contexts and instruction types, including more compositional instructions. I'm aware of some prior work (e.g. [1], [2]) that studied compositional generalization in natural language tasks and found that gains on one synthetic task did not always transfer to other tasks, so increasing the diversity of such benchmarks for assessing compositional generalization and related challenges in the multimodal setting could be a potentially valuable contribution.\n\n[1] https://arxiv.org/abs/2007.08970\n[2] https://aclanthology.org/2021.acl-long.75/ * I'm concerned about the strength of the baselines used in the paper (see my related questions below). While the primary contribution of the paper is the dataset, it is also important to establish strong baselines for this new dataset and to ensure that the conclusions from the empirical results are valid. The appendix states that only a *single Transformer layer* with a *single attention head* was used. This is almost certainly not an optimal depth and number of attention heads. Relatedly, it looks like some models are potentially underfit, according to the figures. With >5M training examples and a relatively simple input space, I would have expected a reasonably sized Transformer model to achieve low training loss and reasonable IID generalization. If these models could have been applied to similar tasks such as gSCAN (even using symbolic tokens to represent the scene context), where they could be compared with comparable baselines from prior work, this would have helped establish that these are indeed reasonably strong baselines that have been well tuned.\n* The qualitative difference between gCOG and datasets from prior work such as gSCAN was not very clearly described. For example, one of the key claims seemed to be gCOG \"employs generic feature sets that are not tied to any specific modality\". However, it seems like it is a useful property for a multimodal dataset to have a clear relation to real-world multimodal tasks. Indeed, the authors provide interpretations of their tasks in the form of natural language instructions and visual scenes (e.g. in Figure 1), and these are very useful for understanding the task. Representing this dataset using familiar modalities (e.g. vision, natural language) could enable future work to study different research questions, e.g. the impact of pre-training. The ability to alternatively represent the task input as a sequence of tokens is also reasonable for studying certain research questions, but this also seems possible for datasets from prior work. For example, I understand that gSCAN includes both symbolic descriptions as well as visual renderings. Anyways, I think clarifying the motivation for this dataset (e.g. increasing diversity of available benchmarks, focusing on different generalization challenges, etc.) separately from how inputs are represented for the experiments in this paper (e.g. token sequence vs. images and natural language) would be useful.\n* Some of the main empirical conclusions (e.g. that generalization to greater \"depth\" is challenging for models such as Transformers) are generally known from prior work.\n\nnits:\n* Introduction paragraph 1 - \"on a carefully controlled generic multimodal reasoning tasks\" -> \"on carefully...\" or \"...task\"\n* Appendix A.2.1 - Maybe reference Tables 8 and 9 where you discuss different positional embeddings.\n* Consider discussing [3] in related work. [3] demonstrated the importance of cross-modal attention for gSCAN, and similarly studied the relative difficulty of various aspects of generalization, including distractors.\n\n[3] https://aclanthology.org/2021.emnlp-main.166/ * Why not try more layers and attention heads, e.g. following a standard hyperparameter setting for model size such as those of BERT-Base? Or even BERT-Small?\n* In Figure 2 (F) why does the single-stream Transformer have almost double the parameters of the double stream Transformer? For the other Transformers, do the encoder blocks used for the task vector and stimulus vector share parameters? \n* What optimizer and hyperparameters (e.g. learning rate) were used for training? How were these chosen? I didn't see these details in Appendix A.2. \n* Position embeddings - Since you are representing 10x10 grids as 1D sequences, 1D relative positions may not capture this structure well. On the other hand, absolute position embeddings seem potentially problematic in the case of the SSTrfmr model, since they will not be consistently assigned to the same grid position if the text sequence is first and has varying length. Mitigating this may be important to provide for a fairer comparison with the SSTrfmr model.\n* To what do you attribute the periodic loss spikes during training that are shown in Figure 4 (E)?\n* I found the usage of \"cross-attention\" a bit confusing. For example, the single stream Transformer features cross-modal attention as an implicit consequence of self-attention over the concatenated sequence. I thought this would commonly be referred to as an instance of \"cross-attention\" between modalities. \n* Does the dataset also contain visual renderings and natural language instructions to enable future work to study these tasks using familiar modalities?",
         "860",
         "10",
         "1"
        ],
        [
         "14",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_DJb6",
         "1699470958350",
         "1699636122858",
         "8",
         "4",
         "3",
         "3",
         "3",
         "The paper introduces a new multimodal question answering benchmark for out-of-distribution generalization, specifically covering task compositionality, robustness to distractors and combinatorial generalization. It uses this benchmark to evaluate various models and analyze their performance. - **Topic**: The paper studies an important topic which in my opinion is underexplored in current deep learning research. Especially given the tendency these days to scale training up to vast amounts of data, I believe it is particularly important to design carefully controlled benchmarks that can: evaluate the model’s performance from a critical and cautious standpoint, point to their fundamental limitations (e.g. systematic generalization), and support further research about ways to overcome these.  \n- **Evaluation**: The paper offers both extensive extrinsic evaluation, with performance comparison of various models on the different generalization skills, as well as intrinsic analysis of their internal representations’ degree of alignment to the stimuli.\n- **Clarity**: The writing quality is good and the paper is clear and easy to follow. The paper is well-organized, claims and findings are clearly stated, and useful figures and diagrams are provided.\n- **Related Works**: It does a good job in providing the relevant context, motivation and related works. \n- **Contribution**: The empirical findings of the paper on the benefits and limitations of different inductive biases such as recurrent and attention-based are important and may be of broad interest to the community. - **Pre-trained models** The paper focuses on models trained from scratch rather than pre-trained. This could be a strength and a weakness. On the one hand, it allows for isolating the contribution of the architectural choices from other factors of optimization, and training data. On the other hand, it has been observed that by training models at large enough scales enables the emergence of generalization capabilities, which we don’t see in smaller scales. I think it will be critical to also analyze the performance of pretrained models on the benchmark, in order to strengthen the paper.\n- **Visual Simplicity**: The visual side of the benchmark is quite rudimentary, featuring colorful letters. Extending it to a larger range of visual tokens/objects, that could have more than one property (color), and a broader set of elements and variations (than 26 letters), could be a straightforward extension that could help make it a bit more challenging visually. - **COG task**: It will be useful to discuss the COG task (rather than just mentioning it) before describing the new gCOG one, so that it will be clearer to the reader what are new contributions of the new benchmark compared to COG and the degree of their importance. In the overview diagram I would also recommend showing a sample also from COG to make the differences clearer. \n- **Grid size / generalization**: It could be interesting to vary the size of the grid in training/evaluation and study its impact on model’s performance. \n- **Terminology**: I recommend changing the phrase “Distractor generalization” to one that better conveys it’s about changing the answer distribution. Maybe e.g. answer distribution shift. I also recommend changing the name “Systematic compositional generalization” to “combinatorial generalization”, to emphasize that the main point is the generalization to permutation, and also to better contrast it with the following “Productive generalization” (which could also be systematic).\n- **Figures**: Would be good to increase the size of the plots in Figure 3b. It will also be good the increase the distance and visual separation between the sub-figures in each figure throughout the paper. \n- In the introduction: “multimodal question-answer” -> “answering”.\n- “This design allowed us” -> “This design allow us”.",
         "591",
         "0",
         "2"
        ],
        [
         "15",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2"
        ],
        [
         "16",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head [1], [2], [3]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works [1][2] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n[1], Frozen clip models are efficient video learners, ECCV-2022\n\n[2], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n[3]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0"
        ],
        [
         "17",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7"
        ],
        [
         "18",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0"
        ],
        [
         "19",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_5Cgw",
         "1697885084973",
         "1699636148336",
         "3",
         "5",
         "3",
         "2",
         "2",
         "The study puts forward a VAE-based approach to acquire disentangled representations without the need for supervision. In this framework, it assumes that diverse data samples exhibit variations across multiple factors, making it particularly well-suited for real-world datasets. The newly proposed technique, referred to as CFASL, introduces a range of unsupervised loss components that serve to instill \"inductive biases.\" These include parallel and perpendicular loss terms, in addition to a sparsity loss designed to encourage alignment along factor axes. The outcomes of this study illustrate the method's superior performance when compared to various other unsupervised disentanglement VAEs, both under single-factor and multi-factor alteration scenarios, across multiple widely used benchmark datasets. 1. The paper represents a significant stride in enhancing the practicality of disentanglement techniques within the realm of real image domains. It grapples with a formidable challenge where we cannot presume access to images that solely vary in a singular factor, thereby intensifying the complexity of extracting disentangled representations.\n\n2. The quantitative findings not only exhibit enhancements in the primary focus of this study, which is the alteration of multiple factors, but also in the scenario involving changes in a single factor. 1. The proposed approach incorporates a diverse array of loss terms within its training objectives, with each term potentially making a distinct contribution. However, this diversity comes at the expense of imposing significant assumptions on the underlying image distribution. While I acknowledge that these assumptions may be justified within the context of the datasets considered in this paper, it's worth noting that some metrics, such as DCI, do not unequivocally demonstrate superiority in the ablation study presented in Table 2.\n\nNevertheless, I believe that the paper could benefit from a more comprehensive exploration of the limitations stemming from these strong assumptions. It would be valuable for the authors to provide concrete examples where these assumptions result in unintended or adverse outcomes. Even for an unsupervised setting, it remains crucial to take into account the nature of transformations within the image domain. A more explicit discussion of these assumption-related limitations would substantially bolster the significance of the claims advanced in this paper, in my view.\n\n2. The qualitative results exhibit low image quality. While this is common across unsupervised disentanglement methods, it is really challenging to get convinced that better disentanglement is achieved. It would be valuable for the author to consider domain-specific metrics for the evaluation phase e.g. face identity loss, facial expression classification, head pose regression, etc. to assess whether only a specific attribute is altered during the single factor change experiments. 1. Following the weaknesses mentioned above, could the authors provide concrete examples (other datasets) where the assumptions induced by the loss terms result in unintended or adverse outcomes compared to the baseline beta-VAE?\n\n2. Could the authors please provide the ablation study results of the different loss terms for all datasets considered in the paper (and not only 3D-Cars)?",
         "483",
         "0",
         "7"
        ],
        [
         "20",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_oACj",
         "1698758328711",
         "1699636148260",
         "5",
         "3",
         "3",
         "1",
         "2",
         "The authors introduce a new VAE architecture which operates on pairs of inputs and utilizes a set of regularization terms to induce structured disentanglement of the latent space with respect to observed symmetry transformations between examples in these pairs. The authors show that their model indeed achieves higher disentanglement scores than relevant baselines on a variety of datasets with a variety of different metrics. Specifically, the authors target the 'multi-factor change' regime, and demonstrate improved performance in this setting with their newly introduced metric. - The related work is well covered, and the authors position their method well in the literature.\n- The proposed combination of losses appears novel to the best of my knowledge, and the use of parallelism and orthogonality losses specifically on latent transformations is an interesting and exciting idea. \n- The study of disentanglement with respect to multiple simultaneously changing factors is important and interesting, and the authors make a notable contribution to this direction.\n- The results appear promising, and indicate that the model is performing well with respect to the baselines. \n- The methodology and extended results in the appendix appear sound. The calculation of P-values in the appendix is very important and appreciated. Furthermore, the use of an ablation study to validate their proposed model is a welcome addition. Weaknesses summarized:\n- The paper is challenging to read as the english is quite poor and the logical flow of the work is unorganized.\n- The method itself is composed of a wide variety of loss terms and the intuition or reasoning for why these terms are necessary is not provided. (Specifically for the parallel and perpendicular losses).\n\nIn more detail:\n\nWeakness 1:\nThere are many typos and poor grammar throughout the paper, with many sentences simply not making much sense. I include a few examples below, but there are many many more and the authors should have someone proof read this work more carefully:\n- In the abstract: \"We propose ... (CFASL) on VAEs for the extension to [a] general multi-factor change condition without constraint.\" \n- \"To implement  group equivariant VAE, Winter et al. (2022); Nasiri & Bepler (2022) achieve the translation and  rotation equivariant VAE\"\n- \"For the equivariant encoder and decoder, we differently propose the single forward process by the  encoder and decoder objective functions compared to previous work (Yang et al., 2022).\"\n- \"Differently, we induce disentanglement learning  with group equivariant VAE for inductive bias.\"\n- 'The unsupervised learning work (Winter et al., 2022) achieves class invariant and group equivariant  function in less constraint condition.'\n\nWeakness 2: \nNaming is extremely unclear. For example, what are 'sections' referred to in Section 3.2? How do these differ from factors? \n\nWeakness 3: \nDespite appealing to a precise probabilistic generative model as its primary value and distinction from prior work, the model itself could be made significantly more elegant in the context of generative models. For example, the 'factor prediction' mechanism could be integrated as a component of the generative model and inferred with another approximate posterior, as done in prior work (Song et al 2023).\n\nWeakness 4:\nThe discussion of learning the Lie algebra is quite rushed and the intuition for why the large set of different loss terms should be incorporated is largely missing.\n\n[1] (Song et al. 2023) https://arxiv.org/pdf/2309.13167.pdf Question 1:\nThe point that prior work with autoencoders does not extend to VAE's does not make much sense to me. Specifically the quote: \"Furthermore, the methods on autoencoder are not directly applicable to VAEs, because  of the large difference to VAE in probabilistic interpretation\". Can the authors provide further details to reinforce this claim?\n\nQuestion 2:\nGiven there are so many loss terms for this model, it is likely that it will be computationally expensive to estimate the correct weightings for each of these terms in a hyperparamter search. Can the authors speak to how this was done in their case and how expensive it was? \n\nQuestion 3:\nOne of the main selling points for this paper was the ability to extend disentanglement methods to 'multi-factor' change. However, for the experiments, the authors consider datasets which guarantee commutativity of transformations. Theoretically then, is there a reason why we should expect the other baseline models to not be able to handle this multi factor change? For example, it seems the axis aligned disentangled representations of the beta-vae should be able to compose multiple transformations simply by jointly changing multiple latent dimensions. Is this not the case?",
         "744",
         "6",
         "1"
        ],
        [
         "21",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_A4b1",
         "1698803382759",
         "1699636148172",
         "5",
         "3",
         "2",
         "2",
         "2",
         "Following the Variational Auto Encoder (VAE) framework, this paper proposes an extension of the single factor (change condition) disentanglement learning method, which they call as Composite Factor-Aligned Symmetry Learning (CFASL). The main idea and/or the assumption is certain scenarios such as the composite/complex symmetries (where certain mathematical transformational relationships exist) can be better captured by utilizing explicit symmetrical relationship information, if provided as additional input to the VAE learning framework. \n\nAs a part of the learning scheme, to facilitate this required piece of information, the proposed method explicitly inputs pairwise symmetrical relationship (and corresponding transformation) information. The expectation is the model, if learned in this fashion, should generate better representative samples from within those transformational subspace/domains. \n\nTo better explain and evaluate the scenario, some new metrics such as m-FVMk (extension of a common metric for a single factor change condition evaluation) have been proposed. They have compared their method with some state-of-the-art methods and on nine benchmark datasets; reported results are found to be promising. The following items seem to have some originality: (i) learning from explicit pairwise transformations, (ii) a network architecture to learn the codebook of symmetries for (i),  (iii) some associated metrics supporting (i) and (ii), and (iv) imposing group equivariant encoder-decoder into the learning framework. \n\nOverall, the paper is well written.  Mathematical derivations of different components seem to be sufficient. The proposed method has been tested on a number of benchmarks (both quantitative and qualitative analysis), and reported results are found to be promising. In addition, the ablation study of different loss functions may have added some extra points. \n\nIn terms of quality, I would rate the work as \"moderate\". In this work, one of the important missing part is the proper probabilistic derivation of the methodology, the core of the VAE framework. Or it may be due to the way the paper/work has been presented. To me, it's not sufficient to connect to the VAE world. It is suggested the authors clarify this important aspect with necessary derivations.  \n\nFor certain items/results, the authors claim statistical significance performance (section 5.2, and appendix D); however, without sufficient details of their significance tests. It is suggested authors include details of these statistical tests. \n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, we may require additional details for a fair companion of their results. \n\nThe paper/research may have some significance, and it would be beneficial if the source code could be released. It is suggested the authors clarify the probabilistic derivation of the approach and make a proper connection to the VAE basics. \n\nIt is suggested authors include details of these statistical tests.\n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, I suggest authors provide further details and release code if possible.",
         "461",
         "0",
         "0"
        ],
        [
         "22",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_DbMo",
         "1698968978898",
         "1699636148102",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The manuscript aims to improve existing methods of unsupervised disentangled representations learning.  Inspired by the symmetry group action approach from (Higgins et al 2018,2022), authors suggest several additions for the conventional beta-VAE  method, resulting  in the form of seven supplementary loss terms. The article is devoted to important subject of disentanglement learning. Authors report improvements over some of existing methods on four simple datasets 1) Only simple datasets are considered, the method is not tested on standard complex datasets like MPI 3D. \n\n2) Reported improvements of CFASL in all measured metrics are essentially always situated within standard deviations of some other methods. \n\n3) Reconstruction loss is not reported in 3 out of 4 datasets. Upon visual inspection of reported samples, the reconstruction quality is not satisfactory. \n\n4) As reported on Figure 4, on 3DShapes dataset, there is no consistent improvement in FVM metric even at the expense of deteriorating reconstruction quality . \n\n5) There is no theoretic justifications for introduction of so many, seven in total,  additional loss terms. \n\n6) Description of Lie group action is not clear, how the action by psi_i is defined? how the dimensions of Lie groups are chosen?\n\n7) The described group action by matrix multiplications do not preserve the normal distribution, so the group equivariant term is not compatible with the  standard KL term from beta-VAE loss. \n\n8) There is no comparison with most recent disentanglement methods like DAVA, TCWAE.\n\n9) Related work section does not mention many works from vast literature on disentanglement learning, eg Disentangling Adversarial Variational Autoencoder (ICLR 2023). Why is the reconstruction quality not reported in three out of four datasets?\n\nWhy the method was not tested on standard more complex datasets like MPI3D?",
         "284",
         "0",
         "0"
        ],
        [
         "23",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_mr2r",
         "1698569976113",
         "1699636242675",
         "3",
         "4",
         "2",
         "2",
         "1",
         "The article offers a Gaussian Mixture-based differential entropy/mutual entropy estimation approach. Furthermore, it provides numerical experiments to test the expected behavior of the estimator and its application to self-supervised learning. The article addresses an important problem of mutual information estimation. It provides relevant numerical experiments to test the validity of the proposed approach. - The main approach proposed by the authors seem to be already appeared in the literature in some references not cited by the authors (please see the questions part).\n\n- There seems to be a major issue about the expressions provided for the proposed approach (please see the questions part).\n\n- The presentation requires improvement. ### I. INTRODUCTION \n\n**3rd paragraph:** \n\n- \"identify matrix\":  identity matrix?\n\n- \"The mutual information can be consequently estimated by the entropy decomposition.\": This sentence follows identity matrix addition sentence. I guess it might be better to clarify causality here. At this point, it is not clear what is meant by \"entropy decomposition\", whether it is a trivial procedure and what enables it (mixture of Gaussians modelling?).\n\n### 2.1 BACKGROUND\n\n**Paragraph before (4)**\n\n- After equation (1): instead of \"for a multi-variable Gaussian variable\" use Gaussian (random) vector ?\n\n- In the notation $$X=[x_1,x_2, \\ldots x_n]$$ $x_i$'s appear as column vectors, however, they are actuallly row vectors as $X\\in\\mathbb{R}^{n\\times d}$\n\n- (5) should be\n\n$$\\mathbf{H}_D(X)=\\sum_{i=1}^k \\frac{1}{2} \\log \\left(\\lambda_i+\\beta\\right)+(d-k)\\log(\\beta)+C_d$$\n\n- After (5): \"Therefore, LogDet can estimate the entropy of multivariate Gaussian variables by approximating the differential entropy.\". This is not a surprise/or contribution as the authors  simply defined (5) using (2) by replacing the true covariance with $\\beta I$ perturbed sample correlation (covariance?) matrix. This is sort of obvious. \n\n### 2.1.1 LOGDET ENTROPY ESTIMATOR FOR NON-GAUSSIAN VARIABLE\n\n- Title : ... NON-GAUSSIAN VECTOR\n\n- Replace variable->vector\n\n- There already exists GMM based entropy/mutual information approximation based works such as \n\n[a]. Lan T, Erdogmus D, Ozertem U, Huang Y. Estimating mutual information using gaussian mixture model for feature ranking and selection. InThe 2006 IEEE international joint conference on neural network proceedings 2006 Jul 16 (pp. 5034-5039). IEEE.\n\n[b]. Huber MF, Bailey T, Durrant-Whyte H, Hanebeck UD. On entropy approximation for Gaussian mixture random vectors. In2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems 2008 Aug 20 (pp. 181-188). IEEE.\n\nYou need to refer to existing literature and clearly state what is novel in your approach relative to them.\n\n\n- Theorem 2 and Theorem 3 of [b] above already covers the lower and upper bounds of mixture of Gaussians. It looks like they are same as what is provided in this section. \n\n- There seems to be a major issue about the upper bound expression. The first expression for the upper bound (at the bottom of page 3), contains covariances ($\\Sigma_i$'s ) obtained from the GMM fitting algorithm, whereas the second line contains the overall sample covariance of actual data, instead of conditional covariance estimates. How do you equate these lines? The second line in fact equals to\n\n$$\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)+\\sum_{i=1}^K \\pi_i \\cdot\\left(-\\log \\pi_i+C_d\\right)$$\n\nas $\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)$ is independent of the summation index $i$. This does not make sense as you disregard covariance parameters of the GMM. \n\n- How do you make the upper bound objective co\n\n### 2.2 THE ISSUE OF MODEL SELECTION\n\n- Title: Model Selection is to generic for the discussion in this section. \"The Issue of Model Order Selection\" could be a better title.\n\n\n\n\n### 3. APPLICATION IN SELF-SUPERVISED LEARNING\n\nThe logdet-mutual information based SSL appears to be proposed in the following reference:\n\n[c]. Ozsoy S, Hamdan S, Arik S, Yuret D, Erdogan A. Self-supervised learning with an information maximization criterion. Advances in Neural Information Processing Systems. 2022 Dec 6;35:35240-53.\n\nThe authors should also clarify the relative novelty relative to [c]. Especially, the impact of GMM order selection as the approach in [c] appears to be for $K=1$. There is also claim in [c] that the use of $K=1$  defines correlative information maximizing which targets a linear (identity in their modified setting) between the representations of augmented versions of inputs. For $K>1$ does  maximizing mutual information between augmentation representation lead to nonlinear mappings between them? Is such organization of representation space desirable for classification tasks, for example?\n\nOr are you just using (18) with order $1$, which seems to be just the approach in [c]. \n\n### 4. RELATED WORKS & 5 SIMULATION STUDIES\n\nAll the references we mentioned above and the relevant references that cite them should be included in this discussion, and simulation results \n\n- 5.2 : ofBelghazi...-> of Belghazi\n- Figure 2: Two small figures and caption could be more informative.\n- 5.4 SSL: What is K for EMP-MILE? Is upper bound employed in EMP-MILE?  what if you directly use MILE?\nHow is backprop used in coordination with the GMM algorithm? As GMM parameters are algorithmically obtained from network output, how does backprop do backward mapping from probabilities $\\pi_i$'s (and there should be covariance estimates $\\hat{\\Sigma}_i$'s, as discussed above)",
         "825",
         "0",
         "11"
        ],
        [
         "24",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_fvqj",
         "1698878886574",
         "1699636242588",
         "3",
         "5",
         "2",
         "1",
         "2",
         "This paper proposes a new approach to estimating the mutual information between a pair of random vectors, by extending the closed-form expression that is available to Gaussian variables to non-Gaussian variables. This is done by estimating Gaussian mixture approximations of the involved densities and then using bounds on the differential entropy of Gaussian mixtures. Estimating mutual information between high-dimensional non-Gaussian variables is an important problem with many applications. The proposed method extends Gaussian (which the authors refer to log-det) estimators to be applicable beyond Gaussian variables via the use of Gaussian mixture approximations, coupled with bounds on the differential entropy of mixtures. Unfortunately. the paper contains several critical flaws, namely a quite sloppy notation, that lead me to recommend its rejection. \n\nThe authors mixture, in a very confusing way, random variables and data matrices, typically using the same notation for both, $X$. For example, in Equations (1), (2), and (10), $X$ is a $d$-dimensional random variable, whereas in Equation (4), $X \\in \\mathbb{R}^{n\\times d}$ is a data matrix. Even worse, in the final equation of page 3, the two different definitions are used together and it is not even clear where the second equality means; it is simply wrong because $X^T X/n$ does not coincide with $\\Sigma_i$.\n\nUnlike what the authors claim, Equation (5) is not equivalent to Equation (5); the two differ by $\\frac{d-k}{2}\\log \\beta$.  \n\nAdding a matrix proportional to identity ($\\beta I$ in the paper) to the sample covariance was not proposed in a 2021 paper. It is a very classical method that can be found in any classical text on covariance matrix estimation, many decades ago.\n\nThe inequality in Equation (8) was not shown by Zhouyin and Liu in 2021. It is a classical result of information theory, that can be found, for example, in the famous Cover and Thomas book. By the way, the citation to this book is wrong in the paper; one of the authors (J. Thomas) is missing. \n\nThe two bounds for the differential entropy of mixtures that the authors claim to have introduced are in fact not new. The upper bound is in fact a well-known corollary of the log sum inequality (see the Cover and Thomas book). The lower bound was proved in 2008 by Huber et al. at https://doi.org/10.1109/MFI.2008.4648062 I have no questions.",
         "383",
         "1",
         "1"
        ],
        [
         "25",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_F4Ta",
         "1698980874812",
         "1699636242491",
         "6",
         "4",
         "3",
         "3",
         "2",
         "This work presents a mutual information (MI) estimator called MILE (LE=logdet estimator) which uses \nthe log det closed form formula of the entropy of Gaussians.\n\nTo accomodate MI to arbitrary densities, a Gaussian mixture model (GMM) is first fit to data and lower/upper bounds on the entropy of GMM is used to define MILE formula Eq 15. \n\nThen MILE is benchmarked with other MI  estimators and MILE can be used in loss functions in semi-supervised learning in experiments. - Simple MI estimator method based on  \n\nZhanghao Zhouyin and Ding Liu. Understanding neural networks with logarithm determinant entropy estimator. arXiv preprint arXiv:2105.03705, 2021\n\n(cited in the paper)\n\n- Very good experiments and comparisons with other MI estimators\n\n- Source codes provided in supplemental information  for reproducible research -The paper is sloppy in its writing, and one problem is to determine the number of components k of the GMM which\n loosen the lower upper bounds on the entropy. \n\n- Another problem is to deal with near singularity (det close to zero) by introducing a regularization term \\beta.\n\n- Give definition of MI and link with copulas, e.g.,\nMa, Jian, and Zengqi Sun. \"Mutual information is copula entropy.\" Tsinghua Science & Technology 16.1 (2011): 51-54.\nThis will relate to Eq. 8 as well.\n\n- Because MI estimation is an important and well-studied topic, I suggest to put Section 4 on related works after the introduction to that the contributions are better explained.\n\n- The lower/upper bounded of entropy of GMMs are not tight. There is a rich litterature which also compares the tightness of the various bounds.\n\nHuber, Marco F., et al. \"On entropy approximation for Gaussian mixture random vectors.\" 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems. IEEE, 2008.\n\nEven in 1D:\nNielsen, Frank, and Ke Sun. \"Guaranteed bounds on the Kullback–Leibler divergence of univariate mixtures.\" IEEE Signal Processing Letters 23.11 (2016): 1543-1546.\n\n- Notice that some distributions do not admit densities (some elliptical distributions for example)\n\n\n\n- Mention MI properties (i.e., tensorization) which defines the self-consistency test of estimators\n\n\n- small remarks:\n* data covariance = scatter matrix\n* after (3), define $\\Sigma_x$ as scatter matrix?\n*  page 3, first sentence need to be rephrased\n* some typos: \npage 7  hyperparamter -> hyperparameter\npage 9 self-supervied -> self-supervised    competitve -> competitive - Would using PCA beforehand be more appropriate in the case of near singularity?\n\n- Can we tackle robustness/variance with f-MI?\n\nMoon, Kevin, and Alfred Hero. \"Multivariate f-divergence estimation with confidence.\" Advances in neural information processing systems 27 (2014).\nEsposito, Amedeo Roberto, Michael Gastpar, and Ibrahim Issa. \"Robust Generalization via f− Mutual Information.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.",
         "447",
         "3",
         "7"
        ],
        [
         "26",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_MHkc",
         "1699156174555",
         "1699636242410",
         "3",
         "4",
         "2",
         "3",
         "2",
         "this paper proposes to use the logdet function for the estimation of mutual information. \ntwo bounds are proposed for this purpose. the results show improvement in comparison \nto the editing methods. the proposed function itself is \"the Coding Length Function\". simple method with good results. In my opinion this paper reinvents \"Coding Length Function\".  \"...the difference is we put a scaling hyperparameter β on the identity matrix I..\" - that is not a difference. both affects SNR. The latter can be affected either way: by multiplying the noise covariance or by division of the data covariance. I do agree that the results are interesting, but the novelty is quite limited due the the above. \n\nplease elaborate on the limitations. \"So, we recommend β = 1e−3 in the following simulation studies\" why not beta=zero? \nFigure 1.b shows that beta=zero correctly estimates the true MI. \nThat raises a question why do you need beta > 0?\n\nHow do you define $\\pi_c$ in e.g., Eq17?\n\nBoth bounds are loose. How can you explain that such loose bounds lead to very small variance in MI?\n\nDo you calculate MILE in batches?",
         "187",
         "0",
         "1"
        ],
        [
         "27",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_oYZA",
         "1699327631740",
         "1699636242348",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The paper proposes uses bounds on the entropy and mutual information for a mixture of Gaussian random variables based on the log determinant calculations used in calculating the entropy for a single Gaussian. In the context of self-supervised learning, the Gaussian mixture is assumed to known based on the augmentation. In other cases the number of mixture components has to be selected. Empirical results are reported on a synthetic benchmark of correlated Gaussians with and without non-linear transformations. Results of self-consistency measures are reported on CIFAR10. The paper is a logical motivation. Differential entropy is easy to calculate for Gaussian distributions, and mixture of Gaussians are universal approximations given enough data, so why not use GMM for mutual information estimation. The insight of using the augmentations as defining the GMM is a useful, simplifying assumption. One main weakness is the lack of extensive comparisons of using this method for self-supervised learning versus other. The one example in the main body (Table 1) shows that at 300 epochs the method is better than some other methods but is inferior to EMP-SSL. At 1000 epochs the other methods outperform the listed, but no results for 1000 epochs are reported. \n\nThe second main weakness is the paper does not give a complete description of the method. The paper is lacking in clarity with some key point unaddressed. The notation is confusing since the random variables (Z,Z') are denoted the same as Z_c, which may be a data point in the empirical sample. There should more clarity on random variables as compared to  sample sets, starting back before equation 4. The confusion carries to last paragraph of Section 4 where $\\mathbf{X}$ is defined but then $X$ is used in the definition. \n\nThe use of one instance for one cluster is not clear to me upon reading it\n\"This is because we treat the augmented data from one instance as a cluster, and this data\naugmentation strategy automatically clusters the data.\" This should be re written.\n\n In equation 17 it is not clear how $\\zeta_c$ captures all instances in the batch. It has only a single $i$ index. Perhaps the $\\zeta_c$ should concatenate them all. In section 3.2, $\\zeta_c$ is a set which indexes the whole match, which makes more sense, but it should be a matrix not a set. In any case, how is the $H(Z)$ term estimated in section 3.1? By keeping $Z_c$ fixed and only augmenting the second the one covariance matrix will be rank-1 (before ridge). \n\nIt doesn't sound like the experiments for the 5.2 are run fairly \" our MILE estimator does not require extra training,\" In this problem the point is that the MI could be changing at each data instance. Thus, other methods do not use access to the change points. MILE should have to be run (which involves performing the GMM since there are no self-clusters as in SSL) at each point. Running an expectation maximization is as much or more training than the updates of network.  \t\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. \n \nIn terms of unsubstantiated claims, the method is clearly biased (not only by the choice of number of components) but also on the non-linear transform cases. It is not clear how well the mutual information estimation would actually work on more complicated data. Thus, even if it is useful for self-supervised learning is not necessarily a more accurate estimate of differential entropy. \n\n**Minor:**\nThere are a number of typographical mistakes that are distracting.\n\nI don't understand what this means\n\"often dwarfing traditional parametric and non-parametric approaches in statistics\"\n\n\" base on the \" -> \"based on the \" \n\nI'm not familiar with this phrasing \"When X subjects to a Gaussian\" \n\n\"a ‘noise’ $\\hat{X}$ \" -> \"a noisy $\\hat{X}$\" \n\nThe paragraph before equation (4) are not clear. \" an expanding factor\" is not defined nor is it clear what is meant by \"enlarging the original covariance matrix\".\n\nExtra $=$ on equation 14.\n\n\"trading each\" -> \"treating each\" ? \n\n\" ground true data\" \n\n\"SMILE: moothed\" -> \"SMILE: smoothed\" \n\nIt should be a parenthetical reference for You et al. (2017) fo LARS optimizer. How is the $H(Z)$ term estimated in section 3.1? Is it also based on augmented data?\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. Are there hyper-parameters for EMP-SSL?  \n\nWhy in Table 1 is 1000 epochs not tested?\n\nIs the GMM method run at each time point in Figure 2?",
         "766",
         "1",
         "2"
        ],
        [
         "28",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_e4bh",
         "1698824679826",
         "1700667146725",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs) which build on the graph theoretical concept of graphexes to include sparse network structures between agents. This improves over prior work on Graphon Mean Field Games which only allows for modelling with dense graphs. The authors derive convergence properties for the finite game. In addition, a learning algorithm based on online mirror descent is provided for a particular class of GXMFGs that follow a core-periphery network structure. Finally, the theoretical claims are empirically validated over both synthetic and real-world networks. - This paper has a clear motivation to extend Graphon Mean Field Games to deal with sparse graphs which are frequently seen in practice. The hybrid graphex approach proposed in this work looks like a natural and intuitive solution.\n- The technical development is principled and the analysis is nontrivial.\n- The overall presentation and clarity is good. - Even though the authors explained in the paper, I didn't like the fact that the proposed GXMFGs have no baseline competitors to compare against. While I agree that one could argue on the contrary that the ability to work with sparse graphs is precisely the unique advantage of GXMGFs, I think that the authors should at least spend some efforts to discuss (if empirical comparison with LPGMFG is indeed unsuitable) how GXMFGs would compare with LPGMFG and GMFG in practice. In Figure 3a, it looks like the curves are diverging rather than converging as k increases? Are the curves coloured correctly?",
         "248",
         "0",
         "0"
        ],
        [
         "29",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_hgJx",
         "1698838739665",
         "1699636550718",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs), a framework for addressing the challenge of learning agent behavior in large populations. GXMFGs leverage graphon theory and graphexes, which represent limiting objects in sparse graph sequences. This approach suits real-world networks with both dense cores and sparse peripheries. The paper presents a specialized learning algorithm for GXMFGs. \n\nKey contributions include:\n\n1. Introduction of GXMFGs, extending the scope of Mean Field Games.\n2. Provides theoretical guarantees to show that GXMFGs accurately approximates finite systems.\n3. Development of a learning algorithm tailored to GXMFGs.\n4. Empirical validation on synthetic and real-world networks, demonstrating GXMFGs' ability to model agent interactions and determine equilibria effectively. - Well-Written and Organized: The paper demonstrates strong writing and organization, enhancing its overall readability and accessibility.\n\n- Clear Motivation: The paper effectively conveys a clear and compelling motivation for addressing the problem it tackles.\n\n- Thorough Discussion of Prior Works: The paper provides a comprehensive and well-structured overview of prior works related to the research area.\n\n- The paper provides solid theoretical contributions complimented with supporting empirical studies strengthens the paper's arguments and findings. As the current paper falls outside the scope of my research interests, I am unable to identify any significant weaknesses in the paper. Consequently, my confidence in assessing the paper is limited. - Providing an intuitive explanation for assumptions 1(b) and 1(c) would greatly enhance the paper's overall readability and accessibility.\n\n- While the paper assumes finite state and action spaces, it may be beneficial to explore whether the proposed approach can be extended to scenarios with infinite action spaces. \n- Including the code for the simulations, would enhance reproducibility.",
         "275",
         "0",
         "4"
        ],
        [
         "30",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_P6cQ",
         "1698854680058",
         "1699636550633",
         "6",
         "4",
         "3",
         "3",
         "3",
         "In this paper, the authors study a class of games with many players who are interacting through a sparse graph structure. More specifically, they are interested in the regime where the number of players tend to infinity. The main solution concept is an extension of the notion of Nash equilibrium. The authors propose a learning algorithm based on online mirror descent. They conclude the paper with examples and numerical simulations. Overall, the paper studies an interesting problem and is relatively clearly written. As far as I know, this is a new extension of MFG to sparse graphs. The algorithm is very inspired from existing ones but there is an adaptation to the problem under consideration (core vs periphery). The model is quite abstract at some places. For the theoretical results, they are mostly about the analysis of the game and I am not sure how relevant they are for this conference (although they are certainly interesting for a certain community). It might have been more interesting to focus more on the learning algorithm. \n\nThere are some typos which make it hard to check the correctness of some parts (see questions). 1. I am wondering if some assumptions are missing. For example below Lemma 1, should $f$ be at least measurable (and perhaps more?) with respect to $\\alpha$ for the integral to make sense?\n\n2. Assumption 2 as used for instance in Lemma 1 does not seem to make much sense (unless I missed something): What is $\\boldsymbol{\\pi}$? We do not know in advance the equilibrium policy and even if we did, we would still need to define the set of admissible deviations for the Nash equilibrium. Could you please clarify?\n\n3. Algorithm 1, line 14: Could you please explain or recall what is $Q^{k, \\mu^{\\tau_{\\mathrm{max}}}}$?\n\nSome typos: Should the state space be either $\\mathcal{X}$ or $X$ (see section 3 for instance)? Does $\\mathbb{G}^\\infty_{\\alpha,t}$ depend on $\\boldsymbol{\\mu}$ or not (see bottom of page 4)? Etc.",
         "324",
         "0",
         "4"
        ],
        [
         "31",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_qFZD",
         "1698724264822",
         "1699636511957",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper introduces out-of-variable (OOV) generalization, which is an the ability to generalize in environments with variables that have never been jointly observed before. OOV is an issue in settings where different variables (e.g. diagnostic tests) are available for different environments (e.g. different patients). The paper investigates challenges for common approaches when faced with the OOV problem, and proposes an OOV predictor that leverage moments of the error distribution. The work contributes to theoretical understandings of OOV and offers a proof-of-concept for a predictor capable of non-trivial OOV transfer. - The paper formally studies a new perspective on generalization.\n- The methods employed in the paper are sound. - The paper does not demonstrate the practical applicability of the concept of OOV generalization, and the setting feels a bit contrived. Also it seems like OOV generalization can be thought of just a case of OOD generalization--if we think about all the variables together as the input, the OOV generalization is just a case of OOD generalization (e.g. covariate shift) where some inputs have clear signal from some features and other inputs have clear signal from other features. \n- It would be helpful to include more intuitive discussion throughout the paper providing more analysis on the sections. For example, more discussion on the assumptions of the settings/theorems would be helpful, and it's not clear exactly under what assumptions the proposed predictor is appropriate. Please see weaknesses above.",
         "236",
         "0",
         "2"
        ],
        [
         "32",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_s9Ga",
         "1698762596885",
         "1700684618252",
         "8",
         "4",
         "3",
         "4",
         "2",
         "This work investigates out-of-variable (OOV) generalization, which is a sub-problem to OOD generalization, and refers to scenarios where an agent needs to generalize to environments containing variables that were never jointly observed before. The paper shows that if the source and target environments contain some overlapping variables (and under certain conditions), information from the predictor in the source environment can improve predictions in the target environment. More specifically,  the moments of the residual distribution from the optimal classifier in the source environment can be used to calculate the generating function with respect to the unobserved variable in the target domain.\n\nBased on this observation, the paper proposes a practical algorithm for OOV prediction, evaluates its performance, and compares it against the marginal predictor and imputed predictor, as well as an Oracle predictor. The paper proposes a new and important problem-setting - OOV generalization, which can occur in real-world situations, on its own or alongside OOD aspects. The work also provides an extensive study of the identification problems of various variants of OOV scenarios, including theoretical proofs and examples. \n\nIn addition, the paper proposes a practical algorithm to solve several OOV scenarios that achieves non-trivial OOV transfer on synthetic data.\n\nThe ideas presented in the paper are novel and the conclusion that information from source domains can be used for prediction in the target domain in this setting is important, and can potentially have a broad impact on future research in the field. The main limitation of the paper is that the proposed approach was tested on only synthetic data, and was not validated using more challenging datasets. \n\nIn addition, the extension of OOV in multi-environments is mentioned mainly in the appendix and the algorithm was not tested empirically for that extension. I would like to ask the following questions:\n\n1. For future work, is there a more complicated/realistic dataset to validate the algorithm?\n2. Is it possible to compare the algorithm to state-of-the-art marginal or causal methods such as Mejia et al. (2021) or Janzing (2018)? To validate if Vapnik’s principle holds and whether the proposed approach indeed improves results due to solving a less general problem.\n3. Theorem 3 connects all moments of the residual distribution to the partial derivatives with respect to the unique variable of the target environment. If additional moments were to be calculated as part of the proposed algorithm, would it improve results (for the general function case)? \n4. In general, since the paper's main claim is that in the real world, it is likely to encounter both aspects of OOD and OOV - How simple is it to combine state-of-the-art  OOD methods with the proposed approach? I cannot imagine at the moment a straightforward way to do that.",
         "454",
         "2",
         "3"
        ],
        [
         "33",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_woi7",
         "1698788842803",
         "1699636511769",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper describes the out-of-variable OOV problem, which in its simplest form, aims to learn a predictor Y = f_t(X2, X3) given an OOV predictor Y = f_s(X1, X2) and a dataset (X2, X3), but without any instance of (X2, X3, Y). The authors describe the setting in which this is possible and develops an algorithm. The key observation is that the third moment of the residue Y - f_s(X1,X2) contains information about X3 that is least polluted by the noise. - The key observation/discovery is clever, and the algorithm is straight-forward to use.\n- The writing is clear, clean, and well-referenced. The examples also made things concrete and easy to follow.\n- The rigor and simplicity of the work can act as a foundation to build OOV research. - The main weakness is the applicability of the method. The authors only showed results for proof-of-concept, not for real-world usage. \n- It is unclear how one could identify whether the assumptions are satisfied given a dataset.\n- It is unclear how bad the predictor would be if the assumptions are not satisfied.\n- It is not yet clear what realistic problem can be well modeled by OOV generalization. Intro:\n- It seems OOV fits very well the frame of missing-not-at-random and covariate-dependent missingness. Could the authors comment on that?\n\nSection 2:\n- Theorem 2 is slightly confusing for me at first glance because I thought PA_Y by definition includes all parents of Y (so x1,x2, x3 in the example) and not just those in the target environment (x2, x3). It may be helpful to clarify.\n\nSection 3:\nAs I am trying to get a sense of the restriction and applicability of the approach, I was wondering the following questions: \n- How does the method fair with the oracle as the magnitude of the noise increases? \n- What if the noise is not gaussian but more heavy tailed? \n- Does the performance degrade or improve with increasing number of variables? \n- I assume Theorem 3 does not apply to discrete variables because of the violation of differentiability; is that right?\n\nSection 4:\n- Can include missing-not-at-random imputation and covariate-missing imputation as two more baseline models (a search in Google scholar using the two key phrases yields some methods).\n- It would be really interesting if the authors could find some real-world datasets, create source and target environments by sub-setting the columns, and see how the method performs.\n- Figure 3: I don’t quite understand the figure. It would be helpful to define OOV loss, be explicit about the number of samples on the y-axis being (x2,x3,y) or (x1,x2,y) or something else. I also don’t understand why relative loss is zero means the method is on par with the oracle predictor. Why not just show how the fine-tuning error compares with oracle training, which seems easier to interpret? Anyway, I am overall a bit confused about the figure, so my questions may not make sense.",
         "493",
         "0",
         "0"
        ],
        [
         "34",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_xwQY",
         "1699441328198",
         "1699636511667",
         "8",
         "3",
         "3",
         "3",
         "3",
         "The paper investigates out-of-variable generalization, namely the ability for a predictive model to generalize to target domains in which the agent has never seen the joint variables in the target domain in a single source domain before. Under certain assumptions as well as when these assumptions don't fully hold, the paper shows that the error residual distribution in an environment provides information on the unobserved causal parent variable in this environment, and they use this information to derive an algorithm that performs OOV generalization with source and target domains that have overlapping sets of causal factors. **Originality**\n- As far as I know, though the problem the paper addresses is well-known as a significant problem, the paper provides several theoretical results, mathematical derivations, and supports these with simple empirical results that are novel.\n\n**Quality**\n- The quality of the paper is high. It addresses a high-value problem in a principled fashion, shows how certain assumptions help obtain certain results and how and in which cases these assumptions can be bypasses while maintain approximately accurate results, and evaluates these cases in terms of loss accuracy as well as sample complexity of its approach versus baseline approaches.\n- The paper openly highlights limitations in its work, such as assumptions made for theorems to hold, and proposes prospective future work in multiple avenues. This refreshingly is (1) included at all and (2) doesn't seem like a mere afterthought.\n\n**Clarity**\n- The paper is mostly clear in its explanation of motivation, preliminaries, approach, baseline usage, results, and limitations.\n- The paper does a great job providing simple, clear real-world examples to elucidate the problem and applications of the various theorems included in multiple cases.\n\n**Significance**\n- The significance of the problem the paper addresses is high and the problem is ubiquitous. The approach is promising and can be applied in many real-world settings through Monte-Carlo sampling or similar methods. The paper shows that their approach can perform relatively well in \"few\"-shot settings though this depends on the number of variables involved and the complexity of the problem.\n\nFrom what I can tell, this is excellent work that I hope motivates further addressing this *out-of-variable* generalization problem by the research and applied AI community. My only reservation is my limited knowledge on the understanding of and state-of-the-art theoretical and applied approaches addressing this problem. - Referring to Figure 1, in the first paragraph in page 3, the claim \"it would seem all but impossible...(orange box)\" could be better explained.\n- In Figure 1, it is unclear whether \"With $Y$ not observed in the target domain\" is an assumption made or is somehow indicated in the diagram or earlier in the paper. Eventually I realized that it's an assumption made, but the illustration Figure 1a alone isn't enough to show this assumption. This ambiguity may clear for some or compound for some later in Section 3. - The abstract states \"merely considering differences in data distributions is inadequate for fully capturing differences between learning environments.\" Doesn't out-of-variable technically fall under out-of-distribution, so shouldn't this be adequate? Perhaps more specificity is needed here.\n- The abstract states \"Mathematically, out-of-variable generalization requires the efficient re-use of past marginal information...\" Why does it require efficient re-use? Could it work with \"non-efficient\" or inefficient re-use?\n- On page 2, should \"modal\" be \"model?\"\n- On page 6, do you mean \"parentheses\" instead of \"brackets\" between Eq (9) and Eq (10)?\n- Why is the joint predictor considered an oracle predictor if MomentLearn outperforms it?\n- Could you explain why MomentLearn is reliably more sample efficient than the oracle predictor for \"few\"-shot prediction?",
         "602",
         "0",
         "0"
        ],
        [
         "35",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_HgHQ",
         "1697165838375",
         "1699635934990",
         "3",
         "5",
         "2",
         "3",
         "2",
         "The paper proposes a simple yet efficient feature direction distillation loss. Experiments show that this significantly improves KD\nperformance. 1. Improving KD by feature norm and direction is reasonable and effectiveness.\n2. Experiments on standard benchmarks demonstrate that adopting $\\mathcal{L}_{dino}$ remarkably improves existing KD methods. 1. The contributions seem a little limited. \n2. There is lack of theoretical analysis of DINO loss. The paper is not good enough to be published on ICLR. 1. How to align the features between heterogeneous architectures?\n2. Could you please provide more theoretical analysis?\n3. What about extending it to a multi-layer version of feature distillation?\n4. How to apply the proposed method to existing KD methods, e.g. ReviewKD, DKD, DIST? Just add the DINO loss function to the total loss ? If so, I think adding other loss like contrastive distillation loss or RKD may also make a improvement.",
         "146",
         "0",
         "8"
        ],
        [
         "36",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_yLjx",
         "1697172920902",
         "1699635934905",
         "6",
         "5",
         "3",
         "3",
         "2",
         "Here is a summary of the key points from the paper:\n\n- The paper proposes a method to improve knowledge distillation (KD) by regularizing student features to align direction with teacher class-means and have sufficiently large norms. \n\n- Current KD methods like logit or feature distillation align student and teacher but don't directly optimize for student's task performance.\n\n- The paper shows regularizing direction using cosine similarity to teacher class means helps improve student accuracy. \n\n- It also finds student models tend to produce smaller-norm features, so encouraging larger norms improves performance. \n\n- A simple combined loss called dino-loss is proposed to simultaneously regularize student feature direction and norm using teacher class means.\n\n- Experiments on CIFAR and ImageNet classification, and COCO detection show dino-loss consistently improves various KD methods like KD, ReviewKD, DKD.\n\n- Dino-loss achieves new state-of-the-art results among KD techniques on classification and detection benchmarks.\n\n- The method is model-agnostic, simple to implement, adds minimal overhead, and benefits from larger teacher models.\n\nIn summary, the key contributions are a way to improve KD by regularizing student features for better alignment and norms, along with a simple and effective dino-loss to achieve this jointly. The results demonstrate consistent gains across tasks and benchmarks. The paper presents an original and significant approach to improve KD via thoughtful feature regularization. The method is intuitive and supported by quality experiments. The gains are demonstrated to be significant across tasks. The presentation and discussion are clear:\n- The method and dino-loss are clearly explained with illustrations and equations. Results are well-presented in tables and figures. Limitations are properly discussed.\n- Improving KD is an important practical problem. The consistent gains are significant. Sets new state-of-the-art results on ImageNet classification and COCO detection.\n- Model-agnostic nature allows wide applicability to various KD methods and models. Simple extension can benefit the community compared to more complex techniques. - The paper should address the lack of novelty by acknowledging that feature normalization techniques have already been widely employed in knowledge distillation. For example, PKD (NeurIPS-2023) specifically incorporates channel alignment for detectors, and SKD (Guo Jia) explores normalization techniques on predictions. and Feature Normalized Knowledge Distillation for\n/mage Classification ECCV2022 also presents feature norm. Furthermore, it is worth investigating whether the proposed method has already been considered in the distiller's search work, as exemplified by KD-Zero: Evolving Knowledge Distiller for Any Teacher-Student Pairs (NeurIPS-2023).\n\n- In addition, the paper should incorporate a thorough discussion of relevant KD-related studies, including Self-Regulated Feature Learning via Teacher-free Feature Distillation (ECCV2022), NORM: Knowledge Distillation via N-to-One Representation Matching (ICLR2023), Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer (NIPS2022), DisWOT: Student Architecture Search for Distillation Without Training (CVPR2023), and Automated Knowledge Distillation via Monte Carlo Tree Search (ICCV2023). These discussions will provide valuable insights into the existing literature, establish connections with previous research, and potentially highlight points of comparison and contrast. The only concern to me is the novelty of the work and I hope the authors could discuss some of the related work I mentioned in the revised version.",
         "510",
         "0",
         "1"
        ],
        [
         "37",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_VRvE",
         "1698736302686",
         "1699635934723",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper studies Knowledge Distillation (KD). A simple loss term namely ND loss is proposed to enhance the distillation performance. It encourages the student to produce large-norm features and aligns the direction of student features and teacher class-means. The ND loss helps not only logit-based distillation methods but also feature-based distillation methods. 1. The proposed method is simple but effective. Encouraging the feature norm for the student is novel in the field of KD.\n2. Experimental results are strong. The authors also conduct experiments on object detection. The proposed loss can improve the existing methods on both image classification and object detection.\n3. The whole paper is organized and written well. It is not a novel thing that decoupling the feature into the magnitude and the direction. Previous works [1][2] already studied this point. [1] uses the teacher classifier to project both teacher features and student features into the same space and then align them. [2] proposes a loss term to align two features’ direction. Compared to the existing works, this paper proposes enlarging feature norm and utilizing the class-mean feature. Authors should check more existing papers and discuss their differences.\n[1] Yang, Jing, et al. \"Knowledge distillation via softmax regression representation learning.\" International Conference on Learning Representations (ICLR), 2021.\n\n[2] Wang, Guo-Hua, Yifan Ge, and Jianxin Wu. \"Distilling knowledge by mimicking features.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 44.11 (2021): 8183-8195. None",
         "235",
         "7",
         "6"
        ],
        [
         "38",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_AuzT",
         "1698788774762",
         "1699635934515",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper proposes to use teacher's class-mean to align student's direction and encourage the student to produce large-norms features, improving the performance of KD. The paper is generally well-written, and the methodology is well-motivated. 1. would expect comparisons and discussion to similarity-preserving KD e.g., [1], which is a large family in feature distillation methods and shows some relations to the proposed method.\n2. Meanwhile, comparisons/discussion to explainablity-based KD, e.g., [2] are needed to see whether those methods can be benefited from the proposed method.\n\n[1] Tung, Fred, and Greg Mori. “Similarity-Preserving Knowledge Distillation.” ICCV 2019.\n\n[2] Guo, Ziyao, et al. \"Class Attention Transfer Based Knowledge Distillation.\" CVPR 2023. Please see weakness.",
         "111",
         "4",
         "6"
        ],
        [
         "39",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_AcYB",
         "1697637540901",
         "1700740134087",
         "5",
         "4",
         "3",
         "2",
         "2",
         "The authors introduce Neural Sinkhorn gradient flow, which is a Wasserstein Gradient Flow wrt to the Sinkhorn divergence. The authors show that the velocity field can be calculated using the Sinkhorn potentials. This allows training a neural network approximating the velocity field. Furthermore, a mean field limit is established. The algorithm is evaluated on a toy example, MNIST image generation and CIFAR10 image generation. The authors do a good job at explaining the underlying concepts of their algorithms. The maths is nicely done. The core idea is very neat and the cifar10 results seem to be good quantitatively wrt other gradient flow works. 1) The article is full with typos. Just to name a few: \"piror\", \"Sinkhron\", \"Experimrnts\", \"speedest descent\", question mark in the appendix and so on. Please fix those. \n\n2) the authors write \"We do not compare with extant neural WGF methods on MNIST because most of the neural WGF\nmethods only show generative power and trajectories on this dataset and lack the criteria to make\ncomparisons.\" There are several papers (also gradient flow based ones), which evaluate a FID on MNIST. Please provide it as well. \n\n3) Also many of the MNIST digits appear flipped. Did the authors use data augmentation there? Also there seems to some slight noise present the generated MNIST digits. \n\n4) Although the CIFAR10 value seems good, there are unfortunately no generated images provided. It is standard practice to sample many images in the appendix. \n\n5) It is unclear what the trajectories show. Does it show the particle flow or the trained Neural Sinkhorn Gradient Flow? \n\n6) The statement of theorem 2 is incorrect. I guess the authors do not want to sample the Euler scheme (eq 14) but the continuous gradient flow, otherwise the statement would need to depend on the step size $\\eta$. \n\n7) In the proof of Theorem 2: Please provide a proof (or reference) why the mean field limit exists. Or do you mean the gradient flow starting at $\\mu_0$ with target $\\mu$ (first two sentences).\n\n8) Later in that proof: why does there exists a weakly convergent subsequence of $\\mu_t^M$? Further, I cant find the definition of $U_{\\mu}$. \n\n9) The code is not runnable, as the model (or any checkpoints) are not provided.\n\n10) From how I understood it, the learning of the velocity field is batched, i.e., one trains for different sets of $(z_i,x_i)$. Since the Sinkhorn dynamic describes an interacting particle system I dont see how this should be possible. To be more precise, one particle $\\tilde{x}$ could be sent to $x_0$ in the first batch, but to a totally different particle $x_1$ in another one, depending on the drawn prior and target samples. Are the positions of the other particles also input to the neural network (i.e by putting them in the channels)? Please elaborate. See weaknesses section. Overall I really like the idea, but the weaknesses prevent me from giving a higher score. It seems like the paper was rushed and is currently not ready for publication. I am willing to raise my score, if the authors address these issues.",
         "516",
         "0",
         "3"
        ],
        [
         "40",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KKim",
         "1698338217824",
         "1700755549491",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces a novel way to train generative models. The authors want to approximate the gradient flow in the Wasserstein space.  They want to approximate the vector field which transports the source distribution to the real-data empirical distribution while minimizing the Sinkhorn divergence. The authors showed the analytical form of the vector field when one considers the Sinkhorn divergence and then they explain how to learn this vector field with a neural network through the simulation of a probability path. They showed that their procedures recover the true probability path when the number of iid samples goes to infinity. Finally, they validate their proposed method on several image-generative tasks. i) The motivation and the introduction are clear\n\nii) Regressing vector fields has been a recent and popular approach with many different applications in machine learning. The proposed approach is interesting and appears to be novel. The theoretical results also show that the proposed method has appealing properties. \n\niii) The authors also provided several experiments showing interesting results from their methods. The first thing I would like to highlight is that I have checked the provided code. I see several inconsistencies and weaknesses between the provided code and the paper:\n\n1. There are several differences in the empirical implementation between the paper and the code. In Appendix A, the authors state that they are computing the entropic potential through stochastic optimization algorithms [Genevay et al, 2016]. However, this is not what is done in practice according to the provided code. In practice, the authors compute the potential between mini-batches of samples, they sample a minibatch of cifar10 experiments, then sample a minibatch of the source Gaussian, and simulate the gradient flows between the two minibatches. This style of minibatch approximation induces a bias that should at least be mentioned in the main paper but also discussed. Indeed, the authors do not compute the true Sinkhorn divergence but a minibatch approximation of it; this approximation is slightly different than the one from [1,2] and that should be discussed. I understand the reason why the authors use this approach (decreasing the cost of this preprocessing step), but this is not what they say they do in Appendix A. In that regard, the paper is much closer to the minibatch optimal transport Flow Matching [Pooladian et al., Tong et al] and Appendix A deserves a major revision.\n\n2. With the provided code, there are several insights that should be discussed in the paper. In the provided cifar experiments, the number of Gaussian samples used is 50000 samples. This number is extremely low to approximate the semi-discrete OT. Therefore, a discussion regarding the statistical performance of the method is needed in my opinion.\n\n3. As your method requires the simulation of the probability path, I wonder about the training time between your method and the recent Flow Matching approaches which are simulation free.\n\n4. There are many typos in the paper (including in titles: ie ExperimRnts, Notaions) that lead to poor clarity...\n\n5. The experiments include two toy datasets (synthetic 2D and MNIST). I would like to know how the method performs on other big datasets (Flowers, CelebA) or on other tasks such as single-cell dynamics [4].\n\n6. The related work on optimal transport is incomplete. Several works used the sliced Wasserstein distance to perform gradient flows [3].\n\n[1] Learning Generative Models with Sinkhorn Divergences, Genevay et al, AISTATS 2018\n[2] Learning with minibatch Wasserstein, Fatras et al, AISTATS 2020\n[3] Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions\n[4] TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics 1. [Pooladian et al., Tong et al.] proved that when the minibatch increases, they get closer to the true optimal transport cost (W_2^2). The interest of their method is that they can rely on minibatches and learn the vector field from an unlimited number of minibatches. Could you follow a similar approach and simulate the gradient flow during training? While it would be an expensive step in training, it might improve the metrics on the different generative model experiments.\n\n2. What is the performance of your method concerning the number of simulation steps (ie Euler integration and its learning rate)?\n\n3. What is the time of the preprocessing step concerning the training time?\n\n4. Could you compare your method with OT-CFM [Pooladian et al., Tong et al.] on the synthetic data? I am curious to compare the differences.\n\nIn my opinion, the mentioned weaknesses have to be revised and this paper should go under a major revision. I deeply think that the experimental section should better highlight what is done in practice and the theoretical section should mention the different biases (statistical and minibatch). Therefore, I recommend rejecting the current manuscript as it does not meet the ICLR acceptance bar.\n\n\n----- EDIT POST REBUTTAL -----\n\nI thank the authors for their answers. I have read the updated manuscript. While it is now better than before, I suggest they add a limitation section where they describe the different biases in their algorithm. I understand the motivations of the paper. Overall, I think that the manuscript deserves another round of reviews but I have decided to move my score to 5 as they have given good answers.",
         "873",
         "7",
         "8"
        ],
        [
         "41",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_Kh9H",
         "1698606606187",
         "1699636333063",
         "6",
         "4",
         "3",
         "2",
         "2",
         "Through a series of approximations (and at times, really, relaxations) the authors show that the Sinkhorn gradient flow from one measure to another can be learned.  They do this by first reducing their relaxed problem to a vector field matching problem, and then proposing a neural network-based Algorithm for matching the Sinkhorn-Wasserstein flow's vector field by a neural network (though no convergence/approximation guarantees are proven).\nThe problem is interesting, and its solution is sufficiently novel to merit publication. The problem is natural to study, the results are mathematically correct, and the experiments are convincing. While the paper is mathematically correct, it does not provide theoretical justification for one of its main components, namely showing that approximate vector field matching yields approximate solutions for all time $t$.  I feel that without this guarantee, there is a gap in the theoretical viability of this model.  Nevertheless, this is a minor point since the length of a conference paper does not allow one to treat every such point.\n\nThere are minor typos throughout. \n* E.g. euclidean instead of Euclidean\n* $lim$ instead of $\\lim$ atop page 15 in the appendix\n* The positive scalar $\\delta$ is not defined in the proof of Theorem $1$\n* In the statement of Lemma 3: \"teh\" should read \"the\"\n\nSome references are obscure\n* For The fact that $\\mu + t\\delta \\mu$ converges weakly to $\\mu$, perhaps it is worth simply noting that due to linearity of integration (wrt to the measure term). Can it be shown that approximate vector field matching yields approximate solutions for all time $t$?",
         "262",
         "0",
         "1"
        ],
        [
         "42",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KkYD",
         "1698745650108",
         "1700818697559",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper under consideration deals with the standard generative modelling setup (image generation from noise). To solve this problem, the authors propose to model the gradient flow w.r.t. the Sinkhorn divergence. The paper utilizes an explicit (forward) Euler discretization scheme, i.e., given a distribution $\\mu_t$ at the current time step $t$, the proposed method aims at finding the subsequent distribution $\\mu_{t + 1}$ following the gradient of the Sinkhorn divergence at point $\\mu_t$. The authors validate their methodology on toy 2D setups as well as standard image benchmarks (MNIST and CIFAR10).\n\n**Post-rebuttal update:** I thank the authors for the detailed answer. The majority of my concerns are properly addressed. I rise my score. However, I still tend to reject the paper. Also I agree with reviewer KKim that minibatch OT approximation should be discussed more thorougly. Thank you. To the best of my knowledge, the framework of the gradient flow w.r.t. Sinkhorn divergence for pure generative modelling has not yet been considered. This indicates that the paper is indeed bringing something novel to the ML community. At the same time, the idea of the Sinkhorn gradient flow has already arisen in previous research. In particular, [A] solves Sinkhorn barycenter problems by adjusting a generative distribution towards the barycenter distribution with the help of a procedure called “functional gradient descent” which is actually the discretization of the gradient flow w.r.t. the sum of Sinkhorn divergences to the target distributions. At the same time, it is worth mentioning, that [A] just simulates particles and does not build a generative model.\nRegarding the other strengths of the paper, I would like to note the well-organized Experiments section.\n\n[A] Sinkhorn Barycenter via Functional Gradient Descent, NeurIPS’2020 - Some theoretical results from the paper are known. For example, the statement of Theorem 1 could be found in [B] (eq. 26) or [C] (eq. 8). \n- The quality of the code provided is not good. There is no README/or other instruction to run the code. There are imports of non-existing classes. So, there is no possibility of checking (at least, qualitatively) the provided experimental results.\n\nFrom my point, the main weakness of the proposed paper is the limited methodological contribution. The authors simulate the particles of data following Sinkhorn divergence - as I already mentioned, this is not a super fresh idea. To make a generative model from these simulated trajectories, the authors simply solve the regression task to learn the local pushforward maps. And that is it. Combined with the fact, that the practical performance of the proposed approach is far from being SOTA in the generative modelling, the overall contribution of the paper seems for me to be limited. - My main question (and, probably, one of the main of my concerns) is regarding the proposed methodology. The authors propose to compute certain $\\mathcal{W}_{\\varepsilon}$ potentials (on discrete support of available samples) and then somehow take the gradients of these potentials w.r.t. the corresponding samples (eq. (13)). From the paper it is not clear how to compute the gradients, because the obtained potentials look like vectors of sample size shape, which are obtained through the iterations of the Sinkhorn algorithm. As I understand, in practice, the authors utilize SampleLoss from the geomloss package ([B]).  The outcome of this observation is that [B] should be properly cited when deriving the algorithm (section 4.2). I recommend authors explicitly use SampleLoss in the algorithm's listing. It will contribute to the clearness of what's going on. \n- The vector field of the Sinkhorn gradient flow is estimated by empirical samples. It is not clear how well this sample estimate approximates the true vector field. This point should be clarified. Note, that Theorem 2 works only for mean-field limit. \n- In the Introduction section, the authors consider a taxonomy of divergences used for gradient flow modelling, namely, \"divergences [...] with the same support\" and \"divergences [...]  with possible different support\". As I understand, the first class is about $f-$ divergences and the second class is about the other types (like Sinkhorn, MMD etc.). I have a question regarding the provided examples of works which deal with the former or the latter type of divergences. The fact is that the works [D], [E], [F], [G] deal with KL-divergence (or f-divergence) minimization. That is why I wonder why did the authors classify them as the second class.\n- A good work regarding poor expressiveness of ICNNs is [H].\n- What is the “ground” set ($\\S$ 3.1, first line).\n- Table 1. What are the differences between 1-RF, 2-RF and 3-RF methods?\n\n[B] Interpolating between Optimal Transport and MMD using Sinkhorn Divergences, AISTATS’2019\n\n[C] Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm, NeurIPS’2019\n\n[D] Large-scale wasserstein gradient flows. NeurIPS'2021\n\n[E] Optimizing functionals on the space of probabilities with input convex neural networks. TMLR\n\n[F]  Proximal optimal tranport modeling of population dynamics. AISTATS\n\n[G] Variational wasserstein gradient flow. ICML\n\n[H] Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. NeurIPS’2021.",
         "827",
         "0",
         "8"
        ],
        [
         "43",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_MEFG",
         "1699146383667",
         "1699636332903",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces the idea of learning a time-dependent velocity field of the Sinkhorn Wasserstein gradient flow from samples from the target distribution to calculate the empirical velocity field approximations. The paper supports its claim by showing that the mean-field limit of this process recovers the true Sinkhorn Wasserstein gradient flow. They also validated the process with some empirical studies. The paper is well written and easy to follow. The proofs and arguments in the appendix are well-typed out and clear.  There are some nice diagrams in the empirical section to supports the claim the authors are making. I think the experiments could be more extensive. One thing about this method is to investigate the number of samples needed. effectively learn the velocity field. This is one important experiment missing as is remains unclear how sample-efficient the proposed method is. It would also make the paper more completing if the method is applied to generative models that output discrete random variable like binary mnist or even language modelling. One possible question is what happens if we change the source distribution to be closer to the target distribution like it was from a generator how would the method perform there. Another question is to better understand the sample complexity of the method as the current method may not be sample efficient due to the empirical distribution being approximated using the samples.",
         "230",
         "0",
         "0"
        ],
        [
         "44",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_JSi7",
         "1698680587788",
         "1699636955419",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This article discusses a method to improve the application of SLM in the medical field, utilizing LLM's medical proficiency to boost SLM performance in medical tasks under privacy-restricted scenarios which has important social significance. The method was tested on MedQA, HEADQA, MedMCQA, and MMLU-professional medicine datasets, showing some improvements over existing methods. Additionally, the authors compared results across different sizes of training sets. see summary 1). Imprecise example of Privacy Protection.\nThe example in Figure 1 indicates that personal privacy issues are only present in the first sentence, and the key words \"man\" and \"admitted\" in that sentence have almost no impact on the subsequent content. Could it then be possible to simply delete the first sentence to achieve privacy protection, as extracting key words here does not seem to play a significant role.\n\n2). Privacy Protection as an Innovation Point\nRegarding the extraction of key words for privacy protection, the paper uses a medical NER model proposed by Neumann et al in 2019. We suggest further improvement of this model, for example, considering age as a crucial keyword for certain diseases and extracting it as necessary to better enrich the innovative aspects of the paper.\n\n3). Ambiguity of Symbols in Annotations\nAnnotation 13 on page 8 only appears in the content of the article but is not explained.\n\n4) The overall innovation of the methodology needs improvement, as the majority of the content relies on existing methods, such as the medical NER (Named Entity Recognition) model. please see the weaknesses.",
         "251",
         "0",
         "3"
        ],
        [
         "45",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_gXvF",
         "1698819472631",
         "1699636955275",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This paper tried to improve the performance of small medical language models by introducing knowledge from large language models, which keeps the privacy of clinical text when using large language models.  The proposed method uses keywords instead of full raw text to generate initial evidence from LLM and feed the evidence to small language model. Privacy-preserving is an essential and common need when using LLM in clinical text. This paper tried to solve this problem by using keywords instead of raw text, the idea is novel and experiments demonstrated the effectiveness of this approach. 1. As this research utilized a named entity recognition model to extract keywords, it is possible that the NER model can extract privacy information such as patient names. Is there any filtering or postprocessing step to avoid that? In addition, it is not guaranteed that NER system will never extract sensitive patient information; for example, if the NER system incorrectly extracts a patient's address as a symptom, then the address may be leaked to LLM. Although it is very rare, it is still necessary to comment on this. \n2. As the LLM already provides a preliminary decision, I am curious about the performance if we only feed the preliminary decision from LLM to SLM. It is worth knowing which part of the LLM-generated information improves the SLM most. \n3. The related work section need to discuss more LLM application in the clinical area, especially the knowledge-enhanced LLM in clinical settings. For example, paper \"Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.\" also utilized external knowledge for clinical questions. \n4. By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem? By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem?",
         "326",
         "0",
         "4"
        ],
        [
         "46",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_TtE2",
         "1698819599156",
         "1700663756238",
         "6",
         "4",
         "2",
         "2",
         "3",
         "The paper studied medical QA problems by incorporating large language models (LLMs) to assist small-language models (SLMs). To protect the private information in the data, the authors propose to first extract keywords and then use the keywords to query LLMs for intermediate content which can be used for SLMs to enhance prediction accuracy. 1. (originality) The proposed method is novel by extracting keywords and privately incorporating LLM for SLM-based predictions.\n2. (clarity) Overall, the paper is fair in presentation. The demonstrations of synthetic medical data with private information and extracted keywords are helpful for understanding the concepts.\n3. (significance) Versus the compared baselines, the proposed methods significantly improve the prediction accuracy on three medical QA tasks.\n4. (quality) The authors thoroughly evaluate the performance of the proposed method. 1. (Clarity) There is no specific definition of the private information. From Figure 1, it seems that privacy definition is restricted to private identifiable information (PII). The authors should clarify the scope of privacy risks. Importantly, the proposed method cannot address general private information leakage that is considered by strict formulations like differential privacy.\n2. (Quality) The evaluation of privacy is not strict. \n  - Risks: It is possible that the keyword extraction includes private identifiable information (PII), for instance, names and dates as shown in Figure 1. There is no theoretical guarantee for privacy protection or empirical evaluation of the leakage rates of such PII.\n  - Metric: The authors used the privacy budget for quantifying privacy risks:  the ratio of the number of words provided to the LLM to the total words in the original question. However, I doubt if the metric can imply some privacy risks. There essentially lacks an intuitive explanation of the relationship between the privacy budget and privacy risks.\n3. (Motivation) As the authors said, SLM presents a large gap compared to LLMs and thus there is no clear motivation to use SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. In the paper, there is no referred evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks. Thus, I strongly doubt if the motivation of the paper can hold. * There is no clear motivation to see SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. Is there any evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks?",
         "426",
         "0",
         "7"
        ],
        [
         "47",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_EBQC",
         "1699202302455",
         "1701315616812",
         "6",
         "3",
         "3",
         "3",
         "3",
         "In situations where text data is subject to privacy protection constraints, this paper designs a small-scale language model to perform diagnoses of diseases. Utilizing the rich prior medical knowledge in LLM, the approach involves generating a medical knowledge-intensive context using privacy-protected text. This generated context, along with key terms extracted from the text and questions, is then input into the SLM, which is fine-tuned during training. Experiments across multiple datasets demonstrate that this fine-tuning process effectively enhances the accuracy of the diagnostic model. 1. This paper focuses on a very important research topic in the field of medicine: how to effectively extract more useful information from incomplete text under the conditions of privacy protection. The author has made full use of the domain knowledge in LLM to effectively fine-tune the SLM, which ensures that the lightweight models can achieve high accuracy.\n\n2. This paper presents rich and comprehensive experiments. Beyond basic decision-making tasks, it also explores solutions for few-shot experiments and out-of-distribution (OOD) model generalization using the methods discussed in this paper.\n\n3. This paper fully utilizes the rich domain knowledge in LLMs to expand the knowledge base of medical reports, achieving excellent diagnostic accuracy even while ensuring privacy protection. 1. The contribution of this paper to the algorithm and the significance of the clinical problems it addresses seem not to be very high.\n\n2. The main work of this paper appears more as an engineering problem, transferring domain knowledge from LLMs to SLMs. From the perspective of algorithmic contribution, there seems to be some room for improvement. 1. The experimental datasets in this paper are all question-and-answer test datasets, and whether the methods of this paper are applicable to medical report datasets requires additional experimentation. This is because in medical reports, how to generate high-quality questions using other LLM interfaces is a question worth studying.\n\n2. Large language models provide additional domain knowledge, but in the context of specific medical tasks, will the direct transfer of knowledge from LLMs to SLMs lead to incorrect information leakage into SLMs? How can we ensure that LLMs only enhance information relevant to the current medical issue without introducing additional errors or irrelevant information? This is a very important issue in the medical field, as it directly relates to patient diagnosis.",
         "378",
         "0",
         "7"
        ],
        [
         "48",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E[x_t^\\top \\eta]>0$, where $E[\\cdot]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9"
        ],
        [
         "49",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 28028
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_eS3u</td>\n",
       "      <td>1698243150596</td>\n",
       "      <td>1699636093263</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>This work proposes LSTNet, a self-supervised m...</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_jP4i</td>\n",
       "      <td>1698652503617</td>\n",
       "      <td>1699636093190</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1) This paper proposes a self-supervised metho...</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_wiS9</td>\n",
       "      <td>1698706547448</td>\n",
       "      <td>1699636093122</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper introduces LSTNet, which leverages ...</td>\n",
       "      <td>570</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_a6Ps</td>\n",
       "      <td>1698768293694</td>\n",
       "      <td>1699636092942</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper attempts to register point cloud pr...</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_Frem</td>\n",
       "      <td>1699350072271</td>\n",
       "      <td>1699636092872</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper presents a method of learning dense...</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28023</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_vt7i</td>\n",
       "      <td>1698673110283</td>\n",
       "      <td>1699636153803</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper extends the analysis of (Woodworth ...</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28024</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_oaZ7</td>\n",
       "      <td>1698928691830</td>\n",
       "      <td>1699636153728</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The paper studies the implicit regularization ...</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_fMm6</td>\n",
       "      <td>1698618130371</td>\n",
       "      <td>1699636636496</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The authors propose a network architecture to ...</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28026</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_tZQw</td>\n",
       "      <td>1698807944071</td>\n",
       "      <td>1699636636378</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper proposes InfoNet, a generalized alg...</td>\n",
       "      <td>346</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28027</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_9qjF</td>\n",
       "      <td>1698910414535</td>\n",
       "      <td>1699636636278</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>* This paper presents an innovative algorithm,...</td>\n",
       "      <td>670</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28028 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zzv4Bf50RW               1647             1695102158671   \n",
       "1        zzv4Bf50RW               1647             1695102158671   \n",
       "2        zzv4Bf50RW               1647             1695102158671   \n",
       "3        zzv4Bf50RW               1647             1695102158671   \n",
       "4        zzv4Bf50RW               1647             1695102158671   \n",
       "...             ...                ...                       ...   \n",
       "28023    014CgNPAGy               2200             1695179071455   \n",
       "28024    014CgNPAGy               2200             1695179071455   \n",
       "28025    0074qaufB6               5962             1695403263602   \n",
       "28026    0074qaufB6               5962             1695403263602   \n",
       "28027    0074qaufB6               5962             1695403263602   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "1      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "2      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "3      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "4      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "...                                                  ...   \n",
       "28023                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28024                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28025          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28026          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28027          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "1      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "2      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "3      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "4      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "...                                                  ...   \n",
       "28023  On the Role of Momentum in the Implicit Bias o...   \n",
       "28024  On the Role of Momentum in the Implicit Bias o...   \n",
       "28025  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28026  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28027  InfoNet: Missing Information Retrieval in Mult...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Establishing accurate dense 3D correspondences...  Reviewer_eS3u   \n",
       "1      Establishing accurate dense 3D correspondences...  Reviewer_jP4i   \n",
       "2      Establishing accurate dense 3D correspondences...  Reviewer_wiS9   \n",
       "3      Establishing accurate dense 3D correspondences...  Reviewer_a6Ps   \n",
       "4      Establishing accurate dense 3D correspondences...  Reviewer_Frem   \n",
       "...                                                  ...            ...   \n",
       "28023  Momentum is a widely adopted and crucial modif...  Reviewer_vt7i   \n",
       "28024  Momentum is a widely adopted and crucial modif...  Reviewer_oaZ7   \n",
       "28025  Faulty sensors in a multiple input stream setu...  Reviewer_fMm6   \n",
       "28026  Faulty sensors in a multiple input stream setu...  Reviewer_tZQw   \n",
       "28027  Faulty sensors in a multiple input stream setu...  Reviewer_9qjF   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  \\\n",
       "0      1698243150596           1699636093263              6   \n",
       "1      1698652503617           1699636093190              5   \n",
       "2      1698706547448           1699636093122              3   \n",
       "3      1698768293694           1699636092942              5   \n",
       "4      1699350072271           1699636092872              5   \n",
       "...              ...                     ...            ...   \n",
       "28023  1698673110283           1699636153803              5   \n",
       "28024  1698928691830           1699636153728              3   \n",
       "28025  1698618130371           1699636636496              1   \n",
       "28026  1698807944071           1699636636378              3   \n",
       "28027  1698910414535           1699636636278              5   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      2                 3                    2   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 2                    2   \n",
       "3                      4                 3                    3   \n",
       "4                      4                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "28023                  4                 3                    3   \n",
       "28024                  4                 1                    2   \n",
       "28025                  4                 2                    2   \n",
       "28026                  3                 3                    2   \n",
       "28027                  4                 2                    3   \n",
       "\n",
       "       review_contribution                                       total_review  \\\n",
       "0                        3  This work proposes LSTNet, a self-supervised m...   \n",
       "1                        2  1) This paper proposes a self-supervised metho...   \n",
       "2                        2  This paper introduces LSTNet, which leverages ...   \n",
       "3                        3  This paper attempts to register point cloud pr...   \n",
       "4                        2  This paper presents a method of learning dense...   \n",
       "...                    ...                                                ...   \n",
       "28023                    2  This paper extends the analysis of (Woodworth ...   \n",
       "28024                    1  The paper studies the implicit regularization ...   \n",
       "28025                    1  The authors propose a network architecture to ...   \n",
       "28026                    2  This paper proposes InfoNet, a generalized alg...   \n",
       "28027                    2  * This paper presents an innovative algorithm,...   \n",
       "\n",
       "       length_words  citation_count  question_count  \n",
       "0               191               0               0  \n",
       "1               215               0               0  \n",
       "2               570               7              10  \n",
       "3               412               0               5  \n",
       "4               290               0               7  \n",
       "...             ...             ...             ...  \n",
       "28023           356               1               5  \n",
       "28024           303               0               0  \n",
       "28025           544               0               7  \n",
       "28026           346              10               4  \n",
       "28027           670               3               1  \n",
       "\n",
       "[28028 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the JSON file as a pandas DataFrame\n",
    "df_reviews = pd.read_json('/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v2.json')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews: 100%|██████████| 28028/28028 [1:10:55<00:00,  6.59it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "05ab2a8a-8913-4486-87ae-2f678baff031",
       "rows": [
        [
         "0",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_eS3u",
         "1698243150596",
         "1699636093263",
         "6",
         "2",
         "3",
         "2",
         "3",
         "This work proposes LSTNet, a self-supervised method to establish reliable 3D dense correspondences irrespective of the input point clouds’ rotational orientation.\n\nSpecifically, LSTNet learns to formulate SO(3)-invariant local shape transform for each point in a dynamic, input-dependent manner. Each point-wise local shape transform can map the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor, which is passed to the decoder to reconstruct the shape and pose of the input point cloud. \n\nThe proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish dense point-wise correspondences via nearest point pairs between cross-reconstructed point clouds. The self- and cross-reconstruction training strategy is simple yet effective. \n\nLSTNet demonstrates state-of-the-art performance on 3D semantic matching when evaluated on the KeypointNet dataset and part segmentation label transfer when evaluated on the ShapeNet dataset. The performance of aligned shape pairs under the setting of I/I shows that other methods, such as CPAE, are much better than LSTNet. The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.\n\nLack of limitations.",
         "191",
         "0",
         "0",
         "0.7074"
        ],
        [
         "1",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_jP4i",
         "1698652503617",
         "1699636093190",
         "5",
         "4",
         "3",
         "3",
         "2",
         "1) This paper proposes a self-supervised method to find semantically corresponding points for a point cloud pair;\n\n2）The main idea is to decouple a point cloud feature learning process into a SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms;\n\n3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method. 1) This paper is generally well-written;\n\n2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant\npoint-wise local shape transforms seems to be novel;\n\n3) Experimental results are good. 1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset. \n\n2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation. \n\n3) The running time and GPU memory cost is blurry for me;\n\n4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation\nfrom Rotated, Noisy, and Decimated Point Cloud Data]. Please refer to the weaknesses.",
         "215",
         "0",
         "0",
         "0.7009"
        ],
        [
         "2",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_wiS9",
         "1698706547448",
         "1699636093122",
         "3",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces LSTNet, which leverages an SO(3)-equivariant encoder-decoder architecture(Vector Neuron Networks, VNNs) and proposes a novel function called local shape transform to further transform the learned features. The proposed method is validated on both the 3D keypoint transfer and part segmentation label transformer tasks. 1. The idea of cross-reconstruction for generating inter-object correspondences in a self-supervised way is interesting;\n\n2. The overall writing is good and the methodology part is well-organized and easy to follow. 1. The novelty of this work seems insufficient for ICLR. The whole pipeline heavily relies on VNNs and the main contribution I personally consider is the local shape transform and the self-supervised mechanism for correspondences.\n\n2. Regarding the local shape transform:\n   2.1. From 3.1.1, the SO(3)-invariant output is $\\mathbf{V}\\mathbf{U}^T \\in \\mathbb{R}^{C \\times C}$, while in 3.1.2, the obtained SO(3)-invariant features $\\mathbf{V} \\in \\mathbb{R}^{C^\\prime \\times 3 \\times N}$ have a different shape;\n\n   2.2 The authors claimed that the local shape transform transforms the global features to local ones. Regarding this, I have two questions. \n\n      2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer. \n\n      2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the \"global\" features by such a mechanism, the features turn to \"local\"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so)\n\n3. Regarding the experiments:\n    3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments;\n\n     3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.\n\n    3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.\n\n   3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?\n\n4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.\n---------------------------------------------\n[1]. Zohaib et al. SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data, ICCV 2023;\n\n[2]. Dent et al. PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors, ECCV 2018\n\n[3]. Ao et al. SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration, CVPR 2021\n\n[4]. Wang et al. You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors, ACM MM 2022\n\n[5]. Yu et al. Rotation-Invariant Transformer for Point Cloud Matching, CVPR 2023 See weaknesses.",
         "570",
         "7",
         "10",
         "0.7698"
        ],
        [
         "3",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_a6Ps",
         "1698768293694",
         "1699636092942",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper attempts to register point cloud properties to their templates without precise correspondences and exact shape matching. To achieve this, the authors trained a local shape transform (LST) network that produces SO(3) invariant correspondences. The training is self-supervised. The experimental results on ShapeNet look nice. - Valid motivation. Unlike the abused topic, vanilla point cloud registration, the motivation stands and could potentially benefit practical usages.\n- The SO(3)-invariant network design intrinsically ensures robustness against rotations.\n- The joint usage of a global descriptor and a local descriptor makes sense and may help with classification and recognition directly.\n- The self-supervision scheme looks plausible by self and cross-reconstruction. My major concern is with the experimental setup. While the experiments on ShapeNet is common in the community and shows good result, I am in general doubtful whether such an approach could be really applied to the real world. \nIn motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. [Scan2CAD, CVPR 2019]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases. \n\nThe authors also take groundtruth keypoints and semantic segmentations from datasets for the experiments. In the real-world, however, obtaining such accurate high-level semantic information already requires a deep understanding of the point cloud, and its segmentation backbone may already be SO(3) invariant. This impairs the strength that the authors proposed. Following my points in the \"weaknesses\" section, I am curious about several relevant problems in the practical setup (i.e., scan to model). \n1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity? \n2. Will the network still be functional if the density distributions are different across input and output? \n3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?\n4. Would non-gt and/or biased key points and semantic parts be transferred properly?\n\nIt would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.",
         "412",
         "0",
         "5",
         "0.7920"
        ],
        [
         "4",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_Frem",
         "1699350072271",
         "1699636092872",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a method of learning dense 3D correspondence between shapes in a self-supervised manner. Specifically, it is built on an existing SO(3)-equivariant representation. The input point clouds are independently encoded to SO(3)-equivariant global shape descriptor Z and dynamic SO(3)-invariant point-wise local shape transforms. Then the network is trained via penalizing errors in self- and cross- reconstructions via the decoder. The experiment validates the effectiveness of the proposed method. 1. The paper is in general well organized and easy to follow. \n2. The proposed method is straightforward and shown to be effective on the test data. 1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method. \n2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.\n3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?\n4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design. Please refer to the Weaknees part.",
         "290",
         "0",
         "7",
         "0.6900"
        ],
        [
         "5",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_xDut",
         "1698437142685",
         "1699636121514",
         "8",
         "5",
         "4",
         "4",
         "3",
         "This paper is about multilingual federated prompt tuning for low-resource languages, bringing together federated learning and prompt-tuning techniques. This approach leverages parameter-efficient fine-tuning which preserves user privacy, and additionally, the authors introduce language distance in order to highlight the strengths of the proposed paradigm. The results show that the technique is parameter efficient and computationally beneficial, reducing by 99% the number of trainable parameters while increasing the performance on downstream tasks (XNLI, NC) of ~7% accuracy. This paper makes a contribution to the federated learning field showing how federated learning can be used to enhance the performance of language models while preserving user privacy. The experiments are well-designed and the results are convincing - added to extensive analyses in order to leverage the capabilities of the proposed paradigm, but also its limitations. Although the paper is generally well-structured, the title mentions `low-resource` languages. However, the two tasks leveraged are primarily on high-resource languages, rather than low-resourced language. I would suggest to the authors to include more tasks - there are many low-resource language datasets (for instance on African languages MasakhaNEWS, Masakhaner (1.0 and 2.0 - which have been cited by the way but not used), MasakhaPOS; Indic languages: https://github.com/AI4Bharat/indicnlp_catalog; etc) and tasks.\n\nThis is rather a highly recommended suggestion, that does not take away the contribution of the paper. Including them would strengthen the paper and be more in accordance with the title. The Aggregation formula is a bit confusing. Did you mean h_{global, t+1} = \\sum_{k=1}^{m} h_{k, t}? Because the `t+1` on the last term does not make sense to me.",
         "262",
         "1",
         "0",
         "0.7963"
        ],
        [
         "6",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_E7Lk",
         "1698484432194",
         "1700794322411",
         "1",
         "5",
         "1",
         "2",
         "2",
         "The paper introduces a finetuning paradigm that combines federated learning (FL) with prompt tuning for multilingual finetuning on certain, with the goal to preserve the privacy of the local data used for the finetuning job. The results show better performance in certain classification tasks, such as New Classification and XNLI. - Federated learning have recently gained good traction, the paper is a good application of it in the tasks of finetuning LLM. The paper chooses to use prompt tuning instead of full tuning to save costs, as well as to avoid overfitting on small data.\n- The method produces better performance on the 2 classification tasks compared to baselines - The proposed is a very trivial combination of federated learning and prompt tuning, which both are established methodology in their own realm. There is no novelty, such as modification or adjustment to the method that may have give a better results. In other words, people with an objective to do federated learning for privacy purpose can easily come up with prompt tuning as a solution to reduce costs.\n- Though it may have implicitly inferred by the concept of FL, the paper did not mention why and how federated learning helps with privacy and in which case one should use FL for their application.\n- The purpose of the task of multilingual finetuning in this case, is not warranted use case of privacy preservation.\n- There is no reported evidence that privacy is actually preserved. Such as whether the final model memorize the local data.\n- There are better parameter-efficient finetuning methods, such as LORA/QLora, that the authors should conduct experiments on and do comparision with prompt tuning.\n- The results show prompt tuning are much worse than full-federated tuning, thus casting doubt if the cost-saving is worth it.\n- Other generative and knowledge-based tasks, such as QA, translations and summarizations should be performed.\n\n**I have read the author responses and I advocate for a strong reject, below are reasons:**\n\n* I mentioned the paper has fundamental problems with originality, novelty, where the paper uses an unrelated existing and non-novel method designed for a different problem (fed-learning) to solve a low-resource \"privacy\" problem that does not make sense or exist yet, in which the method itself much worse than standard training. \n* Instead of addressing the scientific issue, the authors distracted away by pressing that they are helping the low-resource communities, or improving inequality as a societal issue. These multiple responses are lengthy, wordy, unnecessary, and filled with many \"politically correct\" (I don't know better word) things to avoid the scientific issue. Agree that we should help those under-represented communities, but after reading these, I shouldn't feel like rejecting the paper is an action against those communities.\n* The problem of \"a low-resource community who wants to shut down their internet and border\" is unfounded. We train LLM on public data we can find. If they wants to protect their secret data, they can download a public pre-trained model and fine-tune on their own. \n* The real problem is how to improve low-resource with the limited data we have, which the paper fails to suggest a better solution than trivial.\n* Less communication doens't mean more privacy, because we transfer model weights, not the data. And less parameters doesn't mean less private information be leaked. This misconception leads to wrong approach.\n* The author claims to be the first to target the low-resource problem and many other things, but there have been many works in previous years about this. Please be careful with this kind of \"we are first\" statements.\n* Overall, none of the responses has helped resolve the issues stated in the review. - Citation formet incorrect, \\citep{} be used to produce something like (Abc, et al., 2023) and not Abc, et al., 2023 everywhere.\n- Many grammatical errors, such as \"Throughout the fine-tuning...\"\"",
         "646",
         "0",
         "0",
         "0.8297"
        ],
        [
         "7",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_AG4r",
         "1698731849876",
         "1700723834276",
         "3",
         "4",
         "4",
         "1",
         "3",
         "The paper proposes a Multilingual Federated Prompt Tuning paradigm, where lightweight multilingual prompts are encoded and on regional devices in different languages and aggregated by averaging the prompt embeddings. The goal is fine-tuning multilingual large language models on resource-constraint devices in a privacy-preserving way. The paper evaluates this approach via the XNLI task, ablated into data efficiency, \"language distance\", and communication cost, against \"monolingual\" training (baseline). The innovation lies in that the paper somehow mashes federated learning, multi-lingual (low resource) language models, and Parameter-Efficient Fine-Tuning in one paper. The fact that they managed to come up with a storyline for a system that bolsters the benefit of each approach is commendable. - poor presentation: the citations are not separable enough from the main text, e.g., without any parenthesis, rendering the submission unreadable. Against the tradition and ease of reading, abbreviations are not defined in advance, e.g., NLI, PFL, PLM.\n- claims unverifiable: no code release.\n- conflating existing metrics with innovation: language distance is not a new concept.\n- conceptual weakness: the contrived baseline was bound to give the proposed approach an edge due to lack of federated learning. Also, what the paper refers to as prompts are just classifier model input, which are different from decoders-style LLM prompts as commonly acknowledged. Finally, the approach has absolutely nothing to do with privacy which the abstract and the main body consistently bolsters. \n- evaluation weakness: only two tasks (new classification and XNLI) was used in evaluation. In section 5.4.1 \n\n>  In both the NC and XNLI tasks, despite the total number of\nparameters exceeding 278 million, the trainable parameters are only around 1.2 million, accounting\nfor less than 0.5% of the total.\n\nCould the authors clarify which part of the model is being fine-tuned?",
         "293",
         "0",
         "0",
         "0.8387"
        ],
        [
         "8",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_LsRx",
         "1698767055794",
         "1700887244625",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The paper applies federated learning on multilingual scenarios to efficiently parameter-efficient prompt fine-tuning in a manner that preserves user privacy. The idea is to utilize a single global encoder that accumulates the information via federated prompt averaging. Thus, it learns the language patterns without knowing about the user information. They evaluated the experiment on NC and XNLI datasets and found performance improvement over the baseline. - The method is very practical since it is simple and efficient, and it is an appropriate method for training multilingual model.\n- Good analysis on the data efficiency and distance measurement, showing the effectiveness of the proposed method. - In terms of novelty, the proposed idea is not new, and it is only a further investigation of the multilingual setting.\n- Lack of clarity. The paper does not provide enough information about how the prompts are constructed or look like and hyperparameters for all settings. I suggest adding the information to the paper or appendix. Questions:\n- Do you have any findings on why multilingual centralized learning is far worse than federated learning in Table 2?\n- How did you tune the training and parameter averaging?\n\nSuggestions:\n- Figure number is missing on Page 2\n\n\"As depicted in Figure , \"\n\n- Missing Figure/Table \n\n\"This translates to over 99% reduction in the communication overhead shown in 3\"\n\n- Typo\n\n\"Finetuning accuracy across different lanugages on the NC task.\"",
         "234",
         "0",
         "0",
         "0.7573"
        ],
        [
         "9",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_agCZ",
         "1698322956814",
         "1699636820093",
         "5",
         "3",
         "2",
         "2",
         "2",
         "To tackle Multi-Domain Text Classification (MDTC) task, one mainstream of proposed techniques is to extract the features via the shared and private extractors to capture the domain-invariant and domain-specific knowledge, respectively. However, as the number of domains increases, the count of their private extractors will also rapidly surge.  \nThe author proposed a novel approach Stochastic Adversarial Network (SAN) to avoid the unaffordable explosion of parameters when encountering the newly emerged domains. Specifically, the author modeled the domain-specific feature extractors as a multivariate Gaussian distribution. Furthermore, some tricks, such as domain label smoothing and robust pseudo-label regularization techniques, are utilized to improve the overall performance.\nExtensive experiments on two benchmarks demonstrate the superiority of the proposed method compared with the state-of-the-art baselines. 1.\tThis paper proposes a novel approach, called Stochastic Adversarial Network, to reduce the computational cost while meeting a large amount of domains.\n2.\tThis paper originally employs Gaussian distribution to generate private extractors in order to circumvent the extensive parameters found in previous works. \n3.\tThis paper conducts numerous experiments to show the effectiveness of the proposed scheme. Moreover, the parameter sensitivity and ablation study demonstrate the rationale of parameter selection and the necessity of each modules, respectively. 1.\tThe motivation is trivial. It is hard to say that the model size is the bottleneck of the training process according to Table.1 and 9. 342.91M is absolutely fine in current period. Further, inference process may gain nothing in the aspect of computational acceleration as we only choose one private extractor from the Domain Discriminator D. \n2.\tThe baselines are outdated and improvements on two benchmarks are limited. According to Table 2,3 and 4, it can hardly convince me that the proposed model exactly outperforms the SOTA models. It is worth noting that the author points out this limitation in Appendix E. \n3.\tThe writing and organization need to be improved. \na)\tThe emphasis in writing has been misplaced. As the author highlights the role of multivariate Gaussian distribution in Abstract, you are supposed to tell more story of it instead of the regularization term, which is the idea of others.\nb)\tThe effectiveness is not the focus of this article, efficiency is. Therefore, moving D. 5 to the main body of the article perhaps make your contribution more prominent. \nc)\tSome tools can be utilized effectively to optimize sentence structure and composition. 1.\tThe aim of equation (3) is to ensure that the shared Feature Extractor F_s exactly extract the domain-invariant features. Thus the author maximum this loss to let the discriminator D be confused about the features coming from F_s. Here is the question: discriminator D may lack of capabilities to recognize the difference among domains as this loss function does not involve any domain knowledge.\nThere may exists another adversarial network in equation (3), i.e. domain-specific extractor enhances the capabilities of discriminator D and domain-invariant extractor still confuse the discriminator D. \n2.\tAs a classic NLP task, this method inevitably needs to be compared with chatgpt. Currently, chatgpt has shown remarkable zero-shot capabilities. Therefore, you need to convince the reviewers why your method should be used instead of chatgpt or highlight the scenarios in which your method has significant advantages.",
         "534",
         "0",
         "5",
         "0.7784"
        ],
        [
         "10",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_NpVu",
         "1698685251472",
         "1699636819980",
         "1",
         "4",
         "1",
         "3",
         "1",
         "The paper presents a new model for MDTC, built on the previous shared-private feature extraction architecture. The innovation includes 1) modelling the parameter of domain-specific feature extractors as a Gaussian random variable, and for each domain, the parameter is drawn from the distribution. This is why the model is called stochastic adversarial network, or SAN, 2)  domain label smoothing 3) pseudo labelling regularization.  The authors show some empirical successes on some datasets. The paper demonstrates that the authors are well aware of the challenges in MDTC and are familiar with various tools in deep learning (such as reparametrization trick, label smoothing, pseudo labelling etc). I have some concerns about this work.\n\n1. Assuming the design of proposed model is sensible (in fact I have doubts on this; see 2), the work heuristically puts together a bunch of well-known techniques to improve performance. Works of primarily such a nature, although potentially valuable in practice, do not possess enough novelty that justifies a publication in ICLR. \n\n2. I have doubts on the proposed approach in the \"stochastic\" part. Let us track the parameter $W_1$ of the domain-specific feature extractor for domain 1. In the beginning it is drawn from the prescribed Gaussian, say, its value is $W_1^{(0)}$, and after the first iteration, the Gaussian parameter gets updated (using the reparametrization trick)  -- well, whether Gaussian parameter is updated or not is not critical here. Then in the next iteration, $W_1$  is drawn again, let us call it $W_1^{(1)}$. If this understanding is correct, then $W_1^{(0)}$ and $W_1^{(1)}$ can be very different. That is, along the training process, $W_1$ will randomly hop everywhere as long as the Gaussian variance is not vanishing. How would such a scheme work at all? Bringing the parameter $W_2$ of the second domain-specific extractor into the picture would show an even more absurd picture: at each iteration $t$, $W_1^{(t)}$ and  $W_2^{(t)}$ are random variables following the same Gaussian distribution. How would $W_1$ and $W_2$ track their respective domain specific features?  If this structure were to work, it would have to be the case where the Gaussian variance is very small (which might be the case as shown in Figure 3 of the appendix). In that case, all domain-specific extractors are more or less the same, i.e, all equal to the Gaussian mean, only subject to some tiny *domain-nonspecific* random perturbation. That would defeat the entire purpose of having domain specific feature extractors. -- I could misunderstood the paper and I am willing to hear the authors' defence on this. In your defence, please also show the initial and final values of the Gaussian mean vector $\\mu$ (say, in terms of its L1-norm divided by its dimension), I would like compare it with $\\sigma$. See weakness 2.\n\nAdditional question: The authors say that the conventional shared-private adversarial scheme will have \"exponential increase\" in model parameters as new domains emerge? Why is it exponential?",
         "484",
         "0",
         "3",
         "0.7855"
        ],
        [
         "11",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_bAwA",
         "1698806204960",
         "1699636819830",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper tackles the multi-domain text classification (MDTC) problem, and tries to minimize the amount the learning parameters by introducing a stochastic feature extractor (domain feature). The model is effective in handling the benchmark datasets and outperform the other baseline models. Additional multi-source UDA experiment is also conducted as a simple model extension. The proposed model performs strong in the benchmark dataset, with minimized learning parameters. The design of using both shared/private feature extractor is interesting and effective in merging the domain in the latent space. The proposed method is straightforward and easy to understand. 1. Though the proposal seems to be effective and achieving strong performance, the model itself still uses a relative old adversarial backbone, with the discriminator approach for removing the domain invariant feature. The two-feature-extractor approach is interesting, but that is mainly to deal with parameter increase in the MDTC problem. It would be great to see other design improvement in the model.\n2. The performance gain in using the proposed model is marginal on the Amazon review/FDU-MTL datasets. Also, it would be great to have some analysis on adjusting the setting between the two feature extractors. 1. This might be somewhat irrelevant, but would the model perform well in multi domain classification in other domain type(s), e.g., images?",
         "213",
         "0",
         "3",
         "0.7456"
        ],
        [
         "12",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_skmj",
         "1698632081062",
         "1701140370231",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper studies multi-modal generalization in neural networks such as transformer-based models and recurrent networks. To do so, the authors propose Genertic COG, a modular benchmark with multi-modal splits to test for 3 types of generalization: 1) distractor (generalization to different noise distribution), 2) systemic compositional (generalization to new permutation of task structures) and 3) productive compositional (generalization to tasks of greater complexity) generalization. Experiments conducted by the authors showed that while cross-attention based transformers (e.g. CrossAttn and Perceiver) outperform other models and perform well on distractor and systemic compositional generalization, they fail at productive generalization when the depth of the task tree goes to out-of-distribution (>3). Representational analysis is done to show that cross-attention based transformers (e.g. CrossAttn and Perceiver) superior performance on distractor generalization might be due to their ability to better retain task-relevant (e.g. stimulus and response) information at the penultimate layer. +The paper studies a timely and critical question about the generalization capability of multimodal transformer-based models\n\n+The proposed benchmark dataset uncovers a limitation of current multimodal transformer-based models: productive generalization which can facilitate the development of more generalizable transformers/LLMs. \n\n+The paper is generally well-written and easy to follow -While the paper’s studies show that certain designs (e.g. cross-attention) seem to confer multi-modal generalization, there are still some key questions that can be more thoroughly studied to uncover the reasons why this is the case.\n\n-Similarly, important discussions such as why the (cross-attention) transformers might fail at productive generalization is lacking. What is the key architectural difference between dual stream transformer and transformers with cross attn that can explain their generalization performance? Is it only the lack of a cross attention between the different modalities?\n\nPossible typo:\n“Finally, we included a Perceiver-like model (Jaegle et al., 2021), an architecture designed to generically process multimodal inputs (Fig. 2f).”:  (Fig. 2f) > (Fig. 2e).\n\n\n==Post-Rebuttal==\nI appreciate the authors' response and decided to keep my score.",
         "318",
         "1",
         "3",
         "0.8097"
        ],
        [
         "13",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_a4Su",
         "1699400405601",
         "1699636123172",
         "3",
         "3",
         "1",
         "2",
         "2",
         "This paper proposes a new benchmark for assessing various forms of generalization in a multimodal setting named gCOG. The dataset includes several different splits intended to measure different aspects of generalization. The paper also compares several different model architectures on the dataset. * The paper introduces a new dataset, gCOG. While the dataset is conceptually similar to those from prior work, such as gSCAN, it supports different types of contexts and instruction types, including more compositional instructions. I'm aware of some prior work (e.g. [1], [2]) that studied compositional generalization in natural language tasks and found that gains on one synthetic task did not always transfer to other tasks, so increasing the diversity of such benchmarks for assessing compositional generalization and related challenges in the multimodal setting could be a potentially valuable contribution.\n\n[1] https://arxiv.org/abs/2007.08970\n[2] https://aclanthology.org/2021.acl-long.75/ * I'm concerned about the strength of the baselines used in the paper (see my related questions below). While the primary contribution of the paper is the dataset, it is also important to establish strong baselines for this new dataset and to ensure that the conclusions from the empirical results are valid. The appendix states that only a *single Transformer layer* with a *single attention head* was used. This is almost certainly not an optimal depth and number of attention heads. Relatedly, it looks like some models are potentially underfit, according to the figures. With >5M training examples and a relatively simple input space, I would have expected a reasonably sized Transformer model to achieve low training loss and reasonable IID generalization. If these models could have been applied to similar tasks such as gSCAN (even using symbolic tokens to represent the scene context), where they could be compared with comparable baselines from prior work, this would have helped establish that these are indeed reasonably strong baselines that have been well tuned.\n* The qualitative difference between gCOG and datasets from prior work such as gSCAN was not very clearly described. For example, one of the key claims seemed to be gCOG \"employs generic feature sets that are not tied to any specific modality\". However, it seems like it is a useful property for a multimodal dataset to have a clear relation to real-world multimodal tasks. Indeed, the authors provide interpretations of their tasks in the form of natural language instructions and visual scenes (e.g. in Figure 1), and these are very useful for understanding the task. Representing this dataset using familiar modalities (e.g. vision, natural language) could enable future work to study different research questions, e.g. the impact of pre-training. The ability to alternatively represent the task input as a sequence of tokens is also reasonable for studying certain research questions, but this also seems possible for datasets from prior work. For example, I understand that gSCAN includes both symbolic descriptions as well as visual renderings. Anyways, I think clarifying the motivation for this dataset (e.g. increasing diversity of available benchmarks, focusing on different generalization challenges, etc.) separately from how inputs are represented for the experiments in this paper (e.g. token sequence vs. images and natural language) would be useful.\n* Some of the main empirical conclusions (e.g. that generalization to greater \"depth\" is challenging for models such as Transformers) are generally known from prior work.\n\nnits:\n* Introduction paragraph 1 - \"on a carefully controlled generic multimodal reasoning tasks\" -> \"on carefully...\" or \"...task\"\n* Appendix A.2.1 - Maybe reference Tables 8 and 9 where you discuss different positional embeddings.\n* Consider discussing [3] in related work. [3] demonstrated the importance of cross-modal attention for gSCAN, and similarly studied the relative difficulty of various aspects of generalization, including distractors.\n\n[3] https://aclanthology.org/2021.emnlp-main.166/ * Why not try more layers and attention heads, e.g. following a standard hyperparameter setting for model size such as those of BERT-Base? Or even BERT-Small?\n* In Figure 2 (F) why does the single-stream Transformer have almost double the parameters of the double stream Transformer? For the other Transformers, do the encoder blocks used for the task vector and stimulus vector share parameters? \n* What optimizer and hyperparameters (e.g. learning rate) were used for training? How were these chosen? I didn't see these details in Appendix A.2. \n* Position embeddings - Since you are representing 10x10 grids as 1D sequences, 1D relative positions may not capture this structure well. On the other hand, absolute position embeddings seem potentially problematic in the case of the SSTrfmr model, since they will not be consistently assigned to the same grid position if the text sequence is first and has varying length. Mitigating this may be important to provide for a fairer comparison with the SSTrfmr model.\n* To what do you attribute the periodic loss spikes during training that are shown in Figure 4 (E)?\n* I found the usage of \"cross-attention\" a bit confusing. For example, the single stream Transformer features cross-modal attention as an implicit consequence of self-attention over the concatenated sequence. I thought this would commonly be referred to as an instance of \"cross-attention\" between modalities. \n* Does the dataset also contain visual renderings and natural language instructions to enable future work to study these tasks using familiar modalities?",
         "860",
         "10",
         "1",
         "0.8184"
        ],
        [
         "14",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_DJb6",
         "1699470958350",
         "1699636122858",
         "8",
         "4",
         "3",
         "3",
         "3",
         "The paper introduces a new multimodal question answering benchmark for out-of-distribution generalization, specifically covering task compositionality, robustness to distractors and combinatorial generalization. It uses this benchmark to evaluate various models and analyze their performance. - **Topic**: The paper studies an important topic which in my opinion is underexplored in current deep learning research. Especially given the tendency these days to scale training up to vast amounts of data, I believe it is particularly important to design carefully controlled benchmarks that can: evaluate the model’s performance from a critical and cautious standpoint, point to their fundamental limitations (e.g. systematic generalization), and support further research about ways to overcome these.  \n- **Evaluation**: The paper offers both extensive extrinsic evaluation, with performance comparison of various models on the different generalization skills, as well as intrinsic analysis of their internal representations’ degree of alignment to the stimuli.\n- **Clarity**: The writing quality is good and the paper is clear and easy to follow. The paper is well-organized, claims and findings are clearly stated, and useful figures and diagrams are provided.\n- **Related Works**: It does a good job in providing the relevant context, motivation and related works. \n- **Contribution**: The empirical findings of the paper on the benefits and limitations of different inductive biases such as recurrent and attention-based are important and may be of broad interest to the community. - **Pre-trained models** The paper focuses on models trained from scratch rather than pre-trained. This could be a strength and a weakness. On the one hand, it allows for isolating the contribution of the architectural choices from other factors of optimization, and training data. On the other hand, it has been observed that by training models at large enough scales enables the emergence of generalization capabilities, which we don’t see in smaller scales. I think it will be critical to also analyze the performance of pretrained models on the benchmark, in order to strengthen the paper.\n- **Visual Simplicity**: The visual side of the benchmark is quite rudimentary, featuring colorful letters. Extending it to a larger range of visual tokens/objects, that could have more than one property (color), and a broader set of elements and variations (than 26 letters), could be a straightforward extension that could help make it a bit more challenging visually. - **COG task**: It will be useful to discuss the COG task (rather than just mentioning it) before describing the new gCOG one, so that it will be clearer to the reader what are new contributions of the new benchmark compared to COG and the degree of their importance. In the overview diagram I would also recommend showing a sample also from COG to make the differences clearer. \n- **Grid size / generalization**: It could be interesting to vary the size of the grid in training/evaluation and study its impact on model’s performance. \n- **Terminology**: I recommend changing the phrase “Distractor generalization” to one that better conveys it’s about changing the answer distribution. Maybe e.g. answer distribution shift. I also recommend changing the name “Systematic compositional generalization” to “combinatorial generalization”, to emphasize that the main point is the generalization to permutation, and also to better contrast it with the following “Productive generalization” (which could also be systematic).\n- **Figures**: Would be good to increase the size of the plots in Figure 3b. It will also be good the increase the distance and visual separation between the sub-figures in each figure throughout the paper. \n- In the introduction: “multimodal question-answer” -> “answering”.\n- “This design allowed us” -> “This design allow us”.",
         "591",
         "0",
         "2",
         "0.7407"
        ],
        [
         "15",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2",
         "0.8079"
        ],
        [
         "16",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head [1], [2], [3]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works [1][2] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n[1], Frozen clip models are efficient video learners, ECCV-2022\n\n[2], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n[3]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0",
         "0.7694"
        ],
        [
         "17",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7",
         "0.8374"
        ],
        [
         "18",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0",
         "0.7506"
        ],
        [
         "19",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_5Cgw",
         "1697885084973",
         "1699636148336",
         "3",
         "5",
         "3",
         "2",
         "2",
         "The study puts forward a VAE-based approach to acquire disentangled representations without the need for supervision. In this framework, it assumes that diverse data samples exhibit variations across multiple factors, making it particularly well-suited for real-world datasets. The newly proposed technique, referred to as CFASL, introduces a range of unsupervised loss components that serve to instill \"inductive biases.\" These include parallel and perpendicular loss terms, in addition to a sparsity loss designed to encourage alignment along factor axes. The outcomes of this study illustrate the method's superior performance when compared to various other unsupervised disentanglement VAEs, both under single-factor and multi-factor alteration scenarios, across multiple widely used benchmark datasets. 1. The paper represents a significant stride in enhancing the practicality of disentanglement techniques within the realm of real image domains. It grapples with a formidable challenge where we cannot presume access to images that solely vary in a singular factor, thereby intensifying the complexity of extracting disentangled representations.\n\n2. The quantitative findings not only exhibit enhancements in the primary focus of this study, which is the alteration of multiple factors, but also in the scenario involving changes in a single factor. 1. The proposed approach incorporates a diverse array of loss terms within its training objectives, with each term potentially making a distinct contribution. However, this diversity comes at the expense of imposing significant assumptions on the underlying image distribution. While I acknowledge that these assumptions may be justified within the context of the datasets considered in this paper, it's worth noting that some metrics, such as DCI, do not unequivocally demonstrate superiority in the ablation study presented in Table 2.\n\nNevertheless, I believe that the paper could benefit from a more comprehensive exploration of the limitations stemming from these strong assumptions. It would be valuable for the authors to provide concrete examples where these assumptions result in unintended or adverse outcomes. Even for an unsupervised setting, it remains crucial to take into account the nature of transformations within the image domain. A more explicit discussion of these assumption-related limitations would substantially bolster the significance of the claims advanced in this paper, in my view.\n\n2. The qualitative results exhibit low image quality. While this is common across unsupervised disentanglement methods, it is really challenging to get convinced that better disentanglement is achieved. It would be valuable for the author to consider domain-specific metrics for the evaluation phase e.g. face identity loss, facial expression classification, head pose regression, etc. to assess whether only a specific attribute is altered during the single factor change experiments. 1. Following the weaknesses mentioned above, could the authors provide concrete examples (other datasets) where the assumptions induced by the loss terms result in unintended or adverse outcomes compared to the baseline beta-VAE?\n\n2. Could the authors please provide the ablation study results of the different loss terms for all datasets considered in the paper (and not only 3D-Cars)?",
         "483",
         "0",
         "7",
         "0.8442"
        ],
        [
         "20",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_oACj",
         "1698758328711",
         "1699636148260",
         "5",
         "3",
         "3",
         "1",
         "2",
         "The authors introduce a new VAE architecture which operates on pairs of inputs and utilizes a set of regularization terms to induce structured disentanglement of the latent space with respect to observed symmetry transformations between examples in these pairs. The authors show that their model indeed achieves higher disentanglement scores than relevant baselines on a variety of datasets with a variety of different metrics. Specifically, the authors target the 'multi-factor change' regime, and demonstrate improved performance in this setting with their newly introduced metric. - The related work is well covered, and the authors position their method well in the literature.\n- The proposed combination of losses appears novel to the best of my knowledge, and the use of parallelism and orthogonality losses specifically on latent transformations is an interesting and exciting idea. \n- The study of disentanglement with respect to multiple simultaneously changing factors is important and interesting, and the authors make a notable contribution to this direction.\n- The results appear promising, and indicate that the model is performing well with respect to the baselines. \n- The methodology and extended results in the appendix appear sound. The calculation of P-values in the appendix is very important and appreciated. Furthermore, the use of an ablation study to validate their proposed model is a welcome addition. Weaknesses summarized:\n- The paper is challenging to read as the english is quite poor and the logical flow of the work is unorganized.\n- The method itself is composed of a wide variety of loss terms and the intuition or reasoning for why these terms are necessary is not provided. (Specifically for the parallel and perpendicular losses).\n\nIn more detail:\n\nWeakness 1:\nThere are many typos and poor grammar throughout the paper, with many sentences simply not making much sense. I include a few examples below, but there are many many more and the authors should have someone proof read this work more carefully:\n- In the abstract: \"We propose ... (CFASL) on VAEs for the extension to [a] general multi-factor change condition without constraint.\" \n- \"To implement  group equivariant VAE, Winter et al. (2022); Nasiri & Bepler (2022) achieve the translation and  rotation equivariant VAE\"\n- \"For the equivariant encoder and decoder, we differently propose the single forward process by the  encoder and decoder objective functions compared to previous work (Yang et al., 2022).\"\n- \"Differently, we induce disentanglement learning  with group equivariant VAE for inductive bias.\"\n- 'The unsupervised learning work (Winter et al., 2022) achieves class invariant and group equivariant  function in less constraint condition.'\n\nWeakness 2: \nNaming is extremely unclear. For example, what are 'sections' referred to in Section 3.2? How do these differ from factors? \n\nWeakness 3: \nDespite appealing to a precise probabilistic generative model as its primary value and distinction from prior work, the model itself could be made significantly more elegant in the context of generative models. For example, the 'factor prediction' mechanism could be integrated as a component of the generative model and inferred with another approximate posterior, as done in prior work (Song et al 2023).\n\nWeakness 4:\nThe discussion of learning the Lie algebra is quite rushed and the intuition for why the large set of different loss terms should be incorporated is largely missing.\n\n[1] (Song et al. 2023) https://arxiv.org/pdf/2309.13167.pdf Question 1:\nThe point that prior work with autoencoders does not extend to VAE's does not make much sense to me. Specifically the quote: \"Furthermore, the methods on autoencoder are not directly applicable to VAEs, because  of the large difference to VAE in probabilistic interpretation\". Can the authors provide further details to reinforce this claim?\n\nQuestion 2:\nGiven there are so many loss terms for this model, it is likely that it will be computationally expensive to estimate the correct weightings for each of these terms in a hyperparamter search. Can the authors speak to how this was done in their case and how expensive it was? \n\nQuestion 3:\nOne of the main selling points for this paper was the ability to extend disentanglement methods to 'multi-factor' change. However, for the experiments, the authors consider datasets which guarantee commutativity of transformations. Theoretically then, is there a reason why we should expect the other baseline models to not be able to handle this multi factor change? For example, it seems the axis aligned disentangled representations of the beta-vae should be able to compose multiple transformations simply by jointly changing multiple latent dimensions. Is this not the case?",
         "744",
         "6",
         "1",
         "0.7790"
        ],
        [
         "21",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_A4b1",
         "1698803382759",
         "1699636148172",
         "5",
         "3",
         "2",
         "2",
         "2",
         "Following the Variational Auto Encoder (VAE) framework, this paper proposes an extension of the single factor (change condition) disentanglement learning method, which they call as Composite Factor-Aligned Symmetry Learning (CFASL). The main idea and/or the assumption is certain scenarios such as the composite/complex symmetries (where certain mathematical transformational relationships exist) can be better captured by utilizing explicit symmetrical relationship information, if provided as additional input to the VAE learning framework. \n\nAs a part of the learning scheme, to facilitate this required piece of information, the proposed method explicitly inputs pairwise symmetrical relationship (and corresponding transformation) information. The expectation is the model, if learned in this fashion, should generate better representative samples from within those transformational subspace/domains. \n\nTo better explain and evaluate the scenario, some new metrics such as m-FVMk (extension of a common metric for a single factor change condition evaluation) have been proposed. They have compared their method with some state-of-the-art methods and on nine benchmark datasets; reported results are found to be promising. The following items seem to have some originality: (i) learning from explicit pairwise transformations, (ii) a network architecture to learn the codebook of symmetries for (i),  (iii) some associated metrics supporting (i) and (ii), and (iv) imposing group equivariant encoder-decoder into the learning framework. \n\nOverall, the paper is well written.  Mathematical derivations of different components seem to be sufficient. The proposed method has been tested on a number of benchmarks (both quantitative and qualitative analysis), and reported results are found to be promising. In addition, the ablation study of different loss functions may have added some extra points. \n\nIn terms of quality, I would rate the work as \"moderate\". In this work, one of the important missing part is the proper probabilistic derivation of the methodology, the core of the VAE framework. Or it may be due to the way the paper/work has been presented. To me, it's not sufficient to connect to the VAE world. It is suggested the authors clarify this important aspect with necessary derivations.  \n\nFor certain items/results, the authors claim statistical significance performance (section 5.2, and appendix D); however, without sufficient details of their significance tests. It is suggested authors include details of these statistical tests. \n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, we may require additional details for a fair companion of their results. \n\nThe paper/research may have some significance, and it would be beneficial if the source code could be released. It is suggested the authors clarify the probabilistic derivation of the approach and make a proper connection to the VAE basics. \n\nIt is suggested authors include details of these statistical tests.\n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, I suggest authors provide further details and release code if possible.",
         "461",
         "0",
         "0",
         "0.7849"
        ],
        [
         "22",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_DbMo",
         "1698968978898",
         "1699636148102",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The manuscript aims to improve existing methods of unsupervised disentangled representations learning.  Inspired by the symmetry group action approach from (Higgins et al 2018,2022), authors suggest several additions for the conventional beta-VAE  method, resulting  in the form of seven supplementary loss terms. The article is devoted to important subject of disentanglement learning. Authors report improvements over some of existing methods on four simple datasets 1) Only simple datasets are considered, the method is not tested on standard complex datasets like MPI 3D. \n\n2) Reported improvements of CFASL in all measured metrics are essentially always situated within standard deviations of some other methods. \n\n3) Reconstruction loss is not reported in 3 out of 4 datasets. Upon visual inspection of reported samples, the reconstruction quality is not satisfactory. \n\n4) As reported on Figure 4, on 3DShapes dataset, there is no consistent improvement in FVM metric even at the expense of deteriorating reconstruction quality . \n\n5) There is no theoretic justifications for introduction of so many, seven in total,  additional loss terms. \n\n6) Description of Lie group action is not clear, how the action by psi_i is defined? how the dimensions of Lie groups are chosen?\n\n7) The described group action by matrix multiplications do not preserve the normal distribution, so the group equivariant term is not compatible with the  standard KL term from beta-VAE loss. \n\n8) There is no comparison with most recent disentanglement methods like DAVA, TCWAE.\n\n9) Related work section does not mention many works from vast literature on disentanglement learning, eg Disentangling Adversarial Variational Autoencoder (ICLR 2023). Why is the reconstruction quality not reported in three out of four datasets?\n\nWhy the method was not tested on standard more complex datasets like MPI3D?",
         "284",
         "0",
         "0",
         "0.7452"
        ],
        [
         "23",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_mr2r",
         "1698569976113",
         "1699636242675",
         "3",
         "4",
         "2",
         "2",
         "1",
         "The article offers a Gaussian Mixture-based differential entropy/mutual entropy estimation approach. Furthermore, it provides numerical experiments to test the expected behavior of the estimator and its application to self-supervised learning. The article addresses an important problem of mutual information estimation. It provides relevant numerical experiments to test the validity of the proposed approach. - The main approach proposed by the authors seem to be already appeared in the literature in some references not cited by the authors (please see the questions part).\n\n- There seems to be a major issue about the expressions provided for the proposed approach (please see the questions part).\n\n- The presentation requires improvement. ### I. INTRODUCTION \n\n**3rd paragraph:** \n\n- \"identify matrix\":  identity matrix?\n\n- \"The mutual information can be consequently estimated by the entropy decomposition.\": This sentence follows identity matrix addition sentence. I guess it might be better to clarify causality here. At this point, it is not clear what is meant by \"entropy decomposition\", whether it is a trivial procedure and what enables it (mixture of Gaussians modelling?).\n\n### 2.1 BACKGROUND\n\n**Paragraph before (4)**\n\n- After equation (1): instead of \"for a multi-variable Gaussian variable\" use Gaussian (random) vector ?\n\n- In the notation $$X=[x_1,x_2, \\ldots x_n]$$ $x_i$'s appear as column vectors, however, they are actuallly row vectors as $X\\in\\mathbb{R}^{n\\times d}$\n\n- (5) should be\n\n$$\\mathbf{H}_D(X)=\\sum_{i=1}^k \\frac{1}{2} \\log \\left(\\lambda_i+\\beta\\right)+(d-k)\\log(\\beta)+C_d$$\n\n- After (5): \"Therefore, LogDet can estimate the entropy of multivariate Gaussian variables by approximating the differential entropy.\". This is not a surprise/or contribution as the authors  simply defined (5) using (2) by replacing the true covariance with $\\beta I$ perturbed sample correlation (covariance?) matrix. This is sort of obvious. \n\n### 2.1.1 LOGDET ENTROPY ESTIMATOR FOR NON-GAUSSIAN VARIABLE\n\n- Title : ... NON-GAUSSIAN VECTOR\n\n- Replace variable->vector\n\n- There already exists GMM based entropy/mutual information approximation based works such as \n\n[a]. Lan T, Erdogmus D, Ozertem U, Huang Y. Estimating mutual information using gaussian mixture model for feature ranking and selection. InThe 2006 IEEE international joint conference on neural network proceedings 2006 Jul 16 (pp. 5034-5039). IEEE.\n\n[b]. Huber MF, Bailey T, Durrant-Whyte H, Hanebeck UD. On entropy approximation for Gaussian mixture random vectors. In2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems 2008 Aug 20 (pp. 181-188). IEEE.\n\nYou need to refer to existing literature and clearly state what is novel in your approach relative to them.\n\n\n- Theorem 2 and Theorem 3 of [b] above already covers the lower and upper bounds of mixture of Gaussians. It looks like they are same as what is provided in this section. \n\n- There seems to be a major issue about the upper bound expression. The first expression for the upper bound (at the bottom of page 3), contains covariances ($\\Sigma_i$'s ) obtained from the GMM fitting algorithm, whereas the second line contains the overall sample covariance of actual data, instead of conditional covariance estimates. How do you equate these lines? The second line in fact equals to\n\n$$\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)+\\sum_{i=1}^K \\pi_i \\cdot\\left(-\\log \\pi_i+C_d\\right)$$\n\nas $\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)$ is independent of the summation index $i$. This does not make sense as you disregard covariance parameters of the GMM. \n\n- How do you make the upper bound objective co\n\n### 2.2 THE ISSUE OF MODEL SELECTION\n\n- Title: Model Selection is to generic for the discussion in this section. \"The Issue of Model Order Selection\" could be a better title.\n\n\n\n\n### 3. APPLICATION IN SELF-SUPERVISED LEARNING\n\nThe logdet-mutual information based SSL appears to be proposed in the following reference:\n\n[c]. Ozsoy S, Hamdan S, Arik S, Yuret D, Erdogan A. Self-supervised learning with an information maximization criterion. Advances in Neural Information Processing Systems. 2022 Dec 6;35:35240-53.\n\nThe authors should also clarify the relative novelty relative to [c]. Especially, the impact of GMM order selection as the approach in [c] appears to be for $K=1$. There is also claim in [c] that the use of $K=1$  defines correlative information maximizing which targets a linear (identity in their modified setting) between the representations of augmented versions of inputs. For $K>1$ does  maximizing mutual information between augmentation representation lead to nonlinear mappings between them? Is such organization of representation space desirable for classification tasks, for example?\n\nOr are you just using (18) with order $1$, which seems to be just the approach in [c]. \n\n### 4. RELATED WORKS & 5 SIMULATION STUDIES\n\nAll the references we mentioned above and the relevant references that cite them should be included in this discussion, and simulation results \n\n- 5.2 : ofBelghazi...-> of Belghazi\n- Figure 2: Two small figures and caption could be more informative.\n- 5.4 SSL: What is K for EMP-MILE? Is upper bound employed in EMP-MILE?  what if you directly use MILE?\nHow is backprop used in coordination with the GMM algorithm? As GMM parameters are algorithmically obtained from network output, how does backprop do backward mapping from probabilities $\\pi_i$'s (and there should be covariance estimates $\\hat{\\Sigma}_i$'s, as discussed above)",
         "825",
         "0",
         "11",
         "0.7898"
        ],
        [
         "24",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_fvqj",
         "1698878886574",
         "1699636242588",
         "3",
         "5",
         "2",
         "1",
         "2",
         "This paper proposes a new approach to estimating the mutual information between a pair of random vectors, by extending the closed-form expression that is available to Gaussian variables to non-Gaussian variables. This is done by estimating Gaussian mixture approximations of the involved densities and then using bounds on the differential entropy of Gaussian mixtures. Estimating mutual information between high-dimensional non-Gaussian variables is an important problem with many applications. The proposed method extends Gaussian (which the authors refer to log-det) estimators to be applicable beyond Gaussian variables via the use of Gaussian mixture approximations, coupled with bounds on the differential entropy of mixtures. Unfortunately. the paper contains several critical flaws, namely a quite sloppy notation, that lead me to recommend its rejection. \n\nThe authors mixture, in a very confusing way, random variables and data matrices, typically using the same notation for both, $X$. For example, in Equations (1), (2), and (10), $X$ is a $d$-dimensional random variable, whereas in Equation (4), $X \\in \\mathbb{R}^{n\\times d}$ is a data matrix. Even worse, in the final equation of page 3, the two different definitions are used together and it is not even clear where the second equality means; it is simply wrong because $X^T X/n$ does not coincide with $\\Sigma_i$.\n\nUnlike what the authors claim, Equation (5) is not equivalent to Equation (5); the two differ by $\\frac{d-k}{2}\\log \\beta$.  \n\nAdding a matrix proportional to identity ($\\beta I$ in the paper) to the sample covariance was not proposed in a 2021 paper. It is a very classical method that can be found in any classical text on covariance matrix estimation, many decades ago.\n\nThe inequality in Equation (8) was not shown by Zhouyin and Liu in 2021. It is a classical result of information theory, that can be found, for example, in the famous Cover and Thomas book. By the way, the citation to this book is wrong in the paper; one of the authors (J. Thomas) is missing. \n\nThe two bounds for the differential entropy of mixtures that the authors claim to have introduced are in fact not new. The upper bound is in fact a well-known corollary of the log sum inequality (see the Cover and Thomas book). The lower bound was proved in 2008 by Huber et al. at https://doi.org/10.1109/MFI.2008.4648062 I have no questions.",
         "383",
         "1",
         "1",
         "0.7288"
        ],
        [
         "25",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_F4Ta",
         "1698980874812",
         "1699636242491",
         "6",
         "4",
         "3",
         "3",
         "2",
         "This work presents a mutual information (MI) estimator called MILE (LE=logdet estimator) which uses \nthe log det closed form formula of the entropy of Gaussians.\n\nTo accomodate MI to arbitrary densities, a Gaussian mixture model (GMM) is first fit to data and lower/upper bounds on the entropy of GMM is used to define MILE formula Eq 15. \n\nThen MILE is benchmarked with other MI  estimators and MILE can be used in loss functions in semi-supervised learning in experiments. - Simple MI estimator method based on  \n\nZhanghao Zhouyin and Ding Liu. Understanding neural networks with logarithm determinant entropy estimator. arXiv preprint arXiv:2105.03705, 2021\n\n(cited in the paper)\n\n- Very good experiments and comparisons with other MI estimators\n\n- Source codes provided in supplemental information  for reproducible research -The paper is sloppy in its writing, and one problem is to determine the number of components k of the GMM which\n loosen the lower upper bounds on the entropy. \n\n- Another problem is to deal with near singularity (det close to zero) by introducing a regularization term \\beta.\n\n- Give definition of MI and link with copulas, e.g.,\nMa, Jian, and Zengqi Sun. \"Mutual information is copula entropy.\" Tsinghua Science & Technology 16.1 (2011): 51-54.\nThis will relate to Eq. 8 as well.\n\n- Because MI estimation is an important and well-studied topic, I suggest to put Section 4 on related works after the introduction to that the contributions are better explained.\n\n- The lower/upper bounded of entropy of GMMs are not tight. There is a rich litterature which also compares the tightness of the various bounds.\n\nHuber, Marco F., et al. \"On entropy approximation for Gaussian mixture random vectors.\" 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems. IEEE, 2008.\n\nEven in 1D:\nNielsen, Frank, and Ke Sun. \"Guaranteed bounds on the Kullback–Leibler divergence of univariate mixtures.\" IEEE Signal Processing Letters 23.11 (2016): 1543-1546.\n\n- Notice that some distributions do not admit densities (some elliptical distributions for example)\n\n\n\n- Mention MI properties (i.e., tensorization) which defines the self-consistency test of estimators\n\n\n- small remarks:\n* data covariance = scatter matrix\n* after (3), define $\\Sigma_x$ as scatter matrix?\n*  page 3, first sentence need to be rephrased\n* some typos: \npage 7  hyperparamter -> hyperparameter\npage 9 self-supervied -> self-supervised    competitve -> competitive - Would using PCA beforehand be more appropriate in the case of near singularity?\n\n- Can we tackle robustness/variance with f-MI?\n\nMoon, Kevin, and Alfred Hero. \"Multivariate f-divergence estimation with confidence.\" Advances in neural information processing systems 27 (2014).\nEsposito, Amedeo Roberto, Michael Gastpar, and Ibrahim Issa. \"Robust Generalization via f− Mutual Information.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.",
         "447",
         "3",
         "7",
         "0.8255"
        ],
        [
         "26",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_MHkc",
         "1699156174555",
         "1699636242410",
         "3",
         "4",
         "2",
         "3",
         "2",
         "this paper proposes to use the logdet function for the estimation of mutual information. \ntwo bounds are proposed for this purpose. the results show improvement in comparison \nto the editing methods. the proposed function itself is \"the Coding Length Function\". simple method with good results. In my opinion this paper reinvents \"Coding Length Function\".  \"...the difference is we put a scaling hyperparameter β on the identity matrix I..\" - that is not a difference. both affects SNR. The latter can be affected either way: by multiplying the noise covariance or by division of the data covariance. I do agree that the results are interesting, but the novelty is quite limited due the the above. \n\nplease elaborate on the limitations. \"So, we recommend β = 1e−3 in the following simulation studies\" why not beta=zero? \nFigure 1.b shows that beta=zero correctly estimates the true MI. \nThat raises a question why do you need beta > 0?\n\nHow do you define $\\pi_c$ in e.g., Eq17?\n\nBoth bounds are loose. How can you explain that such loose bounds lead to very small variance in MI?\n\nDo you calculate MILE in batches?",
         "187",
         "0",
         "1",
         "0.7572"
        ],
        [
         "27",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_oYZA",
         "1699327631740",
         "1699636242348",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The paper proposes uses bounds on the entropy and mutual information for a mixture of Gaussian random variables based on the log determinant calculations used in calculating the entropy for a single Gaussian. In the context of self-supervised learning, the Gaussian mixture is assumed to known based on the augmentation. In other cases the number of mixture components has to be selected. Empirical results are reported on a synthetic benchmark of correlated Gaussians with and without non-linear transformations. Results of self-consistency measures are reported on CIFAR10. The paper is a logical motivation. Differential entropy is easy to calculate for Gaussian distributions, and mixture of Gaussians are universal approximations given enough data, so why not use GMM for mutual information estimation. The insight of using the augmentations as defining the GMM is a useful, simplifying assumption. One main weakness is the lack of extensive comparisons of using this method for self-supervised learning versus other. The one example in the main body (Table 1) shows that at 300 epochs the method is better than some other methods but is inferior to EMP-SSL. At 1000 epochs the other methods outperform the listed, but no results for 1000 epochs are reported. \n\nThe second main weakness is the paper does not give a complete description of the method. The paper is lacking in clarity with some key point unaddressed. The notation is confusing since the random variables (Z,Z') are denoted the same as Z_c, which may be a data point in the empirical sample. There should more clarity on random variables as compared to  sample sets, starting back before equation 4. The confusion carries to last paragraph of Section 4 where $\\mathbf{X}$ is defined but then $X$ is used in the definition. \n\nThe use of one instance for one cluster is not clear to me upon reading it\n\"This is because we treat the augmented data from one instance as a cluster, and this data\naugmentation strategy automatically clusters the data.\" This should be re written.\n\n In equation 17 it is not clear how $\\zeta_c$ captures all instances in the batch. It has only a single $i$ index. Perhaps the $\\zeta_c$ should concatenate them all. In section 3.2, $\\zeta_c$ is a set which indexes the whole match, which makes more sense, but it should be a matrix not a set. In any case, how is the $H(Z)$ term estimated in section 3.1? By keeping $Z_c$ fixed and only augmenting the second the one covariance matrix will be rank-1 (before ridge). \n\nIt doesn't sound like the experiments for the 5.2 are run fairly \" our MILE estimator does not require extra training,\" In this problem the point is that the MI could be changing at each data instance. Thus, other methods do not use access to the change points. MILE should have to be run (which involves performing the GMM since there are no self-clusters as in SSL) at each point. Running an expectation maximization is as much or more training than the updates of network.  \t\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. \n \nIn terms of unsubstantiated claims, the method is clearly biased (not only by the choice of number of components) but also on the non-linear transform cases. It is not clear how well the mutual information estimation would actually work on more complicated data. Thus, even if it is useful for self-supervised learning is not necessarily a more accurate estimate of differential entropy. \n\n**Minor:**\nThere are a number of typographical mistakes that are distracting.\n\nI don't understand what this means\n\"often dwarfing traditional parametric and non-parametric approaches in statistics\"\n\n\" base on the \" -> \"based on the \" \n\nI'm not familiar with this phrasing \"When X subjects to a Gaussian\" \n\n\"a ‘noise’ $\\hat{X}$ \" -> \"a noisy $\\hat{X}$\" \n\nThe paragraph before equation (4) are not clear. \" an expanding factor\" is not defined nor is it clear what is meant by \"enlarging the original covariance matrix\".\n\nExtra $=$ on equation 14.\n\n\"trading each\" -> \"treating each\" ? \n\n\" ground true data\" \n\n\"SMILE: moothed\" -> \"SMILE: smoothed\" \n\nIt should be a parenthetical reference for You et al. (2017) fo LARS optimizer. How is the $H(Z)$ term estimated in section 3.1? Is it also based on augmented data?\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. Are there hyper-parameters for EMP-SSL?  \n\nWhy in Table 1 is 1000 epochs not tested?\n\nIs the GMM method run at each time point in Figure 2?",
         "766",
         "1",
         "2",
         "0.7605"
        ],
        [
         "28",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_e4bh",
         "1698824679826",
         "1700667146725",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs) which build on the graph theoretical concept of graphexes to include sparse network structures between agents. This improves over prior work on Graphon Mean Field Games which only allows for modelling with dense graphs. The authors derive convergence properties for the finite game. In addition, a learning algorithm based on online mirror descent is provided for a particular class of GXMFGs that follow a core-periphery network structure. Finally, the theoretical claims are empirically validated over both synthetic and real-world networks. - This paper has a clear motivation to extend Graphon Mean Field Games to deal with sparse graphs which are frequently seen in practice. The hybrid graphex approach proposed in this work looks like a natural and intuitive solution.\n- The technical development is principled and the analysis is nontrivial.\n- The overall presentation and clarity is good. - Even though the authors explained in the paper, I didn't like the fact that the proposed GXMFGs have no baseline competitors to compare against. While I agree that one could argue on the contrary that the ability to work with sparse graphs is precisely the unique advantage of GXMGFs, I think that the authors should at least spend some efforts to discuss (if empirical comparison with LPGMFG is indeed unsuitable) how GXMFGs would compare with LPGMFG and GMFG in practice. In Figure 3a, it looks like the curves are diverging rather than converging as k increases? Are the curves coloured correctly?",
         "248",
         "0",
         "0",
         "0.8187"
        ],
        [
         "29",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_hgJx",
         "1698838739665",
         "1699636550718",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs), a framework for addressing the challenge of learning agent behavior in large populations. GXMFGs leverage graphon theory and graphexes, which represent limiting objects in sparse graph sequences. This approach suits real-world networks with both dense cores and sparse peripheries. The paper presents a specialized learning algorithm for GXMFGs. \n\nKey contributions include:\n\n1. Introduction of GXMFGs, extending the scope of Mean Field Games.\n2. Provides theoretical guarantees to show that GXMFGs accurately approximates finite systems.\n3. Development of a learning algorithm tailored to GXMFGs.\n4. Empirical validation on synthetic and real-world networks, demonstrating GXMFGs' ability to model agent interactions and determine equilibria effectively. - Well-Written and Organized: The paper demonstrates strong writing and organization, enhancing its overall readability and accessibility.\n\n- Clear Motivation: The paper effectively conveys a clear and compelling motivation for addressing the problem it tackles.\n\n- Thorough Discussion of Prior Works: The paper provides a comprehensive and well-structured overview of prior works related to the research area.\n\n- The paper provides solid theoretical contributions complimented with supporting empirical studies strengthens the paper's arguments and findings. As the current paper falls outside the scope of my research interests, I am unable to identify any significant weaknesses in the paper. Consequently, my confidence in assessing the paper is limited. - Providing an intuitive explanation for assumptions 1(b) and 1(c) would greatly enhance the paper's overall readability and accessibility.\n\n- While the paper assumes finite state and action spaces, it may be beneficial to explore whether the proposed approach can be extended to scenarios with infinite action spaces. \n- Including the code for the simulations, would enhance reproducibility.",
         "275",
         "0",
         "4",
         "0.8110"
        ],
        [
         "30",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_P6cQ",
         "1698854680058",
         "1699636550633",
         "6",
         "4",
         "3",
         "3",
         "3",
         "In this paper, the authors study a class of games with many players who are interacting through a sparse graph structure. More specifically, they are interested in the regime where the number of players tend to infinity. The main solution concept is an extension of the notion of Nash equilibrium. The authors propose a learning algorithm based on online mirror descent. They conclude the paper with examples and numerical simulations. Overall, the paper studies an interesting problem and is relatively clearly written. As far as I know, this is a new extension of MFG to sparse graphs. The algorithm is very inspired from existing ones but there is an adaptation to the problem under consideration (core vs periphery). The model is quite abstract at some places. For the theoretical results, they are mostly about the analysis of the game and I am not sure how relevant they are for this conference (although they are certainly interesting for a certain community). It might have been more interesting to focus more on the learning algorithm. \n\nThere are some typos which make it hard to check the correctness of some parts (see questions). 1. I am wondering if some assumptions are missing. For example below Lemma 1, should $f$ be at least measurable (and perhaps more?) with respect to $\\alpha$ for the integral to make sense?\n\n2. Assumption 2 as used for instance in Lemma 1 does not seem to make much sense (unless I missed something): What is $\\boldsymbol{\\pi}$? We do not know in advance the equilibrium policy and even if we did, we would still need to define the set of admissible deviations for the Nash equilibrium. Could you please clarify?\n\n3. Algorithm 1, line 14: Could you please explain or recall what is $Q^{k, \\mu^{\\tau_{\\mathrm{max}}}}$?\n\nSome typos: Should the state space be either $\\mathcal{X}$ or $X$ (see section 3 for instance)? Does $\\mathbb{G}^\\infty_{\\alpha,t}$ depend on $\\boldsymbol{\\mu}$ or not (see bottom of page 4)? Etc.",
         "324",
         "0",
         "4",
         "0.8025"
        ],
        [
         "31",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_qFZD",
         "1698724264822",
         "1699636511957",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper introduces out-of-variable (OOV) generalization, which is an the ability to generalize in environments with variables that have never been jointly observed before. OOV is an issue in settings where different variables (e.g. diagnostic tests) are available for different environments (e.g. different patients). The paper investigates challenges for common approaches when faced with the OOV problem, and proposes an OOV predictor that leverage moments of the error distribution. The work contributes to theoretical understandings of OOV and offers a proof-of-concept for a predictor capable of non-trivial OOV transfer. - The paper formally studies a new perspective on generalization.\n- The methods employed in the paper are sound. - The paper does not demonstrate the practical applicability of the concept of OOV generalization, and the setting feels a bit contrived. Also it seems like OOV generalization can be thought of just a case of OOD generalization--if we think about all the variables together as the input, the OOV generalization is just a case of OOD generalization (e.g. covariate shift) where some inputs have clear signal from some features and other inputs have clear signal from other features. \n- It would be helpful to include more intuitive discussion throughout the paper providing more analysis on the sections. For example, more discussion on the assumptions of the settings/theorems would be helpful, and it's not clear exactly under what assumptions the proposed predictor is appropriate. Please see weaknesses above.",
         "236",
         "0",
         "2",
         "0.7220"
        ],
        [
         "32",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_s9Ga",
         "1698762596885",
         "1700684618252",
         "8",
         "4",
         "3",
         "4",
         "2",
         "This work investigates out-of-variable (OOV) generalization, which is a sub-problem to OOD generalization, and refers to scenarios where an agent needs to generalize to environments containing variables that were never jointly observed before. The paper shows that if the source and target environments contain some overlapping variables (and under certain conditions), information from the predictor in the source environment can improve predictions in the target environment. More specifically,  the moments of the residual distribution from the optimal classifier in the source environment can be used to calculate the generating function with respect to the unobserved variable in the target domain.\n\nBased on this observation, the paper proposes a practical algorithm for OOV prediction, evaluates its performance, and compares it against the marginal predictor and imputed predictor, as well as an Oracle predictor. The paper proposes a new and important problem-setting - OOV generalization, which can occur in real-world situations, on its own or alongside OOD aspects. The work also provides an extensive study of the identification problems of various variants of OOV scenarios, including theoretical proofs and examples. \n\nIn addition, the paper proposes a practical algorithm to solve several OOV scenarios that achieves non-trivial OOV transfer on synthetic data.\n\nThe ideas presented in the paper are novel and the conclusion that information from source domains can be used for prediction in the target domain in this setting is important, and can potentially have a broad impact on future research in the field. The main limitation of the paper is that the proposed approach was tested on only synthetic data, and was not validated using more challenging datasets. \n\nIn addition, the extension of OOV in multi-environments is mentioned mainly in the appendix and the algorithm was not tested empirically for that extension. I would like to ask the following questions:\n\n1. For future work, is there a more complicated/realistic dataset to validate the algorithm?\n2. Is it possible to compare the algorithm to state-of-the-art marginal or causal methods such as Mejia et al. (2021) or Janzing (2018)? To validate if Vapnik’s principle holds and whether the proposed approach indeed improves results due to solving a less general problem.\n3. Theorem 3 connects all moments of the residual distribution to the partial derivatives with respect to the unique variable of the target environment. If additional moments were to be calculated as part of the proposed algorithm, would it improve results (for the general function case)? \n4. In general, since the paper's main claim is that in the real world, it is likely to encounter both aspects of OOD and OOV - How simple is it to combine state-of-the-art  OOD methods with the proposed approach? I cannot imagine at the moment a straightforward way to do that.",
         "454",
         "2",
         "3",
         "0.7695"
        ],
        [
         "33",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_woi7",
         "1698788842803",
         "1699636511769",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper describes the out-of-variable OOV problem, which in its simplest form, aims to learn a predictor Y = f_t(X2, X3) given an OOV predictor Y = f_s(X1, X2) and a dataset (X2, X3), but without any instance of (X2, X3, Y). The authors describe the setting in which this is possible and develops an algorithm. The key observation is that the third moment of the residue Y - f_s(X1,X2) contains information about X3 that is least polluted by the noise. - The key observation/discovery is clever, and the algorithm is straight-forward to use.\n- The writing is clear, clean, and well-referenced. The examples also made things concrete and easy to follow.\n- The rigor and simplicity of the work can act as a foundation to build OOV research. - The main weakness is the applicability of the method. The authors only showed results for proof-of-concept, not for real-world usage. \n- It is unclear how one could identify whether the assumptions are satisfied given a dataset.\n- It is unclear how bad the predictor would be if the assumptions are not satisfied.\n- It is not yet clear what realistic problem can be well modeled by OOV generalization. Intro:\n- It seems OOV fits very well the frame of missing-not-at-random and covariate-dependent missingness. Could the authors comment on that?\n\nSection 2:\n- Theorem 2 is slightly confusing for me at first glance because I thought PA_Y by definition includes all parents of Y (so x1,x2, x3 in the example) and not just those in the target environment (x2, x3). It may be helpful to clarify.\n\nSection 3:\nAs I am trying to get a sense of the restriction and applicability of the approach, I was wondering the following questions: \n- How does the method fair with the oracle as the magnitude of the noise increases? \n- What if the noise is not gaussian but more heavy tailed? \n- Does the performance degrade or improve with increasing number of variables? \n- I assume Theorem 3 does not apply to discrete variables because of the violation of differentiability; is that right?\n\nSection 4:\n- Can include missing-not-at-random imputation and covariate-missing imputation as two more baseline models (a search in Google scholar using the two key phrases yields some methods).\n- It would be really interesting if the authors could find some real-world datasets, create source and target environments by sub-setting the columns, and see how the method performs.\n- Figure 3: I don’t quite understand the figure. It would be helpful to define OOV loss, be explicit about the number of samples on the y-axis being (x2,x3,y) or (x1,x2,y) or something else. I also don’t understand why relative loss is zero means the method is on par with the oracle predictor. Why not just show how the fine-tuning error compares with oracle training, which seems easier to interpret? Anyway, I am overall a bit confused about the figure, so my questions may not make sense.",
         "493",
         "0",
         "0",
         "0.7642"
        ],
        [
         "34",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_xwQY",
         "1699441328198",
         "1699636511667",
         "8",
         "3",
         "3",
         "3",
         "3",
         "The paper investigates out-of-variable generalization, namely the ability for a predictive model to generalize to target domains in which the agent has never seen the joint variables in the target domain in a single source domain before. Under certain assumptions as well as when these assumptions don't fully hold, the paper shows that the error residual distribution in an environment provides information on the unobserved causal parent variable in this environment, and they use this information to derive an algorithm that performs OOV generalization with source and target domains that have overlapping sets of causal factors. **Originality**\n- As far as I know, though the problem the paper addresses is well-known as a significant problem, the paper provides several theoretical results, mathematical derivations, and supports these with simple empirical results that are novel.\n\n**Quality**\n- The quality of the paper is high. It addresses a high-value problem in a principled fashion, shows how certain assumptions help obtain certain results and how and in which cases these assumptions can be bypasses while maintain approximately accurate results, and evaluates these cases in terms of loss accuracy as well as sample complexity of its approach versus baseline approaches.\n- The paper openly highlights limitations in its work, such as assumptions made for theorems to hold, and proposes prospective future work in multiple avenues. This refreshingly is (1) included at all and (2) doesn't seem like a mere afterthought.\n\n**Clarity**\n- The paper is mostly clear in its explanation of motivation, preliminaries, approach, baseline usage, results, and limitations.\n- The paper does a great job providing simple, clear real-world examples to elucidate the problem and applications of the various theorems included in multiple cases.\n\n**Significance**\n- The significance of the problem the paper addresses is high and the problem is ubiquitous. The approach is promising and can be applied in many real-world settings through Monte-Carlo sampling or similar methods. The paper shows that their approach can perform relatively well in \"few\"-shot settings though this depends on the number of variables involved and the complexity of the problem.\n\nFrom what I can tell, this is excellent work that I hope motivates further addressing this *out-of-variable* generalization problem by the research and applied AI community. My only reservation is my limited knowledge on the understanding of and state-of-the-art theoretical and applied approaches addressing this problem. - Referring to Figure 1, in the first paragraph in page 3, the claim \"it would seem all but impossible...(orange box)\" could be better explained.\n- In Figure 1, it is unclear whether \"With $Y$ not observed in the target domain\" is an assumption made or is somehow indicated in the diagram or earlier in the paper. Eventually I realized that it's an assumption made, but the illustration Figure 1a alone isn't enough to show this assumption. This ambiguity may clear for some or compound for some later in Section 3. - The abstract states \"merely considering differences in data distributions is inadequate for fully capturing differences between learning environments.\" Doesn't out-of-variable technically fall under out-of-distribution, so shouldn't this be adequate? Perhaps more specificity is needed here.\n- The abstract states \"Mathematically, out-of-variable generalization requires the efficient re-use of past marginal information...\" Why does it require efficient re-use? Could it work with \"non-efficient\" or inefficient re-use?\n- On page 2, should \"modal\" be \"model?\"\n- On page 6, do you mean \"parentheses\" instead of \"brackets\" between Eq (9) and Eq (10)?\n- Why is the joint predictor considered an oracle predictor if MomentLearn outperforms it?\n- Could you explain why MomentLearn is reliably more sample efficient than the oracle predictor for \"few\"-shot prediction?",
         "602",
         "0",
         "0",
         "0.7701"
        ],
        [
         "35",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_HgHQ",
         "1697165838375",
         "1699635934990",
         "3",
         "5",
         "2",
         "3",
         "2",
         "The paper proposes a simple yet efficient feature direction distillation loss. Experiments show that this significantly improves KD\nperformance. 1. Improving KD by feature norm and direction is reasonable and effectiveness.\n2. Experiments on standard benchmarks demonstrate that adopting $\\mathcal{L}_{dino}$ remarkably improves existing KD methods. 1. The contributions seem a little limited. \n2. There is lack of theoretical analysis of DINO loss. The paper is not good enough to be published on ICLR. 1. How to align the features between heterogeneous architectures?\n2. Could you please provide more theoretical analysis?\n3. What about extending it to a multi-layer version of feature distillation?\n4. How to apply the proposed method to existing KD methods, e.g. ReviewKD, DKD, DIST? Just add the DINO loss function to the total loss ? If so, I think adding other loss like contrastive distillation loss or RKD may also make a improvement.",
         "146",
         "0",
         "8",
         "0.8205"
        ],
        [
         "36",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_yLjx",
         "1697172920902",
         "1699635934905",
         "6",
         "5",
         "3",
         "3",
         "2",
         "Here is a summary of the key points from the paper:\n\n- The paper proposes a method to improve knowledge distillation (KD) by regularizing student features to align direction with teacher class-means and have sufficiently large norms. \n\n- Current KD methods like logit or feature distillation align student and teacher but don't directly optimize for student's task performance.\n\n- The paper shows regularizing direction using cosine similarity to teacher class means helps improve student accuracy. \n\n- It also finds student models tend to produce smaller-norm features, so encouraging larger norms improves performance. \n\n- A simple combined loss called dino-loss is proposed to simultaneously regularize student feature direction and norm using teacher class means.\n\n- Experiments on CIFAR and ImageNet classification, and COCO detection show dino-loss consistently improves various KD methods like KD, ReviewKD, DKD.\n\n- Dino-loss achieves new state-of-the-art results among KD techniques on classification and detection benchmarks.\n\n- The method is model-agnostic, simple to implement, adds minimal overhead, and benefits from larger teacher models.\n\nIn summary, the key contributions are a way to improve KD by regularizing student features for better alignment and norms, along with a simple and effective dino-loss to achieve this jointly. The results demonstrate consistent gains across tasks and benchmarks. The paper presents an original and significant approach to improve KD via thoughtful feature regularization. The method is intuitive and supported by quality experiments. The gains are demonstrated to be significant across tasks. The presentation and discussion are clear:\n- The method and dino-loss are clearly explained with illustrations and equations. Results are well-presented in tables and figures. Limitations are properly discussed.\n- Improving KD is an important practical problem. The consistent gains are significant. Sets new state-of-the-art results on ImageNet classification and COCO detection.\n- Model-agnostic nature allows wide applicability to various KD methods and models. Simple extension can benefit the community compared to more complex techniques. - The paper should address the lack of novelty by acknowledging that feature normalization techniques have already been widely employed in knowledge distillation. For example, PKD (NeurIPS-2023) specifically incorporates channel alignment for detectors, and SKD (Guo Jia) explores normalization techniques on predictions. and Feature Normalized Knowledge Distillation for\n/mage Classification ECCV2022 also presents feature norm. Furthermore, it is worth investigating whether the proposed method has already been considered in the distiller's search work, as exemplified by KD-Zero: Evolving Knowledge Distiller for Any Teacher-Student Pairs (NeurIPS-2023).\n\n- In addition, the paper should incorporate a thorough discussion of relevant KD-related studies, including Self-Regulated Feature Learning via Teacher-free Feature Distillation (ECCV2022), NORM: Knowledge Distillation via N-to-One Representation Matching (ICLR2023), Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer (NIPS2022), DisWOT: Student Architecture Search for Distillation Without Training (CVPR2023), and Automated Knowledge Distillation via Monte Carlo Tree Search (ICCV2023). These discussions will provide valuable insights into the existing literature, establish connections with previous research, and potentially highlight points of comparison and contrast. The only concern to me is the novelty of the work and I hope the authors could discuss some of the related work I mentioned in the revised version.",
         "510",
         "0",
         "1",
         "0.8228"
        ],
        [
         "37",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_VRvE",
         "1698736302686",
         "1699635934723",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper studies Knowledge Distillation (KD). A simple loss term namely ND loss is proposed to enhance the distillation performance. It encourages the student to produce large-norm features and aligns the direction of student features and teacher class-means. The ND loss helps not only logit-based distillation methods but also feature-based distillation methods. 1. The proposed method is simple but effective. Encouraging the feature norm for the student is novel in the field of KD.\n2. Experimental results are strong. The authors also conduct experiments on object detection. The proposed loss can improve the existing methods on both image classification and object detection.\n3. The whole paper is organized and written well. It is not a novel thing that decoupling the feature into the magnitude and the direction. Previous works [1][2] already studied this point. [1] uses the teacher classifier to project both teacher features and student features into the same space and then align them. [2] proposes a loss term to align two features’ direction. Compared to the existing works, this paper proposes enlarging feature norm and utilizing the class-mean feature. Authors should check more existing papers and discuss their differences.\n[1] Yang, Jing, et al. \"Knowledge distillation via softmax regression representation learning.\" International Conference on Learning Representations (ICLR), 2021.\n\n[2] Wang, Guo-Hua, Yifan Ge, and Jianxin Wu. \"Distilling knowledge by mimicking features.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 44.11 (2021): 8183-8195. None",
         "235",
         "7",
         "6",
         "0.7478"
        ],
        [
         "38",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_AuzT",
         "1698788774762",
         "1699635934515",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper proposes to use teacher's class-mean to align student's direction and encourage the student to produce large-norms features, improving the performance of KD. The paper is generally well-written, and the methodology is well-motivated. 1. would expect comparisons and discussion to similarity-preserving KD e.g., [1], which is a large family in feature distillation methods and shows some relations to the proposed method.\n2. Meanwhile, comparisons/discussion to explainablity-based KD, e.g., [2] are needed to see whether those methods can be benefited from the proposed method.\n\n[1] Tung, Fred, and Greg Mori. “Similarity-Preserving Knowledge Distillation.” ICCV 2019.\n\n[2] Guo, Ziyao, et al. \"Class Attention Transfer Based Knowledge Distillation.\" CVPR 2023. Please see weakness.",
         "111",
         "4",
         "6",
         "0.7517"
        ],
        [
         "39",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_AcYB",
         "1697637540901",
         "1700740134087",
         "5",
         "4",
         "3",
         "2",
         "2",
         "The authors introduce Neural Sinkhorn gradient flow, which is a Wasserstein Gradient Flow wrt to the Sinkhorn divergence. The authors show that the velocity field can be calculated using the Sinkhorn potentials. This allows training a neural network approximating the velocity field. Furthermore, a mean field limit is established. The algorithm is evaluated on a toy example, MNIST image generation and CIFAR10 image generation. The authors do a good job at explaining the underlying concepts of their algorithms. The maths is nicely done. The core idea is very neat and the cifar10 results seem to be good quantitatively wrt other gradient flow works. 1) The article is full with typos. Just to name a few: \"piror\", \"Sinkhron\", \"Experimrnts\", \"speedest descent\", question mark in the appendix and so on. Please fix those. \n\n2) the authors write \"We do not compare with extant neural WGF methods on MNIST because most of the neural WGF\nmethods only show generative power and trajectories on this dataset and lack the criteria to make\ncomparisons.\" There are several papers (also gradient flow based ones), which evaluate a FID on MNIST. Please provide it as well. \n\n3) Also many of the MNIST digits appear flipped. Did the authors use data augmentation there? Also there seems to some slight noise present the generated MNIST digits. \n\n4) Although the CIFAR10 value seems good, there are unfortunately no generated images provided. It is standard practice to sample many images in the appendix. \n\n5) It is unclear what the trajectories show. Does it show the particle flow or the trained Neural Sinkhorn Gradient Flow? \n\n6) The statement of theorem 2 is incorrect. I guess the authors do not want to sample the Euler scheme (eq 14) but the continuous gradient flow, otherwise the statement would need to depend on the step size $\\eta$. \n\n7) In the proof of Theorem 2: Please provide a proof (or reference) why the mean field limit exists. Or do you mean the gradient flow starting at $\\mu_0$ with target $\\mu$ (first two sentences).\n\n8) Later in that proof: why does there exists a weakly convergent subsequence of $\\mu_t^M$? Further, I cant find the definition of $U_{\\mu}$. \n\n9) The code is not runnable, as the model (or any checkpoints) are not provided.\n\n10) From how I understood it, the learning of the velocity field is batched, i.e., one trains for different sets of $(z_i,x_i)$. Since the Sinkhorn dynamic describes an interacting particle system I dont see how this should be possible. To be more precise, one particle $\\tilde{x}$ could be sent to $x_0$ in the first batch, but to a totally different particle $x_1$ in another one, depending on the drawn prior and target samples. Are the positions of the other particles also input to the neural network (i.e by putting them in the channels)? Please elaborate. See weaknesses section. Overall I really like the idea, but the weaknesses prevent me from giving a higher score. It seems like the paper was rushed and is currently not ready for publication. I am willing to raise my score, if the authors address these issues.",
         "516",
         "0",
         "3",
         "0.7790"
        ],
        [
         "40",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KKim",
         "1698338217824",
         "1700755549491",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces a novel way to train generative models. The authors want to approximate the gradient flow in the Wasserstein space.  They want to approximate the vector field which transports the source distribution to the real-data empirical distribution while minimizing the Sinkhorn divergence. The authors showed the analytical form of the vector field when one considers the Sinkhorn divergence and then they explain how to learn this vector field with a neural network through the simulation of a probability path. They showed that their procedures recover the true probability path when the number of iid samples goes to infinity. Finally, they validate their proposed method on several image-generative tasks. i) The motivation and the introduction are clear\n\nii) Regressing vector fields has been a recent and popular approach with many different applications in machine learning. The proposed approach is interesting and appears to be novel. The theoretical results also show that the proposed method has appealing properties. \n\niii) The authors also provided several experiments showing interesting results from their methods. The first thing I would like to highlight is that I have checked the provided code. I see several inconsistencies and weaknesses between the provided code and the paper:\n\n1. There are several differences in the empirical implementation between the paper and the code. In Appendix A, the authors state that they are computing the entropic potential through stochastic optimization algorithms [Genevay et al, 2016]. However, this is not what is done in practice according to the provided code. In practice, the authors compute the potential between mini-batches of samples, they sample a minibatch of cifar10 experiments, then sample a minibatch of the source Gaussian, and simulate the gradient flows between the two minibatches. This style of minibatch approximation induces a bias that should at least be mentioned in the main paper but also discussed. Indeed, the authors do not compute the true Sinkhorn divergence but a minibatch approximation of it; this approximation is slightly different than the one from [1,2] and that should be discussed. I understand the reason why the authors use this approach (decreasing the cost of this preprocessing step), but this is not what they say they do in Appendix A. In that regard, the paper is much closer to the minibatch optimal transport Flow Matching [Pooladian et al., Tong et al] and Appendix A deserves a major revision.\n\n2. With the provided code, there are several insights that should be discussed in the paper. In the provided cifar experiments, the number of Gaussian samples used is 50000 samples. This number is extremely low to approximate the semi-discrete OT. Therefore, a discussion regarding the statistical performance of the method is needed in my opinion.\n\n3. As your method requires the simulation of the probability path, I wonder about the training time between your method and the recent Flow Matching approaches which are simulation free.\n\n4. There are many typos in the paper (including in titles: ie ExperimRnts, Notaions) that lead to poor clarity...\n\n5. The experiments include two toy datasets (synthetic 2D and MNIST). I would like to know how the method performs on other big datasets (Flowers, CelebA) or on other tasks such as single-cell dynamics [4].\n\n6. The related work on optimal transport is incomplete. Several works used the sliced Wasserstein distance to perform gradient flows [3].\n\n[1] Learning Generative Models with Sinkhorn Divergences, Genevay et al, AISTATS 2018\n[2] Learning with minibatch Wasserstein, Fatras et al, AISTATS 2020\n[3] Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions\n[4] TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics 1. [Pooladian et al., Tong et al.] proved that when the minibatch increases, they get closer to the true optimal transport cost (W_2^2). The interest of their method is that they can rely on minibatches and learn the vector field from an unlimited number of minibatches. Could you follow a similar approach and simulate the gradient flow during training? While it would be an expensive step in training, it might improve the metrics on the different generative model experiments.\n\n2. What is the performance of your method concerning the number of simulation steps (ie Euler integration and its learning rate)?\n\n3. What is the time of the preprocessing step concerning the training time?\n\n4. Could you compare your method with OT-CFM [Pooladian et al., Tong et al.] on the synthetic data? I am curious to compare the differences.\n\nIn my opinion, the mentioned weaknesses have to be revised and this paper should go under a major revision. I deeply think that the experimental section should better highlight what is done in practice and the theoretical section should mention the different biases (statistical and minibatch). Therefore, I recommend rejecting the current manuscript as it does not meet the ICLR acceptance bar.\n\n\n----- EDIT POST REBUTTAL -----\n\nI thank the authors for their answers. I have read the updated manuscript. While it is now better than before, I suggest they add a limitation section where they describe the different biases in their algorithm. I understand the motivations of the paper. Overall, I think that the manuscript deserves another round of reviews but I have decided to move my score to 5 as they have given good answers.",
         "873",
         "7",
         "8",
         "0.7648"
        ],
        [
         "41",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_Kh9H",
         "1698606606187",
         "1699636333063",
         "6",
         "4",
         "3",
         "2",
         "2",
         "Through a series of approximations (and at times, really, relaxations) the authors show that the Sinkhorn gradient flow from one measure to another can be learned.  They do this by first reducing their relaxed problem to a vector field matching problem, and then proposing a neural network-based Algorithm for matching the Sinkhorn-Wasserstein flow's vector field by a neural network (though no convergence/approximation guarantees are proven).\nThe problem is interesting, and its solution is sufficiently novel to merit publication. The problem is natural to study, the results are mathematically correct, and the experiments are convincing. While the paper is mathematically correct, it does not provide theoretical justification for one of its main components, namely showing that approximate vector field matching yields approximate solutions for all time $t$.  I feel that without this guarantee, there is a gap in the theoretical viability of this model.  Nevertheless, this is a minor point since the length of a conference paper does not allow one to treat every such point.\n\nThere are minor typos throughout. \n* E.g. euclidean instead of Euclidean\n* $lim$ instead of $\\lim$ atop page 15 in the appendix\n* The positive scalar $\\delta$ is not defined in the proof of Theorem $1$\n* In the statement of Lemma 3: \"teh\" should read \"the\"\n\nSome references are obscure\n* For The fact that $\\mu + t\\delta \\mu$ converges weakly to $\\mu$, perhaps it is worth simply noting that due to linearity of integration (wrt to the measure term). Can it be shown that approximate vector field matching yields approximate solutions for all time $t$?",
         "262",
         "0",
         "1",
         "0.7647"
        ],
        [
         "42",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KkYD",
         "1698745650108",
         "1700818697559",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper under consideration deals with the standard generative modelling setup (image generation from noise). To solve this problem, the authors propose to model the gradient flow w.r.t. the Sinkhorn divergence. The paper utilizes an explicit (forward) Euler discretization scheme, i.e., given a distribution $\\mu_t$ at the current time step $t$, the proposed method aims at finding the subsequent distribution $\\mu_{t + 1}$ following the gradient of the Sinkhorn divergence at point $\\mu_t$. The authors validate their methodology on toy 2D setups as well as standard image benchmarks (MNIST and CIFAR10).\n\n**Post-rebuttal update:** I thank the authors for the detailed answer. The majority of my concerns are properly addressed. I rise my score. However, I still tend to reject the paper. Also I agree with reviewer KKim that minibatch OT approximation should be discussed more thorougly. Thank you. To the best of my knowledge, the framework of the gradient flow w.r.t. Sinkhorn divergence for pure generative modelling has not yet been considered. This indicates that the paper is indeed bringing something novel to the ML community. At the same time, the idea of the Sinkhorn gradient flow has already arisen in previous research. In particular, [A] solves Sinkhorn barycenter problems by adjusting a generative distribution towards the barycenter distribution with the help of a procedure called “functional gradient descent” which is actually the discretization of the gradient flow w.r.t. the sum of Sinkhorn divergences to the target distributions. At the same time, it is worth mentioning, that [A] just simulates particles and does not build a generative model.\nRegarding the other strengths of the paper, I would like to note the well-organized Experiments section.\n\n[A] Sinkhorn Barycenter via Functional Gradient Descent, NeurIPS’2020 - Some theoretical results from the paper are known. For example, the statement of Theorem 1 could be found in [B] (eq. 26) or [C] (eq. 8). \n- The quality of the code provided is not good. There is no README/or other instruction to run the code. There are imports of non-existing classes. So, there is no possibility of checking (at least, qualitatively) the provided experimental results.\n\nFrom my point, the main weakness of the proposed paper is the limited methodological contribution. The authors simulate the particles of data following Sinkhorn divergence - as I already mentioned, this is not a super fresh idea. To make a generative model from these simulated trajectories, the authors simply solve the regression task to learn the local pushforward maps. And that is it. Combined with the fact, that the practical performance of the proposed approach is far from being SOTA in the generative modelling, the overall contribution of the paper seems for me to be limited. - My main question (and, probably, one of the main of my concerns) is regarding the proposed methodology. The authors propose to compute certain $\\mathcal{W}_{\\varepsilon}$ potentials (on discrete support of available samples) and then somehow take the gradients of these potentials w.r.t. the corresponding samples (eq. (13)). From the paper it is not clear how to compute the gradients, because the obtained potentials look like vectors of sample size shape, which are obtained through the iterations of the Sinkhorn algorithm. As I understand, in practice, the authors utilize SampleLoss from the geomloss package ([B]).  The outcome of this observation is that [B] should be properly cited when deriving the algorithm (section 4.2). I recommend authors explicitly use SampleLoss in the algorithm's listing. It will contribute to the clearness of what's going on. \n- The vector field of the Sinkhorn gradient flow is estimated by empirical samples. It is not clear how well this sample estimate approximates the true vector field. This point should be clarified. Note, that Theorem 2 works only for mean-field limit. \n- In the Introduction section, the authors consider a taxonomy of divergences used for gradient flow modelling, namely, \"divergences [...] with the same support\" and \"divergences [...]  with possible different support\". As I understand, the first class is about $f-$ divergences and the second class is about the other types (like Sinkhorn, MMD etc.). I have a question regarding the provided examples of works which deal with the former or the latter type of divergences. The fact is that the works [D], [E], [F], [G] deal with KL-divergence (or f-divergence) minimization. That is why I wonder why did the authors classify them as the second class.\n- A good work regarding poor expressiveness of ICNNs is [H].\n- What is the “ground” set ($\\S$ 3.1, first line).\n- Table 1. What are the differences between 1-RF, 2-RF and 3-RF methods?\n\n[B] Interpolating between Optimal Transport and MMD using Sinkhorn Divergences, AISTATS’2019\n\n[C] Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm, NeurIPS’2019\n\n[D] Large-scale wasserstein gradient flows. NeurIPS'2021\n\n[E] Optimizing functionals on the space of probabilities with input convex neural networks. TMLR\n\n[F]  Proximal optimal tranport modeling of population dynamics. AISTATS\n\n[G] Variational wasserstein gradient flow. ICML\n\n[H] Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. NeurIPS’2021.",
         "827",
         "0",
         "8",
         "0.7673"
        ],
        [
         "43",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_MEFG",
         "1699146383667",
         "1699636332903",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces the idea of learning a time-dependent velocity field of the Sinkhorn Wasserstein gradient flow from samples from the target distribution to calculate the empirical velocity field approximations. The paper supports its claim by showing that the mean-field limit of this process recovers the true Sinkhorn Wasserstein gradient flow. They also validated the process with some empirical studies. The paper is well written and easy to follow. The proofs and arguments in the appendix are well-typed out and clear.  There are some nice diagrams in the empirical section to supports the claim the authors are making. I think the experiments could be more extensive. One thing about this method is to investigate the number of samples needed. effectively learn the velocity field. This is one important experiment missing as is remains unclear how sample-efficient the proposed method is. It would also make the paper more completing if the method is applied to generative models that output discrete random variable like binary mnist or even language modelling. One possible question is what happens if we change the source distribution to be closer to the target distribution like it was from a generator how would the method perform there. Another question is to better understand the sample complexity of the method as the current method may not be sample efficient due to the empirical distribution being approximated using the samples.",
         "230",
         "0",
         "0",
         "0.7569"
        ],
        [
         "44",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_JSi7",
         "1698680587788",
         "1699636955419",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This article discusses a method to improve the application of SLM in the medical field, utilizing LLM's medical proficiency to boost SLM performance in medical tasks under privacy-restricted scenarios which has important social significance. The method was tested on MedQA, HEADQA, MedMCQA, and MMLU-professional medicine datasets, showing some improvements over existing methods. Additionally, the authors compared results across different sizes of training sets. see summary 1). Imprecise example of Privacy Protection.\nThe example in Figure 1 indicates that personal privacy issues are only present in the first sentence, and the key words \"man\" and \"admitted\" in that sentence have almost no impact on the subsequent content. Could it then be possible to simply delete the first sentence to achieve privacy protection, as extracting key words here does not seem to play a significant role.\n\n2). Privacy Protection as an Innovation Point\nRegarding the extraction of key words for privacy protection, the paper uses a medical NER model proposed by Neumann et al in 2019. We suggest further improvement of this model, for example, considering age as a crucial keyword for certain diseases and extracting it as necessary to better enrich the innovative aspects of the paper.\n\n3). Ambiguity of Symbols in Annotations\nAnnotation 13 on page 8 only appears in the content of the article but is not explained.\n\n4) The overall innovation of the methodology needs improvement, as the majority of the content relies on existing methods, such as the medical NER (Named Entity Recognition) model. please see the weaknesses.",
         "251",
         "0",
         "3",
         "0.8122"
        ],
        [
         "45",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_gXvF",
         "1698819472631",
         "1699636955275",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This paper tried to improve the performance of small medical language models by introducing knowledge from large language models, which keeps the privacy of clinical text when using large language models.  The proposed method uses keywords instead of full raw text to generate initial evidence from LLM and feed the evidence to small language model. Privacy-preserving is an essential and common need when using LLM in clinical text. This paper tried to solve this problem by using keywords instead of raw text, the idea is novel and experiments demonstrated the effectiveness of this approach. 1. As this research utilized a named entity recognition model to extract keywords, it is possible that the NER model can extract privacy information such as patient names. Is there any filtering or postprocessing step to avoid that? In addition, it is not guaranteed that NER system will never extract sensitive patient information; for example, if the NER system incorrectly extracts a patient's address as a symptom, then the address may be leaked to LLM. Although it is very rare, it is still necessary to comment on this. \n2. As the LLM already provides a preliminary decision, I am curious about the performance if we only feed the preliminary decision from LLM to SLM. It is worth knowing which part of the LLM-generated information improves the SLM most. \n3. The related work section need to discuss more LLM application in the clinical area, especially the knowledge-enhanced LLM in clinical settings. For example, paper \"Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.\" also utilized external knowledge for clinical questions. \n4. By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem? By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem?",
         "326",
         "0",
         "4",
         "0.7696"
        ],
        [
         "46",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_TtE2",
         "1698819599156",
         "1700663756238",
         "6",
         "4",
         "2",
         "2",
         "3",
         "The paper studied medical QA problems by incorporating large language models (LLMs) to assist small-language models (SLMs). To protect the private information in the data, the authors propose to first extract keywords and then use the keywords to query LLMs for intermediate content which can be used for SLMs to enhance prediction accuracy. 1. (originality) The proposed method is novel by extracting keywords and privately incorporating LLM for SLM-based predictions.\n2. (clarity) Overall, the paper is fair in presentation. The demonstrations of synthetic medical data with private information and extracted keywords are helpful for understanding the concepts.\n3. (significance) Versus the compared baselines, the proposed methods significantly improve the prediction accuracy on three medical QA tasks.\n4. (quality) The authors thoroughly evaluate the performance of the proposed method. 1. (Clarity) There is no specific definition of the private information. From Figure 1, it seems that privacy definition is restricted to private identifiable information (PII). The authors should clarify the scope of privacy risks. Importantly, the proposed method cannot address general private information leakage that is considered by strict formulations like differential privacy.\n2. (Quality) The evaluation of privacy is not strict. \n  - Risks: It is possible that the keyword extraction includes private identifiable information (PII), for instance, names and dates as shown in Figure 1. There is no theoretical guarantee for privacy protection or empirical evaluation of the leakage rates of such PII.\n  - Metric: The authors used the privacy budget for quantifying privacy risks:  the ratio of the number of words provided to the LLM to the total words in the original question. However, I doubt if the metric can imply some privacy risks. There essentially lacks an intuitive explanation of the relationship between the privacy budget and privacy risks.\n3. (Motivation) As the authors said, SLM presents a large gap compared to LLMs and thus there is no clear motivation to use SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. In the paper, there is no referred evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks. Thus, I strongly doubt if the motivation of the paper can hold. * There is no clear motivation to see SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. Is there any evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks?",
         "426",
         "0",
         "7",
         "0.7723"
        ],
        [
         "47",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_EBQC",
         "1699202302455",
         "1701315616812",
         "6",
         "3",
         "3",
         "3",
         "3",
         "In situations where text data is subject to privacy protection constraints, this paper designs a small-scale language model to perform diagnoses of diseases. Utilizing the rich prior medical knowledge in LLM, the approach involves generating a medical knowledge-intensive context using privacy-protected text. This generated context, along with key terms extracted from the text and questions, is then input into the SLM, which is fine-tuned during training. Experiments across multiple datasets demonstrate that this fine-tuning process effectively enhances the accuracy of the diagnostic model. 1. This paper focuses on a very important research topic in the field of medicine: how to effectively extract more useful information from incomplete text under the conditions of privacy protection. The author has made full use of the domain knowledge in LLM to effectively fine-tune the SLM, which ensures that the lightweight models can achieve high accuracy.\n\n2. This paper presents rich and comprehensive experiments. Beyond basic decision-making tasks, it also explores solutions for few-shot experiments and out-of-distribution (OOD) model generalization using the methods discussed in this paper.\n\n3. This paper fully utilizes the rich domain knowledge in LLMs to expand the knowledge base of medical reports, achieving excellent diagnostic accuracy even while ensuring privacy protection. 1. The contribution of this paper to the algorithm and the significance of the clinical problems it addresses seem not to be very high.\n\n2. The main work of this paper appears more as an engineering problem, transferring domain knowledge from LLMs to SLMs. From the perspective of algorithmic contribution, there seems to be some room for improvement. 1. The experimental datasets in this paper are all question-and-answer test datasets, and whether the methods of this paper are applicable to medical report datasets requires additional experimentation. This is because in medical reports, how to generate high-quality questions using other LLM interfaces is a question worth studying.\n\n2. Large language models provide additional domain knowledge, but in the context of specific medical tasks, will the direct transfer of knowledge from LLMs to SLMs lead to incorrect information leakage into SLMs? How can we ensure that LLMs only enhance information relevant to the current medical issue without introducing additional errors or irrelevant information? This is a very important issue in the medical field, as it directly relates to patient diagnosis.",
         "378",
         "0",
         "7",
         "0.8087"
        ],
        [
         "48",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E[x_t^\\top \\eta]>0$, where $E[\\cdot]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9",
         "0.7199"
        ],
        [
         "49",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9",
         "0.8034"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 28028
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_eS3u</td>\n",
       "      <td>1698243150596</td>\n",
       "      <td>1699636093263</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>This work proposes LSTNet, a self-supervised m...</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_jP4i</td>\n",
       "      <td>1698652503617</td>\n",
       "      <td>1699636093190</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1) This paper proposes a self-supervised metho...</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_wiS9</td>\n",
       "      <td>1698706547448</td>\n",
       "      <td>1699636093122</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper introduces LSTNet, which leverages ...</td>\n",
       "      <td>570</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_a6Ps</td>\n",
       "      <td>1698768293694</td>\n",
       "      <td>1699636092942</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper attempts to register point cloud pr...</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_Frem</td>\n",
       "      <td>1699350072271</td>\n",
       "      <td>1699636092872</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper presents a method of learning dense...</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28023</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_vt7i</td>\n",
       "      <td>1698673110283</td>\n",
       "      <td>1699636153803</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper extends the analysis of (Woodworth ...</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28024</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_oaZ7</td>\n",
       "      <td>1698928691830</td>\n",
       "      <td>1699636153728</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The paper studies the implicit regularization ...</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_fMm6</td>\n",
       "      <td>1698618130371</td>\n",
       "      <td>1699636636496</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The authors propose a network architecture to ...</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28026</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_tZQw</td>\n",
       "      <td>1698807944071</td>\n",
       "      <td>1699636636378</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper proposes InfoNet, a generalized alg...</td>\n",
       "      <td>346</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28027</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_9qjF</td>\n",
       "      <td>1698910414535</td>\n",
       "      <td>1699636636278</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>* This paper presents an innovative algorithm,...</td>\n",
       "      <td>670</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28028 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zzv4Bf50RW               1647             1695102158671   \n",
       "1        zzv4Bf50RW               1647             1695102158671   \n",
       "2        zzv4Bf50RW               1647             1695102158671   \n",
       "3        zzv4Bf50RW               1647             1695102158671   \n",
       "4        zzv4Bf50RW               1647             1695102158671   \n",
       "...             ...                ...                       ...   \n",
       "28023    014CgNPAGy               2200             1695179071455   \n",
       "28024    014CgNPAGy               2200             1695179071455   \n",
       "28025    0074qaufB6               5962             1695403263602   \n",
       "28026    0074qaufB6               5962             1695403263602   \n",
       "28027    0074qaufB6               5962             1695403263602   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "1      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "2      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "3      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "4      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "...                                                  ...   \n",
       "28023                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28024                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28025          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28026          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28027          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "1      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "2      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "3      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "4      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "...                                                  ...   \n",
       "28023  On the Role of Momentum in the Implicit Bias o...   \n",
       "28024  On the Role of Momentum in the Implicit Bias o...   \n",
       "28025  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28026  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28027  InfoNet: Missing Information Retrieval in Mult...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Establishing accurate dense 3D correspondences...  Reviewer_eS3u   \n",
       "1      Establishing accurate dense 3D correspondences...  Reviewer_jP4i   \n",
       "2      Establishing accurate dense 3D correspondences...  Reviewer_wiS9   \n",
       "3      Establishing accurate dense 3D correspondences...  Reviewer_a6Ps   \n",
       "4      Establishing accurate dense 3D correspondences...  Reviewer_Frem   \n",
       "...                                                  ...            ...   \n",
       "28023  Momentum is a widely adopted and crucial modif...  Reviewer_vt7i   \n",
       "28024  Momentum is a widely adopted and crucial modif...  Reviewer_oaZ7   \n",
       "28025  Faulty sensors in a multiple input stream setu...  Reviewer_fMm6   \n",
       "28026  Faulty sensors in a multiple input stream setu...  Reviewer_tZQw   \n",
       "28027  Faulty sensors in a multiple input stream setu...  Reviewer_9qjF   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  \\\n",
       "0      1698243150596           1699636093263              6   \n",
       "1      1698652503617           1699636093190              5   \n",
       "2      1698706547448           1699636093122              3   \n",
       "3      1698768293694           1699636092942              5   \n",
       "4      1699350072271           1699636092872              5   \n",
       "...              ...                     ...            ...   \n",
       "28023  1698673110283           1699636153803              5   \n",
       "28024  1698928691830           1699636153728              3   \n",
       "28025  1698618130371           1699636636496              1   \n",
       "28026  1698807944071           1699636636378              3   \n",
       "28027  1698910414535           1699636636278              5   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      2                 3                    2   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 2                    2   \n",
       "3                      4                 3                    3   \n",
       "4                      4                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "28023                  4                 3                    3   \n",
       "28024                  4                 1                    2   \n",
       "28025                  4                 2                    2   \n",
       "28026                  3                 3                    2   \n",
       "28027                  4                 2                    3   \n",
       "\n",
       "       review_contribution                                       total_review  \\\n",
       "0                        3  This work proposes LSTNet, a self-supervised m...   \n",
       "1                        2  1) This paper proposes a self-supervised metho...   \n",
       "2                        2  This paper introduces LSTNet, which leverages ...   \n",
       "3                        3  This paper attempts to register point cloud pr...   \n",
       "4                        2  This paper presents a method of learning dense...   \n",
       "...                    ...                                                ...   \n",
       "28023                    2  This paper extends the analysis of (Woodworth ...   \n",
       "28024                    1  The paper studies the implicit regularization ...   \n",
       "28025                    1  The authors propose a network architecture to ...   \n",
       "28026                    2  This paper proposes InfoNet, a generalized alg...   \n",
       "28027                    2  * This paper presents an innovative algorithm,...   \n",
       "\n",
       "       length_words  citation_count  question_count   mattr  \n",
       "0               191               0               0  0.7074  \n",
       "1               215               0               0  0.7009  \n",
       "2               570               7              10  0.7698  \n",
       "3               412               0               5  0.7920  \n",
       "4               290               0               7  0.6900  \n",
       "...             ...             ...             ...     ...  \n",
       "28023           356               1               5  0.7166  \n",
       "28024           303               0               0  0.7945  \n",
       "28025           544               0               7  0.7971  \n",
       "28026           346              10               4  0.7788  \n",
       "28027           670               3               1  0.8585  \n",
       "\n",
       "[28028 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from taaled import ld\n",
    "from pylats import lats\n",
    "\n",
    "\n",
    "def compute_mattr(review_text):\n",
    "    mattr_value = \"\"\n",
    "    if review_text is not None:\n",
    "        review_text = review_text.strip()  # Remove leading/trailing whitespace\n",
    "        review_text = review_text.replace('\\n', '')  # Replace newlines with spaces\n",
    "        try:\n",
    "            cleaned = lats.Normalize(review_text, lats.ld_params_en)\n",
    "            tokens = cleaned.toks\n",
    "            mattr_value = f\"{ld.lexdiv(tokens).mattr:.4f}\"\n",
    "        except Exception as e:\n",
    "            mattr_value = \"\"\n",
    "    return mattr_value\n",
    "\n",
    "\n",
    "df_reviews['mattr'] = [\n",
    "    compute_mattr(row['total_review']) for row in tqdm(df_reviews.to_dict('records'), desc=\"Processing reviews\")\n",
    "]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to a different JSON file\n",
    "out = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_ICLR2024_v4.json'\n",
    "df_reviews.to_json(out, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews:  13%|█▎        | 3726/28028 [2:02:09<13:16:43,  1.97s/it]\n",
      "Processing reviews: 100%|██████████| 28028/28028 [00:54<00:00, 517.80it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_days_before_deadline",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6719ff10-f9a6-4f98-8f71-350fd3a0bc28",
       "rows": [
        [
         "0",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_eS3u",
         "1698243150596",
         "1699636093263",
         "6",
         "2",
         "3",
         "2",
         "3",
         "This work proposes LSTNet, a self-supervised method to establish reliable 3D dense correspondences irrespective of the input point clouds’ rotational orientation.\n\nSpecifically, LSTNet learns to formulate SO(3)-invariant local shape transform for each point in a dynamic, input-dependent manner. Each point-wise local shape transform can map the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor, which is passed to the decoder to reconstruct the shape and pose of the input point cloud. \n\nThe proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish dense point-wise correspondences via nearest point pairs between cross-reconstructed point clouds. The self- and cross-reconstruction training strategy is simple yet effective. \n\nLSTNet demonstrates state-of-the-art performance on 3D semantic matching when evaluated on the KeypointNet dataset and part segmentation label transfer when evaluated on the ShapeNet dataset. The performance of aligned shape pairs under the setting of I/I shows that other methods, such as CPAE, are much better than LSTNet. The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.\n\nLack of limitations.",
         "191",
         "0",
         "0",
         "0.7074",
         "67",
         "0.09000000000000001"
        ],
        [
         "1",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_jP4i",
         "1698652503617",
         "1699636093190",
         "5",
         "4",
         "3",
         "3",
         "2",
         "1) This paper proposes a self-supervised method to find semantically corresponding points for a point cloud pair;\n\n2）The main idea is to decouple a point cloud feature learning process into a SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms;\n\n3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method. 1) This paper is generally well-written;\n\n2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant\npoint-wise local shape transforms seems to be novel;\n\n3) Experimental results are good. 1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset. \n\n2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation. \n\n3) The running time and GPU memory cost is blurry for me;\n\n4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation\nfrom Rotated, Noisy, and Decimated Point Cloud Data]. Please refer to the weaknesses.",
         "215",
         "0",
         "0",
         "0.7009",
         "67",
         "0.16018518518518518"
        ],
        [
         "2",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_wiS9",
         "1698706547448",
         "1699636093122",
         "3",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces LSTNet, which leverages an SO(3)-equivariant encoder-decoder architecture(Vector Neuron Networks, VNNs) and proposes a novel function called local shape transform to further transform the learned features. The proposed method is validated on both the 3D keypoint transfer and part segmentation label transformer tasks. 1. The idea of cross-reconstruction for generating inter-object correspondences in a self-supervised way is interesting;\n\n2. The overall writing is good and the methodology part is well-organized and easy to follow. 1. The novelty of this work seems insufficient for ICLR. The whole pipeline heavily relies on VNNs and the main contribution I personally consider is the local shape transform and the self-supervised mechanism for correspondences.\n\n2. Regarding the local shape transform:\n   2.1. From 3.1.1, the SO(3)-invariant output is $\\mathbf{V}\\mathbf{U}^T \\in \\mathbb{R}^{C \\times C}$, while in 3.1.2, the obtained SO(3)-invariant features $\\mathbf{V} \\in \\mathbb{R}^{C^\\prime \\times 3 \\times N}$ have a different shape;\n\n   2.2 The authors claimed that the local shape transform transforms the global features to local ones. Regarding this, I have two questions. \n\n      2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer. \n\n      2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the \"global\" features by such a mechanism, the features turn to \"local\"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so)\n\n3. Regarding the experiments:\n    3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments;\n\n     3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.\n\n    3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.\n\n   3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?\n\n4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.\n---------------------------------------------\n[1]. Zohaib et al. SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data, ICCV 2023;\n\n[2]. Dent et al. PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors, ECCV 2018\n\n[3]. Ao et al. SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration, CVPR 2021\n\n[4]. Wang et al. You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors, ACM MM 2022\n\n[5]. Yu et al. Rotation-Invariant Transformer for Point Cloud Matching, CVPR 2023 See weaknesses.",
         "570",
         "7",
         "10",
         "0.7698",
         "67",
         "0.09538690476190476"
        ],
        [
         "3",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_a6Ps",
         "1698768293694",
         "1699636092942",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper attempts to register point cloud properties to their templates without precise correspondences and exact shape matching. To achieve this, the authors trained a local shape transform (LST) network that produces SO(3) invariant correspondences. The training is self-supervised. The experimental results on ShapeNet look nice. - Valid motivation. Unlike the abused topic, vanilla point cloud registration, the motivation stands and could potentially benefit practical usages.\n- The SO(3)-invariant network design intrinsically ensures robustness against rotations.\n- The joint usage of a global descriptor and a local descriptor makes sense and may help with classification and recognition directly.\n- The self-supervision scheme looks plausible by self and cross-reconstruction. My major concern is with the experimental setup. While the experiments on ShapeNet is common in the community and shows good result, I am in general doubtful whether such an approach could be really applied to the real world. \nIn motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. [Scan2CAD, CVPR 2019]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases. \n\nThe authors also take groundtruth keypoints and semantic segmentations from datasets for the experiments. In the real-world, however, obtaining such accurate high-level semantic information already requires a deep understanding of the point cloud, and its segmentation backbone may already be SO(3) invariant. This impairs the strength that the authors proposed. Following my points in the \"weaknesses\" section, I am curious about several relevant problems in the practical setup (i.e., scan to model). \n1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity? \n2. Will the network still be functional if the density distributions are different across input and output? \n3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?\n4. Would non-gt and/or biased key points and semantic parts be transferred properly?\n\nIt would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.",
         "412",
         "0",
         "5",
         "0.7920",
         "67",
         "0.14001937984496127"
        ],
        [
         "4",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_Frem",
         "1699350072271",
         "1699636092872",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a method of learning dense 3D correspondence between shapes in a self-supervised manner. Specifically, it is built on an existing SO(3)-equivariant representation. The input point clouds are independently encoded to SO(3)-equivariant global shape descriptor Z and dynamic SO(3)-invariant point-wise local shape transforms. Then the network is trained via penalizing errors in self- and cross- reconstructions via the decoder. The experiment validates the effectiveness of the proposed method. 1. The paper is in general well organized and easy to follow. \n2. The proposed method is straightforward and shown to be effective on the test data. 1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method. \n2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.\n3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?\n4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design. Please refer to the Weaknees part.",
         "290",
         "0",
         "7",
         "0.6900",
         "67",
         "0.12424242424242427"
        ],
        [
         "5",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_xDut",
         "1698437142685",
         "1699636121514",
         "8",
         "5",
         "4",
         "4",
         "3",
         "This paper is about multilingual federated prompt tuning for low-resource languages, bringing together federated learning and prompt-tuning techniques. This approach leverages parameter-efficient fine-tuning which preserves user privacy, and additionally, the authors introduce language distance in order to highlight the strengths of the proposed paradigm. The results show that the technique is parameter efficient and computationally beneficial, reducing by 99% the number of trainable parameters while increasing the performance on downstream tasks (XNLI, NC) of ~7% accuracy. This paper makes a contribution to the federated learning field showing how federated learning can be used to enhance the performance of language models while preserving user privacy. The experiments are well-designed and the results are convincing - added to extensive analyses in order to leverage the capabilities of the proposed paradigm, but also its limitations. Although the paper is generally well-structured, the title mentions `low-resource` languages. However, the two tasks leveraged are primarily on high-resource languages, rather than low-resourced language. I would suggest to the authors to include more tasks - there are many low-resource language datasets (for instance on African languages MasakhaNEWS, Masakhaner (1.0 and 2.0 - which have been cited by the way but not used), MasakhaPOS; Indic languages: https://github.com/AI4Bharat/indicnlp_catalog; etc) and tasks.\n\nThis is rather a highly recommended suggestion, that does not take away the contribution of the paper. Including them would strengthen the paper and be more in accordance with the title. The Aggregation formula is a bit confusing. Did you mean h_{global, t+1} = \\sum_{k=1}^{m} h_{k, t}? Because the `t+1` on the last term does not make sense to me.",
         "262",
         "1",
         "0",
         "0.7963",
         "67",
         "0.16645833333333337"
        ],
        [
         "6",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_E7Lk",
         "1698484432194",
         "1700794322411",
         "1",
         "5",
         "1",
         "2",
         "2",
         "The paper introduces a finetuning paradigm that combines federated learning (FL) with prompt tuning for multilingual finetuning on certain, with the goal to preserve the privacy of the local data used for the finetuning job. The results show better performance in certain classification tasks, such as New Classification and XNLI. - Federated learning have recently gained good traction, the paper is a good application of it in the tasks of finetuning LLM. The paper chooses to use prompt tuning instead of full tuning to save costs, as well as to avoid overfitting on small data.\n- The method produces better performance on the 2 classification tasks compared to baselines - The proposed is a very trivial combination of federated learning and prompt tuning, which both are established methodology in their own realm. There is no novelty, such as modification or adjustment to the method that may have give a better results. In other words, people with an objective to do federated learning for privacy purpose can easily come up with prompt tuning as a solution to reduce costs.\n- Though it may have implicitly inferred by the concept of FL, the paper did not mention why and how federated learning helps with privacy and in which case one should use FL for their application.\n- The purpose of the task of multilingual finetuning in this case, is not warranted use case of privacy preservation.\n- There is no reported evidence that privacy is actually preserved. Such as whether the final model memorize the local data.\n- There are better parameter-efficient finetuning methods, such as LORA/QLora, that the authors should conduct experiments on and do comparision with prompt tuning.\n- The results show prompt tuning are much worse than full-federated tuning, thus casting doubt if the cost-saving is worth it.\n- Other generative and knowledge-based tasks, such as QA, translations and summarizations should be performed.\n\n**I have read the author responses and I advocate for a strong reject, below are reasons:**\n\n* I mentioned the paper has fundamental problems with originality, novelty, where the paper uses an unrelated existing and non-novel method designed for a different problem (fed-learning) to solve a low-resource \"privacy\" problem that does not make sense or exist yet, in which the method itself much worse than standard training. \n* Instead of addressing the scientific issue, the authors distracted away by pressing that they are helping the low-resource communities, or improving inequality as a societal issue. These multiple responses are lengthy, wordy, unnecessary, and filled with many \"politically correct\" (I don't know better word) things to avoid the scientific issue. Agree that we should help those under-represented communities, but after reading these, I shouldn't feel like rejecting the paper is an action against those communities.\n* The problem of \"a low-resource community who wants to shut down their internet and border\" is unfounded. We train LLM on public data we can find. If they wants to protect their secret data, they can download a public pre-trained model and fine-tune on their own. \n* The real problem is how to improve low-resource with the limited data we have, which the paper fails to suggest a better solution than trivial.\n* Less communication doens't mean more privacy, because we transfer model weights, not the data. And less parameters doesn't mean less private information be leaked. This misconception leads to wrong approach.\n* The author claims to be the first to target the low-resource problem and many other things, but there have been many works in previous years about this. Please be careful with this kind of \"we are first\" statements.\n* Overall, none of the responses has helped resolve the issues stated in the review. - Citation formet incorrect, \\citep{} be used to produce something like (Abc, et al., 2023) and not Abc, et al., 2023 everywhere.\n- Many grammatical errors, such as \"Throughout the fine-tuning...\"\"",
         "646",
         "0",
         "0",
         "0.8297",
         "53",
         "0.11054215625644194"
        ],
        [
         "7",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_AG4r",
         "1698731849876",
         "1700723834276",
         "3",
         "4",
         "4",
         "1",
         "3",
         "The paper proposes a Multilingual Federated Prompt Tuning paradigm, where lightweight multilingual prompts are encoded and on regional devices in different languages and aggregated by averaging the prompt embeddings. The goal is fine-tuning multilingual large language models on resource-constraint devices in a privacy-preserving way. The paper evaluates this approach via the XNLI task, ablated into data efficiency, \"language distance\", and communication cost, against \"monolingual\" training (baseline). The innovation lies in that the paper somehow mashes federated learning, multi-lingual (low resource) language models, and Parameter-Efficient Fine-Tuning in one paper. The fact that they managed to come up with a storyline for a system that bolsters the benefit of each approach is commendable. - poor presentation: the citations are not separable enough from the main text, e.g., without any parenthesis, rendering the submission unreadable. Against the tradition and ease of reading, abbreviations are not defined in advance, e.g., NLI, PFL, PLM.\n- claims unverifiable: no code release.\n- conflating existing metrics with innovation: language distance is not a new concept.\n- conceptual weakness: the contrived baseline was bound to give the proposed approach an edge due to lack of federated learning. Also, what the paper refers to as prompts are just classifier model input, which are different from decoders-style LLM prompts as commonly acknowledged. Finally, the approach has absolutely nothing to do with privacy which the abstract and the main body consistently bolsters. \n- evaluation weakness: only two tasks (new classification and XNLI) was used in evaluation. In section 5.4.1 \n\n>  In both the NC and XNLI tasks, despite the total number of\nparameters exceeding 278 million, the trainable parameters are only around 1.2 million, accounting\nfor less than 0.5% of the total.\n\nCould the authors clarify which part of the model is being fine-tuned?",
         "293",
         "0",
         "0",
         "0.8387",
         "54",
         "-0.020279323850752432"
        ],
        [
         "8",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_LsRx",
         "1698767055794",
         "1700887244625",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The paper applies federated learning on multilingual scenarios to efficiently parameter-efficient prompt fine-tuning in a manner that preserves user privacy. The idea is to utilize a single global encoder that accumulates the information via federated prompt averaging. Thus, it learns the language patterns without knowing about the user information. They evaluated the experiment on NC and XNLI datasets and found performance improvement over the baseline. - The method is very practical since it is simple and efficient, and it is an appropriate method for training multilingual model.\n- Good analysis on the data efficiency and distance measurement, showing the effectiveness of the proposed method. - In terms of novelty, the proposed idea is not new, and it is only a further investigation of the multilingual setting.\n- Lack of clarity. The paper does not provide enough information about how the prompts are constructed or look like and hyperparameters for all settings. I suggest adding the information to the paper or appendix. Questions:\n- Do you have any findings on why multilingual centralized learning is far worse than federated learning in Table 2?\n- How did you tune the training and parameter averaging?\n\nSuggestions:\n- Figure number is missing on Page 2\n\n\"As depicted in Figure , \"\n\n- Missing Figure/Table \n\n\"This translates to over 99% reduction in the communication overhead shown in 3\"\n\n- Typo\n\n\"Finetuning accuracy across different lanugages on the NC task.\"",
         "234",
         "0",
         "0",
         "0.7573",
         "52",
         "0.03735930735930736"
        ],
        [
         "9",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_agCZ",
         "1698322956814",
         "1699636820093",
         "5",
         "3",
         "2",
         "2",
         "2",
         "To tackle Multi-Domain Text Classification (MDTC) task, one mainstream of proposed techniques is to extract the features via the shared and private extractors to capture the domain-invariant and domain-specific knowledge, respectively. However, as the number of domains increases, the count of their private extractors will also rapidly surge.  \nThe author proposed a novel approach Stochastic Adversarial Network (SAN) to avoid the unaffordable explosion of parameters when encountering the newly emerged domains. Specifically, the author modeled the domain-specific feature extractors as a multivariate Gaussian distribution. Furthermore, some tricks, such as domain label smoothing and robust pseudo-label regularization techniques, are utilized to improve the overall performance.\nExtensive experiments on two benchmarks demonstrate the superiority of the proposed method compared with the state-of-the-art baselines. 1.\tThis paper proposes a novel approach, called Stochastic Adversarial Network, to reduce the computational cost while meeting a large amount of domains.\n2.\tThis paper originally employs Gaussian distribution to generate private extractors in order to circumvent the extensive parameters found in previous works. \n3.\tThis paper conducts numerous experiments to show the effectiveness of the proposed scheme. Moreover, the parameter sensitivity and ablation study demonstrate the rationale of parameter selection and the necessity of each modules, respectively. 1.\tThe motivation is trivial. It is hard to say that the model size is the bottleneck of the training process according to Table.1 and 9. 342.91M is absolutely fine in current period. Further, inference process may gain nothing in the aspect of computational acceleration as we only choose one private extractor from the Domain Discriminator D. \n2.\tThe baselines are outdated and improvements on two benchmarks are limited. According to Table 2,3 and 4, it can hardly convince me that the proposed model exactly outperforms the SOTA models. It is worth noting that the author points out this limitation in Appendix E. \n3.\tThe writing and organization need to be improved. \na)\tThe emphasis in writing has been misplaced. As the author highlights the role of multivariate Gaussian distribution in Abstract, you are supposed to tell more story of it instead of the regularization term, which is the idea of others.\nb)\tThe effectiveness is not the focus of this article, efficiency is. Therefore, moving D. 5 to the main body of the article perhaps make your contribution more prominent. \nc)\tSome tools can be utilized effectively to optimize sentence structure and composition. 1.\tThe aim of equation (3) is to ensure that the shared Feature Extractor F_s exactly extract the domain-invariant features. Thus the author maximum this loss to let the discriminator D be confused about the features coming from F_s. Here is the question: discriminator D may lack of capabilities to recognize the difference among domains as this loss function does not involve any domain knowledge.\nThere may exists another adversarial network in equation (3), i.e. domain-specific extractor enhances the capabilities of discriminator D and domain-invariant extractor still confuse the discriminator D. \n2.\tAs a classic NLP task, this method inevitably needs to be compared with chatgpt. Currently, chatgpt has shown remarkable zero-shot capabilities. Therefore, you need to convince the reviewers why your method should be used instead of chatgpt or highlight the scenarios in which your method has significant advantages.",
         "534",
         "0",
         "5",
         "0.7784",
         "66",
         "0.09682159945317839"
        ],
        [
         "10",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_NpVu",
         "1698685251472",
         "1699636819980",
         "1",
         "4",
         "1",
         "3",
         "1",
         "The paper presents a new model for MDTC, built on the previous shared-private feature extraction architecture. The innovation includes 1) modelling the parameter of domain-specific feature extractors as a Gaussian random variable, and for each domain, the parameter is drawn from the distribution. This is why the model is called stochastic adversarial network, or SAN, 2)  domain label smoothing 3) pseudo labelling regularization.  The authors show some empirical successes on some datasets. The paper demonstrates that the authors are well aware of the challenges in MDTC and are familiar with various tools in deep learning (such as reparametrization trick, label smoothing, pseudo labelling etc). I have some concerns about this work.\n\n1. Assuming the design of proposed model is sensible (in fact I have doubts on this; see 2), the work heuristically puts together a bunch of well-known techniques to improve performance. Works of primarily such a nature, although potentially valuable in practice, do not possess enough novelty that justifies a publication in ICLR. \n\n2. I have doubts on the proposed approach in the \"stochastic\" part. Let us track the parameter $W_1$ of the domain-specific feature extractor for domain 1. In the beginning it is drawn from the prescribed Gaussian, say, its value is $W_1^{(0)}$, and after the first iteration, the Gaussian parameter gets updated (using the reparametrization trick)  -- well, whether Gaussian parameter is updated or not is not critical here. Then in the next iteration, $W_1$  is drawn again, let us call it $W_1^{(1)}$. If this understanding is correct, then $W_1^{(0)}$ and $W_1^{(1)}$ can be very different. That is, along the training process, $W_1$ will randomly hop everywhere as long as the Gaussian variance is not vanishing. How would such a scheme work at all? Bringing the parameter $W_2$ of the second domain-specific extractor into the picture would show an even more absurd picture: at each iteration $t$, $W_1^{(t)}$ and  $W_2^{(t)}$ are random variables following the same Gaussian distribution. How would $W_1$ and $W_2$ track their respective domain specific features?  If this structure were to work, it would have to be the case where the Gaussian variance is very small (which might be the case as shown in Figure 3 of the appendix). In that case, all domain-specific extractors are more or less the same, i.e, all equal to the Gaussian mean, only subject to some tiny *domain-nonspecific* random perturbation. That would defeat the entire purpose of having domain specific feature extractors. -- I could misunderstood the paper and I am willing to hear the authors' defence on this. In your defence, please also show the initial and final values of the Gaussian mean vector $\\mu$ (say, in terms of its L1-norm divided by its dimension), I would like compare it with $\\sigma$. See weakness 2.\n\nAdditional question: The authors say that the conventional shared-private adversarial scheme will have \"exponential increase\" in model parameters as new domains emerge? Why is it exponential?",
         "484",
         "0",
         "3",
         "0.7855",
         "66",
         "-0.036558441558441554"
        ],
        [
         "11",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_bAwA",
         "1698806204960",
         "1699636819830",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper tackles the multi-domain text classification (MDTC) problem, and tries to minimize the amount the learning parameters by introducing a stochastic feature extractor (domain feature). The model is effective in handling the benchmark datasets and outperform the other baseline models. Additional multi-source UDA experiment is also conducted as a simple model extension. The proposed model performs strong in the benchmark dataset, with minimized learning parameters. The design of using both shared/private feature extractor is interesting and effective in merging the domain in the latent space. The proposed method is straightforward and easy to understand. 1. Though the proposal seems to be effective and achieving strong performance, the model itself still uses a relative old adversarial backbone, with the discriminator approach for removing the domain invariant feature. The two-feature-extractor approach is interesting, but that is mainly to deal with parameter increase in the MDTC problem. It would be great to see other design improvement in the model.\n2. The performance gain in using the proposed model is marginal on the Amazon review/FDU-MTL datasets. Also, it would be great to have some analysis on adjusting the setting between the two feature extractors. 1. This might be somewhat irrelevant, but would the model perform well in multi domain classification in other domain type(s), e.g., images?",
         "213",
         "0",
         "3",
         "0.7456",
         "66",
         "0.2683333333333333"
        ],
        [
         "12",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_skmj",
         "1698632081062",
         "1701140370231",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper studies multi-modal generalization in neural networks such as transformer-based models and recurrent networks. To do so, the authors propose Genertic COG, a modular benchmark with multi-modal splits to test for 3 types of generalization: 1) distractor (generalization to different noise distribution), 2) systemic compositional (generalization to new permutation of task structures) and 3) productive compositional (generalization to tasks of greater complexity) generalization. Experiments conducted by the authors showed that while cross-attention based transformers (e.g. CrossAttn and Perceiver) outperform other models and perform well on distractor and systemic compositional generalization, they fail at productive generalization when the depth of the task tree goes to out-of-distribution (>3). Representational analysis is done to show that cross-attention based transformers (e.g. CrossAttn and Perceiver) superior performance on distractor generalization might be due to their ability to better retain task-relevant (e.g. stimulus and response) information at the penultimate layer. +The paper studies a timely and critical question about the generalization capability of multimodal transformer-based models\n\n+The proposed benchmark dataset uncovers a limitation of current multimodal transformer-based models: productive generalization which can facilitate the development of more generalizable transformers/LLMs. \n\n+The paper is generally well-written and easy to follow -While the paper’s studies show that certain designs (e.g. cross-attention) seem to confer multi-modal generalization, there are still some key questions that can be more thoroughly studied to uncover the reasons why this is the case.\n\n-Similarly, important discussions such as why the (cross-attention) transformers might fail at productive generalization is lacking. What is the key architectural difference between dual stream transformer and transformers with cross attn that can explain their generalization performance? Is it only the lack of a cross attention between the different modalities?\n\nPossible typo:\n“Finally, we included a Perceiver-like model (Jaegle et al., 2021), an architecture designed to generically process multimodal inputs (Fig. 2f).”:  (Fig. 2f) > (Fig. 2e).\n\n\n==Post-Rebuttal==\nI appreciate the authors' response and decided to keep my score.",
         "318",
         "1",
         "3",
         "0.8097",
         "49",
         "0.06907081014223872"
        ],
        [
         "13",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_a4Su",
         "1699400405601",
         "1699636123172",
         "3",
         "3",
         "1",
         "2",
         "2",
         "This paper proposes a new benchmark for assessing various forms of generalization in a multimodal setting named gCOG. The dataset includes several different splits intended to measure different aspects of generalization. The paper also compares several different model architectures on the dataset. * The paper introduces a new dataset, gCOG. While the dataset is conceptually similar to those from prior work, such as gSCAN, it supports different types of contexts and instruction types, including more compositional instructions. I'm aware of some prior work (e.g. [1], [2]) that studied compositional generalization in natural language tasks and found that gains on one synthetic task did not always transfer to other tasks, so increasing the diversity of such benchmarks for assessing compositional generalization and related challenges in the multimodal setting could be a potentially valuable contribution.\n\n[1] https://arxiv.org/abs/2007.08970\n[2] https://aclanthology.org/2021.acl-long.75/ * I'm concerned about the strength of the baselines used in the paper (see my related questions below). While the primary contribution of the paper is the dataset, it is also important to establish strong baselines for this new dataset and to ensure that the conclusions from the empirical results are valid. The appendix states that only a *single Transformer layer* with a *single attention head* was used. This is almost certainly not an optimal depth and number of attention heads. Relatedly, it looks like some models are potentially underfit, according to the figures. With >5M training examples and a relatively simple input space, I would have expected a reasonably sized Transformer model to achieve low training loss and reasonable IID generalization. If these models could have been applied to similar tasks such as gSCAN (even using symbolic tokens to represent the scene context), where they could be compared with comparable baselines from prior work, this would have helped establish that these are indeed reasonably strong baselines that have been well tuned.\n* The qualitative difference between gCOG and datasets from prior work such as gSCAN was not very clearly described. For example, one of the key claims seemed to be gCOG \"employs generic feature sets that are not tied to any specific modality\". However, it seems like it is a useful property for a multimodal dataset to have a clear relation to real-world multimodal tasks. Indeed, the authors provide interpretations of their tasks in the form of natural language instructions and visual scenes (e.g. in Figure 1), and these are very useful for understanding the task. Representing this dataset using familiar modalities (e.g. vision, natural language) could enable future work to study different research questions, e.g. the impact of pre-training. The ability to alternatively represent the task input as a sequence of tokens is also reasonable for studying certain research questions, but this also seems possible for datasets from prior work. For example, I understand that gSCAN includes both symbolic descriptions as well as visual renderings. Anyways, I think clarifying the motivation for this dataset (e.g. increasing diversity of available benchmarks, focusing on different generalization challenges, etc.) separately from how inputs are represented for the experiments in this paper (e.g. token sequence vs. images and natural language) would be useful.\n* Some of the main empirical conclusions (e.g. that generalization to greater \"depth\" is challenging for models such as Transformers) are generally known from prior work.\n\nnits:\n* Introduction paragraph 1 - \"on a carefully controlled generic multimodal reasoning tasks\" -> \"on carefully...\" or \"...task\"\n* Appendix A.2.1 - Maybe reference Tables 8 and 9 where you discuss different positional embeddings.\n* Consider discussing [3] in related work. [3] demonstrated the importance of cross-modal attention for gSCAN, and similarly studied the relative difficulty of various aspects of generalization, including distractors.\n\n[3] https://aclanthology.org/2021.emnlp-main.166/ * Why not try more layers and attention heads, e.g. following a standard hyperparameter setting for model size such as those of BERT-Base? Or even BERT-Small?\n* In Figure 2 (F) why does the single-stream Transformer have almost double the parameters of the double stream Transformer? For the other Transformers, do the encoder blocks used for the task vector and stimulus vector share parameters? \n* What optimizer and hyperparameters (e.g. learning rate) were used for training? How were these chosen? I didn't see these details in Appendix A.2. \n* Position embeddings - Since you are representing 10x10 grids as 1D sequences, 1D relative positions may not capture this structure well. On the other hand, absolute position embeddings seem potentially problematic in the case of the SSTrfmr model, since they will not be consistently assigned to the same grid position if the text sequence is first and has varying length. Mitigating this may be important to provide for a fairer comparison with the SSTrfmr model.\n* To what do you attribute the periodic loss spikes during training that are shown in Figure 4 (E)?\n* I found the usage of \"cross-attention\" a bit confusing. For example, the single stream Transformer features cross-modal attention as an implicit consequence of self-attention over the concatenated sequence. I thought this would commonly be referred to as an instance of \"cross-attention\" between modalities. \n* Does the dataset also contain visual renderings and natural language instructions to enable future work to study these tasks using familiar modalities?",
         "860",
         "10",
         "1",
         "0.8184",
         "67",
         "0.07609627300803772"
        ],
        [
         "14",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_DJb6",
         "1699470958350",
         "1699636122858",
         "8",
         "4",
         "3",
         "3",
         "3",
         "The paper introduces a new multimodal question answering benchmark for out-of-distribution generalization, specifically covering task compositionality, robustness to distractors and combinatorial generalization. It uses this benchmark to evaluate various models and analyze their performance. - **Topic**: The paper studies an important topic which in my opinion is underexplored in current deep learning research. Especially given the tendency these days to scale training up to vast amounts of data, I believe it is particularly important to design carefully controlled benchmarks that can: evaluate the model’s performance from a critical and cautious standpoint, point to their fundamental limitations (e.g. systematic generalization), and support further research about ways to overcome these.  \n- **Evaluation**: The paper offers both extensive extrinsic evaluation, with performance comparison of various models on the different generalization skills, as well as intrinsic analysis of their internal representations’ degree of alignment to the stimuli.\n- **Clarity**: The writing quality is good and the paper is clear and easy to follow. The paper is well-organized, claims and findings are clearly stated, and useful figures and diagrams are provided.\n- **Related Works**: It does a good job in providing the relevant context, motivation and related works. \n- **Contribution**: The empirical findings of the paper on the benefits and limitations of different inductive biases such as recurrent and attention-based are important and may be of broad interest to the community. - **Pre-trained models** The paper focuses on models trained from scratch rather than pre-trained. This could be a strength and a weakness. On the one hand, it allows for isolating the contribution of the architectural choices from other factors of optimization, and training data. On the other hand, it has been observed that by training models at large enough scales enables the emergence of generalization capabilities, which we don’t see in smaller scales. I think it will be critical to also analyze the performance of pretrained models on the benchmark, in order to strengthen the paper.\n- **Visual Simplicity**: The visual side of the benchmark is quite rudimentary, featuring colorful letters. Extending it to a larger range of visual tokens/objects, that could have more than one property (color), and a broader set of elements and variations (than 26 letters), could be a straightforward extension that could help make it a bit more challenging visually. - **COG task**: It will be useful to discuss the COG task (rather than just mentioning it) before describing the new gCOG one, so that it will be clearer to the reader what are new contributions of the new benchmark compared to COG and the degree of their importance. In the overview diagram I would also recommend showing a sample also from COG to make the differences clearer. \n- **Grid size / generalization**: It could be interesting to vary the size of the grid in training/evaluation and study its impact on model’s performance. \n- **Terminology**: I recommend changing the phrase “Distractor generalization” to one that better conveys it’s about changing the answer distribution. Maybe e.g. answer distribution shift. I also recommend changing the name “Systematic compositional generalization” to “combinatorial generalization”, to emphasize that the main point is the generalization to permutation, and also to better contrast it with the following “Productive generalization” (which could also be systematic).\n- **Figures**: Would be good to increase the size of the plots in Figure 3b. It will also be good the increase the distance and visual separation between the sub-figures in each figure throughout the paper. \n- In the introduction: “multimodal question-answer” -> “answering”.\n- “This design allowed us” -> “This design allow us”.",
         "591",
         "0",
         "2",
         "0.7407",
         "67",
         "0.17495241827138377"
        ],
        [
         "15",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2",
         "0.8079",
         "67",
         "0.10615942028985506"
        ],
        [
         "16",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head [1], [2], [3]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works [1][2] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n[1], Frozen clip models are efficient video learners, ECCV-2022\n\n[2], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n[3]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0",
         "0.7694",
         "67",
         "0.08203933747412008"
        ],
        [
         "17",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7",
         "0.8374",
         "67",
         "0.052597402597402594"
        ],
        [
         "18",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0",
         "0.7506",
         "67",
         "0.35297619047619044"
        ],
        [
         "19",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_5Cgw",
         "1697885084973",
         "1699636148336",
         "3",
         "5",
         "3",
         "2",
         "2",
         "The study puts forward a VAE-based approach to acquire disentangled representations without the need for supervision. In this framework, it assumes that diverse data samples exhibit variations across multiple factors, making it particularly well-suited for real-world datasets. The newly proposed technique, referred to as CFASL, introduces a range of unsupervised loss components that serve to instill \"inductive biases.\" These include parallel and perpendicular loss terms, in addition to a sparsity loss designed to encourage alignment along factor axes. The outcomes of this study illustrate the method's superior performance when compared to various other unsupervised disentanglement VAEs, both under single-factor and multi-factor alteration scenarios, across multiple widely used benchmark datasets. 1. The paper represents a significant stride in enhancing the practicality of disentanglement techniques within the realm of real image domains. It grapples with a formidable challenge where we cannot presume access to images that solely vary in a singular factor, thereby intensifying the complexity of extracting disentangled representations.\n\n2. The quantitative findings not only exhibit enhancements in the primary focus of this study, which is the alteration of multiple factors, but also in the scenario involving changes in a single factor. 1. The proposed approach incorporates a diverse array of loss terms within its training objectives, with each term potentially making a distinct contribution. However, this diversity comes at the expense of imposing significant assumptions on the underlying image distribution. While I acknowledge that these assumptions may be justified within the context of the datasets considered in this paper, it's worth noting that some metrics, such as DCI, do not unequivocally demonstrate superiority in the ablation study presented in Table 2.\n\nNevertheless, I believe that the paper could benefit from a more comprehensive exploration of the limitations stemming from these strong assumptions. It would be valuable for the authors to provide concrete examples where these assumptions result in unintended or adverse outcomes. Even for an unsupervised setting, it remains crucial to take into account the nature of transformations within the image domain. A more explicit discussion of these assumption-related limitations would substantially bolster the significance of the claims advanced in this paper, in my view.\n\n2. The qualitative results exhibit low image quality. While this is common across unsupervised disentanglement methods, it is really challenging to get convinced that better disentanglement is achieved. It would be valuable for the author to consider domain-specific metrics for the evaluation phase e.g. face identity loss, facial expression classification, head pose regression, etc. to assess whether only a specific attribute is altered during the single factor change experiments. 1. Following the weaknesses mentioned above, could the authors provide concrete examples (other datasets) where the assumptions induced by the loss terms result in unintended or adverse outcomes compared to the baseline beta-VAE?\n\n2. Could the authors please provide the ablation study results of the different loss terms for all datasets considered in the paper (and not only 3D-Cars)?",
         "483",
         "0",
         "7",
         "0.8442",
         "67",
         "0.13886601203674376"
        ],
        [
         "20",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_oACj",
         "1698758328711",
         "1699636148260",
         "5",
         "3",
         "3",
         "1",
         "2",
         "The authors introduce a new VAE architecture which operates on pairs of inputs and utilizes a set of regularization terms to induce structured disentanglement of the latent space with respect to observed symmetry transformations between examples in these pairs. The authors show that their model indeed achieves higher disentanglement scores than relevant baselines on a variety of datasets with a variety of different metrics. Specifically, the authors target the 'multi-factor change' regime, and demonstrate improved performance in this setting with their newly introduced metric. - The related work is well covered, and the authors position their method well in the literature.\n- The proposed combination of losses appears novel to the best of my knowledge, and the use of parallelism and orthogonality losses specifically on latent transformations is an interesting and exciting idea. \n- The study of disentanglement with respect to multiple simultaneously changing factors is important and interesting, and the authors make a notable contribution to this direction.\n- The results appear promising, and indicate that the model is performing well with respect to the baselines. \n- The methodology and extended results in the appendix appear sound. The calculation of P-values in the appendix is very important and appreciated. Furthermore, the use of an ablation study to validate their proposed model is a welcome addition. Weaknesses summarized:\n- The paper is challenging to read as the english is quite poor and the logical flow of the work is unorganized.\n- The method itself is composed of a wide variety of loss terms and the intuition or reasoning for why these terms are necessary is not provided. (Specifically for the parallel and perpendicular losses).\n\nIn more detail:\n\nWeakness 1:\nThere are many typos and poor grammar throughout the paper, with many sentences simply not making much sense. I include a few examples below, but there are many many more and the authors should have someone proof read this work more carefully:\n- In the abstract: \"We propose ... (CFASL) on VAEs for the extension to [a] general multi-factor change condition without constraint.\" \n- \"To implement  group equivariant VAE, Winter et al. (2022); Nasiri & Bepler (2022) achieve the translation and  rotation equivariant VAE\"\n- \"For the equivariant encoder and decoder, we differently propose the single forward process by the  encoder and decoder objective functions compared to previous work (Yang et al., 2022).\"\n- \"Differently, we induce disentanglement learning  with group equivariant VAE for inductive bias.\"\n- 'The unsupervised learning work (Winter et al., 2022) achieves class invariant and group equivariant  function in less constraint condition.'\n\nWeakness 2: \nNaming is extremely unclear. For example, what are 'sections' referred to in Section 3.2? How do these differ from factors? \n\nWeakness 3: \nDespite appealing to a precise probabilistic generative model as its primary value and distinction from prior work, the model itself could be made significantly more elegant in the context of generative models. For example, the 'factor prediction' mechanism could be integrated as a component of the generative model and inferred with another approximate posterior, as done in prior work (Song et al 2023).\n\nWeakness 4:\nThe discussion of learning the Lie algebra is quite rushed and the intuition for why the large set of different loss terms should be incorporated is largely missing.\n\n[1] (Song et al. 2023) https://arxiv.org/pdf/2309.13167.pdf Question 1:\nThe point that prior work with autoencoders does not extend to VAE's does not make much sense to me. Specifically the quote: \"Furthermore, the methods on autoencoder are not directly applicable to VAEs, because  of the large difference to VAE in probabilistic interpretation\". Can the authors provide further details to reinforce this claim?\n\nQuestion 2:\nGiven there are so many loss terms for this model, it is likely that it will be computationally expensive to estimate the correct weightings for each of these terms in a hyperparamter search. Can the authors speak to how this was done in their case and how expensive it was? \n\nQuestion 3:\nOne of the main selling points for this paper was the ability to extend disentanglement methods to 'multi-factor' change. However, for the experiments, the authors consider datasets which guarantee commutativity of transformations. Theoretically then, is there a reason why we should expect the other baseline models to not be able to handle this multi factor change? For example, it seems the axis aligned disentangled representations of the beta-vae should be able to compose multiple transformations simply by jointly changing multiple latent dimensions. Is this not the case?",
         "744",
         "6",
         "1",
         "0.7790",
         "67",
         "0.16209867757812965"
        ],
        [
         "21",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_A4b1",
         "1698803382759",
         "1699636148172",
         "5",
         "3",
         "2",
         "2",
         "2",
         "Following the Variational Auto Encoder (VAE) framework, this paper proposes an extension of the single factor (change condition) disentanglement learning method, which they call as Composite Factor-Aligned Symmetry Learning (CFASL). The main idea and/or the assumption is certain scenarios such as the composite/complex symmetries (where certain mathematical transformational relationships exist) can be better captured by utilizing explicit symmetrical relationship information, if provided as additional input to the VAE learning framework. \n\nAs a part of the learning scheme, to facilitate this required piece of information, the proposed method explicitly inputs pairwise symmetrical relationship (and corresponding transformation) information. The expectation is the model, if learned in this fashion, should generate better representative samples from within those transformational subspace/domains. \n\nTo better explain and evaluate the scenario, some new metrics such as m-FVMk (extension of a common metric for a single factor change condition evaluation) have been proposed. They have compared their method with some state-of-the-art methods and on nine benchmark datasets; reported results are found to be promising. The following items seem to have some originality: (i) learning from explicit pairwise transformations, (ii) a network architecture to learn the codebook of symmetries for (i),  (iii) some associated metrics supporting (i) and (ii), and (iv) imposing group equivariant encoder-decoder into the learning framework. \n\nOverall, the paper is well written.  Mathematical derivations of different components seem to be sufficient. The proposed method has been tested on a number of benchmarks (both quantitative and qualitative analysis), and reported results are found to be promising. In addition, the ablation study of different loss functions may have added some extra points. \n\nIn terms of quality, I would rate the work as \"moderate\". In this work, one of the important missing part is the proper probabilistic derivation of the methodology, the core of the VAE framework. Or it may be due to the way the paper/work has been presented. To me, it's not sufficient to connect to the VAE world. It is suggested the authors clarify this important aspect with necessary derivations.  \n\nFor certain items/results, the authors claim statistical significance performance (section 5.2, and appendix D); however, without sufficient details of their significance tests. It is suggested authors include details of these statistical tests. \n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, we may require additional details for a fair companion of their results. \n\nThe paper/research may have some significance, and it would be beneficial if the source code could be released. It is suggested the authors clarify the probabilistic derivation of the approach and make a proper connection to the VAE basics. \n\nIt is suggested authors include details of these statistical tests.\n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, I suggest authors provide further details and release code if possible.",
         "461",
         "0",
         "0",
         "0.7849",
         "67",
         "0.08550084175084176"
        ],
        [
         "22",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_DbMo",
         "1698968978898",
         "1699636148102",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The manuscript aims to improve existing methods of unsupervised disentangled representations learning.  Inspired by the symmetry group action approach from (Higgins et al 2018,2022), authors suggest several additions for the conventional beta-VAE  method, resulting  in the form of seven supplementary loss terms. The article is devoted to important subject of disentanglement learning. Authors report improvements over some of existing methods on four simple datasets 1) Only simple datasets are considered, the method is not tested on standard complex datasets like MPI 3D. \n\n2) Reported improvements of CFASL in all measured metrics are essentially always situated within standard deviations of some other methods. \n\n3) Reconstruction loss is not reported in 3 out of 4 datasets. Upon visual inspection of reported samples, the reconstruction quality is not satisfactory. \n\n4) As reported on Figure 4, on 3DShapes dataset, there is no consistent improvement in FVM metric even at the expense of deteriorating reconstruction quality . \n\n5) There is no theoretic justifications for introduction of so many, seven in total,  additional loss terms. \n\n6) Description of Lie group action is not clear, how the action by psi_i is defined? how the dimensions of Lie groups are chosen?\n\n7) The described group action by matrix multiplications do not preserve the normal distribution, so the group equivariant term is not compatible with the  standard KL term from beta-VAE loss. \n\n8) There is no comparison with most recent disentanglement methods like DAVA, TCWAE.\n\n9) Related work section does not mention many works from vast literature on disentanglement learning, eg Disentangling Adversarial Variational Autoencoder (ICLR 2023). Why is the reconstruction quality not reported in three out of four datasets?\n\nWhy the method was not tested on standard more complex datasets like MPI3D?",
         "284",
         "0",
         "0",
         "0.7452",
         "67",
         "0.07001488095238095"
        ],
        [
         "23",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_mr2r",
         "1698569976113",
         "1699636242675",
         "3",
         "4",
         "2",
         "2",
         "1",
         "The article offers a Gaussian Mixture-based differential entropy/mutual entropy estimation approach. Furthermore, it provides numerical experiments to test the expected behavior of the estimator and its application to self-supervised learning. The article addresses an important problem of mutual information estimation. It provides relevant numerical experiments to test the validity of the proposed approach. - The main approach proposed by the authors seem to be already appeared in the literature in some references not cited by the authors (please see the questions part).\n\n- There seems to be a major issue about the expressions provided for the proposed approach (please see the questions part).\n\n- The presentation requires improvement. ### I. INTRODUCTION \n\n**3rd paragraph:** \n\n- \"identify matrix\":  identity matrix?\n\n- \"The mutual information can be consequently estimated by the entropy decomposition.\": This sentence follows identity matrix addition sentence. I guess it might be better to clarify causality here. At this point, it is not clear what is meant by \"entropy decomposition\", whether it is a trivial procedure and what enables it (mixture of Gaussians modelling?).\n\n### 2.1 BACKGROUND\n\n**Paragraph before (4)**\n\n- After equation (1): instead of \"for a multi-variable Gaussian variable\" use Gaussian (random) vector ?\n\n- In the notation $$X=[x_1,x_2, \\ldots x_n]$$ $x_i$'s appear as column vectors, however, they are actuallly row vectors as $X\\in\\mathbb{R}^{n\\times d}$\n\n- (5) should be\n\n$$\\mathbf{H}_D(X)=\\sum_{i=1}^k \\frac{1}{2} \\log \\left(\\lambda_i+\\beta\\right)+(d-k)\\log(\\beta)+C_d$$\n\n- After (5): \"Therefore, LogDet can estimate the entropy of multivariate Gaussian variables by approximating the differential entropy.\". This is not a surprise/or contribution as the authors  simply defined (5) using (2) by replacing the true covariance with $\\beta I$ perturbed sample correlation (covariance?) matrix. This is sort of obvious. \n\n### 2.1.1 LOGDET ENTROPY ESTIMATOR FOR NON-GAUSSIAN VARIABLE\n\n- Title : ... NON-GAUSSIAN VECTOR\n\n- Replace variable->vector\n\n- There already exists GMM based entropy/mutual information approximation based works such as \n\n[a]. Lan T, Erdogmus D, Ozertem U, Huang Y. Estimating mutual information using gaussian mixture model for feature ranking and selection. InThe 2006 IEEE international joint conference on neural network proceedings 2006 Jul 16 (pp. 5034-5039). IEEE.\n\n[b]. Huber MF, Bailey T, Durrant-Whyte H, Hanebeck UD. On entropy approximation for Gaussian mixture random vectors. In2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems 2008 Aug 20 (pp. 181-188). IEEE.\n\nYou need to refer to existing literature and clearly state what is novel in your approach relative to them.\n\n\n- Theorem 2 and Theorem 3 of [b] above already covers the lower and upper bounds of mixture of Gaussians. It looks like they are same as what is provided in this section. \n\n- There seems to be a major issue about the upper bound expression. The first expression for the upper bound (at the bottom of page 3), contains covariances ($\\Sigma_i$'s ) obtained from the GMM fitting algorithm, whereas the second line contains the overall sample covariance of actual data, instead of conditional covariance estimates. How do you equate these lines? The second line in fact equals to\n\n$$\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)+\\sum_{i=1}^K \\pi_i \\cdot\\left(-\\log \\pi_i+C_d\\right)$$\n\nas $\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)$ is independent of the summation index $i$. This does not make sense as you disregard covariance parameters of the GMM. \n\n- How do you make the upper bound objective co\n\n### 2.2 THE ISSUE OF MODEL SELECTION\n\n- Title: Model Selection is to generic for the discussion in this section. \"The Issue of Model Order Selection\" could be a better title.\n\n\n\n\n### 3. APPLICATION IN SELF-SUPERVISED LEARNING\n\nThe logdet-mutual information based SSL appears to be proposed in the following reference:\n\n[c]. Ozsoy S, Hamdan S, Arik S, Yuret D, Erdogan A. Self-supervised learning with an information maximization criterion. Advances in Neural Information Processing Systems. 2022 Dec 6;35:35240-53.\n\nThe authors should also clarify the relative novelty relative to [c]. Especially, the impact of GMM order selection as the approach in [c] appears to be for $K=1$. There is also claim in [c] that the use of $K=1$  defines correlative information maximizing which targets a linear (identity in their modified setting) between the representations of augmented versions of inputs. For $K>1$ does  maximizing mutual information between augmentation representation lead to nonlinear mappings between them? Is such organization of representation space desirable for classification tasks, for example?\n\nOr are you just using (18) with order $1$, which seems to be just the approach in [c]. \n\n### 4. RELATED WORKS & 5 SIMULATION STUDIES\n\nAll the references we mentioned above and the relevant references that cite them should be included in this discussion, and simulation results \n\n- 5.2 : ofBelghazi...-> of Belghazi\n- Figure 2: Two small figures and caption could be more informative.\n- 5.4 SSL: What is K for EMP-MILE? Is upper bound employed in EMP-MILE?  what if you directly use MILE?\nHow is backprop used in coordination with the GMM algorithm? As GMM parameters are algorithmically obtained from network output, how does backprop do backward mapping from probabilities $\\pi_i$'s (and there should be covariance estimates $\\hat{\\Sigma}_i$'s, as discussed above)",
         "825",
         "0",
         "11",
         "0.7898",
         "67",
         "0.07583333333333334"
        ],
        [
         "24",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_fvqj",
         "1698878886574",
         "1699636242588",
         "3",
         "5",
         "2",
         "1",
         "2",
         "This paper proposes a new approach to estimating the mutual information between a pair of random vectors, by extending the closed-form expression that is available to Gaussian variables to non-Gaussian variables. This is done by estimating Gaussian mixture approximations of the involved densities and then using bounds on the differential entropy of Gaussian mixtures. Estimating mutual information between high-dimensional non-Gaussian variables is an important problem with many applications. The proposed method extends Gaussian (which the authors refer to log-det) estimators to be applicable beyond Gaussian variables via the use of Gaussian mixture approximations, coupled with bounds on the differential entropy of mixtures. Unfortunately. the paper contains several critical flaws, namely a quite sloppy notation, that lead me to recommend its rejection. \n\nThe authors mixture, in a very confusing way, random variables and data matrices, typically using the same notation for both, $X$. For example, in Equations (1), (2), and (10), $X$ is a $d$-dimensional random variable, whereas in Equation (4), $X \\in \\mathbb{R}^{n\\times d}$ is a data matrix. Even worse, in the final equation of page 3, the two different definitions are used together and it is not even clear where the second equality means; it is simply wrong because $X^T X/n$ does not coincide with $\\Sigma_i$.\n\nUnlike what the authors claim, Equation (5) is not equivalent to Equation (5); the two differ by $\\frac{d-k}{2}\\log \\beta$.  \n\nAdding a matrix proportional to identity ($\\beta I$ in the paper) to the sample covariance was not proposed in a 2021 paper. It is a very classical method that can be found in any classical text on covariance matrix estimation, many decades ago.\n\nThe inequality in Equation (8) was not shown by Zhouyin and Liu in 2021. It is a classical result of information theory, that can be found, for example, in the famous Cover and Thomas book. By the way, the citation to this book is wrong in the paper; one of the authors (J. Thomas) is missing. \n\nThe two bounds for the differential entropy of mixtures that the authors claim to have introduced are in fact not new. The upper bound is in fact a well-known corollary of the log sum inequality (see the Cover and Thomas book). The lower bound was proved in 2008 by Huber et al. at https://doi.org/10.1109/MFI.2008.4648062 I have no questions.",
         "383",
         "1",
         "1",
         "0.7288",
         "67",
         "-0.0535050505050505"
        ],
        [
         "25",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_F4Ta",
         "1698980874812",
         "1699636242491",
         "6",
         "4",
         "3",
         "3",
         "2",
         "This work presents a mutual information (MI) estimator called MILE (LE=logdet estimator) which uses \nthe log det closed form formula of the entropy of Gaussians.\n\nTo accomodate MI to arbitrary densities, a Gaussian mixture model (GMM) is first fit to data and lower/upper bounds on the entropy of GMM is used to define MILE formula Eq 15. \n\nThen MILE is benchmarked with other MI  estimators and MILE can be used in loss functions in semi-supervised learning in experiments. - Simple MI estimator method based on  \n\nZhanghao Zhouyin and Ding Liu. Understanding neural networks with logarithm determinant entropy estimator. arXiv preprint arXiv:2105.03705, 2021\n\n(cited in the paper)\n\n- Very good experiments and comparisons with other MI estimators\n\n- Source codes provided in supplemental information  for reproducible research -The paper is sloppy in its writing, and one problem is to determine the number of components k of the GMM which\n loosen the lower upper bounds on the entropy. \n\n- Another problem is to deal with near singularity (det close to zero) by introducing a regularization term \\beta.\n\n- Give definition of MI and link with copulas, e.g.,\nMa, Jian, and Zengqi Sun. \"Mutual information is copula entropy.\" Tsinghua Science & Technology 16.1 (2011): 51-54.\nThis will relate to Eq. 8 as well.\n\n- Because MI estimation is an important and well-studied topic, I suggest to put Section 4 on related works after the introduction to that the contributions are better explained.\n\n- The lower/upper bounded of entropy of GMMs are not tight. There is a rich litterature which also compares the tightness of the various bounds.\n\nHuber, Marco F., et al. \"On entropy approximation for Gaussian mixture random vectors.\" 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems. IEEE, 2008.\n\nEven in 1D:\nNielsen, Frank, and Ke Sun. \"Guaranteed bounds on the Kullback–Leibler divergence of univariate mixtures.\" IEEE Signal Processing Letters 23.11 (2016): 1543-1546.\n\n- Notice that some distributions do not admit densities (some elliptical distributions for example)\n\n\n\n- Mention MI properties (i.e., tensorization) which defines the self-consistency test of estimators\n\n\n- small remarks:\n* data covariance = scatter matrix\n* after (3), define $\\Sigma_x$ as scatter matrix?\n*  page 3, first sentence need to be rephrased\n* some typos: \npage 7  hyperparamter -> hyperparameter\npage 9 self-supervied -> self-supervised    competitve -> competitive - Would using PCA beforehand be more appropriate in the case of near singularity?\n\n- Can we tackle robustness/variance with f-MI?\n\nMoon, Kevin, and Alfred Hero. \"Multivariate f-divergence estimation with confidence.\" Advances in neural information processing systems 27 (2014).\nEsposito, Amedeo Roberto, Michael Gastpar, and Ibrahim Issa. \"Robust Generalization via f− Mutual Information.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.",
         "447",
         "3",
         "7",
         "0.8255",
         "67",
         "0.13683150183150183"
        ],
        [
         "26",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_MHkc",
         "1699156174555",
         "1699636242410",
         "3",
         "4",
         "2",
         "3",
         "2",
         "this paper proposes to use the logdet function for the estimation of mutual information. \ntwo bounds are proposed for this purpose. the results show improvement in comparison \nto the editing methods. the proposed function itself is \"the Coding Length Function\". simple method with good results. In my opinion this paper reinvents \"Coding Length Function\".  \"...the difference is we put a scaling hyperparameter β on the identity matrix I..\" - that is not a difference. both affects SNR. The latter can be affected either way: by multiplying the noise covariance or by division of the data covariance. I do agree that the results are interesting, but the novelty is quite limited due the the above. \n\nplease elaborate on the limitations. \"So, we recommend β = 1e−3 in the following simulation studies\" why not beta=zero? \nFigure 1.b shows that beta=zero correctly estimates the true MI. \nThat raises a question why do you need beta > 0?\n\nHow do you define $\\pi_c$ in e.g., Eq17?\n\nBoth bounds are loose. How can you explain that such loose bounds lead to very small variance in MI?\n\nDo you calculate MILE in batches?",
         "187",
         "0",
         "1",
         "0.7572",
         "67",
         "0.09819466248037678"
        ],
        [
         "27",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_oYZA",
         "1699327631740",
         "1699636242348",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The paper proposes uses bounds on the entropy and mutual information for a mixture of Gaussian random variables based on the log determinant calculations used in calculating the entropy for a single Gaussian. In the context of self-supervised learning, the Gaussian mixture is assumed to known based on the augmentation. In other cases the number of mixture components has to be selected. Empirical results are reported on a synthetic benchmark of correlated Gaussians with and without non-linear transformations. Results of self-consistency measures are reported on CIFAR10. The paper is a logical motivation. Differential entropy is easy to calculate for Gaussian distributions, and mixture of Gaussians are universal approximations given enough data, so why not use GMM for mutual information estimation. The insight of using the augmentations as defining the GMM is a useful, simplifying assumption. One main weakness is the lack of extensive comparisons of using this method for self-supervised learning versus other. The one example in the main body (Table 1) shows that at 300 epochs the method is better than some other methods but is inferior to EMP-SSL. At 1000 epochs the other methods outperform the listed, but no results for 1000 epochs are reported. \n\nThe second main weakness is the paper does not give a complete description of the method. The paper is lacking in clarity with some key point unaddressed. The notation is confusing since the random variables (Z,Z') are denoted the same as Z_c, which may be a data point in the empirical sample. There should more clarity on random variables as compared to  sample sets, starting back before equation 4. The confusion carries to last paragraph of Section 4 where $\\mathbf{X}$ is defined but then $X$ is used in the definition. \n\nThe use of one instance for one cluster is not clear to me upon reading it\n\"This is because we treat the augmented data from one instance as a cluster, and this data\naugmentation strategy automatically clusters the data.\" This should be re written.\n\n In equation 17 it is not clear how $\\zeta_c$ captures all instances in the batch. It has only a single $i$ index. Perhaps the $\\zeta_c$ should concatenate them all. In section 3.2, $\\zeta_c$ is a set which indexes the whole match, which makes more sense, but it should be a matrix not a set. In any case, how is the $H(Z)$ term estimated in section 3.1? By keeping $Z_c$ fixed and only augmenting the second the one covariance matrix will be rank-1 (before ridge). \n\nIt doesn't sound like the experiments for the 5.2 are run fairly \" our MILE estimator does not require extra training,\" In this problem the point is that the MI could be changing at each data instance. Thus, other methods do not use access to the change points. MILE should have to be run (which involves performing the GMM since there are no self-clusters as in SSL) at each point. Running an expectation maximization is as much or more training than the updates of network.  \t\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. \n \nIn terms of unsubstantiated claims, the method is clearly biased (not only by the choice of number of components) but also on the non-linear transform cases. It is not clear how well the mutual information estimation would actually work on more complicated data. Thus, even if it is useful for self-supervised learning is not necessarily a more accurate estimate of differential entropy. \n\n**Minor:**\nThere are a number of typographical mistakes that are distracting.\n\nI don't understand what this means\n\"often dwarfing traditional parametric and non-parametric approaches in statistics\"\n\n\" base on the \" -> \"based on the \" \n\nI'm not familiar with this phrasing \"When X subjects to a Gaussian\" \n\n\"a ‘noise’ $\\hat{X}$ \" -> \"a noisy $\\hat{X}$\" \n\nThe paragraph before equation (4) are not clear. \" an expanding factor\" is not defined nor is it clear what is meant by \"enlarging the original covariance matrix\".\n\nExtra $=$ on equation 14.\n\n\"trading each\" -> \"treating each\" ? \n\n\" ground true data\" \n\n\"SMILE: moothed\" -> \"SMILE: smoothed\" \n\nIt should be a parenthetical reference for You et al. (2017) fo LARS optimizer. How is the $H(Z)$ term estimated in section 3.1? Is it also based on augmented data?\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. Are there hyper-parameters for EMP-SSL?  \n\nWhy in Table 1 is 1000 epochs not tested?\n\nIs the GMM method run at each time point in Figure 2?",
         "766",
         "1",
         "2",
         "0.7605",
         "67",
         "0.05322184429327287"
        ],
        [
         "28",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_e4bh",
         "1698824679826",
         "1700667146725",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs) which build on the graph theoretical concept of graphexes to include sparse network structures between agents. This improves over prior work on Graphon Mean Field Games which only allows for modelling with dense graphs. The authors derive convergence properties for the finite game. In addition, a learning algorithm based on online mirror descent is provided for a particular class of GXMFGs that follow a core-periphery network structure. Finally, the theoretical claims are empirically validated over both synthetic and real-world networks. - This paper has a clear motivation to extend Graphon Mean Field Games to deal with sparse graphs which are frequently seen in practice. The hybrid graphex approach proposed in this work looks like a natural and intuitive solution.\n- The technical development is principled and the analysis is nontrivial.\n- The overall presentation and clarity is good. - Even though the authors explained in the paper, I didn't like the fact that the proposed GXMFGs have no baseline competitors to compare against. While I agree that one could argue on the contrary that the ability to work with sparse graphs is precisely the unique advantage of GXMGFs, I think that the authors should at least spend some efforts to discuss (if empirical comparison with LPGMFG is indeed unsuitable) how GXMFGs would compare with LPGMFG and GMFG in practice. In Figure 3a, it looks like the curves are diverging rather than converging as k increases? Are the curves coloured correctly?",
         "248",
         "0",
         "0",
         "0.8187",
         "55",
         "0.024007936507936506"
        ],
        [
         "29",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_hgJx",
         "1698838739665",
         "1699636550718",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs), a framework for addressing the challenge of learning agent behavior in large populations. GXMFGs leverage graphon theory and graphexes, which represent limiting objects in sparse graph sequences. This approach suits real-world networks with both dense cores and sparse peripheries. The paper presents a specialized learning algorithm for GXMFGs. \n\nKey contributions include:\n\n1. Introduction of GXMFGs, extending the scope of Mean Field Games.\n2. Provides theoretical guarantees to show that GXMFGs accurately approximates finite systems.\n3. Development of a learning algorithm tailored to GXMFGs.\n4. Empirical validation on synthetic and real-world networks, demonstrating GXMFGs' ability to model agent interactions and determine equilibria effectively. - Well-Written and Organized: The paper demonstrates strong writing and organization, enhancing its overall readability and accessibility.\n\n- Clear Motivation: The paper effectively conveys a clear and compelling motivation for addressing the problem it tackles.\n\n- Thorough Discussion of Prior Works: The paper provides a comprehensive and well-structured overview of prior works related to the research area.\n\n- The paper provides solid theoretical contributions complimented with supporting empirical studies strengthens the paper's arguments and findings. As the current paper falls outside the scope of my research interests, I am unable to identify any significant weaknesses in the paper. Consequently, my confidence in assessing the paper is limited. - Providing an intuitive explanation for assumptions 1(b) and 1(c) would greatly enhance the paper's overall readability and accessibility.\n\n- While the paper assumes finite state and action spaces, it may be beneficial to explore whether the proposed approach can be extended to scenarios with infinite action spaces. \n- Including the code for the simulations, would enhance reproducibility.",
         "275",
         "0",
         "4",
         "0.8110",
         "66",
         "0.11253968253968255"
        ],
        [
         "30",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_P6cQ",
         "1698854680058",
         "1699636550633",
         "6",
         "4",
         "3",
         "3",
         "3",
         "In this paper, the authors study a class of games with many players who are interacting through a sparse graph structure. More specifically, they are interested in the regime where the number of players tend to infinity. The main solution concept is an extension of the notion of Nash equilibrium. The authors propose a learning algorithm based on online mirror descent. They conclude the paper with examples and numerical simulations. Overall, the paper studies an interesting problem and is relatively clearly written. As far as I know, this is a new extension of MFG to sparse graphs. The algorithm is very inspired from existing ones but there is an adaptation to the problem under consideration (core vs periphery). The model is quite abstract at some places. For the theoretical results, they are mostly about the analysis of the game and I am not sure how relevant they are for this conference (although they are certainly interesting for a certain community). It might have been more interesting to focus more on the learning algorithm. \n\nThere are some typos which make it hard to check the correctness of some parts (see questions). 1. I am wondering if some assumptions are missing. For example below Lemma 1, should $f$ be at least measurable (and perhaps more?) with respect to $\\alpha$ for the integral to make sense?\n\n2. Assumption 2 as used for instance in Lemma 1 does not seem to make much sense (unless I missed something): What is $\\boldsymbol{\\pi}$? We do not know in advance the equilibrium policy and even if we did, we would still need to define the set of admissible deviations for the Nash equilibrium. Could you please clarify?\n\n3. Algorithm 1, line 14: Could you please explain or recall what is $Q^{k, \\mu^{\\tau_{\\mathrm{max}}}}$?\n\nSome typos: Should the state space be either $\\mathcal{X}$ or $X$ (see section 3 for instance)? Does $\\mathbb{G}^\\infty_{\\alpha,t}$ depend on $\\boldsymbol{\\mu}$ or not (see bottom of page 4)? Etc.",
         "324",
         "0",
         "4",
         "0.8025",
         "66",
         "0.19302597402597402"
        ],
        [
         "31",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_qFZD",
         "1698724264822",
         "1699636511957",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper introduces out-of-variable (OOV) generalization, which is an the ability to generalize in environments with variables that have never been jointly observed before. OOV is an issue in settings where different variables (e.g. diagnostic tests) are available for different environments (e.g. different patients). The paper investigates challenges for common approaches when faced with the OOV problem, and proposes an OOV predictor that leverage moments of the error distribution. The work contributes to theoretical understandings of OOV and offers a proof-of-concept for a predictor capable of non-trivial OOV transfer. - The paper formally studies a new perspective on generalization.\n- The methods employed in the paper are sound. - The paper does not demonstrate the practical applicability of the concept of OOV generalization, and the setting feels a bit contrived. Also it seems like OOV generalization can be thought of just a case of OOD generalization--if we think about all the variables together as the input, the OOV generalization is just a case of OOD generalization (e.g. covariate shift) where some inputs have clear signal from some features and other inputs have clear signal from other features. \n- It would be helpful to include more intuitive discussion throughout the paper providing more analysis on the sections. For example, more discussion on the assumptions of the settings/theorems would be helpful, and it's not clear exactly under what assumptions the proposed predictor is appropriate. Please see weaknesses above.",
         "236",
         "0",
         "2",
         "0.7220",
         "67",
         "0.11756198347107437"
        ],
        [
         "32",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_s9Ga",
         "1698762596885",
         "1700684618252",
         "8",
         "4",
         "3",
         "4",
         "2",
         "This work investigates out-of-variable (OOV) generalization, which is a sub-problem to OOD generalization, and refers to scenarios where an agent needs to generalize to environments containing variables that were never jointly observed before. The paper shows that if the source and target environments contain some overlapping variables (and under certain conditions), information from the predictor in the source environment can improve predictions in the target environment. More specifically,  the moments of the residual distribution from the optimal classifier in the source environment can be used to calculate the generating function with respect to the unobserved variable in the target domain.\n\nBased on this observation, the paper proposes a practical algorithm for OOV prediction, evaluates its performance, and compares it against the marginal predictor and imputed predictor, as well as an Oracle predictor. The paper proposes a new and important problem-setting - OOV generalization, which can occur in real-world situations, on its own or alongside OOD aspects. The work also provides an extensive study of the identification problems of various variants of OOV scenarios, including theoretical proofs and examples. \n\nIn addition, the paper proposes a practical algorithm to solve several OOV scenarios that achieves non-trivial OOV transfer on synthetic data.\n\nThe ideas presented in the paper are novel and the conclusion that information from source domains can be used for prediction in the target domain in this setting is important, and can potentially have a broad impact on future research in the field. The main limitation of the paper is that the proposed approach was tested on only synthetic data, and was not validated using more challenging datasets. \n\nIn addition, the extension of OOV in multi-environments is mentioned mainly in the appendix and the algorithm was not tested empirically for that extension. I would like to ask the following questions:\n\n1. For future work, is there a more complicated/realistic dataset to validate the algorithm?\n2. Is it possible to compare the algorithm to state-of-the-art marginal or causal methods such as Mejia et al. (2021) or Janzing (2018)? To validate if Vapnik’s principle holds and whether the proposed approach indeed improves results due to solving a less general problem.\n3. Theorem 3 connects all moments of the residual distribution to the partial derivatives with respect to the unique variable of the target environment. If additional moments were to be calculated as part of the proposed algorithm, would it improve results (for the general function case)? \n4. In general, since the paper's main claim is that in the real world, it is likely to encounter both aspects of OOD and OOV - How simple is it to combine state-of-the-art  OOD methods with the proposed approach? I cannot imagine at the moment a straightforward way to do that.",
         "454",
         "2",
         "3",
         "0.7695",
         "54",
         "0.14226340788840788"
        ],
        [
         "33",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_woi7",
         "1698788842803",
         "1699636511769",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper describes the out-of-variable OOV problem, which in its simplest form, aims to learn a predictor Y = f_t(X2, X3) given an OOV predictor Y = f_s(X1, X2) and a dataset (X2, X3), but without any instance of (X2, X3, Y). The authors describe the setting in which this is possible and develops an algorithm. The key observation is that the third moment of the residue Y - f_s(X1,X2) contains information about X3 that is least polluted by the noise. - The key observation/discovery is clever, and the algorithm is straight-forward to use.\n- The writing is clear, clean, and well-referenced. The examples also made things concrete and easy to follow.\n- The rigor and simplicity of the work can act as a foundation to build OOV research. - The main weakness is the applicability of the method. The authors only showed results for proof-of-concept, not for real-world usage. \n- It is unclear how one could identify whether the assumptions are satisfied given a dataset.\n- It is unclear how bad the predictor would be if the assumptions are not satisfied.\n- It is not yet clear what realistic problem can be well modeled by OOV generalization. Intro:\n- It seems OOV fits very well the frame of missing-not-at-random and covariate-dependent missingness. Could the authors comment on that?\n\nSection 2:\n- Theorem 2 is slightly confusing for me at first glance because I thought PA_Y by definition includes all parents of Y (so x1,x2, x3 in the example) and not just those in the target environment (x2, x3). It may be helpful to clarify.\n\nSection 3:\nAs I am trying to get a sense of the restriction and applicability of the approach, I was wondering the following questions: \n- How does the method fair with the oracle as the magnitude of the noise increases? \n- What if the noise is not gaussian but more heavy tailed? \n- Does the performance degrade or improve with increasing number of variables? \n- I assume Theorem 3 does not apply to discrete variables because of the violation of differentiability; is that right?\n\nSection 4:\n- Can include missing-not-at-random imputation and covariate-missing imputation as two more baseline models (a search in Google scholar using the two key phrases yields some methods).\n- It would be really interesting if the authors could find some real-world datasets, create source and target environments by sub-setting the columns, and see how the method performs.\n- Figure 3: I don’t quite understand the figure. It would be helpful to define OOV loss, be explicit about the number of samples on the y-axis being (x2,x3,y) or (x1,x2,y) or something else. I also don’t understand why relative loss is zero means the method is on par with the oracle predictor. Why not just show how the fine-tuning error compares with oracle training, which seems easier to interpret? Anyway, I am overall a bit confused about the figure, so my questions may not make sense.",
         "493",
         "0",
         "0",
         "0.7642",
         "67",
         "0.09470046082949309"
        ],
        [
         "34",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_xwQY",
         "1699441328198",
         "1699636511667",
         "8",
         "3",
         "3",
         "3",
         "3",
         "The paper investigates out-of-variable generalization, namely the ability for a predictive model to generalize to target domains in which the agent has never seen the joint variables in the target domain in a single source domain before. Under certain assumptions as well as when these assumptions don't fully hold, the paper shows that the error residual distribution in an environment provides information on the unobserved causal parent variable in this environment, and they use this information to derive an algorithm that performs OOV generalization with source and target domains that have overlapping sets of causal factors. **Originality**\n- As far as I know, though the problem the paper addresses is well-known as a significant problem, the paper provides several theoretical results, mathematical derivations, and supports these with simple empirical results that are novel.\n\n**Quality**\n- The quality of the paper is high. It addresses a high-value problem in a principled fashion, shows how certain assumptions help obtain certain results and how and in which cases these assumptions can be bypasses while maintain approximately accurate results, and evaluates these cases in terms of loss accuracy as well as sample complexity of its approach versus baseline approaches.\n- The paper openly highlights limitations in its work, such as assumptions made for theorems to hold, and proposes prospective future work in multiple avenues. This refreshingly is (1) included at all and (2) doesn't seem like a mere afterthought.\n\n**Clarity**\n- The paper is mostly clear in its explanation of motivation, preliminaries, approach, baseline usage, results, and limitations.\n- The paper does a great job providing simple, clear real-world examples to elucidate the problem and applications of the various theorems included in multiple cases.\n\n**Significance**\n- The significance of the problem the paper addresses is high and the problem is ubiquitous. The approach is promising and can be applied in many real-world settings through Monte-Carlo sampling or similar methods. The paper shows that their approach can perform relatively well in \"few\"-shot settings though this depends on the number of variables involved and the complexity of the problem.\n\nFrom what I can tell, this is excellent work that I hope motivates further addressing this *out-of-variable* generalization problem by the research and applied AI community. My only reservation is my limited knowledge on the understanding of and state-of-the-art theoretical and applied approaches addressing this problem. - Referring to Figure 1, in the first paragraph in page 3, the claim \"it would seem all but impossible...(orange box)\" could be better explained.\n- In Figure 1, it is unclear whether \"With $Y$ not observed in the target domain\" is an assumption made or is somehow indicated in the diagram or earlier in the paper. Eventually I realized that it's an assumption made, but the illustration Figure 1a alone isn't enough to show this assumption. This ambiguity may clear for some or compound for some later in Section 3. - The abstract states \"merely considering differences in data distributions is inadequate for fully capturing differences between learning environments.\" Doesn't out-of-variable technically fall under out-of-distribution, so shouldn't this be adequate? Perhaps more specificity is needed here.\n- The abstract states \"Mathematically, out-of-variable generalization requires the efficient re-use of past marginal information...\" Why does it require efficient re-use? Could it work with \"non-efficient\" or inefficient re-use?\n- On page 2, should \"modal\" be \"model?\"\n- On page 6, do you mean \"parentheses\" instead of \"brackets\" between Eq (9) and Eq (10)?\n- Why is the joint predictor considered an oracle predictor if MomentLearn outperforms it?\n- Could you explain why MomentLearn is reliably more sample efficient than the oracle predictor for \"few\"-shot prediction?",
         "602",
         "0",
         "0",
         "0.7701",
         "67",
         "0.10227124183006535"
        ],
        [
         "35",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_HgHQ",
         "1697165838375",
         "1699635934990",
         "3",
         "5",
         "2",
         "3",
         "2",
         "The paper proposes a simple yet efficient feature direction distillation loss. Experiments show that this significantly improves KD\nperformance. 1. Improving KD by feature norm and direction is reasonable and effectiveness.\n2. Experiments on standard benchmarks demonstrate that adopting $\\mathcal{L}_{dino}$ remarkably improves existing KD methods. 1. The contributions seem a little limited. \n2. There is lack of theoretical analysis of DINO loss. The paper is not good enough to be published on ICLR. 1. How to align the features between heterogeneous architectures?\n2. Could you please provide more theoretical analysis?\n3. What about extending it to a multi-layer version of feature distillation?\n4. How to apply the proposed method to existing KD methods, e.g. ReviewKD, DKD, DIST? Just add the DINO loss function to the total loss ? If so, I think adding other loss like contrastive distillation loss or RKD may also make a improvement.",
         "146",
         "0",
         "8",
         "0.8205",
         "67",
         "0.07793367346938775"
        ],
        [
         "36",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_yLjx",
         "1697172920902",
         "1699635934905",
         "6",
         "5",
         "3",
         "3",
         "2",
         "Here is a summary of the key points from the paper:\n\n- The paper proposes a method to improve knowledge distillation (KD) by regularizing student features to align direction with teacher class-means and have sufficiently large norms. \n\n- Current KD methods like logit or feature distillation align student and teacher but don't directly optimize for student's task performance.\n\n- The paper shows regularizing direction using cosine similarity to teacher class means helps improve student accuracy. \n\n- It also finds student models tend to produce smaller-norm features, so encouraging larger norms improves performance. \n\n- A simple combined loss called dino-loss is proposed to simultaneously regularize student feature direction and norm using teacher class means.\n\n- Experiments on CIFAR and ImageNet classification, and COCO detection show dino-loss consistently improves various KD methods like KD, ReviewKD, DKD.\n\n- Dino-loss achieves new state-of-the-art results among KD techniques on classification and detection benchmarks.\n\n- The method is model-agnostic, simple to implement, adds minimal overhead, and benefits from larger teacher models.\n\nIn summary, the key contributions are a way to improve KD by regularizing student features for better alignment and norms, along with a simple and effective dino-loss to achieve this jointly. The results demonstrate consistent gains across tasks and benchmarks. The paper presents an original and significant approach to improve KD via thoughtful feature regularization. The method is intuitive and supported by quality experiments. The gains are demonstrated to be significant across tasks. The presentation and discussion are clear:\n- The method and dino-loss are clearly explained with illustrations and equations. Results are well-presented in tables and figures. Limitations are properly discussed.\n- Improving KD is an important practical problem. The consistent gains are significant. Sets new state-of-the-art results on ImageNet classification and COCO detection.\n- Model-agnostic nature allows wide applicability to various KD methods and models. Simple extension can benefit the community compared to more complex techniques. - The paper should address the lack of novelty by acknowledging that feature normalization techniques have already been widely employed in knowledge distillation. For example, PKD (NeurIPS-2023) specifically incorporates channel alignment for detectors, and SKD (Guo Jia) explores normalization techniques on predictions. and Feature Normalized Knowledge Distillation for\n/mage Classification ECCV2022 also presents feature norm. Furthermore, it is worth investigating whether the proposed method has already been considered in the distiller's search work, as exemplified by KD-Zero: Evolving Knowledge Distiller for Any Teacher-Student Pairs (NeurIPS-2023).\n\n- In addition, the paper should incorporate a thorough discussion of relevant KD-related studies, including Self-Regulated Feature Learning via Teacher-free Feature Distillation (ECCV2022), NORM: Knowledge Distillation via N-to-One Representation Matching (ICLR2023), Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer (NIPS2022), DisWOT: Student Architecture Search for Distillation Without Training (CVPR2023), and Automated Knowledge Distillation via Monte Carlo Tree Search (ICCV2023). These discussions will provide valuable insights into the existing literature, establish connections with previous research, and potentially highlight points of comparison and contrast. The only concern to me is the novelty of the work and I hope the authors could discuss some of the related work I mentioned in the revised version.",
         "510",
         "0",
         "1",
         "0.8228",
         "67",
         "0.13425865800865805"
        ],
        [
         "37",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_VRvE",
         "1698736302686",
         "1699635934723",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper studies Knowledge Distillation (KD). A simple loss term namely ND loss is proposed to enhance the distillation performance. It encourages the student to produce large-norm features and aligns the direction of student features and teacher class-means. The ND loss helps not only logit-based distillation methods but also feature-based distillation methods. 1. The proposed method is simple but effective. Encouraging the feature norm for the student is novel in the field of KD.\n2. Experimental results are strong. The authors also conduct experiments on object detection. The proposed loss can improve the existing methods on both image classification and object detection.\n3. The whole paper is organized and written well. It is not a novel thing that decoupling the feature into the magnitude and the direction. Previous works [1][2] already studied this point. [1] uses the teacher classifier to project both teacher features and student features into the same space and then align them. [2] proposes a loss term to align two features’ direction. Compared to the existing works, this paper proposes enlarging feature norm and utilizing the class-mean feature. Authors should check more existing papers and discuss their differences.\n[1] Yang, Jing, et al. \"Knowledge distillation via softmax regression representation learning.\" International Conference on Learning Representations (ICLR), 2021.\n\n[2] Wang, Guo-Hua, Yifan Ge, and Jianxin Wu. \"Distilling knowledge by mimicking features.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 44.11 (2021): 8183-8195. None",
         "235",
         "7",
         "6",
         "0.7478",
         "67",
         "0.1515151515151515"
        ],
        [
         "38",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_AuzT",
         "1698788774762",
         "1699635934515",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper proposes to use teacher's class-mean to align student's direction and encourage the student to produce large-norms features, improving the performance of KD. The paper is generally well-written, and the methodology is well-motivated. 1. would expect comparisons and discussion to similarity-preserving KD e.g., [1], which is a large family in feature distillation methods and shows some relations to the proposed method.\n2. Meanwhile, comparisons/discussion to explainablity-based KD, e.g., [2] are needed to see whether those methods can be benefited from the proposed method.\n\n[1] Tung, Fred, and Greg Mori. “Similarity-Preserving Knowledge Distillation.” ICCV 2019.\n\n[2] Guo, Ziyao, et al. \"Class Attention Transfer Based Knowledge Distillation.\" CVPR 2023. Please see weakness.",
         "111",
         "4",
         "6",
         "0.7517",
         "67",
         "0.13214285714285715"
        ],
        [
         "39",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_AcYB",
         "1697637540901",
         "1700740134087",
         "5",
         "4",
         "3",
         "2",
         "2",
         "The authors introduce Neural Sinkhorn gradient flow, which is a Wasserstein Gradient Flow wrt to the Sinkhorn divergence. The authors show that the velocity field can be calculated using the Sinkhorn potentials. This allows training a neural network approximating the velocity field. Furthermore, a mean field limit is established. The algorithm is evaluated on a toy example, MNIST image generation and CIFAR10 image generation. The authors do a good job at explaining the underlying concepts of their algorithms. The maths is nicely done. The core idea is very neat and the cifar10 results seem to be good quantitatively wrt other gradient flow works. 1) The article is full with typos. Just to name a few: \"piror\", \"Sinkhron\", \"Experimrnts\", \"speedest descent\", question mark in the appendix and so on. Please fix those. \n\n2) the authors write \"We do not compare with extant neural WGF methods on MNIST because most of the neural WGF\nmethods only show generative power and trajectories on this dataset and lack the criteria to make\ncomparisons.\" There are several papers (also gradient flow based ones), which evaluate a FID on MNIST. Please provide it as well. \n\n3) Also many of the MNIST digits appear flipped. Did the authors use data augmentation there? Also there seems to some slight noise present the generated MNIST digits. \n\n4) Although the CIFAR10 value seems good, there are unfortunately no generated images provided. It is standard practice to sample many images in the appendix. \n\n5) It is unclear what the trajectories show. Does it show the particle flow or the trained Neural Sinkhorn Gradient Flow? \n\n6) The statement of theorem 2 is incorrect. I guess the authors do not want to sample the Euler scheme (eq 14) but the continuous gradient flow, otherwise the statement would need to depend on the step size $\\eta$. \n\n7) In the proof of Theorem 2: Please provide a proof (or reference) why the mean field limit exists. Or do you mean the gradient flow starting at $\\mu_0$ with target $\\mu$ (first two sentences).\n\n8) Later in that proof: why does there exists a weakly convergent subsequence of $\\mu_t^M$? Further, I cant find the definition of $U_{\\mu}$. \n\n9) The code is not runnable, as the model (or any checkpoints) are not provided.\n\n10) From how I understood it, the learning of the velocity field is batched, i.e., one trains for different sets of $(z_i,x_i)$. Since the Sinkhorn dynamic describes an interacting particle system I dont see how this should be possible. To be more precise, one particle $\\tilde{x}$ could be sent to $x_0$ in the first batch, but to a totally different particle $x_1$ in another one, depending on the drawn prior and target samples. Are the positions of the other particles also input to the neural network (i.e by putting them in the channels)? Please elaborate. See weaknesses section. Overall I really like the idea, but the weaknesses prevent me from giving a higher score. It seems like the paper was rushed and is currently not ready for publication. I am willing to raise my score, if the authors address these issues.",
         "516",
         "0",
         "3",
         "0.7790",
         "54",
         "0.1480691056910569"
        ],
        [
         "40",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KKim",
         "1698338217824",
         "1700755549491",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces a novel way to train generative models. The authors want to approximate the gradient flow in the Wasserstein space.  They want to approximate the vector field which transports the source distribution to the real-data empirical distribution while minimizing the Sinkhorn divergence. The authors showed the analytical form of the vector field when one considers the Sinkhorn divergence and then they explain how to learn this vector field with a neural network through the simulation of a probability path. They showed that their procedures recover the true probability path when the number of iid samples goes to infinity. Finally, they validate their proposed method on several image-generative tasks. i) The motivation and the introduction are clear\n\nii) Regressing vector fields has been a recent and popular approach with many different applications in machine learning. The proposed approach is interesting and appears to be novel. The theoretical results also show that the proposed method has appealing properties. \n\niii) The authors also provided several experiments showing interesting results from their methods. The first thing I would like to highlight is that I have checked the provided code. I see several inconsistencies and weaknesses between the provided code and the paper:\n\n1. There are several differences in the empirical implementation between the paper and the code. In Appendix A, the authors state that they are computing the entropic potential through stochastic optimization algorithms [Genevay et al, 2016]. However, this is not what is done in practice according to the provided code. In practice, the authors compute the potential between mini-batches of samples, they sample a minibatch of cifar10 experiments, then sample a minibatch of the source Gaussian, and simulate the gradient flows between the two minibatches. This style of minibatch approximation induces a bias that should at least be mentioned in the main paper but also discussed. Indeed, the authors do not compute the true Sinkhorn divergence but a minibatch approximation of it; this approximation is slightly different than the one from [1,2] and that should be discussed. I understand the reason why the authors use this approach (decreasing the cost of this preprocessing step), but this is not what they say they do in Appendix A. In that regard, the paper is much closer to the minibatch optimal transport Flow Matching [Pooladian et al., Tong et al] and Appendix A deserves a major revision.\n\n2. With the provided code, there are several insights that should be discussed in the paper. In the provided cifar experiments, the number of Gaussian samples used is 50000 samples. This number is extremely low to approximate the semi-discrete OT. Therefore, a discussion regarding the statistical performance of the method is needed in my opinion.\n\n3. As your method requires the simulation of the probability path, I wonder about the training time between your method and the recent Flow Matching approaches which are simulation free.\n\n4. There are many typos in the paper (including in titles: ie ExperimRnts, Notaions) that lead to poor clarity...\n\n5. The experiments include two toy datasets (synthetic 2D and MNIST). I would like to know how the method performs on other big datasets (Flowers, CelebA) or on other tasks such as single-cell dynamics [4].\n\n6. The related work on optimal transport is incomplete. Several works used the sliced Wasserstein distance to perform gradient flows [3].\n\n[1] Learning Generative Models with Sinkhorn Divergences, Genevay et al, AISTATS 2018\n[2] Learning with minibatch Wasserstein, Fatras et al, AISTATS 2020\n[3] Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions\n[4] TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics 1. [Pooladian et al., Tong et al.] proved that when the minibatch increases, they get closer to the true optimal transport cost (W_2^2). The interest of their method is that they can rely on minibatches and learn the vector field from an unlimited number of minibatches. Could you follow a similar approach and simulate the gradient flow during training? While it would be an expensive step in training, it might improve the metrics on the different generative model experiments.\n\n2. What is the performance of your method concerning the number of simulation steps (ie Euler integration and its learning rate)?\n\n3. What is the time of the preprocessing step concerning the training time?\n\n4. Could you compare your method with OT-CFM [Pooladian et al., Tong et al.] on the synthetic data? I am curious to compare the differences.\n\nIn my opinion, the mentioned weaknesses have to be revised and this paper should go under a major revision. I deeply think that the experimental section should better highlight what is done in practice and the theoretical section should mention the different biases (statistical and minibatch). Therefore, I recommend rejecting the current manuscript as it does not meet the ICLR acceptance bar.\n\n\n----- EDIT POST REBUTTAL -----\n\nI thank the authors for their answers. I have read the updated manuscript. While it is now better than before, I suggest they add a limitation section where they describe the different biases in their algorithm. I understand the motivations of the paper. Overall, I think that the manuscript deserves another round of reviews but I have decided to move my score to 5 as they have given good answers.",
         "873",
         "7",
         "8",
         "0.7648",
         "54",
         "0.07236111111111111"
        ],
        [
         "41",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_Kh9H",
         "1698606606187",
         "1699636333063",
         "6",
         "4",
         "3",
         "2",
         "2",
         "Through a series of approximations (and at times, really, relaxations) the authors show that the Sinkhorn gradient flow from one measure to another can be learned.  They do this by first reducing their relaxed problem to a vector field matching problem, and then proposing a neural network-based Algorithm for matching the Sinkhorn-Wasserstein flow's vector field by a neural network (though no convergence/approximation guarantees are proven).\nThe problem is interesting, and its solution is sufficiently novel to merit publication. The problem is natural to study, the results are mathematically correct, and the experiments are convincing. While the paper is mathematically correct, it does not provide theoretical justification for one of its main components, namely showing that approximate vector field matching yields approximate solutions for all time $t$.  I feel that without this guarantee, there is a gap in the theoretical viability of this model.  Nevertheless, this is a minor point since the length of a conference paper does not allow one to treat every such point.\n\nThere are minor typos throughout. \n* E.g. euclidean instead of Euclidean\n* $lim$ instead of $\\lim$ atop page 15 in the appendix\n* The positive scalar $\\delta$ is not defined in the proof of Theorem $1$\n* In the statement of Lemma 3: \"teh\" should read \"the\"\n\nSome references are obscure\n* For The fact that $\\mu + t\\delta \\mu$ converges weakly to $\\mu$, perhaps it is worth simply noting that due to linearity of integration (wrt to the measure term). Can it be shown that approximate vector field matching yields approximate solutions for all time $t$?",
         "262",
         "0",
         "1",
         "0.7647",
         "67",
         "0.0019972451790633613"
        ],
        [
         "42",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KkYD",
         "1698745650108",
         "1700818697559",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper under consideration deals with the standard generative modelling setup (image generation from noise). To solve this problem, the authors propose to model the gradient flow w.r.t. the Sinkhorn divergence. The paper utilizes an explicit (forward) Euler discretization scheme, i.e., given a distribution $\\mu_t$ at the current time step $t$, the proposed method aims at finding the subsequent distribution $\\mu_{t + 1}$ following the gradient of the Sinkhorn divergence at point $\\mu_t$. The authors validate their methodology on toy 2D setups as well as standard image benchmarks (MNIST and CIFAR10).\n\n**Post-rebuttal update:** I thank the authors for the detailed answer. The majority of my concerns are properly addressed. I rise my score. However, I still tend to reject the paper. Also I agree with reviewer KKim that minibatch OT approximation should be discussed more thorougly. Thank you. To the best of my knowledge, the framework of the gradient flow w.r.t. Sinkhorn divergence for pure generative modelling has not yet been considered. This indicates that the paper is indeed bringing something novel to the ML community. At the same time, the idea of the Sinkhorn gradient flow has already arisen in previous research. In particular, [A] solves Sinkhorn barycenter problems by adjusting a generative distribution towards the barycenter distribution with the help of a procedure called “functional gradient descent” which is actually the discretization of the gradient flow w.r.t. the sum of Sinkhorn divergences to the target distributions. At the same time, it is worth mentioning, that [A] just simulates particles and does not build a generative model.\nRegarding the other strengths of the paper, I would like to note the well-organized Experiments section.\n\n[A] Sinkhorn Barycenter via Functional Gradient Descent, NeurIPS’2020 - Some theoretical results from the paper are known. For example, the statement of Theorem 1 could be found in [B] (eq. 26) or [C] (eq. 8). \n- The quality of the code provided is not good. There is no README/or other instruction to run the code. There are imports of non-existing classes. So, there is no possibility of checking (at least, qualitatively) the provided experimental results.\n\nFrom my point, the main weakness of the proposed paper is the limited methodological contribution. The authors simulate the particles of data following Sinkhorn divergence - as I already mentioned, this is not a super fresh idea. To make a generative model from these simulated trajectories, the authors simply solve the regression task to learn the local pushforward maps. And that is it. Combined with the fact, that the practical performance of the proposed approach is far from being SOTA in the generative modelling, the overall contribution of the paper seems for me to be limited. - My main question (and, probably, one of the main of my concerns) is regarding the proposed methodology. The authors propose to compute certain $\\mathcal{W}_{\\varepsilon}$ potentials (on discrete support of available samples) and then somehow take the gradients of these potentials w.r.t. the corresponding samples (eq. (13)). From the paper it is not clear how to compute the gradients, because the obtained potentials look like vectors of sample size shape, which are obtained through the iterations of the Sinkhorn algorithm. As I understand, in practice, the authors utilize SampleLoss from the geomloss package ([B]).  The outcome of this observation is that [B] should be properly cited when deriving the algorithm (section 4.2). I recommend authors explicitly use SampleLoss in the algorithm's listing. It will contribute to the clearness of what's going on. \n- The vector field of the Sinkhorn gradient flow is estimated by empirical samples. It is not clear how well this sample estimate approximates the true vector field. This point should be clarified. Note, that Theorem 2 works only for mean-field limit. \n- In the Introduction section, the authors consider a taxonomy of divergences used for gradient flow modelling, namely, \"divergences [...] with the same support\" and \"divergences [...]  with possible different support\". As I understand, the first class is about $f-$ divergences and the second class is about the other types (like Sinkhorn, MMD etc.). I have a question regarding the provided examples of works which deal with the former or the latter type of divergences. The fact is that the works [D], [E], [F], [G] deal with KL-divergence (or f-divergence) minimization. That is why I wonder why did the authors classify them as the second class.\n- A good work regarding poor expressiveness of ICNNs is [H].\n- What is the “ground” set ($\\S$ 3.1, first line).\n- Table 1. What are the differences between 1-RF, 2-RF and 3-RF methods?\n\n[B] Interpolating between Optimal Transport and MMD using Sinkhorn Divergences, AISTATS’2019\n\n[C] Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm, NeurIPS’2019\n\n[D] Large-scale wasserstein gradient flows. NeurIPS'2021\n\n[E] Optimizing functionals on the space of probabilities with input convex neural networks. TMLR\n\n[F]  Proximal optimal tranport modeling of population dynamics. AISTATS\n\n[G] Variational wasserstein gradient flow. ICML\n\n[H] Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. NeurIPS’2021.",
         "827",
         "0",
         "8",
         "0.7673",
         "53",
         "0.08673767752715121"
        ],
        [
         "43",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_MEFG",
         "1699146383667",
         "1699636332903",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces the idea of learning a time-dependent velocity field of the Sinkhorn Wasserstein gradient flow from samples from the target distribution to calculate the empirical velocity field approximations. The paper supports its claim by showing that the mean-field limit of this process recovers the true Sinkhorn Wasserstein gradient flow. They also validated the process with some empirical studies. The paper is well written and easy to follow. The proofs and arguments in the appendix are well-typed out and clear.  There are some nice diagrams in the empirical section to supports the claim the authors are making. I think the experiments could be more extensive. One thing about this method is to investigate the number of samples needed. effectively learn the velocity field. This is one important experiment missing as is remains unclear how sample-efficient the proposed method is. It would also make the paper more completing if the method is applied to generative models that output discrete random variable like binary mnist or even language modelling. One possible question is what happens if we change the source distribution to be closer to the target distribution like it was from a generator how would the method perform there. Another question is to better understand the sample complexity of the method as the current method may not be sample efficient due to the empirical distribution being approximated using the samples.",
         "230",
         "0",
         "0",
         "0.7569",
         "67",
         "0.18728070175438596"
        ],
        [
         "44",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_JSi7",
         "1698680587788",
         "1699636955419",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This article discusses a method to improve the application of SLM in the medical field, utilizing LLM's medical proficiency to boost SLM performance in medical tasks under privacy-restricted scenarios which has important social significance. The method was tested on MedQA, HEADQA, MedMCQA, and MMLU-professional medicine datasets, showing some improvements over existing methods. Additionally, the authors compared results across different sizes of training sets. see summary 1). Imprecise example of Privacy Protection.\nThe example in Figure 1 indicates that personal privacy issues are only present in the first sentence, and the key words \"man\" and \"admitted\" in that sentence have almost no impact on the subsequent content. Could it then be possible to simply delete the first sentence to achieve privacy protection, as extracting key words here does not seem to play a significant role.\n\n2). Privacy Protection as an Innovation Point\nRegarding the extraction of key words for privacy protection, the paper uses a medical NER model proposed by Neumann et al in 2019. We suggest further improvement of this model, for example, considering age as a crucial keyword for certain diseases and extracting it as necessary to better enrich the innovative aspects of the paper.\n\n3). Ambiguity of Symbols in Annotations\nAnnotation 13 on page 8 only appears in the content of the article but is not explained.\n\n4) The overall innovation of the methodology needs improvement, as the majority of the content relies on existing methods, such as the medical NER (Named Entity Recognition) model. please see the weaknesses.",
         "251",
         "0",
         "3",
         "0.8122",
         "66",
         "0.08698686371100164"
        ],
        [
         "45",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_gXvF",
         "1698819472631",
         "1699636955275",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This paper tried to improve the performance of small medical language models by introducing knowledge from large language models, which keeps the privacy of clinical text when using large language models.  The proposed method uses keywords instead of full raw text to generate initial evidence from LLM and feed the evidence to small language model. Privacy-preserving is an essential and common need when using LLM in clinical text. This paper tried to solve this problem by using keywords instead of raw text, the idea is novel and experiments demonstrated the effectiveness of this approach. 1. As this research utilized a named entity recognition model to extract keywords, it is possible that the NER model can extract privacy information such as patient names. Is there any filtering or postprocessing step to avoid that? In addition, it is not guaranteed that NER system will never extract sensitive patient information; for example, if the NER system incorrectly extracts a patient's address as a symptom, then the address may be leaked to LLM. Although it is very rare, it is still necessary to comment on this. \n2. As the LLM already provides a preliminary decision, I am curious about the performance if we only feed the preliminary decision from LLM to SLM. It is worth knowing which part of the LLM-generated information improves the SLM most. \n3. The related work section need to discuss more LLM application in the clinical area, especially the knowledge-enhanced LLM in clinical settings. For example, paper \"Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.\" also utilized external knowledge for clinical questions. \n4. By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem? By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem?",
         "326",
         "0",
         "4",
         "0.7696",
         "66",
         "0.039992507492507476"
        ],
        [
         "46",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_TtE2",
         "1698819599156",
         "1700663756238",
         "6",
         "4",
         "2",
         "2",
         "3",
         "The paper studied medical QA problems by incorporating large language models (LLMs) to assist small-language models (SLMs). To protect the private information in the data, the authors propose to first extract keywords and then use the keywords to query LLMs for intermediate content which can be used for SLMs to enhance prediction accuracy. 1. (originality) The proposed method is novel by extracting keywords and privately incorporating LLM for SLM-based predictions.\n2. (clarity) Overall, the paper is fair in presentation. The demonstrations of synthetic medical data with private information and extracted keywords are helpful for understanding the concepts.\n3. (significance) Versus the compared baselines, the proposed methods significantly improve the prediction accuracy on three medical QA tasks.\n4. (quality) The authors thoroughly evaluate the performance of the proposed method. 1. (Clarity) There is no specific definition of the private information. From Figure 1, it seems that privacy definition is restricted to private identifiable information (PII). The authors should clarify the scope of privacy risks. Importantly, the proposed method cannot address general private information leakage that is considered by strict formulations like differential privacy.\n2. (Quality) The evaluation of privacy is not strict. \n  - Risks: It is possible that the keyword extraction includes private identifiable information (PII), for instance, names and dates as shown in Figure 1. There is no theoretical guarantee for privacy protection or empirical evaluation of the leakage rates of such PII.\n  - Metric: The authors used the privacy budget for quantifying privacy risks:  the ratio of the number of words provided to the LLM to the total words in the original question. However, I doubt if the metric can imply some privacy risks. There essentially lacks an intuitive explanation of the relationship between the privacy budget and privacy risks.\n3. (Motivation) As the authors said, SLM presents a large gap compared to LLMs and thus there is no clear motivation to use SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. In the paper, there is no referred evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks. Thus, I strongly doubt if the motivation of the paper can hold. * There is no clear motivation to see SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. Is there any evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks?",
         "426",
         "0",
         "7",
         "0.7723",
         "55",
         "0.0983912483912484"
        ],
        [
         "47",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_EBQC",
         "1699202302455",
         "1701315616812",
         "6",
         "3",
         "3",
         "3",
         "3",
         "In situations where text data is subject to privacy protection constraints, this paper designs a small-scale language model to perform diagnoses of diseases. Utilizing the rich prior medical knowledge in LLM, the approach involves generating a medical knowledge-intensive context using privacy-protected text. This generated context, along with key terms extracted from the text and questions, is then input into the SLM, which is fine-tuned during training. Experiments across multiple datasets demonstrate that this fine-tuning process effectively enhances the accuracy of the diagnostic model. 1. This paper focuses on a very important research topic in the field of medicine: how to effectively extract more useful information from incomplete text under the conditions of privacy protection. The author has made full use of the domain knowledge in LLM to effectively fine-tune the SLM, which ensures that the lightweight models can achieve high accuracy.\n\n2. This paper presents rich and comprehensive experiments. Beyond basic decision-making tasks, it also explores solutions for few-shot experiments and out-of-distribution (OOD) model generalization using the methods discussed in this paper.\n\n3. This paper fully utilizes the rich domain knowledge in LLMs to expand the knowledge base of medical reports, achieving excellent diagnostic accuracy even while ensuring privacy protection. 1. The contribution of this paper to the algorithm and the significance of the clinical problems it addresses seem not to be very high.\n\n2. The main work of this paper appears more as an engineering problem, transferring domain knowledge from LLMs to SLMs. From the perspective of algorithmic contribution, there seems to be some room for improvement. 1. The experimental datasets in this paper are all question-and-answer test datasets, and whether the methods of this paper are applicable to medical report datasets requires additional experimentation. This is because in medical reports, how to generate high-quality questions using other LLM interfaces is a question worth studying.\n\n2. Large language models provide additional domain knowledge, but in the context of specific medical tasks, will the direct transfer of knowledge from LLMs to SLMs lead to incorrect information leakage into SLMs? How can we ensure that LLMs only enhance information relevant to the current medical issue without introducing additional errors or irrelevant information? This is a very important issue in the medical field, as it directly relates to patient diagnosis.",
         "378",
         "0",
         "7",
         "0.8087",
         "47",
         "0.16517770034843204"
        ],
        [
         "48",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E[x_t^\\top \\eta]>0$, where $E[\\cdot]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9",
         "0.7199",
         "67",
         "0.10480617866981504"
        ],
        [
         "49",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9",
         "0.8034",
         "67",
         "0.04032258064516128"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 28028
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>num_days_before_deadline</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_eS3u</td>\n",
       "      <td>1698243150596</td>\n",
       "      <td>1699636093263</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>This work proposes LSTNet, a self-supervised m...</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>67</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_jP4i</td>\n",
       "      <td>1698652503617</td>\n",
       "      <td>1699636093190</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1) This paper proposes a self-supervised metho...</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>67</td>\n",
       "      <td>0.160185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_wiS9</td>\n",
       "      <td>1698706547448</td>\n",
       "      <td>1699636093122</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper introduces LSTNet, which leverages ...</td>\n",
       "      <td>570</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7698</td>\n",
       "      <td>67</td>\n",
       "      <td>0.095387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_a6Ps</td>\n",
       "      <td>1698768293694</td>\n",
       "      <td>1699636092942</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper attempts to register point cloud pr...</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>67</td>\n",
       "      <td>0.140019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_Frem</td>\n",
       "      <td>1699350072271</td>\n",
       "      <td>1699636092872</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper presents a method of learning dense...</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>67</td>\n",
       "      <td>0.124242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28023</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_vt7i</td>\n",
       "      <td>1698673110283</td>\n",
       "      <td>1699636153803</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper extends the analysis of (Woodworth ...</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>67</td>\n",
       "      <td>0.077504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28024</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_oaZ7</td>\n",
       "      <td>1698928691830</td>\n",
       "      <td>1699636153728</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The paper studies the implicit regularization ...</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>67</td>\n",
       "      <td>0.019907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_fMm6</td>\n",
       "      <td>1698618130371</td>\n",
       "      <td>1699636636496</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The authors propose a network architecture to ...</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7971</td>\n",
       "      <td>66</td>\n",
       "      <td>0.103848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28026</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_tZQw</td>\n",
       "      <td>1698807944071</td>\n",
       "      <td>1699636636378</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper proposes InfoNet, a generalized alg...</td>\n",
       "      <td>346</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>66</td>\n",
       "      <td>0.101576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28027</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_9qjF</td>\n",
       "      <td>1698910414535</td>\n",
       "      <td>1699636636278</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>* This paper presents an innovative algorithm,...</td>\n",
       "      <td>670</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>66</td>\n",
       "      <td>0.135170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28028 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zzv4Bf50RW               1647             1695102158671   \n",
       "1        zzv4Bf50RW               1647             1695102158671   \n",
       "2        zzv4Bf50RW               1647             1695102158671   \n",
       "3        zzv4Bf50RW               1647             1695102158671   \n",
       "4        zzv4Bf50RW               1647             1695102158671   \n",
       "...             ...                ...                       ...   \n",
       "28023    014CgNPAGy               2200             1695179071455   \n",
       "28024    014CgNPAGy               2200             1695179071455   \n",
       "28025    0074qaufB6               5962             1695403263602   \n",
       "28026    0074qaufB6               5962             1695403263602   \n",
       "28027    0074qaufB6               5962             1695403263602   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "1      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "2      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "3      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "4      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "...                                                  ...   \n",
       "28023                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28024                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28025          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28026          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28027          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "1      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "2      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "3      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "4      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "...                                                  ...   \n",
       "28023  On the Role of Momentum in the Implicit Bias o...   \n",
       "28024  On the Role of Momentum in the Implicit Bias o...   \n",
       "28025  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28026  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28027  InfoNet: Missing Information Retrieval in Mult...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Establishing accurate dense 3D correspondences...  Reviewer_eS3u   \n",
       "1      Establishing accurate dense 3D correspondences...  Reviewer_jP4i   \n",
       "2      Establishing accurate dense 3D correspondences...  Reviewer_wiS9   \n",
       "3      Establishing accurate dense 3D correspondences...  Reviewer_a6Ps   \n",
       "4      Establishing accurate dense 3D correspondences...  Reviewer_Frem   \n",
       "...                                                  ...            ...   \n",
       "28023  Momentum is a widely adopted and crucial modif...  Reviewer_vt7i   \n",
       "28024  Momentum is a widely adopted and crucial modif...  Reviewer_oaZ7   \n",
       "28025  Faulty sensors in a multiple input stream setu...  Reviewer_fMm6   \n",
       "28026  Faulty sensors in a multiple input stream setu...  Reviewer_tZQw   \n",
       "28027  Faulty sensors in a multiple input stream setu...  Reviewer_9qjF   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1698243150596           1699636093263              6  ...   \n",
       "1      1698652503617           1699636093190              5  ...   \n",
       "2      1698706547448           1699636093122              3  ...   \n",
       "3      1698768293694           1699636092942              5  ...   \n",
       "4      1699350072271           1699636092872              5  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "28023  1698673110283           1699636153803              5  ...   \n",
       "28024  1698928691830           1699636153728              3  ...   \n",
       "28025  1698618130371           1699636636496              1  ...   \n",
       "28026  1698807944071           1699636636378              3  ...   \n",
       "28027  1698910414535           1699636636278              5  ...   \n",
       "\n",
       "       review_soundness  review_presentation  review_contribution  \\\n",
       "0                     3                    2                    3   \n",
       "1                     3                    3                    2   \n",
       "2                     2                    2                    2   \n",
       "3                     3                    3                    3   \n",
       "4                     3                    3                    2   \n",
       "...                 ...                  ...                  ...   \n",
       "28023                 3                    3                    2   \n",
       "28024                 1                    2                    1   \n",
       "28025                 2                    2                    1   \n",
       "28026                 3                    2                    2   \n",
       "28027                 2                    3                    2   \n",
       "\n",
       "                                            total_review length_words  \\\n",
       "0      This work proposes LSTNet, a self-supervised m...          191   \n",
       "1      1) This paper proposes a self-supervised metho...          215   \n",
       "2      This paper introduces LSTNet, which leverages ...          570   \n",
       "3      This paper attempts to register point cloud pr...          412   \n",
       "4      This paper presents a method of learning dense...          290   \n",
       "...                                                  ...          ...   \n",
       "28023  This paper extends the analysis of (Woodworth ...          356   \n",
       "28024  The paper studies the implicit regularization ...          303   \n",
       "28025  The authors propose a network architecture to ...          544   \n",
       "28026  This paper proposes InfoNet, a generalized alg...          346   \n",
       "28027  * This paper presents an innovative algorithm,...          670   \n",
       "\n",
       "       citation_count  question_count   mattr num_days_before_deadline  \\\n",
       "0                   0               0  0.7074                       67   \n",
       "1                   0               0  0.7009                       67   \n",
       "2                   7              10  0.7698                       67   \n",
       "3                   0               5  0.7920                       67   \n",
       "4                   0               7  0.6900                       67   \n",
       "...               ...             ...     ...                      ...   \n",
       "28023               1               5  0.7166                       67   \n",
       "28024               0               0  0.7945                       67   \n",
       "28025               0               7  0.7971                       66   \n",
       "28026              10               4  0.7788                       66   \n",
       "28027               3               1  0.8585                       66   \n",
       "\n",
       "       sentiment_polarity  \n",
       "0                0.090000  \n",
       "1                0.160185  \n",
       "2                0.095387  \n",
       "3                0.140019  \n",
       "4                0.124242  \n",
       "...                   ...  \n",
       "28023            0.077504  \n",
       "28024            0.019907  \n",
       "28025            0.103848  \n",
       "28026            0.101576  \n",
       "28027            0.135170  \n",
       "\n",
       "[28028 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_sentiment_polarity(review_text):\n",
    "    review_text = review_text.strip()\n",
    "    try:\n",
    "        blob = TextBlob(review_text)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "    except Exception:\n",
    "        sentiment = \"\"\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "df_reviews['sentiment_polarity'] = [\n",
    "    compute_sentiment_polarity(row['total_review']) for row in tqdm(df_reviews.to_dict('records'), desc=\"Processing reviews\")\n",
    "]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to a different JSON file\n",
    "out = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_ICLR2024_v5.json'\n",
    "df_reviews.to_json(out, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_days_before_deadline",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "37409b65-5c4c-4a1d-b2ff-e039f4e293ce",
       "rows": [
        [
         "0",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_eS3u",
         "1698243150596",
         "1699636093263",
         "6",
         "2",
         "3",
         "2",
         "3",
         "This work proposes LSTNet, a self-supervised method to establish reliable 3D dense correspondences irrespective of the input point clouds’ rotational orientation.\n\nSpecifically, LSTNet learns to formulate SO(3)-invariant local shape transform for each point in a dynamic, input-dependent manner. Each point-wise local shape transform can map the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor, which is passed to the decoder to reconstruct the shape and pose of the input point cloud. \n\nThe proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish dense point-wise correspondences via nearest point pairs between cross-reconstructed point clouds. The self- and cross-reconstruction training strategy is simple yet effective. \n\nLSTNet demonstrates state-of-the-art performance on 3D semantic matching when evaluated on the KeypointNet dataset and part segmentation label transfer when evaluated on the ShapeNet dataset. The performance of aligned shape pairs under the setting of I/I shows that other methods, such as CPAE, are much better than LSTNet. The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.\n\nLack of limitations.",
         "191",
         "0",
         "0",
         "0.7074",
         "67",
         "0.09"
        ],
        [
         "1",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_jP4i",
         "1698652503617",
         "1699636093190",
         "5",
         "4",
         "3",
         "3",
         "2",
         "1) This paper proposes a self-supervised method to find semantically corresponding points for a point cloud pair;\n\n2）The main idea is to decouple a point cloud feature learning process into a SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms;\n\n3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method. 1) This paper is generally well-written;\n\n2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant\npoint-wise local shape transforms seems to be novel;\n\n3) Experimental results are good. 1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset. \n\n2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation. \n\n3) The running time and GPU memory cost is blurry for me;\n\n4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation\nfrom Rotated, Noisy, and Decimated Point Cloud Data]. Please refer to the weaknesses.",
         "215",
         "0",
         "0",
         "0.7009",
         "67",
         "0.1601851852"
        ],
        [
         "2",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_wiS9",
         "1698706547448",
         "1699636093122",
         "3",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces LSTNet, which leverages an SO(3)-equivariant encoder-decoder architecture(Vector Neuron Networks, VNNs) and proposes a novel function called local shape transform to further transform the learned features. The proposed method is validated on both the 3D keypoint transfer and part segmentation label transformer tasks. 1. The idea of cross-reconstruction for generating inter-object correspondences in a self-supervised way is interesting;\n\n2. The overall writing is good and the methodology part is well-organized and easy to follow. 1. The novelty of this work seems insufficient for ICLR. The whole pipeline heavily relies on VNNs and the main contribution I personally consider is the local shape transform and the self-supervised mechanism for correspondences.\n\n2. Regarding the local shape transform:\n   2.1. From 3.1.1, the SO(3)-invariant output is $\\mathbf{V}\\mathbf{U}^T \\in \\mathbb{R}^{C \\times C}$, while in 3.1.2, the obtained SO(3)-invariant features $\\mathbf{V} \\in \\mathbb{R}^{C^\\prime \\times 3 \\times N}$ have a different shape;\n\n   2.2 The authors claimed that the local shape transform transforms the global features to local ones. Regarding this, I have two questions. \n\n      2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer. \n\n      2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the \"global\" features by such a mechanism, the features turn to \"local\"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so)\n\n3. Regarding the experiments:\n    3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments;\n\n     3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.\n\n    3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.\n\n   3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?\n\n4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.\n---------------------------------------------\n[1]. Zohaib et al. SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data, ICCV 2023;\n\n[2]. Dent et al. PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors, ECCV 2018\n\n[3]. Ao et al. SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration, CVPR 2021\n\n[4]. Wang et al. You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors, ACM MM 2022\n\n[5]. Yu et al. Rotation-Invariant Transformer for Point Cloud Matching, CVPR 2023 See weaknesses.",
         "570",
         "7",
         "10",
         "0.7698",
         "67",
         "0.0953869048"
        ],
        [
         "3",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_a6Ps",
         "1698768293694",
         "1699636092942",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper attempts to register point cloud properties to their templates without precise correspondences and exact shape matching. To achieve this, the authors trained a local shape transform (LST) network that produces SO(3) invariant correspondences. The training is self-supervised. The experimental results on ShapeNet look nice. - Valid motivation. Unlike the abused topic, vanilla point cloud registration, the motivation stands and could potentially benefit practical usages.\n- The SO(3)-invariant network design intrinsically ensures robustness against rotations.\n- The joint usage of a global descriptor and a local descriptor makes sense and may help with classification and recognition directly.\n- The self-supervision scheme looks plausible by self and cross-reconstruction. My major concern is with the experimental setup. While the experiments on ShapeNet is common in the community and shows good result, I am in general doubtful whether such an approach could be really applied to the real world. \nIn motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. [Scan2CAD, CVPR 2019]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases. \n\nThe authors also take groundtruth keypoints and semantic segmentations from datasets for the experiments. In the real-world, however, obtaining such accurate high-level semantic information already requires a deep understanding of the point cloud, and its segmentation backbone may already be SO(3) invariant. This impairs the strength that the authors proposed. Following my points in the \"weaknesses\" section, I am curious about several relevant problems in the practical setup (i.e., scan to model). \n1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity? \n2. Will the network still be functional if the density distributions are different across input and output? \n3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?\n4. Would non-gt and/or biased key points and semantic parts be transferred properly?\n\nIt would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.",
         "412",
         "0",
         "5",
         "0.7920",
         "67",
         "0.1400193798"
        ],
        [
         "4",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_Frem",
         "1699350072271",
         "1699636092872",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a method of learning dense 3D correspondence between shapes in a self-supervised manner. Specifically, it is built on an existing SO(3)-equivariant representation. The input point clouds are independently encoded to SO(3)-equivariant global shape descriptor Z and dynamic SO(3)-invariant point-wise local shape transforms. Then the network is trained via penalizing errors in self- and cross- reconstructions via the decoder. The experiment validates the effectiveness of the proposed method. 1. The paper is in general well organized and easy to follow. \n2. The proposed method is straightforward and shown to be effective on the test data. 1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method. \n2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.\n3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?\n4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design. Please refer to the Weaknees part.",
         "290",
         "0",
         "7",
         "0.6900",
         "67",
         "0.1242424242"
        ],
        [
         "5",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_xDut",
         "1698437142685",
         "1699636121514",
         "8",
         "5",
         "4",
         "4",
         "3",
         "This paper is about multilingual federated prompt tuning for low-resource languages, bringing together federated learning and prompt-tuning techniques. This approach leverages parameter-efficient fine-tuning which preserves user privacy, and additionally, the authors introduce language distance in order to highlight the strengths of the proposed paradigm. The results show that the technique is parameter efficient and computationally beneficial, reducing by 99% the number of trainable parameters while increasing the performance on downstream tasks (XNLI, NC) of ~7% accuracy. This paper makes a contribution to the federated learning field showing how federated learning can be used to enhance the performance of language models while preserving user privacy. The experiments are well-designed and the results are convincing - added to extensive analyses in order to leverage the capabilities of the proposed paradigm, but also its limitations. Although the paper is generally well-structured, the title mentions `low-resource` languages. However, the two tasks leveraged are primarily on high-resource languages, rather than low-resourced language. I would suggest to the authors to include more tasks - there are many low-resource language datasets (for instance on African languages MasakhaNEWS, Masakhaner (1.0 and 2.0 - which have been cited by the way but not used), MasakhaPOS; Indic languages: https://github.com/AI4Bharat/indicnlp_catalog; etc) and tasks.\n\nThis is rather a highly recommended suggestion, that does not take away the contribution of the paper. Including them would strengthen the paper and be more in accordance with the title. The Aggregation formula is a bit confusing. Did you mean h_{global, t+1} = \\sum_{k=1}^{m} h_{k, t}? Because the `t+1` on the last term does not make sense to me.",
         "262",
         "1",
         "0",
         "0.7963",
         "67",
         "0.1664583333"
        ],
        [
         "6",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_E7Lk",
         "1698484432194",
         "1700794322411",
         "1",
         "5",
         "1",
         "2",
         "2",
         "The paper introduces a finetuning paradigm that combines federated learning (FL) with prompt tuning for multilingual finetuning on certain, with the goal to preserve the privacy of the local data used for the finetuning job. The results show better performance in certain classification tasks, such as New Classification and XNLI. - Federated learning have recently gained good traction, the paper is a good application of it in the tasks of finetuning LLM. The paper chooses to use prompt tuning instead of full tuning to save costs, as well as to avoid overfitting on small data.\n- The method produces better performance on the 2 classification tasks compared to baselines - The proposed is a very trivial combination of federated learning and prompt tuning, which both are established methodology in their own realm. There is no novelty, such as modification or adjustment to the method that may have give a better results. In other words, people with an objective to do federated learning for privacy purpose can easily come up with prompt tuning as a solution to reduce costs.\n- Though it may have implicitly inferred by the concept of FL, the paper did not mention why and how federated learning helps with privacy and in which case one should use FL for their application.\n- The purpose of the task of multilingual finetuning in this case, is not warranted use case of privacy preservation.\n- There is no reported evidence that privacy is actually preserved. Such as whether the final model memorize the local data.\n- There are better parameter-efficient finetuning methods, such as LORA/QLora, that the authors should conduct experiments on and do comparision with prompt tuning.\n- The results show prompt tuning are much worse than full-federated tuning, thus casting doubt if the cost-saving is worth it.\n- Other generative and knowledge-based tasks, such as QA, translations and summarizations should be performed.\n\n**I have read the author responses and I advocate for a strong reject, below are reasons:**\n\n* I mentioned the paper has fundamental problems with originality, novelty, where the paper uses an unrelated existing and non-novel method designed for a different problem (fed-learning) to solve a low-resource \"privacy\" problem that does not make sense or exist yet, in which the method itself much worse than standard training. \n* Instead of addressing the scientific issue, the authors distracted away by pressing that they are helping the low-resource communities, or improving inequality as a societal issue. These multiple responses are lengthy, wordy, unnecessary, and filled with many \"politically correct\" (I don't know better word) things to avoid the scientific issue. Agree that we should help those under-represented communities, but after reading these, I shouldn't feel like rejecting the paper is an action against those communities.\n* The problem of \"a low-resource community who wants to shut down their internet and border\" is unfounded. We train LLM on public data we can find. If they wants to protect their secret data, they can download a public pre-trained model and fine-tune on their own. \n* The real problem is how to improve low-resource with the limited data we have, which the paper fails to suggest a better solution than trivial.\n* Less communication doens't mean more privacy, because we transfer model weights, not the data. And less parameters doesn't mean less private information be leaked. This misconception leads to wrong approach.\n* The author claims to be the first to target the low-resource problem and many other things, but there have been many works in previous years about this. Please be careful with this kind of \"we are first\" statements.\n* Overall, none of the responses has helped resolve the issues stated in the review. - Citation formet incorrect, \\citep{} be used to produce something like (Abc, et al., 2023) and not Abc, et al., 2023 everywhere.\n- Many grammatical errors, such as \"Throughout the fine-tuning...\"\"",
         "646",
         "0",
         "0",
         "0.8297",
         "53",
         "0.1105421563"
        ],
        [
         "7",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_AG4r",
         "1698731849876",
         "1700723834276",
         "3",
         "4",
         "4",
         "1",
         "3",
         "The paper proposes a Multilingual Federated Prompt Tuning paradigm, where lightweight multilingual prompts are encoded and on regional devices in different languages and aggregated by averaging the prompt embeddings. The goal is fine-tuning multilingual large language models on resource-constraint devices in a privacy-preserving way. The paper evaluates this approach via the XNLI task, ablated into data efficiency, \"language distance\", and communication cost, against \"monolingual\" training (baseline). The innovation lies in that the paper somehow mashes federated learning, multi-lingual (low resource) language models, and Parameter-Efficient Fine-Tuning in one paper. The fact that they managed to come up with a storyline for a system that bolsters the benefit of each approach is commendable. - poor presentation: the citations are not separable enough from the main text, e.g., without any parenthesis, rendering the submission unreadable. Against the tradition and ease of reading, abbreviations are not defined in advance, e.g., NLI, PFL, PLM.\n- claims unverifiable: no code release.\n- conflating existing metrics with innovation: language distance is not a new concept.\n- conceptual weakness: the contrived baseline was bound to give the proposed approach an edge due to lack of federated learning. Also, what the paper refers to as prompts are just classifier model input, which are different from decoders-style LLM prompts as commonly acknowledged. Finally, the approach has absolutely nothing to do with privacy which the abstract and the main body consistently bolsters. \n- evaluation weakness: only two tasks (new classification and XNLI) was used in evaluation. In section 5.4.1 \n\n>  In both the NC and XNLI tasks, despite the total number of\nparameters exceeding 278 million, the trainable parameters are only around 1.2 million, accounting\nfor less than 0.5% of the total.\n\nCould the authors clarify which part of the model is being fine-tuned?",
         "293",
         "0",
         "0",
         "0.8387",
         "54",
         "-0.0202793239"
        ],
        [
         "8",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_LsRx",
         "1698767055794",
         "1700887244625",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The paper applies federated learning on multilingual scenarios to efficiently parameter-efficient prompt fine-tuning in a manner that preserves user privacy. The idea is to utilize a single global encoder that accumulates the information via federated prompt averaging. Thus, it learns the language patterns without knowing about the user information. They evaluated the experiment on NC and XNLI datasets and found performance improvement over the baseline. - The method is very practical since it is simple and efficient, and it is an appropriate method for training multilingual model.\n- Good analysis on the data efficiency and distance measurement, showing the effectiveness of the proposed method. - In terms of novelty, the proposed idea is not new, and it is only a further investigation of the multilingual setting.\n- Lack of clarity. The paper does not provide enough information about how the prompts are constructed or look like and hyperparameters for all settings. I suggest adding the information to the paper or appendix. Questions:\n- Do you have any findings on why multilingual centralized learning is far worse than federated learning in Table 2?\n- How did you tune the training and parameter averaging?\n\nSuggestions:\n- Figure number is missing on Page 2\n\n\"As depicted in Figure , \"\n\n- Missing Figure/Table \n\n\"This translates to over 99% reduction in the communication overhead shown in 3\"\n\n- Typo\n\n\"Finetuning accuracy across different lanugages on the NC task.\"",
         "234",
         "0",
         "0",
         "0.7573",
         "52",
         "0.0373593074"
        ],
        [
         "9",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_agCZ",
         "1698322956814",
         "1699636820093",
         "5",
         "3",
         "2",
         "2",
         "2",
         "To tackle Multi-Domain Text Classification (MDTC) task, one mainstream of proposed techniques is to extract the features via the shared and private extractors to capture the domain-invariant and domain-specific knowledge, respectively. However, as the number of domains increases, the count of their private extractors will also rapidly surge.  \nThe author proposed a novel approach Stochastic Adversarial Network (SAN) to avoid the unaffordable explosion of parameters when encountering the newly emerged domains. Specifically, the author modeled the domain-specific feature extractors as a multivariate Gaussian distribution. Furthermore, some tricks, such as domain label smoothing and robust pseudo-label regularization techniques, are utilized to improve the overall performance.\nExtensive experiments on two benchmarks demonstrate the superiority of the proposed method compared with the state-of-the-art baselines. 1.\tThis paper proposes a novel approach, called Stochastic Adversarial Network, to reduce the computational cost while meeting a large amount of domains.\n2.\tThis paper originally employs Gaussian distribution to generate private extractors in order to circumvent the extensive parameters found in previous works. \n3.\tThis paper conducts numerous experiments to show the effectiveness of the proposed scheme. Moreover, the parameter sensitivity and ablation study demonstrate the rationale of parameter selection and the necessity of each modules, respectively. 1.\tThe motivation is trivial. It is hard to say that the model size is the bottleneck of the training process according to Table.1 and 9. 342.91M is absolutely fine in current period. Further, inference process may gain nothing in the aspect of computational acceleration as we only choose one private extractor from the Domain Discriminator D. \n2.\tThe baselines are outdated and improvements on two benchmarks are limited. According to Table 2,3 and 4, it can hardly convince me that the proposed model exactly outperforms the SOTA models. It is worth noting that the author points out this limitation in Appendix E. \n3.\tThe writing and organization need to be improved. \na)\tThe emphasis in writing has been misplaced. As the author highlights the role of multivariate Gaussian distribution in Abstract, you are supposed to tell more story of it instead of the regularization term, which is the idea of others.\nb)\tThe effectiveness is not the focus of this article, efficiency is. Therefore, moving D. 5 to the main body of the article perhaps make your contribution more prominent. \nc)\tSome tools can be utilized effectively to optimize sentence structure and composition. 1.\tThe aim of equation (3) is to ensure that the shared Feature Extractor F_s exactly extract the domain-invariant features. Thus the author maximum this loss to let the discriminator D be confused about the features coming from F_s. Here is the question: discriminator D may lack of capabilities to recognize the difference among domains as this loss function does not involve any domain knowledge.\nThere may exists another adversarial network in equation (3), i.e. domain-specific extractor enhances the capabilities of discriminator D and domain-invariant extractor still confuse the discriminator D. \n2.\tAs a classic NLP task, this method inevitably needs to be compared with chatgpt. Currently, chatgpt has shown remarkable zero-shot capabilities. Therefore, you need to convince the reviewers why your method should be used instead of chatgpt or highlight the scenarios in which your method has significant advantages.",
         "534",
         "0",
         "5",
         "0.7784",
         "66",
         "0.09682159950000001"
        ],
        [
         "10",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_NpVu",
         "1698685251472",
         "1699636819980",
         "1",
         "4",
         "1",
         "3",
         "1",
         "The paper presents a new model for MDTC, built on the previous shared-private feature extraction architecture. The innovation includes 1) modelling the parameter of domain-specific feature extractors as a Gaussian random variable, and for each domain, the parameter is drawn from the distribution. This is why the model is called stochastic adversarial network, or SAN, 2)  domain label smoothing 3) pseudo labelling regularization.  The authors show some empirical successes on some datasets. The paper demonstrates that the authors are well aware of the challenges in MDTC and are familiar with various tools in deep learning (such as reparametrization trick, label smoothing, pseudo labelling etc). I have some concerns about this work.\n\n1. Assuming the design of proposed model is sensible (in fact I have doubts on this; see 2), the work heuristically puts together a bunch of well-known techniques to improve performance. Works of primarily such a nature, although potentially valuable in practice, do not possess enough novelty that justifies a publication in ICLR. \n\n2. I have doubts on the proposed approach in the \"stochastic\" part. Let us track the parameter $W_1$ of the domain-specific feature extractor for domain 1. In the beginning it is drawn from the prescribed Gaussian, say, its value is $W_1^{(0)}$, and after the first iteration, the Gaussian parameter gets updated (using the reparametrization trick)  -- well, whether Gaussian parameter is updated or not is not critical here. Then in the next iteration, $W_1$  is drawn again, let us call it $W_1^{(1)}$. If this understanding is correct, then $W_1^{(0)}$ and $W_1^{(1)}$ can be very different. That is, along the training process, $W_1$ will randomly hop everywhere as long as the Gaussian variance is not vanishing. How would such a scheme work at all? Bringing the parameter $W_2$ of the second domain-specific extractor into the picture would show an even more absurd picture: at each iteration $t$, $W_1^{(t)}$ and  $W_2^{(t)}$ are random variables following the same Gaussian distribution. How would $W_1$ and $W_2$ track their respective domain specific features?  If this structure were to work, it would have to be the case where the Gaussian variance is very small (which might be the case as shown in Figure 3 of the appendix). In that case, all domain-specific extractors are more or less the same, i.e, all equal to the Gaussian mean, only subject to some tiny *domain-nonspecific* random perturbation. That would defeat the entire purpose of having domain specific feature extractors. -- I could misunderstood the paper and I am willing to hear the authors' defence on this. In your defence, please also show the initial and final values of the Gaussian mean vector $\\mu$ (say, in terms of its L1-norm divided by its dimension), I would like compare it with $\\sigma$. See weakness 2.\n\nAdditional question: The authors say that the conventional shared-private adversarial scheme will have \"exponential increase\" in model parameters as new domains emerge? Why is it exponential?",
         "484",
         "0",
         "3",
         "0.7855",
         "66",
         "-0.0365584416"
        ],
        [
         "11",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_bAwA",
         "1698806204960",
         "1699636819830",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper tackles the multi-domain text classification (MDTC) problem, and tries to minimize the amount the learning parameters by introducing a stochastic feature extractor (domain feature). The model is effective in handling the benchmark datasets and outperform the other baseline models. Additional multi-source UDA experiment is also conducted as a simple model extension. The proposed model performs strong in the benchmark dataset, with minimized learning parameters. The design of using both shared/private feature extractor is interesting and effective in merging the domain in the latent space. The proposed method is straightforward and easy to understand. 1. Though the proposal seems to be effective and achieving strong performance, the model itself still uses a relative old adversarial backbone, with the discriminator approach for removing the domain invariant feature. The two-feature-extractor approach is interesting, but that is mainly to deal with parameter increase in the MDTC problem. It would be great to see other design improvement in the model.\n2. The performance gain in using the proposed model is marginal on the Amazon review/FDU-MTL datasets. Also, it would be great to have some analysis on adjusting the setting between the two feature extractors. 1. This might be somewhat irrelevant, but would the model perform well in multi domain classification in other domain type(s), e.g., images?",
         "213",
         "0",
         "3",
         "0.7456",
         "66",
         "0.26833333330000003"
        ],
        [
         "12",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_skmj",
         "1698632081062",
         "1701140370231",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper studies multi-modal generalization in neural networks such as transformer-based models and recurrent networks. To do so, the authors propose Genertic COG, a modular benchmark with multi-modal splits to test for 3 types of generalization: 1) distractor (generalization to different noise distribution), 2) systemic compositional (generalization to new permutation of task structures) and 3) productive compositional (generalization to tasks of greater complexity) generalization. Experiments conducted by the authors showed that while cross-attention based transformers (e.g. CrossAttn and Perceiver) outperform other models and perform well on distractor and systemic compositional generalization, they fail at productive generalization when the depth of the task tree goes to out-of-distribution (>3). Representational analysis is done to show that cross-attention based transformers (e.g. CrossAttn and Perceiver) superior performance on distractor generalization might be due to their ability to better retain task-relevant (e.g. stimulus and response) information at the penultimate layer. +The paper studies a timely and critical question about the generalization capability of multimodal transformer-based models\n\n+The proposed benchmark dataset uncovers a limitation of current multimodal transformer-based models: productive generalization which can facilitate the development of more generalizable transformers/LLMs. \n\n+The paper is generally well-written and easy to follow -While the paper’s studies show that certain designs (e.g. cross-attention) seem to confer multi-modal generalization, there are still some key questions that can be more thoroughly studied to uncover the reasons why this is the case.\n\n-Similarly, important discussions such as why the (cross-attention) transformers might fail at productive generalization is lacking. What is the key architectural difference between dual stream transformer and transformers with cross attn that can explain their generalization performance? Is it only the lack of a cross attention between the different modalities?\n\nPossible typo:\n“Finally, we included a Perceiver-like model (Jaegle et al., 2021), an architecture designed to generically process multimodal inputs (Fig. 2f).”:  (Fig. 2f) > (Fig. 2e).\n\n\n==Post-Rebuttal==\nI appreciate the authors' response and decided to keep my score.",
         "318",
         "1",
         "3",
         "0.8097",
         "49",
         "0.0690708101"
        ],
        [
         "13",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_a4Su",
         "1699400405601",
         "1699636123172",
         "3",
         "3",
         "1",
         "2",
         "2",
         "This paper proposes a new benchmark for assessing various forms of generalization in a multimodal setting named gCOG. The dataset includes several different splits intended to measure different aspects of generalization. The paper also compares several different model architectures on the dataset. * The paper introduces a new dataset, gCOG. While the dataset is conceptually similar to those from prior work, such as gSCAN, it supports different types of contexts and instruction types, including more compositional instructions. I'm aware of some prior work (e.g. [1], [2]) that studied compositional generalization in natural language tasks and found that gains on one synthetic task did not always transfer to other tasks, so increasing the diversity of such benchmarks for assessing compositional generalization and related challenges in the multimodal setting could be a potentially valuable contribution.\n\n[1] https://arxiv.org/abs/2007.08970\n[2] https://aclanthology.org/2021.acl-long.75/ * I'm concerned about the strength of the baselines used in the paper (see my related questions below). While the primary contribution of the paper is the dataset, it is also important to establish strong baselines for this new dataset and to ensure that the conclusions from the empirical results are valid. The appendix states that only a *single Transformer layer* with a *single attention head* was used. This is almost certainly not an optimal depth and number of attention heads. Relatedly, it looks like some models are potentially underfit, according to the figures. With >5M training examples and a relatively simple input space, I would have expected a reasonably sized Transformer model to achieve low training loss and reasonable IID generalization. If these models could have been applied to similar tasks such as gSCAN (even using symbolic tokens to represent the scene context), where they could be compared with comparable baselines from prior work, this would have helped establish that these are indeed reasonably strong baselines that have been well tuned.\n* The qualitative difference between gCOG and datasets from prior work such as gSCAN was not very clearly described. For example, one of the key claims seemed to be gCOG \"employs generic feature sets that are not tied to any specific modality\". However, it seems like it is a useful property for a multimodal dataset to have a clear relation to real-world multimodal tasks. Indeed, the authors provide interpretations of their tasks in the form of natural language instructions and visual scenes (e.g. in Figure 1), and these are very useful for understanding the task. Representing this dataset using familiar modalities (e.g. vision, natural language) could enable future work to study different research questions, e.g. the impact of pre-training. The ability to alternatively represent the task input as a sequence of tokens is also reasonable for studying certain research questions, but this also seems possible for datasets from prior work. For example, I understand that gSCAN includes both symbolic descriptions as well as visual renderings. Anyways, I think clarifying the motivation for this dataset (e.g. increasing diversity of available benchmarks, focusing on different generalization challenges, etc.) separately from how inputs are represented for the experiments in this paper (e.g. token sequence vs. images and natural language) would be useful.\n* Some of the main empirical conclusions (e.g. that generalization to greater \"depth\" is challenging for models such as Transformers) are generally known from prior work.\n\nnits:\n* Introduction paragraph 1 - \"on a carefully controlled generic multimodal reasoning tasks\" -> \"on carefully...\" or \"...task\"\n* Appendix A.2.1 - Maybe reference Tables 8 and 9 where you discuss different positional embeddings.\n* Consider discussing [3] in related work. [3] demonstrated the importance of cross-modal attention for gSCAN, and similarly studied the relative difficulty of various aspects of generalization, including distractors.\n\n[3] https://aclanthology.org/2021.emnlp-main.166/ * Why not try more layers and attention heads, e.g. following a standard hyperparameter setting for model size such as those of BERT-Base? Or even BERT-Small?\n* In Figure 2 (F) why does the single-stream Transformer have almost double the parameters of the double stream Transformer? For the other Transformers, do the encoder blocks used for the task vector and stimulus vector share parameters? \n* What optimizer and hyperparameters (e.g. learning rate) were used for training? How were these chosen? I didn't see these details in Appendix A.2. \n* Position embeddings - Since you are representing 10x10 grids as 1D sequences, 1D relative positions may not capture this structure well. On the other hand, absolute position embeddings seem potentially problematic in the case of the SSTrfmr model, since they will not be consistently assigned to the same grid position if the text sequence is first and has varying length. Mitigating this may be important to provide for a fairer comparison with the SSTrfmr model.\n* To what do you attribute the periodic loss spikes during training that are shown in Figure 4 (E)?\n* I found the usage of \"cross-attention\" a bit confusing. For example, the single stream Transformer features cross-modal attention as an implicit consequence of self-attention over the concatenated sequence. I thought this would commonly be referred to as an instance of \"cross-attention\" between modalities. \n* Does the dataset also contain visual renderings and natural language instructions to enable future work to study these tasks using familiar modalities?",
         "860",
         "10",
         "1",
         "0.8184",
         "67",
         "0.076096273"
        ],
        [
         "14",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_DJb6",
         "1699470958350",
         "1699636122858",
         "8",
         "4",
         "3",
         "3",
         "3",
         "The paper introduces a new multimodal question answering benchmark for out-of-distribution generalization, specifically covering task compositionality, robustness to distractors and combinatorial generalization. It uses this benchmark to evaluate various models and analyze their performance. - **Topic**: The paper studies an important topic which in my opinion is underexplored in current deep learning research. Especially given the tendency these days to scale training up to vast amounts of data, I believe it is particularly important to design carefully controlled benchmarks that can: evaluate the model’s performance from a critical and cautious standpoint, point to their fundamental limitations (e.g. systematic generalization), and support further research about ways to overcome these.  \n- **Evaluation**: The paper offers both extensive extrinsic evaluation, with performance comparison of various models on the different generalization skills, as well as intrinsic analysis of their internal representations’ degree of alignment to the stimuli.\n- **Clarity**: The writing quality is good and the paper is clear and easy to follow. The paper is well-organized, claims and findings are clearly stated, and useful figures and diagrams are provided.\n- **Related Works**: It does a good job in providing the relevant context, motivation and related works. \n- **Contribution**: The empirical findings of the paper on the benefits and limitations of different inductive biases such as recurrent and attention-based are important and may be of broad interest to the community. - **Pre-trained models** The paper focuses on models trained from scratch rather than pre-trained. This could be a strength and a weakness. On the one hand, it allows for isolating the contribution of the architectural choices from other factors of optimization, and training data. On the other hand, it has been observed that by training models at large enough scales enables the emergence of generalization capabilities, which we don’t see in smaller scales. I think it will be critical to also analyze the performance of pretrained models on the benchmark, in order to strengthen the paper.\n- **Visual Simplicity**: The visual side of the benchmark is quite rudimentary, featuring colorful letters. Extending it to a larger range of visual tokens/objects, that could have more than one property (color), and a broader set of elements and variations (than 26 letters), could be a straightforward extension that could help make it a bit more challenging visually. - **COG task**: It will be useful to discuss the COG task (rather than just mentioning it) before describing the new gCOG one, so that it will be clearer to the reader what are new contributions of the new benchmark compared to COG and the degree of their importance. In the overview diagram I would also recommend showing a sample also from COG to make the differences clearer. \n- **Grid size / generalization**: It could be interesting to vary the size of the grid in training/evaluation and study its impact on model’s performance. \n- **Terminology**: I recommend changing the phrase “Distractor generalization” to one that better conveys it’s about changing the answer distribution. Maybe e.g. answer distribution shift. I also recommend changing the name “Systematic compositional generalization” to “combinatorial generalization”, to emphasize that the main point is the generalization to permutation, and also to better contrast it with the following “Productive generalization” (which could also be systematic).\n- **Figures**: Would be good to increase the size of the plots in Figure 3b. It will also be good the increase the distance and visual separation between the sub-figures in each figure throughout the paper. \n- In the introduction: “multimodal question-answer” -> “answering”.\n- “This design allowed us” -> “This design allow us”.",
         "591",
         "0",
         "2",
         "0.7407",
         "67",
         "0.1749524183"
        ],
        [
         "15",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2",
         "0.8079",
         "67",
         "0.1061594203"
        ],
        [
         "16",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head [1], [2], [3]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works [1][2] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n[1], Frozen clip models are efficient video learners, ECCV-2022\n\n[2], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n[3]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0",
         "0.7694",
         "67",
         "0.0820393375"
        ],
        [
         "17",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7",
         "0.8374",
         "67",
         "0.0525974026"
        ],
        [
         "18",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0",
         "0.7506",
         "67",
         "0.3529761905"
        ],
        [
         "19",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_5Cgw",
         "1697885084973",
         "1699636148336",
         "3",
         "5",
         "3",
         "2",
         "2",
         "The study puts forward a VAE-based approach to acquire disentangled representations without the need for supervision. In this framework, it assumes that diverse data samples exhibit variations across multiple factors, making it particularly well-suited for real-world datasets. The newly proposed technique, referred to as CFASL, introduces a range of unsupervised loss components that serve to instill \"inductive biases.\" These include parallel and perpendicular loss terms, in addition to a sparsity loss designed to encourage alignment along factor axes. The outcomes of this study illustrate the method's superior performance when compared to various other unsupervised disentanglement VAEs, both under single-factor and multi-factor alteration scenarios, across multiple widely used benchmark datasets. 1. The paper represents a significant stride in enhancing the practicality of disentanglement techniques within the realm of real image domains. It grapples with a formidable challenge where we cannot presume access to images that solely vary in a singular factor, thereby intensifying the complexity of extracting disentangled representations.\n\n2. The quantitative findings not only exhibit enhancements in the primary focus of this study, which is the alteration of multiple factors, but also in the scenario involving changes in a single factor. 1. The proposed approach incorporates a diverse array of loss terms within its training objectives, with each term potentially making a distinct contribution. However, this diversity comes at the expense of imposing significant assumptions on the underlying image distribution. While I acknowledge that these assumptions may be justified within the context of the datasets considered in this paper, it's worth noting that some metrics, such as DCI, do not unequivocally demonstrate superiority in the ablation study presented in Table 2.\n\nNevertheless, I believe that the paper could benefit from a more comprehensive exploration of the limitations stemming from these strong assumptions. It would be valuable for the authors to provide concrete examples where these assumptions result in unintended or adverse outcomes. Even for an unsupervised setting, it remains crucial to take into account the nature of transformations within the image domain. A more explicit discussion of these assumption-related limitations would substantially bolster the significance of the claims advanced in this paper, in my view.\n\n2. The qualitative results exhibit low image quality. While this is common across unsupervised disentanglement methods, it is really challenging to get convinced that better disentanglement is achieved. It would be valuable for the author to consider domain-specific metrics for the evaluation phase e.g. face identity loss, facial expression classification, head pose regression, etc. to assess whether only a specific attribute is altered during the single factor change experiments. 1. Following the weaknesses mentioned above, could the authors provide concrete examples (other datasets) where the assumptions induced by the loss terms result in unintended or adverse outcomes compared to the baseline beta-VAE?\n\n2. Could the authors please provide the ablation study results of the different loss terms for all datasets considered in the paper (and not only 3D-Cars)?",
         "483",
         "0",
         "7",
         "0.8442",
         "67",
         "0.138866012"
        ],
        [
         "20",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_oACj",
         "1698758328711",
         "1699636148260",
         "5",
         "3",
         "3",
         "1",
         "2",
         "The authors introduce a new VAE architecture which operates on pairs of inputs and utilizes a set of regularization terms to induce structured disentanglement of the latent space with respect to observed symmetry transformations between examples in these pairs. The authors show that their model indeed achieves higher disentanglement scores than relevant baselines on a variety of datasets with a variety of different metrics. Specifically, the authors target the 'multi-factor change' regime, and demonstrate improved performance in this setting with their newly introduced metric. - The related work is well covered, and the authors position their method well in the literature.\n- The proposed combination of losses appears novel to the best of my knowledge, and the use of parallelism and orthogonality losses specifically on latent transformations is an interesting and exciting idea. \n- The study of disentanglement with respect to multiple simultaneously changing factors is important and interesting, and the authors make a notable contribution to this direction.\n- The results appear promising, and indicate that the model is performing well with respect to the baselines. \n- The methodology and extended results in the appendix appear sound. The calculation of P-values in the appendix is very important and appreciated. Furthermore, the use of an ablation study to validate their proposed model is a welcome addition. Weaknesses summarized:\n- The paper is challenging to read as the english is quite poor and the logical flow of the work is unorganized.\n- The method itself is composed of a wide variety of loss terms and the intuition or reasoning for why these terms are necessary is not provided. (Specifically for the parallel and perpendicular losses).\n\nIn more detail:\n\nWeakness 1:\nThere are many typos and poor grammar throughout the paper, with many sentences simply not making much sense. I include a few examples below, but there are many many more and the authors should have someone proof read this work more carefully:\n- In the abstract: \"We propose ... (CFASL) on VAEs for the extension to [a] general multi-factor change condition without constraint.\" \n- \"To implement  group equivariant VAE, Winter et al. (2022); Nasiri & Bepler (2022) achieve the translation and  rotation equivariant VAE\"\n- \"For the equivariant encoder and decoder, we differently propose the single forward process by the  encoder and decoder objective functions compared to previous work (Yang et al., 2022).\"\n- \"Differently, we induce disentanglement learning  with group equivariant VAE for inductive bias.\"\n- 'The unsupervised learning work (Winter et al., 2022) achieves class invariant and group equivariant  function in less constraint condition.'\n\nWeakness 2: \nNaming is extremely unclear. For example, what are 'sections' referred to in Section 3.2? How do these differ from factors? \n\nWeakness 3: \nDespite appealing to a precise probabilistic generative model as its primary value and distinction from prior work, the model itself could be made significantly more elegant in the context of generative models. For example, the 'factor prediction' mechanism could be integrated as a component of the generative model and inferred with another approximate posterior, as done in prior work (Song et al 2023).\n\nWeakness 4:\nThe discussion of learning the Lie algebra is quite rushed and the intuition for why the large set of different loss terms should be incorporated is largely missing.\n\n[1] (Song et al. 2023) https://arxiv.org/pdf/2309.13167.pdf Question 1:\nThe point that prior work with autoencoders does not extend to VAE's does not make much sense to me. Specifically the quote: \"Furthermore, the methods on autoencoder are not directly applicable to VAEs, because  of the large difference to VAE in probabilistic interpretation\". Can the authors provide further details to reinforce this claim?\n\nQuestion 2:\nGiven there are so many loss terms for this model, it is likely that it will be computationally expensive to estimate the correct weightings for each of these terms in a hyperparamter search. Can the authors speak to how this was done in their case and how expensive it was? \n\nQuestion 3:\nOne of the main selling points for this paper was the ability to extend disentanglement methods to 'multi-factor' change. However, for the experiments, the authors consider datasets which guarantee commutativity of transformations. Theoretically then, is there a reason why we should expect the other baseline models to not be able to handle this multi factor change? For example, it seems the axis aligned disentangled representations of the beta-vae should be able to compose multiple transformations simply by jointly changing multiple latent dimensions. Is this not the case?",
         "744",
         "6",
         "1",
         "0.7790",
         "67",
         "0.16209867760000002"
        ],
        [
         "21",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_A4b1",
         "1698803382759",
         "1699636148172",
         "5",
         "3",
         "2",
         "2",
         "2",
         "Following the Variational Auto Encoder (VAE) framework, this paper proposes an extension of the single factor (change condition) disentanglement learning method, which they call as Composite Factor-Aligned Symmetry Learning (CFASL). The main idea and/or the assumption is certain scenarios such as the composite/complex symmetries (where certain mathematical transformational relationships exist) can be better captured by utilizing explicit symmetrical relationship information, if provided as additional input to the VAE learning framework. \n\nAs a part of the learning scheme, to facilitate this required piece of information, the proposed method explicitly inputs pairwise symmetrical relationship (and corresponding transformation) information. The expectation is the model, if learned in this fashion, should generate better representative samples from within those transformational subspace/domains. \n\nTo better explain and evaluate the scenario, some new metrics such as m-FVMk (extension of a common metric for a single factor change condition evaluation) have been proposed. They have compared their method with some state-of-the-art methods and on nine benchmark datasets; reported results are found to be promising. The following items seem to have some originality: (i) learning from explicit pairwise transformations, (ii) a network architecture to learn the codebook of symmetries for (i),  (iii) some associated metrics supporting (i) and (ii), and (iv) imposing group equivariant encoder-decoder into the learning framework. \n\nOverall, the paper is well written.  Mathematical derivations of different components seem to be sufficient. The proposed method has been tested on a number of benchmarks (both quantitative and qualitative analysis), and reported results are found to be promising. In addition, the ablation study of different loss functions may have added some extra points. \n\nIn terms of quality, I would rate the work as \"moderate\". In this work, one of the important missing part is the proper probabilistic derivation of the methodology, the core of the VAE framework. Or it may be due to the way the paper/work has been presented. To me, it's not sufficient to connect to the VAE world. It is suggested the authors clarify this important aspect with necessary derivations.  \n\nFor certain items/results, the authors claim statistical significance performance (section 5.2, and appendix D); however, without sufficient details of their significance tests. It is suggested authors include details of these statistical tests. \n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, we may require additional details for a fair companion of their results. \n\nThe paper/research may have some significance, and it would be beneficial if the source code could be released. It is suggested the authors clarify the probabilistic derivation of the approach and make a proper connection to the VAE basics. \n\nIt is suggested authors include details of these statistical tests.\n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, I suggest authors provide further details and release code if possible.",
         "461",
         "0",
         "0",
         "0.7849",
         "67",
         "0.0855008418"
        ],
        [
         "22",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_DbMo",
         "1698968978898",
         "1699636148102",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The manuscript aims to improve existing methods of unsupervised disentangled representations learning.  Inspired by the symmetry group action approach from (Higgins et al 2018,2022), authors suggest several additions for the conventional beta-VAE  method, resulting  in the form of seven supplementary loss terms. The article is devoted to important subject of disentanglement learning. Authors report improvements over some of existing methods on four simple datasets 1) Only simple datasets are considered, the method is not tested on standard complex datasets like MPI 3D. \n\n2) Reported improvements of CFASL in all measured metrics are essentially always situated within standard deviations of some other methods. \n\n3) Reconstruction loss is not reported in 3 out of 4 datasets. Upon visual inspection of reported samples, the reconstruction quality is not satisfactory. \n\n4) As reported on Figure 4, on 3DShapes dataset, there is no consistent improvement in FVM metric even at the expense of deteriorating reconstruction quality . \n\n5) There is no theoretic justifications for introduction of so many, seven in total,  additional loss terms. \n\n6) Description of Lie group action is not clear, how the action by psi_i is defined? how the dimensions of Lie groups are chosen?\n\n7) The described group action by matrix multiplications do not preserve the normal distribution, so the group equivariant term is not compatible with the  standard KL term from beta-VAE loss. \n\n8) There is no comparison with most recent disentanglement methods like DAVA, TCWAE.\n\n9) Related work section does not mention many works from vast literature on disentanglement learning, eg Disentangling Adversarial Variational Autoencoder (ICLR 2023). Why is the reconstruction quality not reported in three out of four datasets?\n\nWhy the method was not tested on standard more complex datasets like MPI3D?",
         "284",
         "0",
         "0",
         "0.7452",
         "67",
         "0.070014881"
        ],
        [
         "23",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_mr2r",
         "1698569976113",
         "1699636242675",
         "3",
         "4",
         "2",
         "2",
         "1",
         "The article offers a Gaussian Mixture-based differential entropy/mutual entropy estimation approach. Furthermore, it provides numerical experiments to test the expected behavior of the estimator and its application to self-supervised learning. The article addresses an important problem of mutual information estimation. It provides relevant numerical experiments to test the validity of the proposed approach. - The main approach proposed by the authors seem to be already appeared in the literature in some references not cited by the authors (please see the questions part).\n\n- There seems to be a major issue about the expressions provided for the proposed approach (please see the questions part).\n\n- The presentation requires improvement. ### I. INTRODUCTION \n\n**3rd paragraph:** \n\n- \"identify matrix\":  identity matrix?\n\n- \"The mutual information can be consequently estimated by the entropy decomposition.\": This sentence follows identity matrix addition sentence. I guess it might be better to clarify causality here. At this point, it is not clear what is meant by \"entropy decomposition\", whether it is a trivial procedure and what enables it (mixture of Gaussians modelling?).\n\n### 2.1 BACKGROUND\n\n**Paragraph before (4)**\n\n- After equation (1): instead of \"for a multi-variable Gaussian variable\" use Gaussian (random) vector ?\n\n- In the notation $$X=[x_1,x_2, \\ldots x_n]$$ $x_i$'s appear as column vectors, however, they are actuallly row vectors as $X\\in\\mathbb{R}^{n\\times d}$\n\n- (5) should be\n\n$$\\mathbf{H}_D(X)=\\sum_{i=1}^k \\frac{1}{2} \\log \\left(\\lambda_i+\\beta\\right)+(d-k)\\log(\\beta)+C_d$$\n\n- After (5): \"Therefore, LogDet can estimate the entropy of multivariate Gaussian variables by approximating the differential entropy.\". This is not a surprise/or contribution as the authors  simply defined (5) using (2) by replacing the true covariance with $\\beta I$ perturbed sample correlation (covariance?) matrix. This is sort of obvious. \n\n### 2.1.1 LOGDET ENTROPY ESTIMATOR FOR NON-GAUSSIAN VARIABLE\n\n- Title : ... NON-GAUSSIAN VECTOR\n\n- Replace variable->vector\n\n- There already exists GMM based entropy/mutual information approximation based works such as \n\n[a]. Lan T, Erdogmus D, Ozertem U, Huang Y. Estimating mutual information using gaussian mixture model for feature ranking and selection. InThe 2006 IEEE international joint conference on neural network proceedings 2006 Jul 16 (pp. 5034-5039). IEEE.\n\n[b]. Huber MF, Bailey T, Durrant-Whyte H, Hanebeck UD. On entropy approximation for Gaussian mixture random vectors. In2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems 2008 Aug 20 (pp. 181-188). IEEE.\n\nYou need to refer to existing literature and clearly state what is novel in your approach relative to them.\n\n\n- Theorem 2 and Theorem 3 of [b] above already covers the lower and upper bounds of mixture of Gaussians. It looks like they are same as what is provided in this section. \n\n- There seems to be a major issue about the upper bound expression. The first expression for the upper bound (at the bottom of page 3), contains covariances ($\\Sigma_i$'s ) obtained from the GMM fitting algorithm, whereas the second line contains the overall sample covariance of actual data, instead of conditional covariance estimates. How do you equate these lines? The second line in fact equals to\n\n$$\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)+\\sum_{i=1}^K \\pi_i \\cdot\\left(-\\log \\pi_i+C_d\\right)$$\n\nas $\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)$ is independent of the summation index $i$. This does not make sense as you disregard covariance parameters of the GMM. \n\n- How do you make the upper bound objective co\n\n### 2.2 THE ISSUE OF MODEL SELECTION\n\n- Title: Model Selection is to generic for the discussion in this section. \"The Issue of Model Order Selection\" could be a better title.\n\n\n\n\n### 3. APPLICATION IN SELF-SUPERVISED LEARNING\n\nThe logdet-mutual information based SSL appears to be proposed in the following reference:\n\n[c]. Ozsoy S, Hamdan S, Arik S, Yuret D, Erdogan A. Self-supervised learning with an information maximization criterion. Advances in Neural Information Processing Systems. 2022 Dec 6;35:35240-53.\n\nThe authors should also clarify the relative novelty relative to [c]. Especially, the impact of GMM order selection as the approach in [c] appears to be for $K=1$. There is also claim in [c] that the use of $K=1$  defines correlative information maximizing which targets a linear (identity in their modified setting) between the representations of augmented versions of inputs. For $K>1$ does  maximizing mutual information between augmentation representation lead to nonlinear mappings between them? Is such organization of representation space desirable for classification tasks, for example?\n\nOr are you just using (18) with order $1$, which seems to be just the approach in [c]. \n\n### 4. RELATED WORKS & 5 SIMULATION STUDIES\n\nAll the references we mentioned above and the relevant references that cite them should be included in this discussion, and simulation results \n\n- 5.2 : ofBelghazi...-> of Belghazi\n- Figure 2: Two small figures and caption could be more informative.\n- 5.4 SSL: What is K for EMP-MILE? Is upper bound employed in EMP-MILE?  what if you directly use MILE?\nHow is backprop used in coordination with the GMM algorithm? As GMM parameters are algorithmically obtained from network output, how does backprop do backward mapping from probabilities $\\pi_i$'s (and there should be covariance estimates $\\hat{\\Sigma}_i$'s, as discussed above)",
         "825",
         "0",
         "11",
         "0.7898",
         "67",
         "0.0758333333"
        ],
        [
         "24",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_fvqj",
         "1698878886574",
         "1699636242588",
         "3",
         "5",
         "2",
         "1",
         "2",
         "This paper proposes a new approach to estimating the mutual information between a pair of random vectors, by extending the closed-form expression that is available to Gaussian variables to non-Gaussian variables. This is done by estimating Gaussian mixture approximations of the involved densities and then using bounds on the differential entropy of Gaussian mixtures. Estimating mutual information between high-dimensional non-Gaussian variables is an important problem with many applications. The proposed method extends Gaussian (which the authors refer to log-det) estimators to be applicable beyond Gaussian variables via the use of Gaussian mixture approximations, coupled with bounds on the differential entropy of mixtures. Unfortunately. the paper contains several critical flaws, namely a quite sloppy notation, that lead me to recommend its rejection. \n\nThe authors mixture, in a very confusing way, random variables and data matrices, typically using the same notation for both, $X$. For example, in Equations (1), (2), and (10), $X$ is a $d$-dimensional random variable, whereas in Equation (4), $X \\in \\mathbb{R}^{n\\times d}$ is a data matrix. Even worse, in the final equation of page 3, the two different definitions are used together and it is not even clear where the second equality means; it is simply wrong because $X^T X/n$ does not coincide with $\\Sigma_i$.\n\nUnlike what the authors claim, Equation (5) is not equivalent to Equation (5); the two differ by $\\frac{d-k}{2}\\log \\beta$.  \n\nAdding a matrix proportional to identity ($\\beta I$ in the paper) to the sample covariance was not proposed in a 2021 paper. It is a very classical method that can be found in any classical text on covariance matrix estimation, many decades ago.\n\nThe inequality in Equation (8) was not shown by Zhouyin and Liu in 2021. It is a classical result of information theory, that can be found, for example, in the famous Cover and Thomas book. By the way, the citation to this book is wrong in the paper; one of the authors (J. Thomas) is missing. \n\nThe two bounds for the differential entropy of mixtures that the authors claim to have introduced are in fact not new. The upper bound is in fact a well-known corollary of the log sum inequality (see the Cover and Thomas book). The lower bound was proved in 2008 by Huber et al. at https://doi.org/10.1109/MFI.2008.4648062 I have no questions.",
         "383",
         "1",
         "1",
         "0.7288",
         "67",
         "-0.053505050500000005"
        ],
        [
         "25",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_F4Ta",
         "1698980874812",
         "1699636242491",
         "6",
         "4",
         "3",
         "3",
         "2",
         "This work presents a mutual information (MI) estimator called MILE (LE=logdet estimator) which uses \nthe log det closed form formula of the entropy of Gaussians.\n\nTo accomodate MI to arbitrary densities, a Gaussian mixture model (GMM) is first fit to data and lower/upper bounds on the entropy of GMM is used to define MILE formula Eq 15. \n\nThen MILE is benchmarked with other MI  estimators and MILE can be used in loss functions in semi-supervised learning in experiments. - Simple MI estimator method based on  \n\nZhanghao Zhouyin and Ding Liu. Understanding neural networks with logarithm determinant entropy estimator. arXiv preprint arXiv:2105.03705, 2021\n\n(cited in the paper)\n\n- Very good experiments and comparisons with other MI estimators\n\n- Source codes provided in supplemental information  for reproducible research -The paper is sloppy in its writing, and one problem is to determine the number of components k of the GMM which\n loosen the lower upper bounds on the entropy. \n\n- Another problem is to deal with near singularity (det close to zero) by introducing a regularization term \\beta.\n\n- Give definition of MI and link with copulas, e.g.,\nMa, Jian, and Zengqi Sun. \"Mutual information is copula entropy.\" Tsinghua Science & Technology 16.1 (2011): 51-54.\nThis will relate to Eq. 8 as well.\n\n- Because MI estimation is an important and well-studied topic, I suggest to put Section 4 on related works after the introduction to that the contributions are better explained.\n\n- The lower/upper bounded of entropy of GMMs are not tight. There is a rich litterature which also compares the tightness of the various bounds.\n\nHuber, Marco F., et al. \"On entropy approximation for Gaussian mixture random vectors.\" 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems. IEEE, 2008.\n\nEven in 1D:\nNielsen, Frank, and Ke Sun. \"Guaranteed bounds on the Kullback–Leibler divergence of univariate mixtures.\" IEEE Signal Processing Letters 23.11 (2016): 1543-1546.\n\n- Notice that some distributions do not admit densities (some elliptical distributions for example)\n\n\n\n- Mention MI properties (i.e., tensorization) which defines the self-consistency test of estimators\n\n\n- small remarks:\n* data covariance = scatter matrix\n* after (3), define $\\Sigma_x$ as scatter matrix?\n*  page 3, first sentence need to be rephrased\n* some typos: \npage 7  hyperparamter -> hyperparameter\npage 9 self-supervied -> self-supervised    competitve -> competitive - Would using PCA beforehand be more appropriate in the case of near singularity?\n\n- Can we tackle robustness/variance with f-MI?\n\nMoon, Kevin, and Alfred Hero. \"Multivariate f-divergence estimation with confidence.\" Advances in neural information processing systems 27 (2014).\nEsposito, Amedeo Roberto, Michael Gastpar, and Ibrahim Issa. \"Robust Generalization via f− Mutual Information.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.",
         "447",
         "3",
         "7",
         "0.8255",
         "67",
         "0.1368315018"
        ],
        [
         "26",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_MHkc",
         "1699156174555",
         "1699636242410",
         "3",
         "4",
         "2",
         "3",
         "2",
         "this paper proposes to use the logdet function for the estimation of mutual information. \ntwo bounds are proposed for this purpose. the results show improvement in comparison \nto the editing methods. the proposed function itself is \"the Coding Length Function\". simple method with good results. In my opinion this paper reinvents \"Coding Length Function\".  \"...the difference is we put a scaling hyperparameter β on the identity matrix I..\" - that is not a difference. both affects SNR. The latter can be affected either way: by multiplying the noise covariance or by division of the data covariance. I do agree that the results are interesting, but the novelty is quite limited due the the above. \n\nplease elaborate on the limitations. \"So, we recommend β = 1e−3 in the following simulation studies\" why not beta=zero? \nFigure 1.b shows that beta=zero correctly estimates the true MI. \nThat raises a question why do you need beta > 0?\n\nHow do you define $\\pi_c$ in e.g., Eq17?\n\nBoth bounds are loose. How can you explain that such loose bounds lead to very small variance in MI?\n\nDo you calculate MILE in batches?",
         "187",
         "0",
         "1",
         "0.7572",
         "67",
         "0.0981946625"
        ],
        [
         "27",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_oYZA",
         "1699327631740",
         "1699636242348",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The paper proposes uses bounds on the entropy and mutual information for a mixture of Gaussian random variables based on the log determinant calculations used in calculating the entropy for a single Gaussian. In the context of self-supervised learning, the Gaussian mixture is assumed to known based on the augmentation. In other cases the number of mixture components has to be selected. Empirical results are reported on a synthetic benchmark of correlated Gaussians with and without non-linear transformations. Results of self-consistency measures are reported on CIFAR10. The paper is a logical motivation. Differential entropy is easy to calculate for Gaussian distributions, and mixture of Gaussians are universal approximations given enough data, so why not use GMM for mutual information estimation. The insight of using the augmentations as defining the GMM is a useful, simplifying assumption. One main weakness is the lack of extensive comparisons of using this method for self-supervised learning versus other. The one example in the main body (Table 1) shows that at 300 epochs the method is better than some other methods but is inferior to EMP-SSL. At 1000 epochs the other methods outperform the listed, but no results for 1000 epochs are reported. \n\nThe second main weakness is the paper does not give a complete description of the method. The paper is lacking in clarity with some key point unaddressed. The notation is confusing since the random variables (Z,Z') are denoted the same as Z_c, which may be a data point in the empirical sample. There should more clarity on random variables as compared to  sample sets, starting back before equation 4. The confusion carries to last paragraph of Section 4 where $\\mathbf{X}$ is defined but then $X$ is used in the definition. \n\nThe use of one instance for one cluster is not clear to me upon reading it\n\"This is because we treat the augmented data from one instance as a cluster, and this data\naugmentation strategy automatically clusters the data.\" This should be re written.\n\n In equation 17 it is not clear how $\\zeta_c$ captures all instances in the batch. It has only a single $i$ index. Perhaps the $\\zeta_c$ should concatenate them all. In section 3.2, $\\zeta_c$ is a set which indexes the whole match, which makes more sense, but it should be a matrix not a set. In any case, how is the $H(Z)$ term estimated in section 3.1? By keeping $Z_c$ fixed and only augmenting the second the one covariance matrix will be rank-1 (before ridge). \n\nIt doesn't sound like the experiments for the 5.2 are run fairly \" our MILE estimator does not require extra training,\" In this problem the point is that the MI could be changing at each data instance. Thus, other methods do not use access to the change points. MILE should have to be run (which involves performing the GMM since there are no self-clusters as in SSL) at each point. Running an expectation maximization is as much or more training than the updates of network.  \t\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. \n \nIn terms of unsubstantiated claims, the method is clearly biased (not only by the choice of number of components) but also on the non-linear transform cases. It is not clear how well the mutual information estimation would actually work on more complicated data. Thus, even if it is useful for self-supervised learning is not necessarily a more accurate estimate of differential entropy. \n\n**Minor:**\nThere are a number of typographical mistakes that are distracting.\n\nI don't understand what this means\n\"often dwarfing traditional parametric and non-parametric approaches in statistics\"\n\n\" base on the \" -> \"based on the \" \n\nI'm not familiar with this phrasing \"When X subjects to a Gaussian\" \n\n\"a ‘noise’ $\\hat{X}$ \" -> \"a noisy $\\hat{X}$\" \n\nThe paragraph before equation (4) are not clear. \" an expanding factor\" is not defined nor is it clear what is meant by \"enlarging the original covariance matrix\".\n\nExtra $=$ on equation 14.\n\n\"trading each\" -> \"treating each\" ? \n\n\" ground true data\" \n\n\"SMILE: moothed\" -> \"SMILE: smoothed\" \n\nIt should be a parenthetical reference for You et al. (2017) fo LARS optimizer. How is the $H(Z)$ term estimated in section 3.1? Is it also based on augmented data?\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. Are there hyper-parameters for EMP-SSL?  \n\nWhy in Table 1 is 1000 epochs not tested?\n\nIs the GMM method run at each time point in Figure 2?",
         "766",
         "1",
         "2",
         "0.7605",
         "67",
         "0.0532218443"
        ],
        [
         "28",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_e4bh",
         "1698824679826",
         "1700667146725",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs) which build on the graph theoretical concept of graphexes to include sparse network structures between agents. This improves over prior work on Graphon Mean Field Games which only allows for modelling with dense graphs. The authors derive convergence properties for the finite game. In addition, a learning algorithm based on online mirror descent is provided for a particular class of GXMFGs that follow a core-periphery network structure. Finally, the theoretical claims are empirically validated over both synthetic and real-world networks. - This paper has a clear motivation to extend Graphon Mean Field Games to deal with sparse graphs which are frequently seen in practice. The hybrid graphex approach proposed in this work looks like a natural and intuitive solution.\n- The technical development is principled and the analysis is nontrivial.\n- The overall presentation and clarity is good. - Even though the authors explained in the paper, I didn't like the fact that the proposed GXMFGs have no baseline competitors to compare against. While I agree that one could argue on the contrary that the ability to work with sparse graphs is precisely the unique advantage of GXMGFs, I think that the authors should at least spend some efforts to discuss (if empirical comparison with LPGMFG is indeed unsuitable) how GXMFGs would compare with LPGMFG and GMFG in practice. In Figure 3a, it looks like the curves are diverging rather than converging as k increases? Are the curves coloured correctly?",
         "248",
         "0",
         "0",
         "0.8187",
         "55",
         "0.0240079365"
        ],
        [
         "29",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_hgJx",
         "1698838739665",
         "1699636550718",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs), a framework for addressing the challenge of learning agent behavior in large populations. GXMFGs leverage graphon theory and graphexes, which represent limiting objects in sparse graph sequences. This approach suits real-world networks with both dense cores and sparse peripheries. The paper presents a specialized learning algorithm for GXMFGs. \n\nKey contributions include:\n\n1. Introduction of GXMFGs, extending the scope of Mean Field Games.\n2. Provides theoretical guarantees to show that GXMFGs accurately approximates finite systems.\n3. Development of a learning algorithm tailored to GXMFGs.\n4. Empirical validation on synthetic and real-world networks, demonstrating GXMFGs' ability to model agent interactions and determine equilibria effectively. - Well-Written and Organized: The paper demonstrates strong writing and organization, enhancing its overall readability and accessibility.\n\n- Clear Motivation: The paper effectively conveys a clear and compelling motivation for addressing the problem it tackles.\n\n- Thorough Discussion of Prior Works: The paper provides a comprehensive and well-structured overview of prior works related to the research area.\n\n- The paper provides solid theoretical contributions complimented with supporting empirical studies strengthens the paper's arguments and findings. As the current paper falls outside the scope of my research interests, I am unable to identify any significant weaknesses in the paper. Consequently, my confidence in assessing the paper is limited. - Providing an intuitive explanation for assumptions 1(b) and 1(c) would greatly enhance the paper's overall readability and accessibility.\n\n- While the paper assumes finite state and action spaces, it may be beneficial to explore whether the proposed approach can be extended to scenarios with infinite action spaces. \n- Including the code for the simulations, would enhance reproducibility.",
         "275",
         "0",
         "4",
         "0.8110",
         "66",
         "0.1125396825"
        ],
        [
         "30",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_P6cQ",
         "1698854680058",
         "1699636550633",
         "6",
         "4",
         "3",
         "3",
         "3",
         "In this paper, the authors study a class of games with many players who are interacting through a sparse graph structure. More specifically, they are interested in the regime where the number of players tend to infinity. The main solution concept is an extension of the notion of Nash equilibrium. The authors propose a learning algorithm based on online mirror descent. They conclude the paper with examples and numerical simulations. Overall, the paper studies an interesting problem and is relatively clearly written. As far as I know, this is a new extension of MFG to sparse graphs. The algorithm is very inspired from existing ones but there is an adaptation to the problem under consideration (core vs periphery). The model is quite abstract at some places. For the theoretical results, they are mostly about the analysis of the game and I am not sure how relevant they are for this conference (although they are certainly interesting for a certain community). It might have been more interesting to focus more on the learning algorithm. \n\nThere are some typos which make it hard to check the correctness of some parts (see questions). 1. I am wondering if some assumptions are missing. For example below Lemma 1, should $f$ be at least measurable (and perhaps more?) with respect to $\\alpha$ for the integral to make sense?\n\n2. Assumption 2 as used for instance in Lemma 1 does not seem to make much sense (unless I missed something): What is $\\boldsymbol{\\pi}$? We do not know in advance the equilibrium policy and even if we did, we would still need to define the set of admissible deviations for the Nash equilibrium. Could you please clarify?\n\n3. Algorithm 1, line 14: Could you please explain or recall what is $Q^{k, \\mu^{\\tau_{\\mathrm{max}}}}$?\n\nSome typos: Should the state space be either $\\mathcal{X}$ or $X$ (see section 3 for instance)? Does $\\mathbb{G}^\\infty_{\\alpha,t}$ depend on $\\boldsymbol{\\mu}$ or not (see bottom of page 4)? Etc.",
         "324",
         "0",
         "4",
         "0.8025",
         "66",
         "0.19302597400000002"
        ],
        [
         "31",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_qFZD",
         "1698724264822",
         "1699636511957",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper introduces out-of-variable (OOV) generalization, which is an the ability to generalize in environments with variables that have never been jointly observed before. OOV is an issue in settings where different variables (e.g. diagnostic tests) are available for different environments (e.g. different patients). The paper investigates challenges for common approaches when faced with the OOV problem, and proposes an OOV predictor that leverage moments of the error distribution. The work contributes to theoretical understandings of OOV and offers a proof-of-concept for a predictor capable of non-trivial OOV transfer. - The paper formally studies a new perspective on generalization.\n- The methods employed in the paper are sound. - The paper does not demonstrate the practical applicability of the concept of OOV generalization, and the setting feels a bit contrived. Also it seems like OOV generalization can be thought of just a case of OOD generalization--if we think about all the variables together as the input, the OOV generalization is just a case of OOD generalization (e.g. covariate shift) where some inputs have clear signal from some features and other inputs have clear signal from other features. \n- It would be helpful to include more intuitive discussion throughout the paper providing more analysis on the sections. For example, more discussion on the assumptions of the settings/theorems would be helpful, and it's not clear exactly under what assumptions the proposed predictor is appropriate. Please see weaknesses above.",
         "236",
         "0",
         "2",
         "0.7220",
         "67",
         "0.11756198350000001"
        ],
        [
         "32",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_s9Ga",
         "1698762596885",
         "1700684618252",
         "8",
         "4",
         "3",
         "4",
         "2",
         "This work investigates out-of-variable (OOV) generalization, which is a sub-problem to OOD generalization, and refers to scenarios where an agent needs to generalize to environments containing variables that were never jointly observed before. The paper shows that if the source and target environments contain some overlapping variables (and under certain conditions), information from the predictor in the source environment can improve predictions in the target environment. More specifically,  the moments of the residual distribution from the optimal classifier in the source environment can be used to calculate the generating function with respect to the unobserved variable in the target domain.\n\nBased on this observation, the paper proposes a practical algorithm for OOV prediction, evaluates its performance, and compares it against the marginal predictor and imputed predictor, as well as an Oracle predictor. The paper proposes a new and important problem-setting - OOV generalization, which can occur in real-world situations, on its own or alongside OOD aspects. The work also provides an extensive study of the identification problems of various variants of OOV scenarios, including theoretical proofs and examples. \n\nIn addition, the paper proposes a practical algorithm to solve several OOV scenarios that achieves non-trivial OOV transfer on synthetic data.\n\nThe ideas presented in the paper are novel and the conclusion that information from source domains can be used for prediction in the target domain in this setting is important, and can potentially have a broad impact on future research in the field. The main limitation of the paper is that the proposed approach was tested on only synthetic data, and was not validated using more challenging datasets. \n\nIn addition, the extension of OOV in multi-environments is mentioned mainly in the appendix and the algorithm was not tested empirically for that extension. I would like to ask the following questions:\n\n1. For future work, is there a more complicated/realistic dataset to validate the algorithm?\n2. Is it possible to compare the algorithm to state-of-the-art marginal or causal methods such as Mejia et al. (2021) or Janzing (2018)? To validate if Vapnik’s principle holds and whether the proposed approach indeed improves results due to solving a less general problem.\n3. Theorem 3 connects all moments of the residual distribution to the partial derivatives with respect to the unique variable of the target environment. If additional moments were to be calculated as part of the proposed algorithm, would it improve results (for the general function case)? \n4. In general, since the paper's main claim is that in the real world, it is likely to encounter both aspects of OOD and OOV - How simple is it to combine state-of-the-art  OOD methods with the proposed approach? I cannot imagine at the moment a straightforward way to do that.",
         "454",
         "2",
         "3",
         "0.7695",
         "54",
         "0.1422634079"
        ],
        [
         "33",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_woi7",
         "1698788842803",
         "1699636511769",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper describes the out-of-variable OOV problem, which in its simplest form, aims to learn a predictor Y = f_t(X2, X3) given an OOV predictor Y = f_s(X1, X2) and a dataset (X2, X3), but without any instance of (X2, X3, Y). The authors describe the setting in which this is possible and develops an algorithm. The key observation is that the third moment of the residue Y - f_s(X1,X2) contains information about X3 that is least polluted by the noise. - The key observation/discovery is clever, and the algorithm is straight-forward to use.\n- The writing is clear, clean, and well-referenced. The examples also made things concrete and easy to follow.\n- The rigor and simplicity of the work can act as a foundation to build OOV research. - The main weakness is the applicability of the method. The authors only showed results for proof-of-concept, not for real-world usage. \n- It is unclear how one could identify whether the assumptions are satisfied given a dataset.\n- It is unclear how bad the predictor would be if the assumptions are not satisfied.\n- It is not yet clear what realistic problem can be well modeled by OOV generalization. Intro:\n- It seems OOV fits very well the frame of missing-not-at-random and covariate-dependent missingness. Could the authors comment on that?\n\nSection 2:\n- Theorem 2 is slightly confusing for me at first glance because I thought PA_Y by definition includes all parents of Y (so x1,x2, x3 in the example) and not just those in the target environment (x2, x3). It may be helpful to clarify.\n\nSection 3:\nAs I am trying to get a sense of the restriction and applicability of the approach, I was wondering the following questions: \n- How does the method fair with the oracle as the magnitude of the noise increases? \n- What if the noise is not gaussian but more heavy tailed? \n- Does the performance degrade or improve with increasing number of variables? \n- I assume Theorem 3 does not apply to discrete variables because of the violation of differentiability; is that right?\n\nSection 4:\n- Can include missing-not-at-random imputation and covariate-missing imputation as two more baseline models (a search in Google scholar using the two key phrases yields some methods).\n- It would be really interesting if the authors could find some real-world datasets, create source and target environments by sub-setting the columns, and see how the method performs.\n- Figure 3: I don’t quite understand the figure. It would be helpful to define OOV loss, be explicit about the number of samples on the y-axis being (x2,x3,y) or (x1,x2,y) or something else. I also don’t understand why relative loss is zero means the method is on par with the oracle predictor. Why not just show how the fine-tuning error compares with oracle training, which seems easier to interpret? Anyway, I am overall a bit confused about the figure, so my questions may not make sense.",
         "493",
         "0",
         "0",
         "0.7642",
         "67",
         "0.0947004608"
        ],
        [
         "34",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_xwQY",
         "1699441328198",
         "1699636511667",
         "8",
         "3",
         "3",
         "3",
         "3",
         "The paper investigates out-of-variable generalization, namely the ability for a predictive model to generalize to target domains in which the agent has never seen the joint variables in the target domain in a single source domain before. Under certain assumptions as well as when these assumptions don't fully hold, the paper shows that the error residual distribution in an environment provides information on the unobserved causal parent variable in this environment, and they use this information to derive an algorithm that performs OOV generalization with source and target domains that have overlapping sets of causal factors. **Originality**\n- As far as I know, though the problem the paper addresses is well-known as a significant problem, the paper provides several theoretical results, mathematical derivations, and supports these with simple empirical results that are novel.\n\n**Quality**\n- The quality of the paper is high. It addresses a high-value problem in a principled fashion, shows how certain assumptions help obtain certain results and how and in which cases these assumptions can be bypasses while maintain approximately accurate results, and evaluates these cases in terms of loss accuracy as well as sample complexity of its approach versus baseline approaches.\n- The paper openly highlights limitations in its work, such as assumptions made for theorems to hold, and proposes prospective future work in multiple avenues. This refreshingly is (1) included at all and (2) doesn't seem like a mere afterthought.\n\n**Clarity**\n- The paper is mostly clear in its explanation of motivation, preliminaries, approach, baseline usage, results, and limitations.\n- The paper does a great job providing simple, clear real-world examples to elucidate the problem and applications of the various theorems included in multiple cases.\n\n**Significance**\n- The significance of the problem the paper addresses is high and the problem is ubiquitous. The approach is promising and can be applied in many real-world settings through Monte-Carlo sampling or similar methods. The paper shows that their approach can perform relatively well in \"few\"-shot settings though this depends on the number of variables involved and the complexity of the problem.\n\nFrom what I can tell, this is excellent work that I hope motivates further addressing this *out-of-variable* generalization problem by the research and applied AI community. My only reservation is my limited knowledge on the understanding of and state-of-the-art theoretical and applied approaches addressing this problem. - Referring to Figure 1, in the first paragraph in page 3, the claim \"it would seem all but impossible...(orange box)\" could be better explained.\n- In Figure 1, it is unclear whether \"With $Y$ not observed in the target domain\" is an assumption made or is somehow indicated in the diagram or earlier in the paper. Eventually I realized that it's an assumption made, but the illustration Figure 1a alone isn't enough to show this assumption. This ambiguity may clear for some or compound for some later in Section 3. - The abstract states \"merely considering differences in data distributions is inadequate for fully capturing differences between learning environments.\" Doesn't out-of-variable technically fall under out-of-distribution, so shouldn't this be adequate? Perhaps more specificity is needed here.\n- The abstract states \"Mathematically, out-of-variable generalization requires the efficient re-use of past marginal information...\" Why does it require efficient re-use? Could it work with \"non-efficient\" or inefficient re-use?\n- On page 2, should \"modal\" be \"model?\"\n- On page 6, do you mean \"parentheses\" instead of \"brackets\" between Eq (9) and Eq (10)?\n- Why is the joint predictor considered an oracle predictor if MomentLearn outperforms it?\n- Could you explain why MomentLearn is reliably more sample efficient than the oracle predictor for \"few\"-shot prediction?",
         "602",
         "0",
         "0",
         "0.7701",
         "67",
         "0.10227124180000001"
        ],
        [
         "35",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_HgHQ",
         "1697165838375",
         "1699635934990",
         "3",
         "5",
         "2",
         "3",
         "2",
         "The paper proposes a simple yet efficient feature direction distillation loss. Experiments show that this significantly improves KD\nperformance. 1. Improving KD by feature norm and direction is reasonable and effectiveness.\n2. Experiments on standard benchmarks demonstrate that adopting $\\mathcal{L}_{dino}$ remarkably improves existing KD methods. 1. The contributions seem a little limited. \n2. There is lack of theoretical analysis of DINO loss. The paper is not good enough to be published on ICLR. 1. How to align the features between heterogeneous architectures?\n2. Could you please provide more theoretical analysis?\n3. What about extending it to a multi-layer version of feature distillation?\n4. How to apply the proposed method to existing KD methods, e.g. ReviewKD, DKD, DIST? Just add the DINO loss function to the total loss ? If so, I think adding other loss like contrastive distillation loss or RKD may also make a improvement.",
         "146",
         "0",
         "8",
         "0.8205",
         "67",
         "0.07793367350000001"
        ],
        [
         "36",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_yLjx",
         "1697172920902",
         "1699635934905",
         "6",
         "5",
         "3",
         "3",
         "2",
         "Here is a summary of the key points from the paper:\n\n- The paper proposes a method to improve knowledge distillation (KD) by regularizing student features to align direction with teacher class-means and have sufficiently large norms. \n\n- Current KD methods like logit or feature distillation align student and teacher but don't directly optimize for student's task performance.\n\n- The paper shows regularizing direction using cosine similarity to teacher class means helps improve student accuracy. \n\n- It also finds student models tend to produce smaller-norm features, so encouraging larger norms improves performance. \n\n- A simple combined loss called dino-loss is proposed to simultaneously regularize student feature direction and norm using teacher class means.\n\n- Experiments on CIFAR and ImageNet classification, and COCO detection show dino-loss consistently improves various KD methods like KD, ReviewKD, DKD.\n\n- Dino-loss achieves new state-of-the-art results among KD techniques on classification and detection benchmarks.\n\n- The method is model-agnostic, simple to implement, adds minimal overhead, and benefits from larger teacher models.\n\nIn summary, the key contributions are a way to improve KD by regularizing student features for better alignment and norms, along with a simple and effective dino-loss to achieve this jointly. The results demonstrate consistent gains across tasks and benchmarks. The paper presents an original and significant approach to improve KD via thoughtful feature regularization. The method is intuitive and supported by quality experiments. The gains are demonstrated to be significant across tasks. The presentation and discussion are clear:\n- The method and dino-loss are clearly explained with illustrations and equations. Results are well-presented in tables and figures. Limitations are properly discussed.\n- Improving KD is an important practical problem. The consistent gains are significant. Sets new state-of-the-art results on ImageNet classification and COCO detection.\n- Model-agnostic nature allows wide applicability to various KD methods and models. Simple extension can benefit the community compared to more complex techniques. - The paper should address the lack of novelty by acknowledging that feature normalization techniques have already been widely employed in knowledge distillation. For example, PKD (NeurIPS-2023) specifically incorporates channel alignment for detectors, and SKD (Guo Jia) explores normalization techniques on predictions. and Feature Normalized Knowledge Distillation for\n/mage Classification ECCV2022 also presents feature norm. Furthermore, it is worth investigating whether the proposed method has already been considered in the distiller's search work, as exemplified by KD-Zero: Evolving Knowledge Distiller for Any Teacher-Student Pairs (NeurIPS-2023).\n\n- In addition, the paper should incorporate a thorough discussion of relevant KD-related studies, including Self-Regulated Feature Learning via Teacher-free Feature Distillation (ECCV2022), NORM: Knowledge Distillation via N-to-One Representation Matching (ICLR2023), Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer (NIPS2022), DisWOT: Student Architecture Search for Distillation Without Training (CVPR2023), and Automated Knowledge Distillation via Monte Carlo Tree Search (ICCV2023). These discussions will provide valuable insights into the existing literature, establish connections with previous research, and potentially highlight points of comparison and contrast. The only concern to me is the novelty of the work and I hope the authors could discuss some of the related work I mentioned in the revised version.",
         "510",
         "0",
         "1",
         "0.8228",
         "67",
         "0.134258658"
        ],
        [
         "37",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_VRvE",
         "1698736302686",
         "1699635934723",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper studies Knowledge Distillation (KD). A simple loss term namely ND loss is proposed to enhance the distillation performance. It encourages the student to produce large-norm features and aligns the direction of student features and teacher class-means. The ND loss helps not only logit-based distillation methods but also feature-based distillation methods. 1. The proposed method is simple but effective. Encouraging the feature norm for the student is novel in the field of KD.\n2. Experimental results are strong. The authors also conduct experiments on object detection. The proposed loss can improve the existing methods on both image classification and object detection.\n3. The whole paper is organized and written well. It is not a novel thing that decoupling the feature into the magnitude and the direction. Previous works [1][2] already studied this point. [1] uses the teacher classifier to project both teacher features and student features into the same space and then align them. [2] proposes a loss term to align two features’ direction. Compared to the existing works, this paper proposes enlarging feature norm and utilizing the class-mean feature. Authors should check more existing papers and discuss their differences.\n[1] Yang, Jing, et al. \"Knowledge distillation via softmax regression representation learning.\" International Conference on Learning Representations (ICLR), 2021.\n\n[2] Wang, Guo-Hua, Yifan Ge, and Jianxin Wu. \"Distilling knowledge by mimicking features.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 44.11 (2021): 8183-8195. None",
         "235",
         "7",
         "6",
         "0.7478",
         "67",
         "0.1515151515"
        ],
        [
         "38",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_AuzT",
         "1698788774762",
         "1699635934515",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper proposes to use teacher's class-mean to align student's direction and encourage the student to produce large-norms features, improving the performance of KD. The paper is generally well-written, and the methodology is well-motivated. 1. would expect comparisons and discussion to similarity-preserving KD e.g., [1], which is a large family in feature distillation methods and shows some relations to the proposed method.\n2. Meanwhile, comparisons/discussion to explainablity-based KD, e.g., [2] are needed to see whether those methods can be benefited from the proposed method.\n\n[1] Tung, Fred, and Greg Mori. “Similarity-Preserving Knowledge Distillation.” ICCV 2019.\n\n[2] Guo, Ziyao, et al. \"Class Attention Transfer Based Knowledge Distillation.\" CVPR 2023. Please see weakness.",
         "111",
         "4",
         "6",
         "0.7517",
         "67",
         "0.1321428571"
        ],
        [
         "39",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_AcYB",
         "1697637540901",
         "1700740134087",
         "5",
         "4",
         "3",
         "2",
         "2",
         "The authors introduce Neural Sinkhorn gradient flow, which is a Wasserstein Gradient Flow wrt to the Sinkhorn divergence. The authors show that the velocity field can be calculated using the Sinkhorn potentials. This allows training a neural network approximating the velocity field. Furthermore, a mean field limit is established. The algorithm is evaluated on a toy example, MNIST image generation and CIFAR10 image generation. The authors do a good job at explaining the underlying concepts of their algorithms. The maths is nicely done. The core idea is very neat and the cifar10 results seem to be good quantitatively wrt other gradient flow works. 1) The article is full with typos. Just to name a few: \"piror\", \"Sinkhron\", \"Experimrnts\", \"speedest descent\", question mark in the appendix and so on. Please fix those. \n\n2) the authors write \"We do not compare with extant neural WGF methods on MNIST because most of the neural WGF\nmethods only show generative power and trajectories on this dataset and lack the criteria to make\ncomparisons.\" There are several papers (also gradient flow based ones), which evaluate a FID on MNIST. Please provide it as well. \n\n3) Also many of the MNIST digits appear flipped. Did the authors use data augmentation there? Also there seems to some slight noise present the generated MNIST digits. \n\n4) Although the CIFAR10 value seems good, there are unfortunately no generated images provided. It is standard practice to sample many images in the appendix. \n\n5) It is unclear what the trajectories show. Does it show the particle flow or the trained Neural Sinkhorn Gradient Flow? \n\n6) The statement of theorem 2 is incorrect. I guess the authors do not want to sample the Euler scheme (eq 14) but the continuous gradient flow, otherwise the statement would need to depend on the step size $\\eta$. \n\n7) In the proof of Theorem 2: Please provide a proof (or reference) why the mean field limit exists. Or do you mean the gradient flow starting at $\\mu_0$ with target $\\mu$ (first two sentences).\n\n8) Later in that proof: why does there exists a weakly convergent subsequence of $\\mu_t^M$? Further, I cant find the definition of $U_{\\mu}$. \n\n9) The code is not runnable, as the model (or any checkpoints) are not provided.\n\n10) From how I understood it, the learning of the velocity field is batched, i.e., one trains for different sets of $(z_i,x_i)$. Since the Sinkhorn dynamic describes an interacting particle system I dont see how this should be possible. To be more precise, one particle $\\tilde{x}$ could be sent to $x_0$ in the first batch, but to a totally different particle $x_1$ in another one, depending on the drawn prior and target samples. Are the positions of the other particles also input to the neural network (i.e by putting them in the channels)? Please elaborate. See weaknesses section. Overall I really like the idea, but the weaknesses prevent me from giving a higher score. It seems like the paper was rushed and is currently not ready for publication. I am willing to raise my score, if the authors address these issues.",
         "516",
         "0",
         "3",
         "0.7790",
         "54",
         "0.1480691057"
        ],
        [
         "40",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KKim",
         "1698338217824",
         "1700755549491",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces a novel way to train generative models. The authors want to approximate the gradient flow in the Wasserstein space.  They want to approximate the vector field which transports the source distribution to the real-data empirical distribution while minimizing the Sinkhorn divergence. The authors showed the analytical form of the vector field when one considers the Sinkhorn divergence and then they explain how to learn this vector field with a neural network through the simulation of a probability path. They showed that their procedures recover the true probability path when the number of iid samples goes to infinity. Finally, they validate their proposed method on several image-generative tasks. i) The motivation and the introduction are clear\n\nii) Regressing vector fields has been a recent and popular approach with many different applications in machine learning. The proposed approach is interesting and appears to be novel. The theoretical results also show that the proposed method has appealing properties. \n\niii) The authors also provided several experiments showing interesting results from their methods. The first thing I would like to highlight is that I have checked the provided code. I see several inconsistencies and weaknesses between the provided code and the paper:\n\n1. There are several differences in the empirical implementation between the paper and the code. In Appendix A, the authors state that they are computing the entropic potential through stochastic optimization algorithms [Genevay et al, 2016]. However, this is not what is done in practice according to the provided code. In practice, the authors compute the potential between mini-batches of samples, they sample a minibatch of cifar10 experiments, then sample a minibatch of the source Gaussian, and simulate the gradient flows between the two minibatches. This style of minibatch approximation induces a bias that should at least be mentioned in the main paper but also discussed. Indeed, the authors do not compute the true Sinkhorn divergence but a minibatch approximation of it; this approximation is slightly different than the one from [1,2] and that should be discussed. I understand the reason why the authors use this approach (decreasing the cost of this preprocessing step), but this is not what they say they do in Appendix A. In that regard, the paper is much closer to the minibatch optimal transport Flow Matching [Pooladian et al., Tong et al] and Appendix A deserves a major revision.\n\n2. With the provided code, there are several insights that should be discussed in the paper. In the provided cifar experiments, the number of Gaussian samples used is 50000 samples. This number is extremely low to approximate the semi-discrete OT. Therefore, a discussion regarding the statistical performance of the method is needed in my opinion.\n\n3. As your method requires the simulation of the probability path, I wonder about the training time between your method and the recent Flow Matching approaches which are simulation free.\n\n4. There are many typos in the paper (including in titles: ie ExperimRnts, Notaions) that lead to poor clarity...\n\n5. The experiments include two toy datasets (synthetic 2D and MNIST). I would like to know how the method performs on other big datasets (Flowers, CelebA) or on other tasks such as single-cell dynamics [4].\n\n6. The related work on optimal transport is incomplete. Several works used the sliced Wasserstein distance to perform gradient flows [3].\n\n[1] Learning Generative Models with Sinkhorn Divergences, Genevay et al, AISTATS 2018\n[2] Learning with minibatch Wasserstein, Fatras et al, AISTATS 2020\n[3] Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions\n[4] TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics 1. [Pooladian et al., Tong et al.] proved that when the minibatch increases, they get closer to the true optimal transport cost (W_2^2). The interest of their method is that they can rely on minibatches and learn the vector field from an unlimited number of minibatches. Could you follow a similar approach and simulate the gradient flow during training? While it would be an expensive step in training, it might improve the metrics on the different generative model experiments.\n\n2. What is the performance of your method concerning the number of simulation steps (ie Euler integration and its learning rate)?\n\n3. What is the time of the preprocessing step concerning the training time?\n\n4. Could you compare your method with OT-CFM [Pooladian et al., Tong et al.] on the synthetic data? I am curious to compare the differences.\n\nIn my opinion, the mentioned weaknesses have to be revised and this paper should go under a major revision. I deeply think that the experimental section should better highlight what is done in practice and the theoretical section should mention the different biases (statistical and minibatch). Therefore, I recommend rejecting the current manuscript as it does not meet the ICLR acceptance bar.\n\n\n----- EDIT POST REBUTTAL -----\n\nI thank the authors for their answers. I have read the updated manuscript. While it is now better than before, I suggest they add a limitation section where they describe the different biases in their algorithm. I understand the motivations of the paper. Overall, I think that the manuscript deserves another round of reviews but I have decided to move my score to 5 as they have given good answers.",
         "873",
         "7",
         "8",
         "0.7648",
         "54",
         "0.0723611111"
        ],
        [
         "41",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_Kh9H",
         "1698606606187",
         "1699636333063",
         "6",
         "4",
         "3",
         "2",
         "2",
         "Through a series of approximations (and at times, really, relaxations) the authors show that the Sinkhorn gradient flow from one measure to another can be learned.  They do this by first reducing their relaxed problem to a vector field matching problem, and then proposing a neural network-based Algorithm for matching the Sinkhorn-Wasserstein flow's vector field by a neural network (though no convergence/approximation guarantees are proven).\nThe problem is interesting, and its solution is sufficiently novel to merit publication. The problem is natural to study, the results are mathematically correct, and the experiments are convincing. While the paper is mathematically correct, it does not provide theoretical justification for one of its main components, namely showing that approximate vector field matching yields approximate solutions for all time $t$.  I feel that without this guarantee, there is a gap in the theoretical viability of this model.  Nevertheless, this is a minor point since the length of a conference paper does not allow one to treat every such point.\n\nThere are minor typos throughout. \n* E.g. euclidean instead of Euclidean\n* $lim$ instead of $\\lim$ atop page 15 in the appendix\n* The positive scalar $\\delta$ is not defined in the proof of Theorem $1$\n* In the statement of Lemma 3: \"teh\" should read \"the\"\n\nSome references are obscure\n* For The fact that $\\mu + t\\delta \\mu$ converges weakly to $\\mu$, perhaps it is worth simply noting that due to linearity of integration (wrt to the measure term). Can it be shown that approximate vector field matching yields approximate solutions for all time $t$?",
         "262",
         "0",
         "1",
         "0.7647",
         "67",
         "0.0019972452"
        ],
        [
         "42",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KkYD",
         "1698745650108",
         "1700818697559",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper under consideration deals with the standard generative modelling setup (image generation from noise). To solve this problem, the authors propose to model the gradient flow w.r.t. the Sinkhorn divergence. The paper utilizes an explicit (forward) Euler discretization scheme, i.e., given a distribution $\\mu_t$ at the current time step $t$, the proposed method aims at finding the subsequent distribution $\\mu_{t + 1}$ following the gradient of the Sinkhorn divergence at point $\\mu_t$. The authors validate their methodology on toy 2D setups as well as standard image benchmarks (MNIST and CIFAR10).\n\n**Post-rebuttal update:** I thank the authors for the detailed answer. The majority of my concerns are properly addressed. I rise my score. However, I still tend to reject the paper. Also I agree with reviewer KKim that minibatch OT approximation should be discussed more thorougly. Thank you. To the best of my knowledge, the framework of the gradient flow w.r.t. Sinkhorn divergence for pure generative modelling has not yet been considered. This indicates that the paper is indeed bringing something novel to the ML community. At the same time, the idea of the Sinkhorn gradient flow has already arisen in previous research. In particular, [A] solves Sinkhorn barycenter problems by adjusting a generative distribution towards the barycenter distribution with the help of a procedure called “functional gradient descent” which is actually the discretization of the gradient flow w.r.t. the sum of Sinkhorn divergences to the target distributions. At the same time, it is worth mentioning, that [A] just simulates particles and does not build a generative model.\nRegarding the other strengths of the paper, I would like to note the well-organized Experiments section.\n\n[A] Sinkhorn Barycenter via Functional Gradient Descent, NeurIPS’2020 - Some theoretical results from the paper are known. For example, the statement of Theorem 1 could be found in [B] (eq. 26) or [C] (eq. 8). \n- The quality of the code provided is not good. There is no README/or other instruction to run the code. There are imports of non-existing classes. So, there is no possibility of checking (at least, qualitatively) the provided experimental results.\n\nFrom my point, the main weakness of the proposed paper is the limited methodological contribution. The authors simulate the particles of data following Sinkhorn divergence - as I already mentioned, this is not a super fresh idea. To make a generative model from these simulated trajectories, the authors simply solve the regression task to learn the local pushforward maps. And that is it. Combined with the fact, that the practical performance of the proposed approach is far from being SOTA in the generative modelling, the overall contribution of the paper seems for me to be limited. - My main question (and, probably, one of the main of my concerns) is regarding the proposed methodology. The authors propose to compute certain $\\mathcal{W}_{\\varepsilon}$ potentials (on discrete support of available samples) and then somehow take the gradients of these potentials w.r.t. the corresponding samples (eq. (13)). From the paper it is not clear how to compute the gradients, because the obtained potentials look like vectors of sample size shape, which are obtained through the iterations of the Sinkhorn algorithm. As I understand, in practice, the authors utilize SampleLoss from the geomloss package ([B]).  The outcome of this observation is that [B] should be properly cited when deriving the algorithm (section 4.2). I recommend authors explicitly use SampleLoss in the algorithm's listing. It will contribute to the clearness of what's going on. \n- The vector field of the Sinkhorn gradient flow is estimated by empirical samples. It is not clear how well this sample estimate approximates the true vector field. This point should be clarified. Note, that Theorem 2 works only for mean-field limit. \n- In the Introduction section, the authors consider a taxonomy of divergences used for gradient flow modelling, namely, \"divergences [...] with the same support\" and \"divergences [...]  with possible different support\". As I understand, the first class is about $f-$ divergences and the second class is about the other types (like Sinkhorn, MMD etc.). I have a question regarding the provided examples of works which deal with the former or the latter type of divergences. The fact is that the works [D], [E], [F], [G] deal with KL-divergence (or f-divergence) minimization. That is why I wonder why did the authors classify them as the second class.\n- A good work regarding poor expressiveness of ICNNs is [H].\n- What is the “ground” set ($\\S$ 3.1, first line).\n- Table 1. What are the differences between 1-RF, 2-RF and 3-RF methods?\n\n[B] Interpolating between Optimal Transport and MMD using Sinkhorn Divergences, AISTATS’2019\n\n[C] Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm, NeurIPS’2019\n\n[D] Large-scale wasserstein gradient flows. NeurIPS'2021\n\n[E] Optimizing functionals on the space of probabilities with input convex neural networks. TMLR\n\n[F]  Proximal optimal tranport modeling of population dynamics. AISTATS\n\n[G] Variational wasserstein gradient flow. ICML\n\n[H] Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. NeurIPS’2021.",
         "827",
         "0",
         "8",
         "0.7673",
         "53",
         "0.0867376775"
        ],
        [
         "43",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_MEFG",
         "1699146383667",
         "1699636332903",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces the idea of learning a time-dependent velocity field of the Sinkhorn Wasserstein gradient flow from samples from the target distribution to calculate the empirical velocity field approximations. The paper supports its claim by showing that the mean-field limit of this process recovers the true Sinkhorn Wasserstein gradient flow. They also validated the process with some empirical studies. The paper is well written and easy to follow. The proofs and arguments in the appendix are well-typed out and clear.  There are some nice diagrams in the empirical section to supports the claim the authors are making. I think the experiments could be more extensive. One thing about this method is to investigate the number of samples needed. effectively learn the velocity field. This is one important experiment missing as is remains unclear how sample-efficient the proposed method is. It would also make the paper more completing if the method is applied to generative models that output discrete random variable like binary mnist or even language modelling. One possible question is what happens if we change the source distribution to be closer to the target distribution like it was from a generator how would the method perform there. Another question is to better understand the sample complexity of the method as the current method may not be sample efficient due to the empirical distribution being approximated using the samples.",
         "230",
         "0",
         "0",
         "0.7569",
         "67",
         "0.1872807018"
        ],
        [
         "44",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_JSi7",
         "1698680587788",
         "1699636955419",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This article discusses a method to improve the application of SLM in the medical field, utilizing LLM's medical proficiency to boost SLM performance in medical tasks under privacy-restricted scenarios which has important social significance. The method was tested on MedQA, HEADQA, MedMCQA, and MMLU-professional medicine datasets, showing some improvements over existing methods. Additionally, the authors compared results across different sizes of training sets. see summary 1). Imprecise example of Privacy Protection.\nThe example in Figure 1 indicates that personal privacy issues are only present in the first sentence, and the key words \"man\" and \"admitted\" in that sentence have almost no impact on the subsequent content. Could it then be possible to simply delete the first sentence to achieve privacy protection, as extracting key words here does not seem to play a significant role.\n\n2). Privacy Protection as an Innovation Point\nRegarding the extraction of key words for privacy protection, the paper uses a medical NER model proposed by Neumann et al in 2019. We suggest further improvement of this model, for example, considering age as a crucial keyword for certain diseases and extracting it as necessary to better enrich the innovative aspects of the paper.\n\n3). Ambiguity of Symbols in Annotations\nAnnotation 13 on page 8 only appears in the content of the article but is not explained.\n\n4) The overall innovation of the methodology needs improvement, as the majority of the content relies on existing methods, such as the medical NER (Named Entity Recognition) model. please see the weaknesses.",
         "251",
         "0",
         "3",
         "0.8122",
         "66",
         "0.0869868637"
        ],
        [
         "45",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_gXvF",
         "1698819472631",
         "1699636955275",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This paper tried to improve the performance of small medical language models by introducing knowledge from large language models, which keeps the privacy of clinical text when using large language models.  The proposed method uses keywords instead of full raw text to generate initial evidence from LLM and feed the evidence to small language model. Privacy-preserving is an essential and common need when using LLM in clinical text. This paper tried to solve this problem by using keywords instead of raw text, the idea is novel and experiments demonstrated the effectiveness of this approach. 1. As this research utilized a named entity recognition model to extract keywords, it is possible that the NER model can extract privacy information such as patient names. Is there any filtering or postprocessing step to avoid that? In addition, it is not guaranteed that NER system will never extract sensitive patient information; for example, if the NER system incorrectly extracts a patient's address as a symptom, then the address may be leaked to LLM. Although it is very rare, it is still necessary to comment on this. \n2. As the LLM already provides a preliminary decision, I am curious about the performance if we only feed the preliminary decision from LLM to SLM. It is worth knowing which part of the LLM-generated information improves the SLM most. \n3. The related work section need to discuss more LLM application in the clinical area, especially the knowledge-enhanced LLM in clinical settings. For example, paper \"Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.\" also utilized external knowledge for clinical questions. \n4. By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem? By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem?",
         "326",
         "0",
         "4",
         "0.7696",
         "66",
         "0.0399925075"
        ],
        [
         "46",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_TtE2",
         "1698819599156",
         "1700663756238",
         "6",
         "4",
         "2",
         "2",
         "3",
         "The paper studied medical QA problems by incorporating large language models (LLMs) to assist small-language models (SLMs). To protect the private information in the data, the authors propose to first extract keywords and then use the keywords to query LLMs for intermediate content which can be used for SLMs to enhance prediction accuracy. 1. (originality) The proposed method is novel by extracting keywords and privately incorporating LLM for SLM-based predictions.\n2. (clarity) Overall, the paper is fair in presentation. The demonstrations of synthetic medical data with private information and extracted keywords are helpful for understanding the concepts.\n3. (significance) Versus the compared baselines, the proposed methods significantly improve the prediction accuracy on three medical QA tasks.\n4. (quality) The authors thoroughly evaluate the performance of the proposed method. 1. (Clarity) There is no specific definition of the private information. From Figure 1, it seems that privacy definition is restricted to private identifiable information (PII). The authors should clarify the scope of privacy risks. Importantly, the proposed method cannot address general private information leakage that is considered by strict formulations like differential privacy.\n2. (Quality) The evaluation of privacy is not strict. \n  - Risks: It is possible that the keyword extraction includes private identifiable information (PII), for instance, names and dates as shown in Figure 1. There is no theoretical guarantee for privacy protection or empirical evaluation of the leakage rates of such PII.\n  - Metric: The authors used the privacy budget for quantifying privacy risks:  the ratio of the number of words provided to the LLM to the total words in the original question. However, I doubt if the metric can imply some privacy risks. There essentially lacks an intuitive explanation of the relationship between the privacy budget and privacy risks.\n3. (Motivation) As the authors said, SLM presents a large gap compared to LLMs and thus there is no clear motivation to use SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. In the paper, there is no referred evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks. Thus, I strongly doubt if the motivation of the paper can hold. * There is no clear motivation to see SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. Is there any evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks?",
         "426",
         "0",
         "7",
         "0.7723",
         "55",
         "0.0983912484"
        ],
        [
         "47",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_EBQC",
         "1699202302455",
         "1701315616812",
         "6",
         "3",
         "3",
         "3",
         "3",
         "In situations where text data is subject to privacy protection constraints, this paper designs a small-scale language model to perform diagnoses of diseases. Utilizing the rich prior medical knowledge in LLM, the approach involves generating a medical knowledge-intensive context using privacy-protected text. This generated context, along with key terms extracted from the text and questions, is then input into the SLM, which is fine-tuned during training. Experiments across multiple datasets demonstrate that this fine-tuning process effectively enhances the accuracy of the diagnostic model. 1. This paper focuses on a very important research topic in the field of medicine: how to effectively extract more useful information from incomplete text under the conditions of privacy protection. The author has made full use of the domain knowledge in LLM to effectively fine-tune the SLM, which ensures that the lightweight models can achieve high accuracy.\n\n2. This paper presents rich and comprehensive experiments. Beyond basic decision-making tasks, it also explores solutions for few-shot experiments and out-of-distribution (OOD) model generalization using the methods discussed in this paper.\n\n3. This paper fully utilizes the rich domain knowledge in LLMs to expand the knowledge base of medical reports, achieving excellent diagnostic accuracy even while ensuring privacy protection. 1. The contribution of this paper to the algorithm and the significance of the clinical problems it addresses seem not to be very high.\n\n2. The main work of this paper appears more as an engineering problem, transferring domain knowledge from LLMs to SLMs. From the perspective of algorithmic contribution, there seems to be some room for improvement. 1. The experimental datasets in this paper are all question-and-answer test datasets, and whether the methods of this paper are applicable to medical report datasets requires additional experimentation. This is because in medical reports, how to generate high-quality questions using other LLM interfaces is a question worth studying.\n\n2. Large language models provide additional domain knowledge, but in the context of specific medical tasks, will the direct transfer of knowledge from LLMs to SLMs lead to incorrect information leakage into SLMs? How can we ensure that LLMs only enhance information relevant to the current medical issue without introducing additional errors or irrelevant information? This is a very important issue in the medical field, as it directly relates to patient diagnosis.",
         "378",
         "0",
         "7",
         "0.8087",
         "47",
         "0.1651777003"
        ],
        [
         "48",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E[x_t^\\top \\eta]>0$, where $E[\\cdot]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9",
         "0.7199",
         "67",
         "0.1048061787"
        ],
        [
         "49",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9",
         "0.8034",
         "67",
         "0.040322580600000005"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 28028
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>num_days_before_deadline</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_eS3u</td>\n",
       "      <td>1698243150596</td>\n",
       "      <td>1699636093263</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>This work proposes LSTNet, a self-supervised m...</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>67</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_jP4i</td>\n",
       "      <td>1698652503617</td>\n",
       "      <td>1699636093190</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1) This paper proposes a self-supervised metho...</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>67</td>\n",
       "      <td>0.160185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_wiS9</td>\n",
       "      <td>1698706547448</td>\n",
       "      <td>1699636093122</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper introduces LSTNet, which leverages ...</td>\n",
       "      <td>570</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7698</td>\n",
       "      <td>67</td>\n",
       "      <td>0.095387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_a6Ps</td>\n",
       "      <td>1698768293694</td>\n",
       "      <td>1699636092942</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper attempts to register point cloud pr...</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>67</td>\n",
       "      <td>0.140019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_Frem</td>\n",
       "      <td>1699350072271</td>\n",
       "      <td>1699636092872</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper presents a method of learning dense...</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>67</td>\n",
       "      <td>0.124242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28023</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_vt7i</td>\n",
       "      <td>1698673110283</td>\n",
       "      <td>1699636153803</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper extends the analysis of (Woodworth ...</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>67</td>\n",
       "      <td>0.077504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28024</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_oaZ7</td>\n",
       "      <td>1698928691830</td>\n",
       "      <td>1699636153728</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The paper studies the implicit regularization ...</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>67</td>\n",
       "      <td>0.019907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_fMm6</td>\n",
       "      <td>1698618130371</td>\n",
       "      <td>1699636636496</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The authors propose a network architecture to ...</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7971</td>\n",
       "      <td>66</td>\n",
       "      <td>0.103848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28026</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_tZQw</td>\n",
       "      <td>1698807944071</td>\n",
       "      <td>1699636636378</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper proposes InfoNet, a generalized alg...</td>\n",
       "      <td>346</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>66</td>\n",
       "      <td>0.101576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28027</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_9qjF</td>\n",
       "      <td>1698910414535</td>\n",
       "      <td>1699636636278</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>* This paper presents an innovative algorithm,...</td>\n",
       "      <td>670</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>66</td>\n",
       "      <td>0.135170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28028 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zzv4Bf50RW               1647             1695102158671   \n",
       "1        zzv4Bf50RW               1647             1695102158671   \n",
       "2        zzv4Bf50RW               1647             1695102158671   \n",
       "3        zzv4Bf50RW               1647             1695102158671   \n",
       "4        zzv4Bf50RW               1647             1695102158671   \n",
       "...             ...                ...                       ...   \n",
       "28023    014CgNPAGy               2200             1695179071455   \n",
       "28024    014CgNPAGy               2200             1695179071455   \n",
       "28025    0074qaufB6               5962             1695403263602   \n",
       "28026    0074qaufB6               5962             1695403263602   \n",
       "28027    0074qaufB6               5962             1695403263602   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "1      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "2      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "3      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "4      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "...                                                  ...   \n",
       "28023                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28024                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28025          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28026          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28027          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "1      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "2      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "3      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "4      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "...                                                  ...   \n",
       "28023  On the Role of Momentum in the Implicit Bias o...   \n",
       "28024  On the Role of Momentum in the Implicit Bias o...   \n",
       "28025  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28026  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28027  InfoNet: Missing Information Retrieval in Mult...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Establishing accurate dense 3D correspondences...  Reviewer_eS3u   \n",
       "1      Establishing accurate dense 3D correspondences...  Reviewer_jP4i   \n",
       "2      Establishing accurate dense 3D correspondences...  Reviewer_wiS9   \n",
       "3      Establishing accurate dense 3D correspondences...  Reviewer_a6Ps   \n",
       "4      Establishing accurate dense 3D correspondences...  Reviewer_Frem   \n",
       "...                                                  ...            ...   \n",
       "28023  Momentum is a widely adopted and crucial modif...  Reviewer_vt7i   \n",
       "28024  Momentum is a widely adopted and crucial modif...  Reviewer_oaZ7   \n",
       "28025  Faulty sensors in a multiple input stream setu...  Reviewer_fMm6   \n",
       "28026  Faulty sensors in a multiple input stream setu...  Reviewer_tZQw   \n",
       "28027  Faulty sensors in a multiple input stream setu...  Reviewer_9qjF   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1698243150596           1699636093263              6  ...   \n",
       "1      1698652503617           1699636093190              5  ...   \n",
       "2      1698706547448           1699636093122              3  ...   \n",
       "3      1698768293694           1699636092942              5  ...   \n",
       "4      1699350072271           1699636092872              5  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "28023  1698673110283           1699636153803              5  ...   \n",
       "28024  1698928691830           1699636153728              3  ...   \n",
       "28025  1698618130371           1699636636496              1  ...   \n",
       "28026  1698807944071           1699636636378              3  ...   \n",
       "28027  1698910414535           1699636636278              5  ...   \n",
       "\n",
       "       review_soundness  review_presentation  review_contribution  \\\n",
       "0                     3                    2                    3   \n",
       "1                     3                    3                    2   \n",
       "2                     2                    2                    2   \n",
       "3                     3                    3                    3   \n",
       "4                     3                    3                    2   \n",
       "...                 ...                  ...                  ...   \n",
       "28023                 3                    3                    2   \n",
       "28024                 1                    2                    1   \n",
       "28025                 2                    2                    1   \n",
       "28026                 3                    2                    2   \n",
       "28027                 2                    3                    2   \n",
       "\n",
       "                                            total_review length_words  \\\n",
       "0      This work proposes LSTNet, a self-supervised m...          191   \n",
       "1      1) This paper proposes a self-supervised metho...          215   \n",
       "2      This paper introduces LSTNet, which leverages ...          570   \n",
       "3      This paper attempts to register point cloud pr...          412   \n",
       "4      This paper presents a method of learning dense...          290   \n",
       "...                                                  ...          ...   \n",
       "28023  This paper extends the analysis of (Woodworth ...          356   \n",
       "28024  The paper studies the implicit regularization ...          303   \n",
       "28025  The authors propose a network architecture to ...          544   \n",
       "28026  This paper proposes InfoNet, a generalized alg...          346   \n",
       "28027  * This paper presents an innovative algorithm,...          670   \n",
       "\n",
       "       citation_count  question_count   mattr num_days_before_deadline  \\\n",
       "0                   0               0  0.7074                       67   \n",
       "1                   0               0  0.7009                       67   \n",
       "2                   7              10  0.7698                       67   \n",
       "3                   0               5  0.7920                       67   \n",
       "4                   0               7  0.6900                       67   \n",
       "...               ...             ...     ...                      ...   \n",
       "28023               1               5  0.7166                       67   \n",
       "28024               0               0  0.7945                       67   \n",
       "28025               0               7  0.7971                       66   \n",
       "28026              10               4  0.7788                       66   \n",
       "28027               3               1  0.8585                       66   \n",
       "\n",
       "       sentiment_polarity  \n",
       "0                0.090000  \n",
       "1                0.160185  \n",
       "2                0.095387  \n",
       "3                0.140019  \n",
       "4                0.124242  \n",
       "...                   ...  \n",
       "28023            0.077504  \n",
       "28024            0.019907  \n",
       "28025            0.103848  \n",
       "28026            0.101576  \n",
       "28027            0.135170  \n",
       "\n",
       "[28028 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the JSON file as a pandas DataFrame\n",
    "df_reviews = pd.read_json('/home/ali/Review_Quality_Benchmark/data/processed/openreview_ICLR2024_v5.json')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing similarity scores: 100%|██████████| 28028/28028 [07:54<00:00, 59.12it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cf9eb07c-9d7b-4145-af65-29e065601d21",
       "rows": [
        [
         "0",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_eS3u",
         "1698243150596",
         "1699636093263",
         "6",
         "2",
         "3",
         "2",
         "3",
         "This work proposes LSTNet, a self-supervised method to establish reliable 3D dense correspondences irrespective of the input point clouds’ rotational orientation.\n\nSpecifically, LSTNet learns to formulate SO(3)-invariant local shape transform for each point in a dynamic, input-dependent manner. Each point-wise local shape transform can map the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor, which is passed to the decoder to reconstruct the shape and pose of the input point cloud. \n\nThe proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish dense point-wise correspondences via nearest point pairs between cross-reconstructed point clouds. The self- and cross-reconstruction training strategy is simple yet effective. \n\nLSTNet demonstrates state-of-the-art performance on 3D semantic matching when evaluated on the KeypointNet dataset and part segmentation label transfer when evaluated on the ShapeNet dataset. The performance of aligned shape pairs under the setting of I/I shows that other methods, such as CPAE, are much better than LSTNet. The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.\n\nLack of limitations.",
         "191",
         "0",
         "0",
         "0.7074",
         "0.09",
         "0.9708871841430664"
        ],
        [
         "1",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_jP4i",
         "1698652503617",
         "1699636093190",
         "5",
         "4",
         "3",
         "3",
         "2",
         "1) This paper proposes a self-supervised method to find semantically corresponding points for a point cloud pair;\n\n2）The main idea is to decouple a point cloud feature learning process into a SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms;\n\n3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method. 1) This paper is generally well-written;\n\n2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant\npoint-wise local shape transforms seems to be novel;\n\n3) Experimental results are good. 1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset. \n\n2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation. \n\n3) The running time and GPU memory cost is blurry for me;\n\n4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation\nfrom Rotated, Noisy, and Decimated Point Cloud Data]. Please refer to the weaknesses.",
         "215",
         "0",
         "0",
         "0.7009",
         "0.1601851852",
         "0.8842770457267761"
        ],
        [
         "2",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_wiS9",
         "1698706547448",
         "1699636093122",
         "3",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces LSTNet, which leverages an SO(3)-equivariant encoder-decoder architecture(Vector Neuron Networks, VNNs) and proposes a novel function called local shape transform to further transform the learned features. The proposed method is validated on both the 3D keypoint transfer and part segmentation label transformer tasks. 1. The idea of cross-reconstruction for generating inter-object correspondences in a self-supervised way is interesting;\n\n2. The overall writing is good and the methodology part is well-organized and easy to follow. 1. The novelty of this work seems insufficient for ICLR. The whole pipeline heavily relies on VNNs and the main contribution I personally consider is the local shape transform and the self-supervised mechanism for correspondences.\n\n2. Regarding the local shape transform:\n   2.1. From 3.1.1, the SO(3)-invariant output is $\\mathbf{V}\\mathbf{U}^T \\in \\mathbb{R}^{C \\times C}$, while in 3.1.2, the obtained SO(3)-invariant features $\\mathbf{V} \\in \\mathbb{R}^{C^\\prime \\times 3 \\times N}$ have a different shape;\n\n   2.2 The authors claimed that the local shape transform transforms the global features to local ones. Regarding this, I have two questions. \n\n      2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer. \n\n      2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the \"global\" features by such a mechanism, the features turn to \"local\"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so)\n\n3. Regarding the experiments:\n    3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments;\n\n     3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.\n\n    3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.\n\n   3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?\n\n4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.\n---------------------------------------------\n[1]. Zohaib et al. SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data, ICCV 2023;\n\n[2]. Dent et al. PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors, ECCV 2018\n\n[3]. Ao et al. SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration, CVPR 2021\n\n[4]. Wang et al. You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors, ACM MM 2022\n\n[5]. Yu et al. Rotation-Invariant Transformer for Point Cloud Matching, CVPR 2023 See weaknesses.",
         "570",
         "7",
         "10",
         "0.7698",
         "0.0953869048",
         "0.8982679843902588"
        ],
        [
         "3",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_a6Ps",
         "1698768293694",
         "1699636092942",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper attempts to register point cloud properties to their templates without precise correspondences and exact shape matching. To achieve this, the authors trained a local shape transform (LST) network that produces SO(3) invariant correspondences. The training is self-supervised. The experimental results on ShapeNet look nice. - Valid motivation. Unlike the abused topic, vanilla point cloud registration, the motivation stands and could potentially benefit practical usages.\n- The SO(3)-invariant network design intrinsically ensures robustness against rotations.\n- The joint usage of a global descriptor and a local descriptor makes sense and may help with classification and recognition directly.\n- The self-supervision scheme looks plausible by self and cross-reconstruction. My major concern is with the experimental setup. While the experiments on ShapeNet is common in the community and shows good result, I am in general doubtful whether such an approach could be really applied to the real world. \nIn motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. [Scan2CAD, CVPR 2019]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases. \n\nThe authors also take groundtruth keypoints and semantic segmentations from datasets for the experiments. In the real-world, however, obtaining such accurate high-level semantic information already requires a deep understanding of the point cloud, and its segmentation backbone may already be SO(3) invariant. This impairs the strength that the authors proposed. Following my points in the \"weaknesses\" section, I am curious about several relevant problems in the practical setup (i.e., scan to model). \n1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity? \n2. Will the network still be functional if the density distributions are different across input and output? \n3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?\n4. Would non-gt and/or biased key points and semantic parts be transferred properly?\n\nIt would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.",
         "412",
         "0",
         "5",
         "0.7920",
         "0.1400193798",
         "0.9250699281692505"
        ],
        [
         "4",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_Frem",
         "1699350072271",
         "1699636092872",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a method of learning dense 3D correspondence between shapes in a self-supervised manner. Specifically, it is built on an existing SO(3)-equivariant representation. The input point clouds are independently encoded to SO(3)-equivariant global shape descriptor Z and dynamic SO(3)-invariant point-wise local shape transforms. Then the network is trained via penalizing errors in self- and cross- reconstructions via the decoder. The experiment validates the effectiveness of the proposed method. 1. The paper is in general well organized and easy to follow. \n2. The proposed method is straightforward and shown to be effective on the test data. 1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method. \n2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.\n3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?\n4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design. Please refer to the Weaknees part.",
         "290",
         "0",
         "7",
         "0.6900",
         "0.1242424242",
         "0.9471604824066162"
        ],
        [
         "5",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_xDut",
         "1698437142685",
         "1699636121514",
         "8",
         "5",
         "4",
         "4",
         "3",
         "This paper is about multilingual federated prompt tuning for low-resource languages, bringing together federated learning and prompt-tuning techniques. This approach leverages parameter-efficient fine-tuning which preserves user privacy, and additionally, the authors introduce language distance in order to highlight the strengths of the proposed paradigm. The results show that the technique is parameter efficient and computationally beneficial, reducing by 99% the number of trainable parameters while increasing the performance on downstream tasks (XNLI, NC) of ~7% accuracy. This paper makes a contribution to the federated learning field showing how federated learning can be used to enhance the performance of language models while preserving user privacy. The experiments are well-designed and the results are convincing - added to extensive analyses in order to leverage the capabilities of the proposed paradigm, but also its limitations. Although the paper is generally well-structured, the title mentions `low-resource` languages. However, the two tasks leveraged are primarily on high-resource languages, rather than low-resourced language. I would suggest to the authors to include more tasks - there are many low-resource language datasets (for instance on African languages MasakhaNEWS, Masakhaner (1.0 and 2.0 - which have been cited by the way but not used), MasakhaPOS; Indic languages: https://github.com/AI4Bharat/indicnlp_catalog; etc) and tasks.\n\nThis is rather a highly recommended suggestion, that does not take away the contribution of the paper. Including them would strengthen the paper and be more in accordance with the title. The Aggregation formula is a bit confusing. Did you mean h_{global, t+1} = \\sum_{k=1}^{m} h_{k, t}? Because the `t+1` on the last term does not make sense to me.",
         "262",
         "1",
         "0",
         "0.7963",
         "0.1664583333",
         "0.9397115707397461"
        ],
        [
         "6",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_E7Lk",
         "1698484432194",
         "1700794322411",
         "1",
         "5",
         "1",
         "2",
         "2",
         "The paper introduces a finetuning paradigm that combines federated learning (FL) with prompt tuning for multilingual finetuning on certain, with the goal to preserve the privacy of the local data used for the finetuning job. The results show better performance in certain classification tasks, such as New Classification and XNLI. - Federated learning have recently gained good traction, the paper is a good application of it in the tasks of finetuning LLM. The paper chooses to use prompt tuning instead of full tuning to save costs, as well as to avoid overfitting on small data.\n- The method produces better performance on the 2 classification tasks compared to baselines - The proposed is a very trivial combination of federated learning and prompt tuning, which both are established methodology in their own realm. There is no novelty, such as modification or adjustment to the method that may have give a better results. In other words, people with an objective to do federated learning for privacy purpose can easily come up with prompt tuning as a solution to reduce costs.\n- Though it may have implicitly inferred by the concept of FL, the paper did not mention why and how federated learning helps with privacy and in which case one should use FL for their application.\n- The purpose of the task of multilingual finetuning in this case, is not warranted use case of privacy preservation.\n- There is no reported evidence that privacy is actually preserved. Such as whether the final model memorize the local data.\n- There are better parameter-efficient finetuning methods, such as LORA/QLora, that the authors should conduct experiments on and do comparision with prompt tuning.\n- The results show prompt tuning are much worse than full-federated tuning, thus casting doubt if the cost-saving is worth it.\n- Other generative and knowledge-based tasks, such as QA, translations and summarizations should be performed.\n\n**I have read the author responses and I advocate for a strong reject, below are reasons:**\n\n* I mentioned the paper has fundamental problems with originality, novelty, where the paper uses an unrelated existing and non-novel method designed for a different problem (fed-learning) to solve a low-resource \"privacy\" problem that does not make sense or exist yet, in which the method itself much worse than standard training. \n* Instead of addressing the scientific issue, the authors distracted away by pressing that they are helping the low-resource communities, or improving inequality as a societal issue. These multiple responses are lengthy, wordy, unnecessary, and filled with many \"politically correct\" (I don't know better word) things to avoid the scientific issue. Agree that we should help those under-represented communities, but after reading these, I shouldn't feel like rejecting the paper is an action against those communities.\n* The problem of \"a low-resource community who wants to shut down their internet and border\" is unfounded. We train LLM on public data we can find. If they wants to protect their secret data, they can download a public pre-trained model and fine-tune on their own. \n* The real problem is how to improve low-resource with the limited data we have, which the paper fails to suggest a better solution than trivial.\n* Less communication doens't mean more privacy, because we transfer model weights, not the data. And less parameters doesn't mean less private information be leaked. This misconception leads to wrong approach.\n* The author claims to be the first to target the low-resource problem and many other things, but there have been many works in previous years about this. Please be careful with this kind of \"we are first\" statements.\n* Overall, none of the responses has helped resolve the issues stated in the review. - Citation formet incorrect, \\citep{} be used to produce something like (Abc, et al., 2023) and not Abc, et al., 2023 everywhere.\n- Many grammatical errors, such as \"Throughout the fine-tuning...\"\"",
         "646",
         "0",
         "0",
         "0.8297",
         "0.1105421563",
         "0.9287629723548889"
        ],
        [
         "7",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_AG4r",
         "1698731849876",
         "1700723834276",
         "3",
         "4",
         "4",
         "1",
         "3",
         "The paper proposes a Multilingual Federated Prompt Tuning paradigm, where lightweight multilingual prompts are encoded and on regional devices in different languages and aggregated by averaging the prompt embeddings. The goal is fine-tuning multilingual large language models on resource-constraint devices in a privacy-preserving way. The paper evaluates this approach via the XNLI task, ablated into data efficiency, \"language distance\", and communication cost, against \"monolingual\" training (baseline). The innovation lies in that the paper somehow mashes federated learning, multi-lingual (low resource) language models, and Parameter-Efficient Fine-Tuning in one paper. The fact that they managed to come up with a storyline for a system that bolsters the benefit of each approach is commendable. - poor presentation: the citations are not separable enough from the main text, e.g., without any parenthesis, rendering the submission unreadable. Against the tradition and ease of reading, abbreviations are not defined in advance, e.g., NLI, PFL, PLM.\n- claims unverifiable: no code release.\n- conflating existing metrics with innovation: language distance is not a new concept.\n- conceptual weakness: the contrived baseline was bound to give the proposed approach an edge due to lack of federated learning. Also, what the paper refers to as prompts are just classifier model input, which are different from decoders-style LLM prompts as commonly acknowledged. Finally, the approach has absolutely nothing to do with privacy which the abstract and the main body consistently bolsters. \n- evaluation weakness: only two tasks (new classification and XNLI) was used in evaluation. In section 5.4.1 \n\n>  In both the NC and XNLI tasks, despite the total number of\nparameters exceeding 278 million, the trainable parameters are only around 1.2 million, accounting\nfor less than 0.5% of the total.\n\nCould the authors clarify which part of the model is being fine-tuned?",
         "293",
         "0",
         "0",
         "0.8387",
         "-0.0202793239",
         "0.8988320827484131"
        ],
        [
         "8",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_LsRx",
         "1698767055794",
         "1700887244625",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The paper applies federated learning on multilingual scenarios to efficiently parameter-efficient prompt fine-tuning in a manner that preserves user privacy. The idea is to utilize a single global encoder that accumulates the information via federated prompt averaging. Thus, it learns the language patterns without knowing about the user information. They evaluated the experiment on NC and XNLI datasets and found performance improvement over the baseline. - The method is very practical since it is simple and efficient, and it is an appropriate method for training multilingual model.\n- Good analysis on the data efficiency and distance measurement, showing the effectiveness of the proposed method. - In terms of novelty, the proposed idea is not new, and it is only a further investigation of the multilingual setting.\n- Lack of clarity. The paper does not provide enough information about how the prompts are constructed or look like and hyperparameters for all settings. I suggest adding the information to the paper or appendix. Questions:\n- Do you have any findings on why multilingual centralized learning is far worse than federated learning in Table 2?\n- How did you tune the training and parameter averaging?\n\nSuggestions:\n- Figure number is missing on Page 2\n\n\"As depicted in Figure , \"\n\n- Missing Figure/Table \n\n\"This translates to over 99% reduction in the communication overhead shown in 3\"\n\n- Typo\n\n\"Finetuning accuracy across different lanugages on the NC task.\"",
         "234",
         "0",
         "0",
         "0.7573",
         "0.0373593074",
         "0.901097297668457"
        ],
        [
         "9",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_agCZ",
         "1698322956814",
         "1699636820093",
         "5",
         "3",
         "2",
         "2",
         "2",
         "To tackle Multi-Domain Text Classification (MDTC) task, one mainstream of proposed techniques is to extract the features via the shared and private extractors to capture the domain-invariant and domain-specific knowledge, respectively. However, as the number of domains increases, the count of their private extractors will also rapidly surge.  \nThe author proposed a novel approach Stochastic Adversarial Network (SAN) to avoid the unaffordable explosion of parameters when encountering the newly emerged domains. Specifically, the author modeled the domain-specific feature extractors as a multivariate Gaussian distribution. Furthermore, some tricks, such as domain label smoothing and robust pseudo-label regularization techniques, are utilized to improve the overall performance.\nExtensive experiments on two benchmarks demonstrate the superiority of the proposed method compared with the state-of-the-art baselines. 1.\tThis paper proposes a novel approach, called Stochastic Adversarial Network, to reduce the computational cost while meeting a large amount of domains.\n2.\tThis paper originally employs Gaussian distribution to generate private extractors in order to circumvent the extensive parameters found in previous works. \n3.\tThis paper conducts numerous experiments to show the effectiveness of the proposed scheme. Moreover, the parameter sensitivity and ablation study demonstrate the rationale of parameter selection and the necessity of each modules, respectively. 1.\tThe motivation is trivial. It is hard to say that the model size is the bottleneck of the training process according to Table.1 and 9. 342.91M is absolutely fine in current period. Further, inference process may gain nothing in the aspect of computational acceleration as we only choose one private extractor from the Domain Discriminator D. \n2.\tThe baselines are outdated and improvements on two benchmarks are limited. According to Table 2,3 and 4, it can hardly convince me that the proposed model exactly outperforms the SOTA models. It is worth noting that the author points out this limitation in Appendix E. \n3.\tThe writing and organization need to be improved. \na)\tThe emphasis in writing has been misplaced. As the author highlights the role of multivariate Gaussian distribution in Abstract, you are supposed to tell more story of it instead of the regularization term, which is the idea of others.\nb)\tThe effectiveness is not the focus of this article, efficiency is. Therefore, moving D. 5 to the main body of the article perhaps make your contribution more prominent. \nc)\tSome tools can be utilized effectively to optimize sentence structure and composition. 1.\tThe aim of equation (3) is to ensure that the shared Feature Extractor F_s exactly extract the domain-invariant features. Thus the author maximum this loss to let the discriminator D be confused about the features coming from F_s. Here is the question: discriminator D may lack of capabilities to recognize the difference among domains as this loss function does not involve any domain knowledge.\nThere may exists another adversarial network in equation (3), i.e. domain-specific extractor enhances the capabilities of discriminator D and domain-invariant extractor still confuse the discriminator D. \n2.\tAs a classic NLP task, this method inevitably needs to be compared with chatgpt. Currently, chatgpt has shown remarkable zero-shot capabilities. Therefore, you need to convince the reviewers why your method should be used instead of chatgpt or highlight the scenarios in which your method has significant advantages.",
         "534",
         "0",
         "5",
         "0.7784",
         "0.09682159950000001",
         "0.9668992161750793"
        ],
        [
         "10",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_NpVu",
         "1698685251472",
         "1699636819980",
         "1",
         "4",
         "1",
         "3",
         "1",
         "The paper presents a new model for MDTC, built on the previous shared-private feature extraction architecture. The innovation includes 1) modelling the parameter of domain-specific feature extractors as a Gaussian random variable, and for each domain, the parameter is drawn from the distribution. This is why the model is called stochastic adversarial network, or SAN, 2)  domain label smoothing 3) pseudo labelling regularization.  The authors show some empirical successes on some datasets. The paper demonstrates that the authors are well aware of the challenges in MDTC and are familiar with various tools in deep learning (such as reparametrization trick, label smoothing, pseudo labelling etc). I have some concerns about this work.\n\n1. Assuming the design of proposed model is sensible (in fact I have doubts on this; see 2), the work heuristically puts together a bunch of well-known techniques to improve performance. Works of primarily such a nature, although potentially valuable in practice, do not possess enough novelty that justifies a publication in ICLR. \n\n2. I have doubts on the proposed approach in the \"stochastic\" part. Let us track the parameter $W_1$ of the domain-specific feature extractor for domain 1. In the beginning it is drawn from the prescribed Gaussian, say, its value is $W_1^{(0)}$, and after the first iteration, the Gaussian parameter gets updated (using the reparametrization trick)  -- well, whether Gaussian parameter is updated or not is not critical here. Then in the next iteration, $W_1$  is drawn again, let us call it $W_1^{(1)}$. If this understanding is correct, then $W_1^{(0)}$ and $W_1^{(1)}$ can be very different. That is, along the training process, $W_1$ will randomly hop everywhere as long as the Gaussian variance is not vanishing. How would such a scheme work at all? Bringing the parameter $W_2$ of the second domain-specific extractor into the picture would show an even more absurd picture: at each iteration $t$, $W_1^{(t)}$ and  $W_2^{(t)}$ are random variables following the same Gaussian distribution. How would $W_1$ and $W_2$ track their respective domain specific features?  If this structure were to work, it would have to be the case where the Gaussian variance is very small (which might be the case as shown in Figure 3 of the appendix). In that case, all domain-specific extractors are more or less the same, i.e, all equal to the Gaussian mean, only subject to some tiny *domain-nonspecific* random perturbation. That would defeat the entire purpose of having domain specific feature extractors. -- I could misunderstood the paper and I am willing to hear the authors' defence on this. In your defence, please also show the initial and final values of the Gaussian mean vector $\\mu$ (say, in terms of its L1-norm divided by its dimension), I would like compare it with $\\sigma$. See weakness 2.\n\nAdditional question: The authors say that the conventional shared-private adversarial scheme will have \"exponential increase\" in model parameters as new domains emerge? Why is it exponential?",
         "484",
         "0",
         "3",
         "0.7855",
         "-0.0365584416",
         "0.8471299409866333"
        ],
        [
         "11",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_bAwA",
         "1698806204960",
         "1699636819830",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper tackles the multi-domain text classification (MDTC) problem, and tries to minimize the amount the learning parameters by introducing a stochastic feature extractor (domain feature). The model is effective in handling the benchmark datasets and outperform the other baseline models. Additional multi-source UDA experiment is also conducted as a simple model extension. The proposed model performs strong in the benchmark dataset, with minimized learning parameters. The design of using both shared/private feature extractor is interesting and effective in merging the domain in the latent space. The proposed method is straightforward and easy to understand. 1. Though the proposal seems to be effective and achieving strong performance, the model itself still uses a relative old adversarial backbone, with the discriminator approach for removing the domain invariant feature. The two-feature-extractor approach is interesting, but that is mainly to deal with parameter increase in the MDTC problem. It would be great to see other design improvement in the model.\n2. The performance gain in using the proposed model is marginal on the Amazon review/FDU-MTL datasets. Also, it would be great to have some analysis on adjusting the setting between the two feature extractors. 1. This might be somewhat irrelevant, but would the model perform well in multi domain classification in other domain type(s), e.g., images?",
         "213",
         "0",
         "3",
         "0.7456",
         "0.26833333330000003",
         "0.9479958415031433"
        ],
        [
         "12",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_skmj",
         "1698632081062",
         "1701140370231",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper studies multi-modal generalization in neural networks such as transformer-based models and recurrent networks. To do so, the authors propose Genertic COG, a modular benchmark with multi-modal splits to test for 3 types of generalization: 1) distractor (generalization to different noise distribution), 2) systemic compositional (generalization to new permutation of task structures) and 3) productive compositional (generalization to tasks of greater complexity) generalization. Experiments conducted by the authors showed that while cross-attention based transformers (e.g. CrossAttn and Perceiver) outperform other models and perform well on distractor and systemic compositional generalization, they fail at productive generalization when the depth of the task tree goes to out-of-distribution (>3). Representational analysis is done to show that cross-attention based transformers (e.g. CrossAttn and Perceiver) superior performance on distractor generalization might be due to their ability to better retain task-relevant (e.g. stimulus and response) information at the penultimate layer. +The paper studies a timely and critical question about the generalization capability of multimodal transformer-based models\n\n+The proposed benchmark dataset uncovers a limitation of current multimodal transformer-based models: productive generalization which can facilitate the development of more generalizable transformers/LLMs. \n\n+The paper is generally well-written and easy to follow -While the paper’s studies show that certain designs (e.g. cross-attention) seem to confer multi-modal generalization, there are still some key questions that can be more thoroughly studied to uncover the reasons why this is the case.\n\n-Similarly, important discussions such as why the (cross-attention) transformers might fail at productive generalization is lacking. What is the key architectural difference between dual stream transformer and transformers with cross attn that can explain their generalization performance? Is it only the lack of a cross attention between the different modalities?\n\nPossible typo:\n“Finally, we included a Perceiver-like model (Jaegle et al., 2021), an architecture designed to generically process multimodal inputs (Fig. 2f).”:  (Fig. 2f) > (Fig. 2e).\n\n\n==Post-Rebuttal==\nI appreciate the authors' response and decided to keep my score.",
         "318",
         "1",
         "3",
         "0.8097",
         "0.0690708101",
         "0.8793090581893921"
        ],
        [
         "13",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_a4Su",
         "1699400405601",
         "1699636123172",
         "3",
         "3",
         "1",
         "2",
         "2",
         "This paper proposes a new benchmark for assessing various forms of generalization in a multimodal setting named gCOG. The dataset includes several different splits intended to measure different aspects of generalization. The paper also compares several different model architectures on the dataset. * The paper introduces a new dataset, gCOG. While the dataset is conceptually similar to those from prior work, such as gSCAN, it supports different types of contexts and instruction types, including more compositional instructions. I'm aware of some prior work (e.g. [1], [2]) that studied compositional generalization in natural language tasks and found that gains on one synthetic task did not always transfer to other tasks, so increasing the diversity of such benchmarks for assessing compositional generalization and related challenges in the multimodal setting could be a potentially valuable contribution.\n\n[1] https://arxiv.org/abs/2007.08970\n[2] https://aclanthology.org/2021.acl-long.75/ * I'm concerned about the strength of the baselines used in the paper (see my related questions below). While the primary contribution of the paper is the dataset, it is also important to establish strong baselines for this new dataset and to ensure that the conclusions from the empirical results are valid. The appendix states that only a *single Transformer layer* with a *single attention head* was used. This is almost certainly not an optimal depth and number of attention heads. Relatedly, it looks like some models are potentially underfit, according to the figures. With >5M training examples and a relatively simple input space, I would have expected a reasonably sized Transformer model to achieve low training loss and reasonable IID generalization. If these models could have been applied to similar tasks such as gSCAN (even using symbolic tokens to represent the scene context), where they could be compared with comparable baselines from prior work, this would have helped establish that these are indeed reasonably strong baselines that have been well tuned.\n* The qualitative difference between gCOG and datasets from prior work such as gSCAN was not very clearly described. For example, one of the key claims seemed to be gCOG \"employs generic feature sets that are not tied to any specific modality\". However, it seems like it is a useful property for a multimodal dataset to have a clear relation to real-world multimodal tasks. Indeed, the authors provide interpretations of their tasks in the form of natural language instructions and visual scenes (e.g. in Figure 1), and these are very useful for understanding the task. Representing this dataset using familiar modalities (e.g. vision, natural language) could enable future work to study different research questions, e.g. the impact of pre-training. The ability to alternatively represent the task input as a sequence of tokens is also reasonable for studying certain research questions, but this also seems possible for datasets from prior work. For example, I understand that gSCAN includes both symbolic descriptions as well as visual renderings. Anyways, I think clarifying the motivation for this dataset (e.g. increasing diversity of available benchmarks, focusing on different generalization challenges, etc.) separately from how inputs are represented for the experiments in this paper (e.g. token sequence vs. images and natural language) would be useful.\n* Some of the main empirical conclusions (e.g. that generalization to greater \"depth\" is challenging for models such as Transformers) are generally known from prior work.\n\nnits:\n* Introduction paragraph 1 - \"on a carefully controlled generic multimodal reasoning tasks\" -> \"on carefully...\" or \"...task\"\n* Appendix A.2.1 - Maybe reference Tables 8 and 9 where you discuss different positional embeddings.\n* Consider discussing [3] in related work. [3] demonstrated the importance of cross-modal attention for gSCAN, and similarly studied the relative difficulty of various aspects of generalization, including distractors.\n\n[3] https://aclanthology.org/2021.emnlp-main.166/ * Why not try more layers and attention heads, e.g. following a standard hyperparameter setting for model size such as those of BERT-Base? Or even BERT-Small?\n* In Figure 2 (F) why does the single-stream Transformer have almost double the parameters of the double stream Transformer? For the other Transformers, do the encoder blocks used for the task vector and stimulus vector share parameters? \n* What optimizer and hyperparameters (e.g. learning rate) were used for training? How were these chosen? I didn't see these details in Appendix A.2. \n* Position embeddings - Since you are representing 10x10 grids as 1D sequences, 1D relative positions may not capture this structure well. On the other hand, absolute position embeddings seem potentially problematic in the case of the SSTrfmr model, since they will not be consistently assigned to the same grid position if the text sequence is first and has varying length. Mitigating this may be important to provide for a fairer comparison with the SSTrfmr model.\n* To what do you attribute the periodic loss spikes during training that are shown in Figure 4 (E)?\n* I found the usage of \"cross-attention\" a bit confusing. For example, the single stream Transformer features cross-modal attention as an implicit consequence of self-attention over the concatenated sequence. I thought this would commonly be referred to as an instance of \"cross-attention\" between modalities. \n* Does the dataset also contain visual renderings and natural language instructions to enable future work to study these tasks using familiar modalities?",
         "860",
         "10",
         "1",
         "0.8184",
         "0.076096273",
         "0.8955636024475098"
        ],
        [
         "14",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_DJb6",
         "1699470958350",
         "1699636122858",
         "8",
         "4",
         "3",
         "3",
         "3",
         "The paper introduces a new multimodal question answering benchmark for out-of-distribution generalization, specifically covering task compositionality, robustness to distractors and combinatorial generalization. It uses this benchmark to evaluate various models and analyze their performance. - **Topic**: The paper studies an important topic which in my opinion is underexplored in current deep learning research. Especially given the tendency these days to scale training up to vast amounts of data, I believe it is particularly important to design carefully controlled benchmarks that can: evaluate the model’s performance from a critical and cautious standpoint, point to their fundamental limitations (e.g. systematic generalization), and support further research about ways to overcome these.  \n- **Evaluation**: The paper offers both extensive extrinsic evaluation, with performance comparison of various models on the different generalization skills, as well as intrinsic analysis of their internal representations’ degree of alignment to the stimuli.\n- **Clarity**: The writing quality is good and the paper is clear and easy to follow. The paper is well-organized, claims and findings are clearly stated, and useful figures and diagrams are provided.\n- **Related Works**: It does a good job in providing the relevant context, motivation and related works. \n- **Contribution**: The empirical findings of the paper on the benefits and limitations of different inductive biases such as recurrent and attention-based are important and may be of broad interest to the community. - **Pre-trained models** The paper focuses on models trained from scratch rather than pre-trained. This could be a strength and a weakness. On the one hand, it allows for isolating the contribution of the architectural choices from other factors of optimization, and training data. On the other hand, it has been observed that by training models at large enough scales enables the emergence of generalization capabilities, which we don’t see in smaller scales. I think it will be critical to also analyze the performance of pretrained models on the benchmark, in order to strengthen the paper.\n- **Visual Simplicity**: The visual side of the benchmark is quite rudimentary, featuring colorful letters. Extending it to a larger range of visual tokens/objects, that could have more than one property (color), and a broader set of elements and variations (than 26 letters), could be a straightforward extension that could help make it a bit more challenging visually. - **COG task**: It will be useful to discuss the COG task (rather than just mentioning it) before describing the new gCOG one, so that it will be clearer to the reader what are new contributions of the new benchmark compared to COG and the degree of their importance. In the overview diagram I would also recommend showing a sample also from COG to make the differences clearer. \n- **Grid size / generalization**: It could be interesting to vary the size of the grid in training/evaluation and study its impact on model’s performance. \n- **Terminology**: I recommend changing the phrase “Distractor generalization” to one that better conveys it’s about changing the answer distribution. Maybe e.g. answer distribution shift. I also recommend changing the name “Systematic compositional generalization” to “combinatorial generalization”, to emphasize that the main point is the generalization to permutation, and also to better contrast it with the following “Productive generalization” (which could also be systematic).\n- **Figures**: Would be good to increase the size of the plots in Figure 3b. It will also be good the increase the distance and visual separation between the sub-figures in each figure throughout the paper. \n- In the introduction: “multimodal question-answer” -> “answering”.\n- “This design allowed us” -> “This design allow us”.",
         "591",
         "0",
         "2",
         "0.7407",
         "0.1749524183",
         "0.948541522026062"
        ],
        [
         "15",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2",
         "0.8079",
         "0.1061594203",
         "0.8954392671585083"
        ],
        [
         "16",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head [1], [2], [3]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works [1][2] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n[1], Frozen clip models are efficient video learners, ECCV-2022\n\n[2], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n[3]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0",
         "0.7694",
         "0.0820393375",
         "0.8567712306976318"
        ],
        [
         "17",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7",
         "0.8374",
         "0.0525974026",
         "0.9221839308738708"
        ],
        [
         "18",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0",
         "0.7506",
         "0.3529761905",
         "0.8587207794189453"
        ],
        [
         "19",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_5Cgw",
         "1697885084973",
         "1699636148336",
         "3",
         "5",
         "3",
         "2",
         "2",
         "The study puts forward a VAE-based approach to acquire disentangled representations without the need for supervision. In this framework, it assumes that diverse data samples exhibit variations across multiple factors, making it particularly well-suited for real-world datasets. The newly proposed technique, referred to as CFASL, introduces a range of unsupervised loss components that serve to instill \"inductive biases.\" These include parallel and perpendicular loss terms, in addition to a sparsity loss designed to encourage alignment along factor axes. The outcomes of this study illustrate the method's superior performance when compared to various other unsupervised disentanglement VAEs, both under single-factor and multi-factor alteration scenarios, across multiple widely used benchmark datasets. 1. The paper represents a significant stride in enhancing the practicality of disentanglement techniques within the realm of real image domains. It grapples with a formidable challenge where we cannot presume access to images that solely vary in a singular factor, thereby intensifying the complexity of extracting disentangled representations.\n\n2. The quantitative findings not only exhibit enhancements in the primary focus of this study, which is the alteration of multiple factors, but also in the scenario involving changes in a single factor. 1. The proposed approach incorporates a diverse array of loss terms within its training objectives, with each term potentially making a distinct contribution. However, this diversity comes at the expense of imposing significant assumptions on the underlying image distribution. While I acknowledge that these assumptions may be justified within the context of the datasets considered in this paper, it's worth noting that some metrics, such as DCI, do not unequivocally demonstrate superiority in the ablation study presented in Table 2.\n\nNevertheless, I believe that the paper could benefit from a more comprehensive exploration of the limitations stemming from these strong assumptions. It would be valuable for the authors to provide concrete examples where these assumptions result in unintended or adverse outcomes. Even for an unsupervised setting, it remains crucial to take into account the nature of transformations within the image domain. A more explicit discussion of these assumption-related limitations would substantially bolster the significance of the claims advanced in this paper, in my view.\n\n2. The qualitative results exhibit low image quality. While this is common across unsupervised disentanglement methods, it is really challenging to get convinced that better disentanglement is achieved. It would be valuable for the author to consider domain-specific metrics for the evaluation phase e.g. face identity loss, facial expression classification, head pose regression, etc. to assess whether only a specific attribute is altered during the single factor change experiments. 1. Following the weaknesses mentioned above, could the authors provide concrete examples (other datasets) where the assumptions induced by the loss terms result in unintended or adverse outcomes compared to the baseline beta-VAE?\n\n2. Could the authors please provide the ablation study results of the different loss terms for all datasets considered in the paper (and not only 3D-Cars)?",
         "483",
         "0",
         "7",
         "0.8442",
         "0.138866012",
         "0.8097960948944092"
        ],
        [
         "20",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_oACj",
         "1698758328711",
         "1699636148260",
         "5",
         "3",
         "3",
         "1",
         "2",
         "The authors introduce a new VAE architecture which operates on pairs of inputs and utilizes a set of regularization terms to induce structured disentanglement of the latent space with respect to observed symmetry transformations between examples in these pairs. The authors show that their model indeed achieves higher disentanglement scores than relevant baselines on a variety of datasets with a variety of different metrics. Specifically, the authors target the 'multi-factor change' regime, and demonstrate improved performance in this setting with their newly introduced metric. - The related work is well covered, and the authors position their method well in the literature.\n- The proposed combination of losses appears novel to the best of my knowledge, and the use of parallelism and orthogonality losses specifically on latent transformations is an interesting and exciting idea. \n- The study of disentanglement with respect to multiple simultaneously changing factors is important and interesting, and the authors make a notable contribution to this direction.\n- The results appear promising, and indicate that the model is performing well with respect to the baselines. \n- The methodology and extended results in the appendix appear sound. The calculation of P-values in the appendix is very important and appreciated. Furthermore, the use of an ablation study to validate their proposed model is a welcome addition. Weaknesses summarized:\n- The paper is challenging to read as the english is quite poor and the logical flow of the work is unorganized.\n- The method itself is composed of a wide variety of loss terms and the intuition or reasoning for why these terms are necessary is not provided. (Specifically for the parallel and perpendicular losses).\n\nIn more detail:\n\nWeakness 1:\nThere are many typos and poor grammar throughout the paper, with many sentences simply not making much sense. I include a few examples below, but there are many many more and the authors should have someone proof read this work more carefully:\n- In the abstract: \"We propose ... (CFASL) on VAEs for the extension to [a] general multi-factor change condition without constraint.\" \n- \"To implement  group equivariant VAE, Winter et al. (2022); Nasiri & Bepler (2022) achieve the translation and  rotation equivariant VAE\"\n- \"For the equivariant encoder and decoder, we differently propose the single forward process by the  encoder and decoder objective functions compared to previous work (Yang et al., 2022).\"\n- \"Differently, we induce disentanglement learning  with group equivariant VAE for inductive bias.\"\n- 'The unsupervised learning work (Winter et al., 2022) achieves class invariant and group equivariant  function in less constraint condition.'\n\nWeakness 2: \nNaming is extremely unclear. For example, what are 'sections' referred to in Section 3.2? How do these differ from factors? \n\nWeakness 3: \nDespite appealing to a precise probabilistic generative model as its primary value and distinction from prior work, the model itself could be made significantly more elegant in the context of generative models. For example, the 'factor prediction' mechanism could be integrated as a component of the generative model and inferred with another approximate posterior, as done in prior work (Song et al 2023).\n\nWeakness 4:\nThe discussion of learning the Lie algebra is quite rushed and the intuition for why the large set of different loss terms should be incorporated is largely missing.\n\n[1] (Song et al. 2023) https://arxiv.org/pdf/2309.13167.pdf Question 1:\nThe point that prior work with autoencoders does not extend to VAE's does not make much sense to me. Specifically the quote: \"Furthermore, the methods on autoencoder are not directly applicable to VAEs, because  of the large difference to VAE in probabilistic interpretation\". Can the authors provide further details to reinforce this claim?\n\nQuestion 2:\nGiven there are so many loss terms for this model, it is likely that it will be computationally expensive to estimate the correct weightings for each of these terms in a hyperparamter search. Can the authors speak to how this was done in their case and how expensive it was? \n\nQuestion 3:\nOne of the main selling points for this paper was the ability to extend disentanglement methods to 'multi-factor' change. However, for the experiments, the authors consider datasets which guarantee commutativity of transformations. Theoretically then, is there a reason why we should expect the other baseline models to not be able to handle this multi factor change? For example, it seems the axis aligned disentangled representations of the beta-vae should be able to compose multiple transformations simply by jointly changing multiple latent dimensions. Is this not the case?",
         "744",
         "6",
         "1",
         "0.7790",
         "0.16209867760000002",
         "0.8877041339874268"
        ],
        [
         "21",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_A4b1",
         "1698803382759",
         "1699636148172",
         "5",
         "3",
         "2",
         "2",
         "2",
         "Following the Variational Auto Encoder (VAE) framework, this paper proposes an extension of the single factor (change condition) disentanglement learning method, which they call as Composite Factor-Aligned Symmetry Learning (CFASL). The main idea and/or the assumption is certain scenarios such as the composite/complex symmetries (where certain mathematical transformational relationships exist) can be better captured by utilizing explicit symmetrical relationship information, if provided as additional input to the VAE learning framework. \n\nAs a part of the learning scheme, to facilitate this required piece of information, the proposed method explicitly inputs pairwise symmetrical relationship (and corresponding transformation) information. The expectation is the model, if learned in this fashion, should generate better representative samples from within those transformational subspace/domains. \n\nTo better explain and evaluate the scenario, some new metrics such as m-FVMk (extension of a common metric for a single factor change condition evaluation) have been proposed. They have compared their method with some state-of-the-art methods and on nine benchmark datasets; reported results are found to be promising. The following items seem to have some originality: (i) learning from explicit pairwise transformations, (ii) a network architecture to learn the codebook of symmetries for (i),  (iii) some associated metrics supporting (i) and (ii), and (iv) imposing group equivariant encoder-decoder into the learning framework. \n\nOverall, the paper is well written.  Mathematical derivations of different components seem to be sufficient. The proposed method has been tested on a number of benchmarks (both quantitative and qualitative analysis), and reported results are found to be promising. In addition, the ablation study of different loss functions may have added some extra points. \n\nIn terms of quality, I would rate the work as \"moderate\". In this work, one of the important missing part is the proper probabilistic derivation of the methodology, the core of the VAE framework. Or it may be due to the way the paper/work has been presented. To me, it's not sufficient to connect to the VAE world. It is suggested the authors clarify this important aspect with necessary derivations.  \n\nFor certain items/results, the authors claim statistical significance performance (section 5.2, and appendix D); however, without sufficient details of their significance tests. It is suggested authors include details of these statistical tests. \n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, we may require additional details for a fair companion of their results. \n\nThe paper/research may have some significance, and it would be beneficial if the source code could be released. It is suggested the authors clarify the probabilistic derivation of the approach and make a proper connection to the VAE basics. \n\nIt is suggested authors include details of these statistical tests.\n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, I suggest authors provide further details and release code if possible.",
         "461",
         "0",
         "0",
         "0.7849",
         "0.0855008418",
         "0.9382466077804565"
        ],
        [
         "22",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_DbMo",
         "1698968978898",
         "1699636148102",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The manuscript aims to improve existing methods of unsupervised disentangled representations learning.  Inspired by the symmetry group action approach from (Higgins et al 2018,2022), authors suggest several additions for the conventional beta-VAE  method, resulting  in the form of seven supplementary loss terms. The article is devoted to important subject of disentanglement learning. Authors report improvements over some of existing methods on four simple datasets 1) Only simple datasets are considered, the method is not tested on standard complex datasets like MPI 3D. \n\n2) Reported improvements of CFASL in all measured metrics are essentially always situated within standard deviations of some other methods. \n\n3) Reconstruction loss is not reported in 3 out of 4 datasets. Upon visual inspection of reported samples, the reconstruction quality is not satisfactory. \n\n4) As reported on Figure 4, on 3DShapes dataset, there is no consistent improvement in FVM metric even at the expense of deteriorating reconstruction quality . \n\n5) There is no theoretic justifications for introduction of so many, seven in total,  additional loss terms. \n\n6) Description of Lie group action is not clear, how the action by psi_i is defined? how the dimensions of Lie groups are chosen?\n\n7) The described group action by matrix multiplications do not preserve the normal distribution, so the group equivariant term is not compatible with the  standard KL term from beta-VAE loss. \n\n8) There is no comparison with most recent disentanglement methods like DAVA, TCWAE.\n\n9) Related work section does not mention many works from vast literature on disentanglement learning, eg Disentangling Adversarial Variational Autoencoder (ICLR 2023). Why is the reconstruction quality not reported in three out of four datasets?\n\nWhy the method was not tested on standard more complex datasets like MPI3D?",
         "284",
         "0",
         "0",
         "0.7452",
         "0.070014881",
         "0.8747272491455078"
        ],
        [
         "23",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_mr2r",
         "1698569976113",
         "1699636242675",
         "3",
         "4",
         "2",
         "2",
         "1",
         "The article offers a Gaussian Mixture-based differential entropy/mutual entropy estimation approach. Furthermore, it provides numerical experiments to test the expected behavior of the estimator and its application to self-supervised learning. The article addresses an important problem of mutual information estimation. It provides relevant numerical experiments to test the validity of the proposed approach. - The main approach proposed by the authors seem to be already appeared in the literature in some references not cited by the authors (please see the questions part).\n\n- There seems to be a major issue about the expressions provided for the proposed approach (please see the questions part).\n\n- The presentation requires improvement. ### I. INTRODUCTION \n\n**3rd paragraph:** \n\n- \"identify matrix\":  identity matrix?\n\n- \"The mutual information can be consequently estimated by the entropy decomposition.\": This sentence follows identity matrix addition sentence. I guess it might be better to clarify causality here. At this point, it is not clear what is meant by \"entropy decomposition\", whether it is a trivial procedure and what enables it (mixture of Gaussians modelling?).\n\n### 2.1 BACKGROUND\n\n**Paragraph before (4)**\n\n- After equation (1): instead of \"for a multi-variable Gaussian variable\" use Gaussian (random) vector ?\n\n- In the notation $$X=[x_1,x_2, \\ldots x_n]$$ $x_i$'s appear as column vectors, however, they are actuallly row vectors as $X\\in\\mathbb{R}^{n\\times d}$\n\n- (5) should be\n\n$$\\mathbf{H}_D(X)=\\sum_{i=1}^k \\frac{1}{2} \\log \\left(\\lambda_i+\\beta\\right)+(d-k)\\log(\\beta)+C_d$$\n\n- After (5): \"Therefore, LogDet can estimate the entropy of multivariate Gaussian variables by approximating the differential entropy.\". This is not a surprise/or contribution as the authors  simply defined (5) using (2) by replacing the true covariance with $\\beta I$ perturbed sample correlation (covariance?) matrix. This is sort of obvious. \n\n### 2.1.1 LOGDET ENTROPY ESTIMATOR FOR NON-GAUSSIAN VARIABLE\n\n- Title : ... NON-GAUSSIAN VECTOR\n\n- Replace variable->vector\n\n- There already exists GMM based entropy/mutual information approximation based works such as \n\n[a]. Lan T, Erdogmus D, Ozertem U, Huang Y. Estimating mutual information using gaussian mixture model for feature ranking and selection. InThe 2006 IEEE international joint conference on neural network proceedings 2006 Jul 16 (pp. 5034-5039). IEEE.\n\n[b]. Huber MF, Bailey T, Durrant-Whyte H, Hanebeck UD. On entropy approximation for Gaussian mixture random vectors. In2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems 2008 Aug 20 (pp. 181-188). IEEE.\n\nYou need to refer to existing literature and clearly state what is novel in your approach relative to them.\n\n\n- Theorem 2 and Theorem 3 of [b] above already covers the lower and upper bounds of mixture of Gaussians. It looks like they are same as what is provided in this section. \n\n- There seems to be a major issue about the upper bound expression. The first expression for the upper bound (at the bottom of page 3), contains covariances ($\\Sigma_i$'s ) obtained from the GMM fitting algorithm, whereas the second line contains the overall sample covariance of actual data, instead of conditional covariance estimates. How do you equate these lines? The second line in fact equals to\n\n$$\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)+\\sum_{i=1}^K \\pi_i \\cdot\\left(-\\log \\pi_i+C_d\\right)$$\n\nas $\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)$ is independent of the summation index $i$. This does not make sense as you disregard covariance parameters of the GMM. \n\n- How do you make the upper bound objective co\n\n### 2.2 THE ISSUE OF MODEL SELECTION\n\n- Title: Model Selection is to generic for the discussion in this section. \"The Issue of Model Order Selection\" could be a better title.\n\n\n\n\n### 3. APPLICATION IN SELF-SUPERVISED LEARNING\n\nThe logdet-mutual information based SSL appears to be proposed in the following reference:\n\n[c]. Ozsoy S, Hamdan S, Arik S, Yuret D, Erdogan A. Self-supervised learning with an information maximization criterion. Advances in Neural Information Processing Systems. 2022 Dec 6;35:35240-53.\n\nThe authors should also clarify the relative novelty relative to [c]. Especially, the impact of GMM order selection as the approach in [c] appears to be for $K=1$. There is also claim in [c] that the use of $K=1$  defines correlative information maximizing which targets a linear (identity in their modified setting) between the representations of augmented versions of inputs. For $K>1$ does  maximizing mutual information between augmentation representation lead to nonlinear mappings between them? Is such organization of representation space desirable for classification tasks, for example?\n\nOr are you just using (18) with order $1$, which seems to be just the approach in [c]. \n\n### 4. RELATED WORKS & 5 SIMULATION STUDIES\n\nAll the references we mentioned above and the relevant references that cite them should be included in this discussion, and simulation results \n\n- 5.2 : ofBelghazi...-> of Belghazi\n- Figure 2: Two small figures and caption could be more informative.\n- 5.4 SSL: What is K for EMP-MILE? Is upper bound employed in EMP-MILE?  what if you directly use MILE?\nHow is backprop used in coordination with the GMM algorithm? As GMM parameters are algorithmically obtained from network output, how does backprop do backward mapping from probabilities $\\pi_i$'s (and there should be covariance estimates $\\hat{\\Sigma}_i$'s, as discussed above)",
         "825",
         "0",
         "11",
         "0.7898",
         "0.0758333333",
         "0.919431209564209"
        ],
        [
         "24",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_fvqj",
         "1698878886574",
         "1699636242588",
         "3",
         "5",
         "2",
         "1",
         "2",
         "This paper proposes a new approach to estimating the mutual information between a pair of random vectors, by extending the closed-form expression that is available to Gaussian variables to non-Gaussian variables. This is done by estimating Gaussian mixture approximations of the involved densities and then using bounds on the differential entropy of Gaussian mixtures. Estimating mutual information between high-dimensional non-Gaussian variables is an important problem with many applications. The proposed method extends Gaussian (which the authors refer to log-det) estimators to be applicable beyond Gaussian variables via the use of Gaussian mixture approximations, coupled with bounds on the differential entropy of mixtures. Unfortunately. the paper contains several critical flaws, namely a quite sloppy notation, that lead me to recommend its rejection. \n\nThe authors mixture, in a very confusing way, random variables and data matrices, typically using the same notation for both, $X$. For example, in Equations (1), (2), and (10), $X$ is a $d$-dimensional random variable, whereas in Equation (4), $X \\in \\mathbb{R}^{n\\times d}$ is a data matrix. Even worse, in the final equation of page 3, the two different definitions are used together and it is not even clear where the second equality means; it is simply wrong because $X^T X/n$ does not coincide with $\\Sigma_i$.\n\nUnlike what the authors claim, Equation (5) is not equivalent to Equation (5); the two differ by $\\frac{d-k}{2}\\log \\beta$.  \n\nAdding a matrix proportional to identity ($\\beta I$ in the paper) to the sample covariance was not proposed in a 2021 paper. It is a very classical method that can be found in any classical text on covariance matrix estimation, many decades ago.\n\nThe inequality in Equation (8) was not shown by Zhouyin and Liu in 2021. It is a classical result of information theory, that can be found, for example, in the famous Cover and Thomas book. By the way, the citation to this book is wrong in the paper; one of the authors (J. Thomas) is missing. \n\nThe two bounds for the differential entropy of mixtures that the authors claim to have introduced are in fact not new. The upper bound is in fact a well-known corollary of the log sum inequality (see the Cover and Thomas book). The lower bound was proved in 2008 by Huber et al. at https://doi.org/10.1109/MFI.2008.4648062 I have no questions.",
         "383",
         "1",
         "1",
         "0.7288",
         "-0.053505050500000005",
         "0.8470067381858826"
        ],
        [
         "25",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_F4Ta",
         "1698980874812",
         "1699636242491",
         "6",
         "4",
         "3",
         "3",
         "2",
         "This work presents a mutual information (MI) estimator called MILE (LE=logdet estimator) which uses \nthe log det closed form formula of the entropy of Gaussians.\n\nTo accomodate MI to arbitrary densities, a Gaussian mixture model (GMM) is first fit to data and lower/upper bounds on the entropy of GMM is used to define MILE formula Eq 15. \n\nThen MILE is benchmarked with other MI  estimators and MILE can be used in loss functions in semi-supervised learning in experiments. - Simple MI estimator method based on  \n\nZhanghao Zhouyin and Ding Liu. Understanding neural networks with logarithm determinant entropy estimator. arXiv preprint arXiv:2105.03705, 2021\n\n(cited in the paper)\n\n- Very good experiments and comparisons with other MI estimators\n\n- Source codes provided in supplemental information  for reproducible research -The paper is sloppy in its writing, and one problem is to determine the number of components k of the GMM which\n loosen the lower upper bounds on the entropy. \n\n- Another problem is to deal with near singularity (det close to zero) by introducing a regularization term \\beta.\n\n- Give definition of MI and link with copulas, e.g.,\nMa, Jian, and Zengqi Sun. \"Mutual information is copula entropy.\" Tsinghua Science & Technology 16.1 (2011): 51-54.\nThis will relate to Eq. 8 as well.\n\n- Because MI estimation is an important and well-studied topic, I suggest to put Section 4 on related works after the introduction to that the contributions are better explained.\n\n- The lower/upper bounded of entropy of GMMs are not tight. There is a rich litterature which also compares the tightness of the various bounds.\n\nHuber, Marco F., et al. \"On entropy approximation for Gaussian mixture random vectors.\" 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems. IEEE, 2008.\n\nEven in 1D:\nNielsen, Frank, and Ke Sun. \"Guaranteed bounds on the Kullback–Leibler divergence of univariate mixtures.\" IEEE Signal Processing Letters 23.11 (2016): 1543-1546.\n\n- Notice that some distributions do not admit densities (some elliptical distributions for example)\n\n\n\n- Mention MI properties (i.e., tensorization) which defines the self-consistency test of estimators\n\n\n- small remarks:\n* data covariance = scatter matrix\n* after (3), define $\\Sigma_x$ as scatter matrix?\n*  page 3, first sentence need to be rephrased\n* some typos: \npage 7  hyperparamter -> hyperparameter\npage 9 self-supervied -> self-supervised    competitve -> competitive - Would using PCA beforehand be more appropriate in the case of near singularity?\n\n- Can we tackle robustness/variance with f-MI?\n\nMoon, Kevin, and Alfred Hero. \"Multivariate f-divergence estimation with confidence.\" Advances in neural information processing systems 27 (2014).\nEsposito, Amedeo Roberto, Michael Gastpar, and Ibrahim Issa. \"Robust Generalization via f− Mutual Information.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.",
         "447",
         "3",
         "7",
         "0.8255",
         "0.1368315018",
         "0.9330754280090332"
        ],
        [
         "26",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_MHkc",
         "1699156174555",
         "1699636242410",
         "3",
         "4",
         "2",
         "3",
         "2",
         "this paper proposes to use the logdet function for the estimation of mutual information. \ntwo bounds are proposed for this purpose. the results show improvement in comparison \nto the editing methods. the proposed function itself is \"the Coding Length Function\". simple method with good results. In my opinion this paper reinvents \"Coding Length Function\".  \"...the difference is we put a scaling hyperparameter β on the identity matrix I..\" - that is not a difference. both affects SNR. The latter can be affected either way: by multiplying the noise covariance or by division of the data covariance. I do agree that the results are interesting, but the novelty is quite limited due the the above. \n\nplease elaborate on the limitations. \"So, we recommend β = 1e−3 in the following simulation studies\" why not beta=zero? \nFigure 1.b shows that beta=zero correctly estimates the true MI. \nThat raises a question why do you need beta > 0?\n\nHow do you define $\\pi_c$ in e.g., Eq17?\n\nBoth bounds are loose. How can you explain that such loose bounds lead to very small variance in MI?\n\nDo you calculate MILE in batches?",
         "187",
         "0",
         "1",
         "0.7572",
         "0.0981946625",
         "0.8652637600898743"
        ],
        [
         "27",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_oYZA",
         "1699327631740",
         "1699636242348",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The paper proposes uses bounds on the entropy and mutual information for a mixture of Gaussian random variables based on the log determinant calculations used in calculating the entropy for a single Gaussian. In the context of self-supervised learning, the Gaussian mixture is assumed to known based on the augmentation. In other cases the number of mixture components has to be selected. Empirical results are reported on a synthetic benchmark of correlated Gaussians with and without non-linear transformations. Results of self-consistency measures are reported on CIFAR10. The paper is a logical motivation. Differential entropy is easy to calculate for Gaussian distributions, and mixture of Gaussians are universal approximations given enough data, so why not use GMM for mutual information estimation. The insight of using the augmentations as defining the GMM is a useful, simplifying assumption. One main weakness is the lack of extensive comparisons of using this method for self-supervised learning versus other. The one example in the main body (Table 1) shows that at 300 epochs the method is better than some other methods but is inferior to EMP-SSL. At 1000 epochs the other methods outperform the listed, but no results for 1000 epochs are reported. \n\nThe second main weakness is the paper does not give a complete description of the method. The paper is lacking in clarity with some key point unaddressed. The notation is confusing since the random variables (Z,Z') are denoted the same as Z_c, which may be a data point in the empirical sample. There should more clarity on random variables as compared to  sample sets, starting back before equation 4. The confusion carries to last paragraph of Section 4 where $\\mathbf{X}$ is defined but then $X$ is used in the definition. \n\nThe use of one instance for one cluster is not clear to me upon reading it\n\"This is because we treat the augmented data from one instance as a cluster, and this data\naugmentation strategy automatically clusters the data.\" This should be re written.\n\n In equation 17 it is not clear how $\\zeta_c$ captures all instances in the batch. It has only a single $i$ index. Perhaps the $\\zeta_c$ should concatenate them all. In section 3.2, $\\zeta_c$ is a set which indexes the whole match, which makes more sense, but it should be a matrix not a set. In any case, how is the $H(Z)$ term estimated in section 3.1? By keeping $Z_c$ fixed and only augmenting the second the one covariance matrix will be rank-1 (before ridge). \n\nIt doesn't sound like the experiments for the 5.2 are run fairly \" our MILE estimator does not require extra training,\" In this problem the point is that the MI could be changing at each data instance. Thus, other methods do not use access to the change points. MILE should have to be run (which involves performing the GMM since there are no self-clusters as in SSL) at each point. Running an expectation maximization is as much or more training than the updates of network.  \t\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. \n \nIn terms of unsubstantiated claims, the method is clearly biased (not only by the choice of number of components) but also on the non-linear transform cases. It is not clear how well the mutual information estimation would actually work on more complicated data. Thus, even if it is useful for self-supervised learning is not necessarily a more accurate estimate of differential entropy. \n\n**Minor:**\nThere are a number of typographical mistakes that are distracting.\n\nI don't understand what this means\n\"often dwarfing traditional parametric and non-parametric approaches in statistics\"\n\n\" base on the \" -> \"based on the \" \n\nI'm not familiar with this phrasing \"When X subjects to a Gaussian\" \n\n\"a ‘noise’ $\\hat{X}$ \" -> \"a noisy $\\hat{X}$\" \n\nThe paragraph before equation (4) are not clear. \" an expanding factor\" is not defined nor is it clear what is meant by \"enlarging the original covariance matrix\".\n\nExtra $=$ on equation 14.\n\n\"trading each\" -> \"treating each\" ? \n\n\" ground true data\" \n\n\"SMILE: moothed\" -> \"SMILE: smoothed\" \n\nIt should be a parenthetical reference for You et al. (2017) fo LARS optimizer. How is the $H(Z)$ term estimated in section 3.1? Is it also based on augmented data?\n\nIn the SSL, the trade-off parameter having to be searched in the grid  [0.01,0.1,1.0,2.0] doesn't seem to be efficient compared to EMP-SSL. Are there hyper-parameters for EMP-SSL?  \n\nWhy in Table 1 is 1000 epochs not tested?\n\nIs the GMM method run at each time point in Figure 2?",
         "766",
         "1",
         "2",
         "0.7605",
         "0.0532218443",
         "0.8940244317054749"
        ],
        [
         "28",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_e4bh",
         "1698824679826",
         "1700667146725",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs) which build on the graph theoretical concept of graphexes to include sparse network structures between agents. This improves over prior work on Graphon Mean Field Games which only allows for modelling with dense graphs. The authors derive convergence properties for the finite game. In addition, a learning algorithm based on online mirror descent is provided for a particular class of GXMFGs that follow a core-periphery network structure. Finally, the theoretical claims are empirically validated over both synthetic and real-world networks. - This paper has a clear motivation to extend Graphon Mean Field Games to deal with sparse graphs which are frequently seen in practice. The hybrid graphex approach proposed in this work looks like a natural and intuitive solution.\n- The technical development is principled and the analysis is nontrivial.\n- The overall presentation and clarity is good. - Even though the authors explained in the paper, I didn't like the fact that the proposed GXMFGs have no baseline competitors to compare against. While I agree that one could argue on the contrary that the ability to work with sparse graphs is precisely the unique advantage of GXMGFs, I think that the authors should at least spend some efforts to discuss (if empirical comparison with LPGMFG is indeed unsuitable) how GXMFGs would compare with LPGMFG and GMFG in practice. In Figure 3a, it looks like the curves are diverging rather than converging as k increases? Are the curves coloured correctly?",
         "248",
         "0",
         "0",
         "0.8187",
         "0.0240079365",
         "0.9548254013061523"
        ],
        [
         "29",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_hgJx",
         "1698838739665",
         "1699636550718",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs), a framework for addressing the challenge of learning agent behavior in large populations. GXMFGs leverage graphon theory and graphexes, which represent limiting objects in sparse graph sequences. This approach suits real-world networks with both dense cores and sparse peripheries. The paper presents a specialized learning algorithm for GXMFGs. \n\nKey contributions include:\n\n1. Introduction of GXMFGs, extending the scope of Mean Field Games.\n2. Provides theoretical guarantees to show that GXMFGs accurately approximates finite systems.\n3. Development of a learning algorithm tailored to GXMFGs.\n4. Empirical validation on synthetic and real-world networks, demonstrating GXMFGs' ability to model agent interactions and determine equilibria effectively. - Well-Written and Organized: The paper demonstrates strong writing and organization, enhancing its overall readability and accessibility.\n\n- Clear Motivation: The paper effectively conveys a clear and compelling motivation for addressing the problem it tackles.\n\n- Thorough Discussion of Prior Works: The paper provides a comprehensive and well-structured overview of prior works related to the research area.\n\n- The paper provides solid theoretical contributions complimented with supporting empirical studies strengthens the paper's arguments and findings. As the current paper falls outside the scope of my research interests, I am unable to identify any significant weaknesses in the paper. Consequently, my confidence in assessing the paper is limited. - Providing an intuitive explanation for assumptions 1(b) and 1(c) would greatly enhance the paper's overall readability and accessibility.\n\n- While the paper assumes finite state and action spaces, it may be beneficial to explore whether the proposed approach can be extended to scenarios with infinite action spaces. \n- Including the code for the simulations, would enhance reproducibility.",
         "275",
         "0",
         "4",
         "0.8110",
         "0.1125396825",
         "0.9475759267807007"
        ],
        [
         "30",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_P6cQ",
         "1698854680058",
         "1699636550633",
         "6",
         "4",
         "3",
         "3",
         "3",
         "In this paper, the authors study a class of games with many players who are interacting through a sparse graph structure. More specifically, they are interested in the regime where the number of players tend to infinity. The main solution concept is an extension of the notion of Nash equilibrium. The authors propose a learning algorithm based on online mirror descent. They conclude the paper with examples and numerical simulations. Overall, the paper studies an interesting problem and is relatively clearly written. As far as I know, this is a new extension of MFG to sparse graphs. The algorithm is very inspired from existing ones but there is an adaptation to the problem under consideration (core vs periphery). The model is quite abstract at some places. For the theoretical results, they are mostly about the analysis of the game and I am not sure how relevant they are for this conference (although they are certainly interesting for a certain community). It might have been more interesting to focus more on the learning algorithm. \n\nThere are some typos which make it hard to check the correctness of some parts (see questions). 1. I am wondering if some assumptions are missing. For example below Lemma 1, should $f$ be at least measurable (and perhaps more?) with respect to $\\alpha$ for the integral to make sense?\n\n2. Assumption 2 as used for instance in Lemma 1 does not seem to make much sense (unless I missed something): What is $\\boldsymbol{\\pi}$? We do not know in advance the equilibrium policy and even if we did, we would still need to define the set of admissible deviations for the Nash equilibrium. Could you please clarify?\n\n3. Algorithm 1, line 14: Could you please explain or recall what is $Q^{k, \\mu^{\\tau_{\\mathrm{max}}}}$?\n\nSome typos: Should the state space be either $\\mathcal{X}$ or $X$ (see section 3 for instance)? Does $\\mathbb{G}^\\infty_{\\alpha,t}$ depend on $\\boldsymbol{\\mu}$ or not (see bottom of page 4)? Etc.",
         "324",
         "0",
         "4",
         "0.8025",
         "0.19302597400000002",
         "0.9195409417152405"
        ],
        [
         "31",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_qFZD",
         "1698724264822",
         "1699636511957",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper introduces out-of-variable (OOV) generalization, which is an the ability to generalize in environments with variables that have never been jointly observed before. OOV is an issue in settings where different variables (e.g. diagnostic tests) are available for different environments (e.g. different patients). The paper investigates challenges for common approaches when faced with the OOV problem, and proposes an OOV predictor that leverage moments of the error distribution. The work contributes to theoretical understandings of OOV and offers a proof-of-concept for a predictor capable of non-trivial OOV transfer. - The paper formally studies a new perspective on generalization.\n- The methods employed in the paper are sound. - The paper does not demonstrate the practical applicability of the concept of OOV generalization, and the setting feels a bit contrived. Also it seems like OOV generalization can be thought of just a case of OOD generalization--if we think about all the variables together as the input, the OOV generalization is just a case of OOD generalization (e.g. covariate shift) where some inputs have clear signal from some features and other inputs have clear signal from other features. \n- It would be helpful to include more intuitive discussion throughout the paper providing more analysis on the sections. For example, more discussion on the assumptions of the settings/theorems would be helpful, and it's not clear exactly under what assumptions the proposed predictor is appropriate. Please see weaknesses above.",
         "236",
         "0",
         "2",
         "0.7220",
         "0.11756198350000001",
         "0.8290046453475952"
        ],
        [
         "32",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_s9Ga",
         "1698762596885",
         "1700684618252",
         "8",
         "4",
         "3",
         "4",
         "2",
         "This work investigates out-of-variable (OOV) generalization, which is a sub-problem to OOD generalization, and refers to scenarios where an agent needs to generalize to environments containing variables that were never jointly observed before. The paper shows that if the source and target environments contain some overlapping variables (and under certain conditions), information from the predictor in the source environment can improve predictions in the target environment. More specifically,  the moments of the residual distribution from the optimal classifier in the source environment can be used to calculate the generating function with respect to the unobserved variable in the target domain.\n\nBased on this observation, the paper proposes a practical algorithm for OOV prediction, evaluates its performance, and compares it against the marginal predictor and imputed predictor, as well as an Oracle predictor. The paper proposes a new and important problem-setting - OOV generalization, which can occur in real-world situations, on its own or alongside OOD aspects. The work also provides an extensive study of the identification problems of various variants of OOV scenarios, including theoretical proofs and examples. \n\nIn addition, the paper proposes a practical algorithm to solve several OOV scenarios that achieves non-trivial OOV transfer on synthetic data.\n\nThe ideas presented in the paper are novel and the conclusion that information from source domains can be used for prediction in the target domain in this setting is important, and can potentially have a broad impact on future research in the field. The main limitation of the paper is that the proposed approach was tested on only synthetic data, and was not validated using more challenging datasets. \n\nIn addition, the extension of OOV in multi-environments is mentioned mainly in the appendix and the algorithm was not tested empirically for that extension. I would like to ask the following questions:\n\n1. For future work, is there a more complicated/realistic dataset to validate the algorithm?\n2. Is it possible to compare the algorithm to state-of-the-art marginal or causal methods such as Mejia et al. (2021) or Janzing (2018)? To validate if Vapnik’s principle holds and whether the proposed approach indeed improves results due to solving a less general problem.\n3. Theorem 3 connects all moments of the residual distribution to the partial derivatives with respect to the unique variable of the target environment. If additional moments were to be calculated as part of the proposed algorithm, would it improve results (for the general function case)? \n4. In general, since the paper's main claim is that in the real world, it is likely to encounter both aspects of OOD and OOV - How simple is it to combine state-of-the-art  OOD methods with the proposed approach? I cannot imagine at the moment a straightforward way to do that.",
         "454",
         "2",
         "3",
         "0.7695",
         "0.1422634079",
         "0.9121482372283936"
        ],
        [
         "33",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_woi7",
         "1698788842803",
         "1699636511769",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper describes the out-of-variable OOV problem, which in its simplest form, aims to learn a predictor Y = f_t(X2, X3) given an OOV predictor Y = f_s(X1, X2) and a dataset (X2, X3), but without any instance of (X2, X3, Y). The authors describe the setting in which this is possible and develops an algorithm. The key observation is that the third moment of the residue Y - f_s(X1,X2) contains information about X3 that is least polluted by the noise. - The key observation/discovery is clever, and the algorithm is straight-forward to use.\n- The writing is clear, clean, and well-referenced. The examples also made things concrete and easy to follow.\n- The rigor and simplicity of the work can act as a foundation to build OOV research. - The main weakness is the applicability of the method. The authors only showed results for proof-of-concept, not for real-world usage. \n- It is unclear how one could identify whether the assumptions are satisfied given a dataset.\n- It is unclear how bad the predictor would be if the assumptions are not satisfied.\n- It is not yet clear what realistic problem can be well modeled by OOV generalization. Intro:\n- It seems OOV fits very well the frame of missing-not-at-random and covariate-dependent missingness. Could the authors comment on that?\n\nSection 2:\n- Theorem 2 is slightly confusing for me at first glance because I thought PA_Y by definition includes all parents of Y (so x1,x2, x3 in the example) and not just those in the target environment (x2, x3). It may be helpful to clarify.\n\nSection 3:\nAs I am trying to get a sense of the restriction and applicability of the approach, I was wondering the following questions: \n- How does the method fair with the oracle as the magnitude of the noise increases? \n- What if the noise is not gaussian but more heavy tailed? \n- Does the performance degrade or improve with increasing number of variables? \n- I assume Theorem 3 does not apply to discrete variables because of the violation of differentiability; is that right?\n\nSection 4:\n- Can include missing-not-at-random imputation and covariate-missing imputation as two more baseline models (a search in Google scholar using the two key phrases yields some methods).\n- It would be really interesting if the authors could find some real-world datasets, create source and target environments by sub-setting the columns, and see how the method performs.\n- Figure 3: I don’t quite understand the figure. It would be helpful to define OOV loss, be explicit about the number of samples on the y-axis being (x2,x3,y) or (x1,x2,y) or something else. I also don’t understand why relative loss is zero means the method is on par with the oracle predictor. Why not just show how the fine-tuning error compares with oracle training, which seems easier to interpret? Anyway, I am overall a bit confused about the figure, so my questions may not make sense.",
         "493",
         "0",
         "0",
         "0.7642",
         "0.0947004608",
         "0.8592604398727417"
        ],
        [
         "34",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_xwQY",
         "1699441328198",
         "1699636511667",
         "8",
         "3",
         "3",
         "3",
         "3",
         "The paper investigates out-of-variable generalization, namely the ability for a predictive model to generalize to target domains in which the agent has never seen the joint variables in the target domain in a single source domain before. Under certain assumptions as well as when these assumptions don't fully hold, the paper shows that the error residual distribution in an environment provides information on the unobserved causal parent variable in this environment, and they use this information to derive an algorithm that performs OOV generalization with source and target domains that have overlapping sets of causal factors. **Originality**\n- As far as I know, though the problem the paper addresses is well-known as a significant problem, the paper provides several theoretical results, mathematical derivations, and supports these with simple empirical results that are novel.\n\n**Quality**\n- The quality of the paper is high. It addresses a high-value problem in a principled fashion, shows how certain assumptions help obtain certain results and how and in which cases these assumptions can be bypasses while maintain approximately accurate results, and evaluates these cases in terms of loss accuracy as well as sample complexity of its approach versus baseline approaches.\n- The paper openly highlights limitations in its work, such as assumptions made for theorems to hold, and proposes prospective future work in multiple avenues. This refreshingly is (1) included at all and (2) doesn't seem like a mere afterthought.\n\n**Clarity**\n- The paper is mostly clear in its explanation of motivation, preliminaries, approach, baseline usage, results, and limitations.\n- The paper does a great job providing simple, clear real-world examples to elucidate the problem and applications of the various theorems included in multiple cases.\n\n**Significance**\n- The significance of the problem the paper addresses is high and the problem is ubiquitous. The approach is promising and can be applied in many real-world settings through Monte-Carlo sampling or similar methods. The paper shows that their approach can perform relatively well in \"few\"-shot settings though this depends on the number of variables involved and the complexity of the problem.\n\nFrom what I can tell, this is excellent work that I hope motivates further addressing this *out-of-variable* generalization problem by the research and applied AI community. My only reservation is my limited knowledge on the understanding of and state-of-the-art theoretical and applied approaches addressing this problem. - Referring to Figure 1, in the first paragraph in page 3, the claim \"it would seem all but impossible...(orange box)\" could be better explained.\n- In Figure 1, it is unclear whether \"With $Y$ not observed in the target domain\" is an assumption made or is somehow indicated in the diagram or earlier in the paper. Eventually I realized that it's an assumption made, but the illustration Figure 1a alone isn't enough to show this assumption. This ambiguity may clear for some or compound for some later in Section 3. - The abstract states \"merely considering differences in data distributions is inadequate for fully capturing differences between learning environments.\" Doesn't out-of-variable technically fall under out-of-distribution, so shouldn't this be adequate? Perhaps more specificity is needed here.\n- The abstract states \"Mathematically, out-of-variable generalization requires the efficient re-use of past marginal information...\" Why does it require efficient re-use? Could it work with \"non-efficient\" or inefficient re-use?\n- On page 2, should \"modal\" be \"model?\"\n- On page 6, do you mean \"parentheses\" instead of \"brackets\" between Eq (9) and Eq (10)?\n- Why is the joint predictor considered an oracle predictor if MomentLearn outperforms it?\n- Could you explain why MomentLearn is reliably more sample efficient than the oracle predictor for \"few\"-shot prediction?",
         "602",
         "0",
         "0",
         "0.7701",
         "0.10227124180000001",
         "0.9314678907394409"
        ],
        [
         "35",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_HgHQ",
         "1697165838375",
         "1699635934990",
         "3",
         "5",
         "2",
         "3",
         "2",
         "The paper proposes a simple yet efficient feature direction distillation loss. Experiments show that this significantly improves KD\nperformance. 1. Improving KD by feature norm and direction is reasonable and effectiveness.\n2. Experiments on standard benchmarks demonstrate that adopting $\\mathcal{L}_{dino}$ remarkably improves existing KD methods. 1. The contributions seem a little limited. \n2. There is lack of theoretical analysis of DINO loss. The paper is not good enough to be published on ICLR. 1. How to align the features between heterogeneous architectures?\n2. Could you please provide more theoretical analysis?\n3. What about extending it to a multi-layer version of feature distillation?\n4. How to apply the proposed method to existing KD methods, e.g. ReviewKD, DKD, DIST? Just add the DINO loss function to the total loss ? If so, I think adding other loss like contrastive distillation loss or RKD may also make a improvement.",
         "146",
         "0",
         "8",
         "0.8205",
         "0.07793367350000001",
         "0.8326533436775208"
        ],
        [
         "36",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_yLjx",
         "1697172920902",
         "1699635934905",
         "6",
         "5",
         "3",
         "3",
         "2",
         "Here is a summary of the key points from the paper:\n\n- The paper proposes a method to improve knowledge distillation (KD) by regularizing student features to align direction with teacher class-means and have sufficiently large norms. \n\n- Current KD methods like logit or feature distillation align student and teacher but don't directly optimize for student's task performance.\n\n- The paper shows regularizing direction using cosine similarity to teacher class means helps improve student accuracy. \n\n- It also finds student models tend to produce smaller-norm features, so encouraging larger norms improves performance. \n\n- A simple combined loss called dino-loss is proposed to simultaneously regularize student feature direction and norm using teacher class means.\n\n- Experiments on CIFAR and ImageNet classification, and COCO detection show dino-loss consistently improves various KD methods like KD, ReviewKD, DKD.\n\n- Dino-loss achieves new state-of-the-art results among KD techniques on classification and detection benchmarks.\n\n- The method is model-agnostic, simple to implement, adds minimal overhead, and benefits from larger teacher models.\n\nIn summary, the key contributions are a way to improve KD by regularizing student features for better alignment and norms, along with a simple and effective dino-loss to achieve this jointly. The results demonstrate consistent gains across tasks and benchmarks. The paper presents an original and significant approach to improve KD via thoughtful feature regularization. The method is intuitive and supported by quality experiments. The gains are demonstrated to be significant across tasks. The presentation and discussion are clear:\n- The method and dino-loss are clearly explained with illustrations and equations. Results are well-presented in tables and figures. Limitations are properly discussed.\n- Improving KD is an important practical problem. The consistent gains are significant. Sets new state-of-the-art results on ImageNet classification and COCO detection.\n- Model-agnostic nature allows wide applicability to various KD methods and models. Simple extension can benefit the community compared to more complex techniques. - The paper should address the lack of novelty by acknowledging that feature normalization techniques have already been widely employed in knowledge distillation. For example, PKD (NeurIPS-2023) specifically incorporates channel alignment for detectors, and SKD (Guo Jia) explores normalization techniques on predictions. and Feature Normalized Knowledge Distillation for\n/mage Classification ECCV2022 also presents feature norm. Furthermore, it is worth investigating whether the proposed method has already been considered in the distiller's search work, as exemplified by KD-Zero: Evolving Knowledge Distiller for Any Teacher-Student Pairs (NeurIPS-2023).\n\n- In addition, the paper should incorporate a thorough discussion of relevant KD-related studies, including Self-Regulated Feature Learning via Teacher-free Feature Distillation (ECCV2022), NORM: Knowledge Distillation via N-to-One Representation Matching (ICLR2023), Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer (NIPS2022), DisWOT: Student Architecture Search for Distillation Without Training (CVPR2023), and Automated Knowledge Distillation via Monte Carlo Tree Search (ICCV2023). These discussions will provide valuable insights into the existing literature, establish connections with previous research, and potentially highlight points of comparison and contrast. The only concern to me is the novelty of the work and I hope the authors could discuss some of the related work I mentioned in the revised version.",
         "510",
         "0",
         "1",
         "0.8228",
         "0.134258658",
         "0.9310495853424072"
        ],
        [
         "37",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_VRvE",
         "1698736302686",
         "1699635934723",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper studies Knowledge Distillation (KD). A simple loss term namely ND loss is proposed to enhance the distillation performance. It encourages the student to produce large-norm features and aligns the direction of student features and teacher class-means. The ND loss helps not only logit-based distillation methods but also feature-based distillation methods. 1. The proposed method is simple but effective. Encouraging the feature norm for the student is novel in the field of KD.\n2. Experimental results are strong. The authors also conduct experiments on object detection. The proposed loss can improve the existing methods on both image classification and object detection.\n3. The whole paper is organized and written well. It is not a novel thing that decoupling the feature into the magnitude and the direction. Previous works [1][2] already studied this point. [1] uses the teacher classifier to project both teacher features and student features into the same space and then align them. [2] proposes a loss term to align two features’ direction. Compared to the existing works, this paper proposes enlarging feature norm and utilizing the class-mean feature. Authors should check more existing papers and discuss their differences.\n[1] Yang, Jing, et al. \"Knowledge distillation via softmax regression representation learning.\" International Conference on Learning Representations (ICLR), 2021.\n\n[2] Wang, Guo-Hua, Yifan Ge, and Jianxin Wu. \"Distilling knowledge by mimicking features.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 44.11 (2021): 8183-8195. None",
         "235",
         "7",
         "6",
         "0.7478",
         "0.1515151515",
         "0.9257477521896362"
        ],
        [
         "38",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_AuzT",
         "1698788774762",
         "1699635934515",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper proposes to use teacher's class-mean to align student's direction and encourage the student to produce large-norms features, improving the performance of KD. The paper is generally well-written, and the methodology is well-motivated. 1. would expect comparisons and discussion to similarity-preserving KD e.g., [1], which is a large family in feature distillation methods and shows some relations to the proposed method.\n2. Meanwhile, comparisons/discussion to explainablity-based KD, e.g., [2] are needed to see whether those methods can be benefited from the proposed method.\n\n[1] Tung, Fred, and Greg Mori. “Similarity-Preserving Knowledge Distillation.” ICCV 2019.\n\n[2] Guo, Ziyao, et al. \"Class Attention Transfer Based Knowledge Distillation.\" CVPR 2023. Please see weakness.",
         "111",
         "4",
         "6",
         "0.7517",
         "0.1321428571",
         "0.8699356317520142"
        ],
        [
         "39",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_AcYB",
         "1697637540901",
         "1700740134087",
         "5",
         "4",
         "3",
         "2",
         "2",
         "The authors introduce Neural Sinkhorn gradient flow, which is a Wasserstein Gradient Flow wrt to the Sinkhorn divergence. The authors show that the velocity field can be calculated using the Sinkhorn potentials. This allows training a neural network approximating the velocity field. Furthermore, a mean field limit is established. The algorithm is evaluated on a toy example, MNIST image generation and CIFAR10 image generation. The authors do a good job at explaining the underlying concepts of their algorithms. The maths is nicely done. The core idea is very neat and the cifar10 results seem to be good quantitatively wrt other gradient flow works. 1) The article is full with typos. Just to name a few: \"piror\", \"Sinkhron\", \"Experimrnts\", \"speedest descent\", question mark in the appendix and so on. Please fix those. \n\n2) the authors write \"We do not compare with extant neural WGF methods on MNIST because most of the neural WGF\nmethods only show generative power and trajectories on this dataset and lack the criteria to make\ncomparisons.\" There are several papers (also gradient flow based ones), which evaluate a FID on MNIST. Please provide it as well. \n\n3) Also many of the MNIST digits appear flipped. Did the authors use data augmentation there? Also there seems to some slight noise present the generated MNIST digits. \n\n4) Although the CIFAR10 value seems good, there are unfortunately no generated images provided. It is standard practice to sample many images in the appendix. \n\n5) It is unclear what the trajectories show. Does it show the particle flow or the trained Neural Sinkhorn Gradient Flow? \n\n6) The statement of theorem 2 is incorrect. I guess the authors do not want to sample the Euler scheme (eq 14) but the continuous gradient flow, otherwise the statement would need to depend on the step size $\\eta$. \n\n7) In the proof of Theorem 2: Please provide a proof (or reference) why the mean field limit exists. Or do you mean the gradient flow starting at $\\mu_0$ with target $\\mu$ (first two sentences).\n\n8) Later in that proof: why does there exists a weakly convergent subsequence of $\\mu_t^M$? Further, I cant find the definition of $U_{\\mu}$. \n\n9) The code is not runnable, as the model (or any checkpoints) are not provided.\n\n10) From how I understood it, the learning of the velocity field is batched, i.e., one trains for different sets of $(z_i,x_i)$. Since the Sinkhorn dynamic describes an interacting particle system I dont see how this should be possible. To be more precise, one particle $\\tilde{x}$ could be sent to $x_0$ in the first batch, but to a totally different particle $x_1$ in another one, depending on the drawn prior and target samples. Are the positions of the other particles also input to the neural network (i.e by putting them in the channels)? Please elaborate. See weaknesses section. Overall I really like the idea, but the weaknesses prevent me from giving a higher score. It seems like the paper was rushed and is currently not ready for publication. I am willing to raise my score, if the authors address these issues.",
         "516",
         "0",
         "3",
         "0.7790",
         "0.1480691057",
         "0.8920141458511353"
        ],
        [
         "40",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KKim",
         "1698338217824",
         "1700755549491",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces a novel way to train generative models. The authors want to approximate the gradient flow in the Wasserstein space.  They want to approximate the vector field which transports the source distribution to the real-data empirical distribution while minimizing the Sinkhorn divergence. The authors showed the analytical form of the vector field when one considers the Sinkhorn divergence and then they explain how to learn this vector field with a neural network through the simulation of a probability path. They showed that their procedures recover the true probability path when the number of iid samples goes to infinity. Finally, they validate their proposed method on several image-generative tasks. i) The motivation and the introduction are clear\n\nii) Regressing vector fields has been a recent and popular approach with many different applications in machine learning. The proposed approach is interesting and appears to be novel. The theoretical results also show that the proposed method has appealing properties. \n\niii) The authors also provided several experiments showing interesting results from their methods. The first thing I would like to highlight is that I have checked the provided code. I see several inconsistencies and weaknesses between the provided code and the paper:\n\n1. There are several differences in the empirical implementation between the paper and the code. In Appendix A, the authors state that they are computing the entropic potential through stochastic optimization algorithms [Genevay et al, 2016]. However, this is not what is done in practice according to the provided code. In practice, the authors compute the potential between mini-batches of samples, they sample a minibatch of cifar10 experiments, then sample a minibatch of the source Gaussian, and simulate the gradient flows between the two minibatches. This style of minibatch approximation induces a bias that should at least be mentioned in the main paper but also discussed. Indeed, the authors do not compute the true Sinkhorn divergence but a minibatch approximation of it; this approximation is slightly different than the one from [1,2] and that should be discussed. I understand the reason why the authors use this approach (decreasing the cost of this preprocessing step), but this is not what they say they do in Appendix A. In that regard, the paper is much closer to the minibatch optimal transport Flow Matching [Pooladian et al., Tong et al] and Appendix A deserves a major revision.\n\n2. With the provided code, there are several insights that should be discussed in the paper. In the provided cifar experiments, the number of Gaussian samples used is 50000 samples. This number is extremely low to approximate the semi-discrete OT. Therefore, a discussion regarding the statistical performance of the method is needed in my opinion.\n\n3. As your method requires the simulation of the probability path, I wonder about the training time between your method and the recent Flow Matching approaches which are simulation free.\n\n4. There are many typos in the paper (including in titles: ie ExperimRnts, Notaions) that lead to poor clarity...\n\n5. The experiments include two toy datasets (synthetic 2D and MNIST). I would like to know how the method performs on other big datasets (Flowers, CelebA) or on other tasks such as single-cell dynamics [4].\n\n6. The related work on optimal transport is incomplete. Several works used the sliced Wasserstein distance to perform gradient flows [3].\n\n[1] Learning Generative Models with Sinkhorn Divergences, Genevay et al, AISTATS 2018\n[2] Learning with minibatch Wasserstein, Fatras et al, AISTATS 2020\n[3] Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions\n[4] TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics 1. [Pooladian et al., Tong et al.] proved that when the minibatch increases, they get closer to the true optimal transport cost (W_2^2). The interest of their method is that they can rely on minibatches and learn the vector field from an unlimited number of minibatches. Could you follow a similar approach and simulate the gradient flow during training? While it would be an expensive step in training, it might improve the metrics on the different generative model experiments.\n\n2. What is the performance of your method concerning the number of simulation steps (ie Euler integration and its learning rate)?\n\n3. What is the time of the preprocessing step concerning the training time?\n\n4. Could you compare your method with OT-CFM [Pooladian et al., Tong et al.] on the synthetic data? I am curious to compare the differences.\n\nIn my opinion, the mentioned weaknesses have to be revised and this paper should go under a major revision. I deeply think that the experimental section should better highlight what is done in practice and the theoretical section should mention the different biases (statistical and minibatch). Therefore, I recommend rejecting the current manuscript as it does not meet the ICLR acceptance bar.\n\n\n----- EDIT POST REBUTTAL -----\n\nI thank the authors for their answers. I have read the updated manuscript. While it is now better than before, I suggest they add a limitation section where they describe the different biases in their algorithm. I understand the motivations of the paper. Overall, I think that the manuscript deserves another round of reviews but I have decided to move my score to 5 as they have given good answers.",
         "873",
         "7",
         "8",
         "0.7648",
         "0.0723611111",
         "0.8572189807891846"
        ],
        [
         "41",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_Kh9H",
         "1698606606187",
         "1699636333063",
         "6",
         "4",
         "3",
         "2",
         "2",
         "Through a series of approximations (and at times, really, relaxations) the authors show that the Sinkhorn gradient flow from one measure to another can be learned.  They do this by first reducing their relaxed problem to a vector field matching problem, and then proposing a neural network-based Algorithm for matching the Sinkhorn-Wasserstein flow's vector field by a neural network (though no convergence/approximation guarantees are proven).\nThe problem is interesting, and its solution is sufficiently novel to merit publication. The problem is natural to study, the results are mathematically correct, and the experiments are convincing. While the paper is mathematically correct, it does not provide theoretical justification for one of its main components, namely showing that approximate vector field matching yields approximate solutions for all time $t$.  I feel that without this guarantee, there is a gap in the theoretical viability of this model.  Nevertheless, this is a minor point since the length of a conference paper does not allow one to treat every such point.\n\nThere are minor typos throughout. \n* E.g. euclidean instead of Euclidean\n* $lim$ instead of $\\lim$ atop page 15 in the appendix\n* The positive scalar $\\delta$ is not defined in the proof of Theorem $1$\n* In the statement of Lemma 3: \"teh\" should read \"the\"\n\nSome references are obscure\n* For The fact that $\\mu + t\\delta \\mu$ converges weakly to $\\mu$, perhaps it is worth simply noting that due to linearity of integration (wrt to the measure term). Can it be shown that approximate vector field matching yields approximate solutions for all time $t$?",
         "262",
         "0",
         "1",
         "0.7647",
         "0.0019972452",
         "0.8472071886062622"
        ],
        [
         "42",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KkYD",
         "1698745650108",
         "1700818697559",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper under consideration deals with the standard generative modelling setup (image generation from noise). To solve this problem, the authors propose to model the gradient flow w.r.t. the Sinkhorn divergence. The paper utilizes an explicit (forward) Euler discretization scheme, i.e., given a distribution $\\mu_t$ at the current time step $t$, the proposed method aims at finding the subsequent distribution $\\mu_{t + 1}$ following the gradient of the Sinkhorn divergence at point $\\mu_t$. The authors validate their methodology on toy 2D setups as well as standard image benchmarks (MNIST and CIFAR10).\n\n**Post-rebuttal update:** I thank the authors for the detailed answer. The majority of my concerns are properly addressed. I rise my score. However, I still tend to reject the paper. Also I agree with reviewer KKim that minibatch OT approximation should be discussed more thorougly. Thank you. To the best of my knowledge, the framework of the gradient flow w.r.t. Sinkhorn divergence for pure generative modelling has not yet been considered. This indicates that the paper is indeed bringing something novel to the ML community. At the same time, the idea of the Sinkhorn gradient flow has already arisen in previous research. In particular, [A] solves Sinkhorn barycenter problems by adjusting a generative distribution towards the barycenter distribution with the help of a procedure called “functional gradient descent” which is actually the discretization of the gradient flow w.r.t. the sum of Sinkhorn divergences to the target distributions. At the same time, it is worth mentioning, that [A] just simulates particles and does not build a generative model.\nRegarding the other strengths of the paper, I would like to note the well-organized Experiments section.\n\n[A] Sinkhorn Barycenter via Functional Gradient Descent, NeurIPS’2020 - Some theoretical results from the paper are known. For example, the statement of Theorem 1 could be found in [B] (eq. 26) or [C] (eq. 8). \n- The quality of the code provided is not good. There is no README/or other instruction to run the code. There are imports of non-existing classes. So, there is no possibility of checking (at least, qualitatively) the provided experimental results.\n\nFrom my point, the main weakness of the proposed paper is the limited methodological contribution. The authors simulate the particles of data following Sinkhorn divergence - as I already mentioned, this is not a super fresh idea. To make a generative model from these simulated trajectories, the authors simply solve the regression task to learn the local pushforward maps. And that is it. Combined with the fact, that the practical performance of the proposed approach is far from being SOTA in the generative modelling, the overall contribution of the paper seems for me to be limited. - My main question (and, probably, one of the main of my concerns) is regarding the proposed methodology. The authors propose to compute certain $\\mathcal{W}_{\\varepsilon}$ potentials (on discrete support of available samples) and then somehow take the gradients of these potentials w.r.t. the corresponding samples (eq. (13)). From the paper it is not clear how to compute the gradients, because the obtained potentials look like vectors of sample size shape, which are obtained through the iterations of the Sinkhorn algorithm. As I understand, in practice, the authors utilize SampleLoss from the geomloss package ([B]).  The outcome of this observation is that [B] should be properly cited when deriving the algorithm (section 4.2). I recommend authors explicitly use SampleLoss in the algorithm's listing. It will contribute to the clearness of what's going on. \n- The vector field of the Sinkhorn gradient flow is estimated by empirical samples. It is not clear how well this sample estimate approximates the true vector field. This point should be clarified. Note, that Theorem 2 works only for mean-field limit. \n- In the Introduction section, the authors consider a taxonomy of divergences used for gradient flow modelling, namely, \"divergences [...] with the same support\" and \"divergences [...]  with possible different support\". As I understand, the first class is about $f-$ divergences and the second class is about the other types (like Sinkhorn, MMD etc.). I have a question regarding the provided examples of works which deal with the former or the latter type of divergences. The fact is that the works [D], [E], [F], [G] deal with KL-divergence (or f-divergence) minimization. That is why I wonder why did the authors classify them as the second class.\n- A good work regarding poor expressiveness of ICNNs is [H].\n- What is the “ground” set ($\\S$ 3.1, first line).\n- Table 1. What are the differences between 1-RF, 2-RF and 3-RF methods?\n\n[B] Interpolating between Optimal Transport and MMD using Sinkhorn Divergences, AISTATS’2019\n\n[C] Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm, NeurIPS’2019\n\n[D] Large-scale wasserstein gradient flows. NeurIPS'2021\n\n[E] Optimizing functionals on the space of probabilities with input convex neural networks. TMLR\n\n[F]  Proximal optimal tranport modeling of population dynamics. AISTATS\n\n[G] Variational wasserstein gradient flow. ICML\n\n[H] Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. NeurIPS’2021.",
         "827",
         "0",
         "8",
         "0.7673",
         "0.0867376775",
         "0.8458420038223267"
        ],
        [
         "43",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_MEFG",
         "1699146383667",
         "1699636332903",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces the idea of learning a time-dependent velocity field of the Sinkhorn Wasserstein gradient flow from samples from the target distribution to calculate the empirical velocity field approximations. The paper supports its claim by showing that the mean-field limit of this process recovers the true Sinkhorn Wasserstein gradient flow. They also validated the process with some empirical studies. The paper is well written and easy to follow. The proofs and arguments in the appendix are well-typed out and clear.  There are some nice diagrams in the empirical section to supports the claim the authors are making. I think the experiments could be more extensive. One thing about this method is to investigate the number of samples needed. effectively learn the velocity field. This is one important experiment missing as is remains unclear how sample-efficient the proposed method is. It would also make the paper more completing if the method is applied to generative models that output discrete random variable like binary mnist or even language modelling. One possible question is what happens if we change the source distribution to be closer to the target distribution like it was from a generator how would the method perform there. Another question is to better understand the sample complexity of the method as the current method may not be sample efficient due to the empirical distribution being approximated using the samples.",
         "230",
         "0",
         "0",
         "0.7569",
         "0.1872807018",
         "0.8377009034156799"
        ],
        [
         "44",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_JSi7",
         "1698680587788",
         "1699636955419",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This article discusses a method to improve the application of SLM in the medical field, utilizing LLM's medical proficiency to boost SLM performance in medical tasks under privacy-restricted scenarios which has important social significance. The method was tested on MedQA, HEADQA, MedMCQA, and MMLU-professional medicine datasets, showing some improvements over existing methods. Additionally, the authors compared results across different sizes of training sets. see summary 1). Imprecise example of Privacy Protection.\nThe example in Figure 1 indicates that personal privacy issues are only present in the first sentence, and the key words \"man\" and \"admitted\" in that sentence have almost no impact on the subsequent content. Could it then be possible to simply delete the first sentence to achieve privacy protection, as extracting key words here does not seem to play a significant role.\n\n2). Privacy Protection as an Innovation Point\nRegarding the extraction of key words for privacy protection, the paper uses a medical NER model proposed by Neumann et al in 2019. We suggest further improvement of this model, for example, considering age as a crucial keyword for certain diseases and extracting it as necessary to better enrich the innovative aspects of the paper.\n\n3). Ambiguity of Symbols in Annotations\nAnnotation 13 on page 8 only appears in the content of the article but is not explained.\n\n4) The overall innovation of the methodology needs improvement, as the majority of the content relies on existing methods, such as the medical NER (Named Entity Recognition) model. please see the weaknesses.",
         "251",
         "0",
         "3",
         "0.8122",
         "0.0869868637",
         "0.8446011543273926"
        ],
        [
         "45",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_gXvF",
         "1698819472631",
         "1699636955275",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This paper tried to improve the performance of small medical language models by introducing knowledge from large language models, which keeps the privacy of clinical text when using large language models.  The proposed method uses keywords instead of full raw text to generate initial evidence from LLM and feed the evidence to small language model. Privacy-preserving is an essential and common need when using LLM in clinical text. This paper tried to solve this problem by using keywords instead of raw text, the idea is novel and experiments demonstrated the effectiveness of this approach. 1. As this research utilized a named entity recognition model to extract keywords, it is possible that the NER model can extract privacy information such as patient names. Is there any filtering or postprocessing step to avoid that? In addition, it is not guaranteed that NER system will never extract sensitive patient information; for example, if the NER system incorrectly extracts a patient's address as a symptom, then the address may be leaked to LLM. Although it is very rare, it is still necessary to comment on this. \n2. As the LLM already provides a preliminary decision, I am curious about the performance if we only feed the preliminary decision from LLM to SLM. It is worth knowing which part of the LLM-generated information improves the SLM most. \n3. The related work section need to discuss more LLM application in the clinical area, especially the knowledge-enhanced LLM in clinical settings. For example, paper \"Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.\" also utilized external knowledge for clinical questions. \n4. By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem? By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem?",
         "326",
         "0",
         "4",
         "0.7696",
         "0.0399925075",
         "0.9072911739349365"
        ],
        [
         "46",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_TtE2",
         "1698819599156",
         "1700663756238",
         "6",
         "4",
         "2",
         "2",
         "3",
         "The paper studied medical QA problems by incorporating large language models (LLMs) to assist small-language models (SLMs). To protect the private information in the data, the authors propose to first extract keywords and then use the keywords to query LLMs for intermediate content which can be used for SLMs to enhance prediction accuracy. 1. (originality) The proposed method is novel by extracting keywords and privately incorporating LLM for SLM-based predictions.\n2. (clarity) Overall, the paper is fair in presentation. The demonstrations of synthetic medical data with private information and extracted keywords are helpful for understanding the concepts.\n3. (significance) Versus the compared baselines, the proposed methods significantly improve the prediction accuracy on three medical QA tasks.\n4. (quality) The authors thoroughly evaluate the performance of the proposed method. 1. (Clarity) There is no specific definition of the private information. From Figure 1, it seems that privacy definition is restricted to private identifiable information (PII). The authors should clarify the scope of privacy risks. Importantly, the proposed method cannot address general private information leakage that is considered by strict formulations like differential privacy.\n2. (Quality) The evaluation of privacy is not strict. \n  - Risks: It is possible that the keyword extraction includes private identifiable information (PII), for instance, names and dates as shown in Figure 1. There is no theoretical guarantee for privacy protection or empirical evaluation of the leakage rates of such PII.\n  - Metric: The authors used the privacy budget for quantifying privacy risks:  the ratio of the number of words provided to the LLM to the total words in the original question. However, I doubt if the metric can imply some privacy risks. There essentially lacks an intuitive explanation of the relationship between the privacy budget and privacy risks.\n3. (Motivation) As the authors said, SLM presents a large gap compared to LLMs and thus there is no clear motivation to use SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. In the paper, there is no referred evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks. Thus, I strongly doubt if the motivation of the paper can hold. * There is no clear motivation to see SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. Is there any evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks?",
         "426",
         "0",
         "7",
         "0.7723",
         "0.0983912484",
         "0.9060524702072144"
        ],
        [
         "47",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_EBQC",
         "1699202302455",
         "1701315616812",
         "6",
         "3",
         "3",
         "3",
         "3",
         "In situations where text data is subject to privacy protection constraints, this paper designs a small-scale language model to perform diagnoses of diseases. Utilizing the rich prior medical knowledge in LLM, the approach involves generating a medical knowledge-intensive context using privacy-protected text. This generated context, along with key terms extracted from the text and questions, is then input into the SLM, which is fine-tuned during training. Experiments across multiple datasets demonstrate that this fine-tuning process effectively enhances the accuracy of the diagnostic model. 1. This paper focuses on a very important research topic in the field of medicine: how to effectively extract more useful information from incomplete text under the conditions of privacy protection. The author has made full use of the domain knowledge in LLM to effectively fine-tune the SLM, which ensures that the lightweight models can achieve high accuracy.\n\n2. This paper presents rich and comprehensive experiments. Beyond basic decision-making tasks, it also explores solutions for few-shot experiments and out-of-distribution (OOD) model generalization using the methods discussed in this paper.\n\n3. This paper fully utilizes the rich domain knowledge in LLMs to expand the knowledge base of medical reports, achieving excellent diagnostic accuracy even while ensuring privacy protection. 1. The contribution of this paper to the algorithm and the significance of the clinical problems it addresses seem not to be very high.\n\n2. The main work of this paper appears more as an engineering problem, transferring domain knowledge from LLMs to SLMs. From the perspective of algorithmic contribution, there seems to be some room for improvement. 1. The experimental datasets in this paper are all question-and-answer test datasets, and whether the methods of this paper are applicable to medical report datasets requires additional experimentation. This is because in medical reports, how to generate high-quality questions using other LLM interfaces is a question worth studying.\n\n2. Large language models provide additional domain knowledge, but in the context of specific medical tasks, will the direct transfer of knowledge from LLMs to SLMs lead to incorrect information leakage into SLMs? How can we ensure that LLMs only enhance information relevant to the current medical issue without introducing additional errors or irrelevant information? This is a very important issue in the medical field, as it directly relates to patient diagnosis.",
         "378",
         "0",
         "7",
         "0.8087",
         "0.1651777003",
         "0.9162929654121399"
        ],
        [
         "48",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E[x_t^\\top \\eta]>0$, where $E[\\cdot]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9",
         "0.7199",
         "0.1048061787",
         "0.9118013978004456"
        ],
        [
         "49",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9",
         "0.8034",
         "0.040322580600000005",
         "0.9313320517539978"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 28028
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_eS3u</td>\n",
       "      <td>1698243150596</td>\n",
       "      <td>1699636093263</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>This work proposes LSTNet, a self-supervised m...</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.970887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_jP4i</td>\n",
       "      <td>1698652503617</td>\n",
       "      <td>1699636093190</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1) This paper proposes a self-supervised metho...</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>0.160185</td>\n",
       "      <td>0.884277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_wiS9</td>\n",
       "      <td>1698706547448</td>\n",
       "      <td>1699636093122</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper introduces LSTNet, which leverages ...</td>\n",
       "      <td>570</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7698</td>\n",
       "      <td>0.095387</td>\n",
       "      <td>0.898268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_a6Ps</td>\n",
       "      <td>1698768293694</td>\n",
       "      <td>1699636092942</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper attempts to register point cloud pr...</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>0.140019</td>\n",
       "      <td>0.925070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_Frem</td>\n",
       "      <td>1699350072271</td>\n",
       "      <td>1699636092872</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper presents a method of learning dense...</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.124242</td>\n",
       "      <td>0.947160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28023</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_vt7i</td>\n",
       "      <td>1698673110283</td>\n",
       "      <td>1699636153803</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper extends the analysis of (Woodworth ...</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.077504</td>\n",
       "      <td>0.915013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28024</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_oaZ7</td>\n",
       "      <td>1698928691830</td>\n",
       "      <td>1699636153728</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The paper studies the implicit regularization ...</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>0.917441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_fMm6</td>\n",
       "      <td>1698618130371</td>\n",
       "      <td>1699636636496</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The authors propose a network architecture to ...</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7971</td>\n",
       "      <td>0.103848</td>\n",
       "      <td>0.840419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28026</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_tZQw</td>\n",
       "      <td>1698807944071</td>\n",
       "      <td>1699636636378</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper proposes InfoNet, a generalized alg...</td>\n",
       "      <td>346</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.101576</td>\n",
       "      <td>0.908464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28027</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_9qjF</td>\n",
       "      <td>1698910414535</td>\n",
       "      <td>1699636636278</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>* This paper presents an innovative algorithm,...</td>\n",
       "      <td>670</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.135170</td>\n",
       "      <td>0.933620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28028 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zzv4Bf50RW               1647             1695102158671   \n",
       "1        zzv4Bf50RW               1647             1695102158671   \n",
       "2        zzv4Bf50RW               1647             1695102158671   \n",
       "3        zzv4Bf50RW               1647             1695102158671   \n",
       "4        zzv4Bf50RW               1647             1695102158671   \n",
       "...             ...                ...                       ...   \n",
       "28023    014CgNPAGy               2200             1695179071455   \n",
       "28024    014CgNPAGy               2200             1695179071455   \n",
       "28025    0074qaufB6               5962             1695403263602   \n",
       "28026    0074qaufB6               5962             1695403263602   \n",
       "28027    0074qaufB6               5962             1695403263602   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "1      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "2      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "3      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "4      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "...                                                  ...   \n",
       "28023                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28024                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28025          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28026          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28027          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "1      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "2      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "3      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "4      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "...                                                  ...   \n",
       "28023  On the Role of Momentum in the Implicit Bias o...   \n",
       "28024  On the Role of Momentum in the Implicit Bias o...   \n",
       "28025  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28026  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28027  InfoNet: Missing Information Retrieval in Mult...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Establishing accurate dense 3D correspondences...  Reviewer_eS3u   \n",
       "1      Establishing accurate dense 3D correspondences...  Reviewer_jP4i   \n",
       "2      Establishing accurate dense 3D correspondences...  Reviewer_wiS9   \n",
       "3      Establishing accurate dense 3D correspondences...  Reviewer_a6Ps   \n",
       "4      Establishing accurate dense 3D correspondences...  Reviewer_Frem   \n",
       "...                                                  ...            ...   \n",
       "28023  Momentum is a widely adopted and crucial modif...  Reviewer_vt7i   \n",
       "28024  Momentum is a widely adopted and crucial modif...  Reviewer_oaZ7   \n",
       "28025  Faulty sensors in a multiple input stream setu...  Reviewer_fMm6   \n",
       "28026  Faulty sensors in a multiple input stream setu...  Reviewer_tZQw   \n",
       "28027  Faulty sensors in a multiple input stream setu...  Reviewer_9qjF   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1698243150596           1699636093263              6  ...   \n",
       "1      1698652503617           1699636093190              5  ...   \n",
       "2      1698706547448           1699636093122              3  ...   \n",
       "3      1698768293694           1699636092942              5  ...   \n",
       "4      1699350072271           1699636092872              5  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "28023  1698673110283           1699636153803              5  ...   \n",
       "28024  1698928691830           1699636153728              3  ...   \n",
       "28025  1698618130371           1699636636496              1  ...   \n",
       "28026  1698807944071           1699636636378              3  ...   \n",
       "28027  1698910414535           1699636636278              5  ...   \n",
       "\n",
       "       review_soundness  review_presentation  review_contribution  \\\n",
       "0                     3                    2                    3   \n",
       "1                     3                    3                    2   \n",
       "2                     2                    2                    2   \n",
       "3                     3                    3                    3   \n",
       "4                     3                    3                    2   \n",
       "...                 ...                  ...                  ...   \n",
       "28023                 3                    3                    2   \n",
       "28024                 1                    2                    1   \n",
       "28025                 2                    2                    1   \n",
       "28026                 3                    2                    2   \n",
       "28027                 2                    3                    2   \n",
       "\n",
       "                                            total_review length_words  \\\n",
       "0      This work proposes LSTNet, a self-supervised m...          191   \n",
       "1      1) This paper proposes a self-supervised metho...          215   \n",
       "2      This paper introduces LSTNet, which leverages ...          570   \n",
       "3      This paper attempts to register point cloud pr...          412   \n",
       "4      This paper presents a method of learning dense...          290   \n",
       "...                                                  ...          ...   \n",
       "28023  This paper extends the analysis of (Woodworth ...          356   \n",
       "28024  The paper studies the implicit regularization ...          303   \n",
       "28025  The authors propose a network architecture to ...          544   \n",
       "28026  This paper proposes InfoNet, a generalized alg...          346   \n",
       "28027  * This paper presents an innovative algorithm,...          670   \n",
       "\n",
       "       citation_count  question_count   mattr sentiment_polarity  \\\n",
       "0                   0               0  0.7074           0.090000   \n",
       "1                   0               0  0.7009           0.160185   \n",
       "2                   7              10  0.7698           0.095387   \n",
       "3                   0               5  0.7920           0.140019   \n",
       "4                   0               7  0.6900           0.124242   \n",
       "...               ...             ...     ...                ...   \n",
       "28023               1               5  0.7166           0.077504   \n",
       "28024               0               0  0.7945           0.019907   \n",
       "28025               0               7  0.7971           0.103848   \n",
       "28026              10               4  0.7788           0.101576   \n",
       "28027               3               1  0.8585           0.135170   \n",
       "\n",
       "       similarity_score  \n",
       "0              0.970887  \n",
       "1              0.884277  \n",
       "2              0.898268  \n",
       "3              0.925070  \n",
       "4              0.947160  \n",
       "...                 ...  \n",
       "28023          0.915013  \n",
       "28024          0.917441  \n",
       "28025          0.840419  \n",
       "28026          0.908464  \n",
       "28027          0.933620  \n",
       "\n",
       "[28028 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Load SPECTER model ---\n",
    "model_name = \"allenai/specter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def encoding_text(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def compute_relevance_score(review_text, title, abstract):\n",
    "    # Encode document\n",
    "    doc_emb = encoding_text(f\"{title} {abstract}\")\n",
    "\n",
    "    # Encode review text\n",
    "    review_emb = encoding_text(review_text)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return F.cosine_similarity(doc_emb, review_emb).item()\n",
    "\n",
    "\n",
    "# Compute similarity score for each row with progress bar\n",
    "df_reviews['similarity_score'] = [\n",
    "    compute_relevance_score(row['total_review'], row['submission_title'], row['submission_abstract'])\n",
    "    for row in tqdm(df_reviews.to_dict('records'), desc=\"Computing similarity scores\")\n",
    "]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from tqdm import tqdm\n",
    "# from convokit import Corpus, download, TextParser, PolitenessStrategies, Classifier, Utterance, Speaker\n",
    "\n",
    "# # Step 1: Load training corpus\n",
    "# print(\"📥 Downloading training corpus...\")\n",
    "# train_corpus = Corpus(filename=download('wiki-politeness-annotated'))\n",
    "\n",
    "# # Step 2: Load review data and convert to Utterances with dummy speakers\n",
    "# review_utterances = []\n",
    "\n",
    "# with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "#     reader = list(csv.DictReader(f))\n",
    "#     for idx, row in tqdm(enumerate(reader), desc=\"🔧 Preparing Utterances\", total=1805):  # Adjust total if needed\n",
    "#         review_text = row.get(\"review_text\", \"\").strip()\n",
    "#         if review_text:\n",
    "#             dummy_speaker = Speaker(id=f\"reviewer_{idx}\")\n",
    "#             review_utterances.append(\n",
    "#                 Utterance(id=str(idx), text=review_text, speaker=dummy_speaker, meta={\"orig_row\": row})\n",
    "#             )\n",
    "\n",
    "# # Step 3: Build test corpus\n",
    "# print(\"📦 Building test corpus...\")\n",
    "# test_corpus = Corpus(utterances=review_utterances)\n",
    "\n",
    "# # Step 4: Parse\n",
    "# print(\"🧠 Parsing utterances...\")\n",
    "# parser = TextParser()\n",
    "# parser.transform(train_corpus)\n",
    "# parser.transform(test_corpus)\n",
    "\n",
    "# # Step 5: Extract politeness strategies\n",
    "# print(\"✨ Extracting politeness strategies...\")\n",
    "# ps = PolitenessStrategies()\n",
    "# ps.transform(train_corpus)\n",
    "# ps.transform(test_corpus)\n",
    "\n",
    "# # Step 6: Train classifier\n",
    "# print(\"🎓 Training classifier...\")\n",
    "# clf = Classifier(obj_type='utterance', pred_feats=['politeness_strategies'],\n",
    "#                  labeller=lambda utt: utt.meta.get(\"Binary\") == 1)\n",
    "# clf.fit(train_corpus)\n",
    "# clf.transform(test_corpus)\n",
    "\n",
    "# # Step 7: Summarize results\n",
    "# print(\"📈 Summarizing scores...\")\n",
    "# results = clf.summarize(test_corpus)\n",
    "\n",
    "# # Step 8: Merge back to CSV rows\n",
    "# print(\"🧾 Merging scores into CSV...\")\n",
    "# output_rows = []\n",
    "# fieldnames = list(reader[0].keys())\n",
    "# if \"politeness_score\" not in fieldnames:\n",
    "#     fieldnames.append(\"politeness_score\")\n",
    "\n",
    "# for utt in tqdm(test_corpus.iter_utterances(), desc=\"🔗 Assigning Scores\"):\n",
    "#     row = utt.meta[\"orig_row\"]\n",
    "#     try:\n",
    "#         score = results.loc[utt.id, \"pred_score\"]\n",
    "#         row[\"politeness_score\"] = round(score, 4)\n",
    "#     except KeyError:\n",
    "#         row[\"politeness_score\"] = \"\"\n",
    "#     output_rows.append(row)\n",
    "\n",
    "# # Step 9: Save\n",
    "# print(\"💾 Saving to review_analysis.csv...\")\n",
    "# with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(output_rows)\n",
    "\n",
    "# print(\"✅ All done! Politeness scores are now in your CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOROUSH's CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace with your own path\n",
    "output_file = \"../data/XXXXX.csv\"\n",
    "input_file = output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Note' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m----> 8\u001b[0m     paper_id \u001b[38;5;241m=\u001b[39m \u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m paper_id\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNK\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paper_id:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Note' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "rows = []\n",
    "\n",
    "for paper in data:\n",
    "    paper_id = paper.get(\"id\", \"\").strip()\n",
    "    if paper_id.upper() == \"UNK\" or not paper_id:\n",
    "        continue\n",
    "\n",
    "    paper_date_str = paper.get(\"date\", \"\")\n",
    "    try:\n",
    "        paper_date = datetime.strptime(paper_date_str, \"%m/%d/%Y\")\n",
    "    except Exception:\n",
    "        paper_date = None\n",
    "\n",
    "    for review in paper.get(\"reviews\", []):\n",
    "        reviewer = review.get(\"reviewer\", \"Anonymous\").strip()\n",
    "        review_date_str = review.get(\"date\", \"\").strip()\n",
    "\n",
    "        # Clean review text\n",
    "        review_text = review.get(\"comment\", \"\")\n",
    "        review_text = review_text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        review_suggestion = review.get(\"suggestion\", \"\")\n",
    "\n",
    "        length_words = len(review_text.split())\n",
    "\n",
    "        try:\n",
    "            review_date = datetime.strptime(review_date_str, \"%d/%b/%Y\")\n",
    "            days_to_submit = (review_date - paper_date).days if paper_date else None\n",
    "        except Exception:\n",
    "            days_to_submit = None\n",
    "\n",
    "        rows.append({\n",
    "            \"paper_id\": paper_id,\n",
    "            \"reviewer\": reviewer,\n",
    "            \"review_date\": review_date_str,\n",
    "            \"review_suggestion\": review_suggestion,\n",
    "            \"length_words\": length_words,\n",
    "            \"days_to_submit\": days_to_submit,\n",
    "            \"review_text\": review_text\n",
    "        })\n",
    "\n",
    "# Save to CSV with proper quoting\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=rows[0].keys(), quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"✅ Cleaned and saved {len(rows)} reviews with full text to review_analysis.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pylats taaled spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting taaled\n",
      "  Downloading taaled-0.32.tar.gz (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.0/1.5 MB 653.6 kB/s eta 0:00:03\n",
      "     -------------- ------------------------- 0.5/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.4/1.5 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 9.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pylats\n",
      "  Downloading pylats-0.37.tar.gz (4.6 MB)\n",
      "     ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.6/4.6 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.4/4.6 MB 17.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 2.4/4.6 MB 18.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.6/4.6 MB 21.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.5/4.6 MB 20.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.6/4.6 MB 19.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: spacy in c:\\users\\soroush\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Building wheels for collected packages: taaled, pylats\n",
      "  Building wheel for taaled (setup.py): started\n",
      "  Building wheel for taaled (setup.py): finished with status 'done'\n",
      "  Created wheel for taaled: filename=taaled-0.32-py3-none-any.whl size=1478311 sha256=c506d55eaafed3e29bc232435d9c5f6427263851b7b6789e1cc5c9babcdcd668\n",
      "  Stored in directory: c:\\users\\soroush\\appdata\\local\\pip\\cache\\wheels\\7c\\02\\9d\\a4b381628668e3a1b37cf6466f2de260c96c281ea5494cd067\n",
      "  Building wheel for pylats (setup.py): started\n",
      "  Building wheel for pylats (setup.py): finished with status 'done'\n",
      "  Created wheel for pylats: filename=pylats-0.37-py3-none-any.whl size=4725036 sha256=6a1927d3c335e95e123deb8d9263259d0fdd5b7d535bc340c49a45865e90d528\n",
      "  Stored in directory: c:\\users\\soroush\\appdata\\local\\pip\\cache\\wheels\\cf\\07\\05\\223a18327f4040b164c92b33a97cafb0a2edd9b2a3ed0c2c04\n",
      "Successfully built taaled pylats\n",
      "Installing collected packages: pylats, taaled\n",
      "Successfully installed pylats-0.37 taaled-0.32\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 660.6 kB/s eta 0:00:20\n",
      "      --------------------------------------- 0.3/12.8 MB 3.8 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.9/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 8.2 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.4/12.8 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.1/12.8 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.0/12.8 MB 14.0 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 14.8 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 15.7 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.2/12.8 MB 16.4 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 17.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.7/12.8 MB 20.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 12.1/12.8 MB 23.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 22.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 21.8 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
      "     ---------------------------------------- 0.0/457.4 MB ? eta -:--:--\n",
      "     -------------------------------------- 0.0/457.4 MB 660.6 kB/s eta 0:11:33\n",
      "     ---------------------------------------- 0.3/457.4 MB 3.7 MB/s eta 0:02:05\n",
      "     ---------------------------------------- 0.8/457.4 MB 6.3 MB/s eta 0:01:13\n",
      "     --------------------------------------- 1.9/457.4 MB 10.8 MB/s eta 0:00:43\n",
      "     --------------------------------------- 2.7/457.4 MB 12.1 MB/s eta 0:00:38\n",
      "     --------------------------------------- 3.8/457.4 MB 14.3 MB/s eta 0:00:32\n",
      "     --------------------------------------- 4.6/457.4 MB 15.5 MB/s eta 0:00:30\n",
      "     --------------------------------------- 5.0/457.4 MB 14.6 MB/s eta 0:00:32\n",
      "     --------------------------------------- 5.6/457.4 MB 13.7 MB/s eta 0:00:33\n",
      "      -------------------------------------- 6.2/457.4 MB 14.2 MB/s eta 0:00:32\n",
      "      -------------------------------------- 7.6/457.4 MB 15.1 MB/s eta 0:00:30\n",
      "      -------------------------------------- 8.7/457.4 MB 15.9 MB/s eta 0:00:29\n",
      "      ------------------------------------- 10.0/457.4 MB 16.9 MB/s eta 0:00:27\n",
      "      ------------------------------------- 11.3/457.4 MB 20.5 MB/s eta 0:00:22\n",
      "      ------------------------------------- 11.7/457.4 MB 19.8 MB/s eta 0:00:23\n",
      "     - ------------------------------------ 12.9/457.4 MB 19.9 MB/s eta 0:00:23\n",
      "     - ------------------------------------ 13.9/457.4 MB 19.9 MB/s eta 0:00:23\n",
      "     - ------------------------------------ 15.3/457.4 MB 22.6 MB/s eta 0:00:20\n",
      "     - ------------------------------------ 17.4/457.4 MB 27.3 MB/s eta 0:00:17\n",
      "     - ------------------------------------ 18.7/457.4 MB 27.3 MB/s eta 0:00:17\n",
      "     - ------------------------------------ 20.4/457.4 MB 27.3 MB/s eta 0:00:17\n",
      "     - ------------------------------------ 21.9/457.4 MB 29.7 MB/s eta 0:00:15\n",
      "     - ------------------------------------ 23.1/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 24.2/457.4 MB 32.7 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 26.2/457.4 MB 32.8 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 27.7/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 28.9/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 30.5/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 31.8/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 32.9/457.4 MB 29.7 MB/s eta 0:00:15\n",
      "     -- ----------------------------------- 34.2/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 35.9/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 37.4/457.4 MB 29.7 MB/s eta 0:00:15\n",
      "     --- ---------------------------------- 39.4/457.4 MB 32.8 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 41.0/457.4 MB 32.8 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 42.1/457.4 MB 32.8 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 43.2/457.4 MB 32.8 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 44.7/457.4 MB 32.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 46.4/457.4 MB 32.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 47.6/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 49.0/457.4 MB 29.7 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 50.6/457.4 MB 29.8 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 51.7/457.4 MB 28.5 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 52.9/457.4 MB 29.7 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 54.6/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ---- --------------------------------- 55.6/457.4 MB 28.5 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 57.3/457.4 MB 29.7 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 58.4/457.4 MB 28.4 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 59.6/457.4 MB 28.4 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 60.8/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 62.0/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 63.5/457.4 MB 28.5 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 64.7/457.4 MB 28.5 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 66.0/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 67.4/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 68.5/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 70.0/457.4 MB 28.5 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 71.6/457.4 MB 29.7 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 73.3/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 74.9/457.4 MB 31.1 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 76.1/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 77.4/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 78.9/457.4 MB 32.8 MB/s eta 0:00:12\n",
      "     ------ ------------------------------- 80.6/457.4 MB 32.8 MB/s eta 0:00:12\n",
      "     ------ ------------------------------- 81.6/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 82.7/457.4 MB 28.4 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 84.2/457.4 MB 29.7 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 85.6/457.4 MB 28.4 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 86.6/457.4 MB 31.2 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 86.6/457.4 MB 31.2 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 86.6/457.4 MB 31.2 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 88.2/457.4 MB 22.6 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 89.4/457.4 MB 22.6 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 90.8/457.4 MB 21.8 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 92.4/457.4 MB 22.6 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 93.5/457.4 MB 22.5 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 94.5/457.4 MB 23.4 MB/s eta 0:00:16\n",
      "     ------- ------------------------------ 95.7/457.4 MB 21.9 MB/s eta 0:00:17\n",
      "     -------- ----------------------------- 97.2/457.4 MB 29.7 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 98.5/457.4 MB 27.3 MB/s eta 0:00:14\n",
      "     -------- ----------------------------- 99.8/457.4 MB 28.5 MB/s eta 0:00:13\n",
      "     -------- ---------------------------- 101.0/457.4 MB 27.3 MB/s eta 0:00:14\n",
      "     -------- ---------------------------- 102.8/457.4 MB 28.4 MB/s eta 0:00:13\n",
      "     -------- ---------------------------- 103.9/457.4 MB 28.4 MB/s eta 0:00:13\n",
      "     -------- ---------------------------- 104.8/457.4 MB 29.7 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 106.5/457.4 MB 28.5 MB/s eta 0:00:13\n",
      "     -------- ---------------------------- 108.3/457.4 MB 31.1 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 108.8/457.4 MB 29.7 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 108.8/457.4 MB 29.7 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 110.0/457.4 MB 24.2 MB/s eta 0:00:15\n",
      "     --------- --------------------------- 112.7/457.4 MB 27.3 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 114.3/457.4 MB 28.5 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 115.2/457.4 MB 28.4 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 116.7/457.4 MB 27.3 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 118.2/457.4 MB 27.3 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 119.6/457.4 MB 34.4 MB/s eta 0:00:10\n",
      "     --------- --------------------------- 121.6/457.4 MB 32.8 MB/s eta 0:00:11\n",
      "     --------- --------------------------- 122.9/457.4 MB 31.2 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 124.1/457.4 MB 31.2 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 125.5/457.4 MB 32.7 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 127.2/457.4 MB 34.4 MB/s eta 0:00:10\n",
      "     ---------- -------------------------- 128.9/457.4 MB 32.7 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 130.1/457.4 MB 32.7 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 131.8/457.4 MB 32.8 MB/s eta 0:00:10\n",
      "     ---------- -------------------------- 133.9/457.4 MB 34.4 MB/s eta 0:00:10\n",
      "     ---------- -------------------------- 135.8/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 137.3/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 138.8/457.4 MB 34.4 MB/s eta 0:00:10\n",
      "     ----------- ------------------------- 141.0/457.4 MB 38.5 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 142.8/457.4 MB 38.5 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 144.6/457.4 MB 38.5 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 146.2/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 147.5/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ------------ ------------------------ 149.2/457.4 MB 38.6 MB/s eta 0:00:08\n",
      "     ------------ ------------------------ 151.7/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     ------------ ------------------------ 153.2/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     ------------ ------------------------ 155.1/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ------------ ------------------------ 157.2/457.4 MB 40.9 MB/s eta 0:00:08\n",
      "     ------------ ------------------------ 158.7/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 160.8/457.4 MB 40.9 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 162.4/457.4 MB 38.6 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 164.4/457.4 MB 38.6 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 166.7/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 168.8/457.4 MB 43.7 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 170.3/457.4 MB 40.9 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 172.5/457.4 MB 40.9 MB/s eta 0:00:07\n",
      "     -------------- ---------------------- 174.0/457.4 MB 40.9 MB/s eta 0:00:07\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 177.9/457.4 MB 22.6 MB/s eta 0:00:13\n",
      "     -------------- ---------------------- 177.9/457.4 MB 22.6 MB/s eta 0:00:13\n",
      "     -------------- ---------------------- 177.9/457.4 MB 22.6 MB/s eta 0:00:13\n",
      "     -------------- ---------------------- 177.9/457.4 MB 22.6 MB/s eta 0:00:13\n",
      "     -------------- ---------------------- 179.0/457.4 MB 16.8 MB/s eta 0:00:17\n",
      "     -------------- ---------------------- 182.6/457.4 MB 18.2 MB/s eta 0:00:16\n",
      "     -------------- ---------------------- 183.2/457.4 MB 17.2 MB/s eta 0:00:16\n",
      "     -------------- ---------------------- 185.3/457.4 MB 28.5 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 185.4/457.4 MB 28.5 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 185.4/457.4 MB 28.5 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 185.4/457.4 MB 28.5 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 188.4/457.4 MB 29.7 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 188.4/457.4 MB 29.7 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 188.4/457.4 MB 29.7 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 191.4/457.4 MB 21.8 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 194.9/457.4 MB 16.4 MB/s eta 0:00:17\n",
      "     --------------- --------------------- 195.4/457.4 MB 15.6 MB/s eta 0:00:17\n",
      "     --------------- --------------------- 195.9/457.4 MB 18.7 MB/s eta 0:00:14\n",
      "     --------------- --------------------- 197.4/457.4 MB 18.2 MB/s eta 0:00:15\n",
      "     --------------- --------------------- 197.4/457.4 MB 16.0 MB/s eta 0:00:17\n",
      "     ---------------- -------------------- 199.6/457.4 MB 18.7 MB/s eta 0:00:14\n",
      "     ---------------- -------------------- 201.4/457.4 MB 17.7 MB/s eta 0:00:15\n",
      "     ---------------- -------------------- 202.4/457.4 MB 17.3 MB/s eta 0:00:15\n",
      "     ---------------- -------------------- 203.8/457.4 MB 26.2 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 205.5/457.4 MB 26.2 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 206.8/457.4 MB 29.8 MB/s eta 0:00:09\n",
      "     ---------------- -------------------- 208.3/457.4 MB 34.4 MB/s eta 0:00:08\n",
      "     ---------------- -------------------- 209.9/457.4 MB 32.8 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 211.5/457.4 MB 31.2 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 213.0/457.4 MB 34.4 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 214.4/457.4 MB 34.4 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 216.1/457.4 MB 32.7 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 217.8/457.4 MB 34.4 MB/s eta 0:00:07\n",
      "     ----------------- ------------------- 219.5/457.4 MB 34.6 MB/s eta 0:00:07\n",
      "     ----------------- ------------------- 220.4/457.4 MB 34.4 MB/s eta 0:00:07\n",
      "     ----------------- ------------------- 221.9/457.4 MB 32.8 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 223.1/457.4 MB 34.4 MB/s eta 0:00:07\n",
      "     ------------------ ------------------ 223.7/457.4 MB 28.5 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 226.2/457.4 MB 32.8 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 227.7/457.4 MB 29.7 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 229.1/457.4 MB 29.7 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 231.1/457.4 MB 36.4 MB/s eta 0:00:07\n",
      "     ------------------ ------------------ 232.8/457.4 MB 32.7 MB/s eta 0:00:07\n",
      "     ------------------ ------------------ 234.2/457.4 MB 38.5 MB/s eta 0:00:06\n",
      "     ------------------- ----------------- 235.6/457.4 MB 34.6 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 237.8/457.4 MB 36.4 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 239.1/457.4 MB 36.4 MB/s eta 0:00:06\n",
      "     ------------------- ----------------- 240.6/457.4 MB 36.4 MB/s eta 0:00:06\n",
      "     ------------------- ----------------- 242.0/457.4 MB 32.7 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 243.5/457.4 MB 32.7 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 244.0/457.4 MB 34.6 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 244.0/457.4 MB 34.6 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 246.1/457.4 MB 28.5 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 246.1/457.4 MB 28.5 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 247.5/457.4 MB 24.2 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 247.5/457.4 MB 24.2 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 249.1/457.4 MB 21.8 MB/s eta 0:00:10\n",
      "     -------------------- ---------------- 249.1/457.4 MB 21.8 MB/s eta 0:00:10\n",
      "     -------------------- ---------------- 250.0/457.4 MB 19.2 MB/s eta 0:00:11\n",
      "     -------------------- ---------------- 252.1/457.4 MB 19.8 MB/s eta 0:00:11\n",
      "     -------------------- ---------------- 253.2/457.4 MB 19.3 MB/s eta 0:00:11\n",
      "     -------------------- ---------------- 254.4/457.4 MB 22.6 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 255.5/457.4 MB 21.1 MB/s eta 0:00:10\n",
      "     -------------------- ---------------- 256.7/457.4 MB 23.4 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 257.8/457.4 MB 27.3 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 259.1/457.4 MB 24.2 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 260.7/457.4 MB 28.5 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 262.8/457.4 MB 29.7 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 263.9/457.4 MB 29.7 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 265.5/457.4 MB 31.2 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 267.4/457.4 MB 34.4 MB/s eta 0:00:06\n",
      "     --------------------- --------------- 268.8/457.4 MB 34.6 MB/s eta 0:00:06\n",
      "     --------------------- --------------- 270.2/457.4 MB 34.4 MB/s eta 0:00:06\n",
      "     --------------------- --------------- 271.5/457.4 MB 34.4 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 272.6/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 273.8/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 275.7/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 277.0/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 278.2/457.4 MB 29.7 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 278.9/457.4 MB 27.3 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 281.4/457.4 MB 29.8 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 282.0/457.4 MB 32.8 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 283.5/457.4 MB 29.7 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 285.7/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 287.0/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 288.4/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 289.7/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ----------------------- ------------- 291.0/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 292.5/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ----------------------- ------------- 293.9/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 295.5/457.4 MB 29.7 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 297.2/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 298.4/457.4 MB 29.7 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 300.2/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 301.8/457.4 MB 32.7 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 303.2/457.4 MB 32.8 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 304.9/457.4 MB 32.8 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 306.6/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 308.3/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 309.6/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 311.3/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 313.0/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 314.4/457.4 MB 32.7 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 316.1/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 318.1/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 319.6/457.4 MB 36.3 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 321.5/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 323.6/457.4 MB 38.6 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 325.1/457.4 MB 38.6 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 326.8/457.4 MB 40.9 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 328.5/457.4 MB 38.5 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 330.2/457.4 MB 38.5 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 331.8/457.4 MB 38.5 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 333.9/457.4 MB 38.5 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 335.4/457.4 MB 38.6 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 336.9/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 338.5/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 339.9/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 341.6/457.4 MB 34.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 343.7/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 345.7/457.4 MB 38.5 MB/s eta 0:00:03\n",
      "     ---------------------------- -------- 347.2/457.4 MB 36.3 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 348.0/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 348.2/457.4 MB 29.8 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 351.4/457.4 MB 34.4 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 354.6/457.4 MB 38.5 MB/s eta 0:00:03\n",
      "     ---------------------------- -------- 357.7/457.4 MB 46.7 MB/s eta 0:00:03\n",
      "     ----------------------------- ------- 361.1/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 364.0/457.4 MB 65.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 367.1/457.4 MB 65.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 370.1/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 373.2/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 376.3/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 379.0/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 382.0/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 385.2/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 388.0/457.4 MB 65.2 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 391.5/457.4 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ----- 394.3/457.4 MB 65.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 397.4/457.4 MB 65.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 399.0/457.4 MB 59.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 402.2/457.4 MB 59.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 402.2/457.4 MB 59.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 404.9/457.4 MB 46.7 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 406.7/457.4 MB 40.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 407.6/457.4 MB 38.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 407.6/457.4 MB 38.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 407.6/457.4 MB 38.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 407.6/457.4 MB 38.5 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 409.4/457.4 MB 24.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 410.8/457.4 MB 22.6 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 411.4/457.4 MB 21.1 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 412.9/457.4 MB 22.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 412.9/457.4 MB 22.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 415.0/457.4 MB 19.3 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 415.0/457.4 MB 19.3 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 416.8/457.4 MB 18.2 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 419.3/457.4 MB 26.2 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 420.5/457.4 MB 24.2 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 421.6/457.4 MB 26.2 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 423.1/457.4 MB 26.2 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 424.6/457.4 MB 29.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 426.1/457.4 MB 34.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 427.5/457.4 MB 31.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 428.6/457.4 MB 29.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 430.4/457.4 MB 29.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 432.1/457.4 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 433.3/457.4 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 434.9/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 436.2/457.4 MB 29.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 437.9/457.4 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 439.0/457.4 MB 32.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 440.7/457.4 MB 32.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 442.2/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 443.9/457.4 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  445.5/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  446.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  450.8/457.4 MB 19.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  451.2/457.4 MB 18.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  451.8/457.4 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  454.6/457.4 MB 18.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.5/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.0/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 457.4/457.4 MB 9.4 MB/s eta 0:00:00\n",
      "Collecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
      "  Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
      "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
      "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
      "  Downloading curated_tokenizers-0.0.9-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.6.0)\n",
      "Requirement already satisfied: regex>=2022 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2023.10.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.1.3)\n",
      "Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl (236 kB)\n",
      "   ---------------------------------------- 0.0/236.3 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/236.3 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 236.3/236.3 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading curated_tokenizers-0.0.9-cp312-cp312-win_amd64.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.5/731.5 kB 23.3 MB/s eta 0:00:00\n",
      "Downloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
      "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 spacy-curated-transformers-0.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n",
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.9 MB 1.7 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.1/12.9 MB 13.4 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 2.4/12.9 MB 19.5 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.3/12.9 MB 25.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.3/12.9 MB 28.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.9 MB 32.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.3/12.9 MB 43.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.9/12.9 MB 46.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 43.7 MB/s eta 0:00:00\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "Collecting es-dep-news-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_dep_news_trf-3.8.0/es_dep_news_trf-3.8.0-py3-none-any.whl (407.8 MB)\n",
      "     ---------------------------------------- 0.0/407.8 MB ? eta -:--:--\n",
      "     -------------------------------------- 0.0/407.8 MB 653.6 kB/s eta 0:10:24\n",
      "     ---------------------------------------- 0.2/407.8 MB 2.3 MB/s eta 0:02:59\n",
      "     ---------------------------------------- 1.0/407.8 MB 6.9 MB/s eta 0:00:59\n",
      "     ---------------------------------------- 1.6/407.8 MB 8.4 MB/s eta 0:00:49\n",
      "     ---------------------------------------- 2.3/407.8 MB 9.9 MB/s eta 0:00:41\n",
      "     --------------------------------------- 3.4/407.8 MB 12.2 MB/s eta 0:00:34\n",
      "     --------------------------------------- 4.3/407.8 MB 13.0 MB/s eta 0:00:32\n",
      "     --------------------------------------- 5.1/407.8 MB 14.1 MB/s eta 0:00:29\n",
      "      -------------------------------------- 6.6/407.8 MB 15.6 MB/s eta 0:00:26\n",
      "      -------------------------------------- 7.9/407.8 MB 16.7 MB/s eta 0:00:24\n",
      "      -------------------------------------- 9.0/407.8 MB 18.0 MB/s eta 0:00:23\n",
      "     - ------------------------------------ 10.8/407.8 MB 23.4 MB/s eta 0:00:17\n",
      "     - ------------------------------------ 12.7/407.8 MB 28.5 MB/s eta 0:00:14\n",
      "     - ------------------------------------ 14.5/407.8 MB 32.7 MB/s eta 0:00:13\n",
      "     - ------------------------------------ 16.2/407.8 MB 34.4 MB/s eta 0:00:12\n",
      "     - ------------------------------------ 18.2/407.8 MB 38.5 MB/s eta 0:00:11\n",
      "     - ------------------------------------ 19.4/407.8 MB 38.5 MB/s eta 0:00:11\n",
      "     - ------------------------------------ 20.5/407.8 MB 32.8 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 22.1/407.8 MB 34.4 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 24.4/407.8 MB 36.4 MB/s eta 0:00:11\n",
      "     -- ----------------------------------- 25.5/407.8 MB 32.8 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 26.9/407.8 MB 32.7 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 28.2/407.8 MB 31.2 MB/s eta 0:00:13\n",
      "     -- ----------------------------------- 29.3/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     -- ----------------------------------- 30.7/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     -- ----------------------------------- 31.9/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 33.2/407.8 MB 27.3 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 34.7/407.8 MB 28.5 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 36.2/407.8 MB 28.5 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 37.6/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 39.2/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 40.5/407.8 MB 31.2 MB/s eta 0:00:12\n",
      "     --- ---------------------------------- 42.1/407.8 MB 31.1 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 43.2/407.8 MB 31.2 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 45.1/407.8 MB 32.8 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 46.8/407.8 MB 32.8 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 48.7/407.8 MB 34.4 MB/s eta 0:00:11\n",
      "     ---- --------------------------------- 50.3/407.8 MB 34.4 MB/s eta 0:00:11\n",
      "     ---- --------------------------------- 51.4/407.8 MB 34.4 MB/s eta 0:00:11\n",
      "     ---- --------------------------------- 52.8/407.8 MB 32.7 MB/s eta 0:00:11\n",
      "     ----- -------------------------------- 54.6/407.8 MB 34.4 MB/s eta 0:00:11\n",
      "     ----- -------------------------------- 55.9/407.8 MB 32.8 MB/s eta 0:00:11\n",
      "     ----- -------------------------------- 56.8/407.8 MB 29.8 MB/s eta 0:00:12\n",
      "     ----- -------------------------------- 58.1/407.8 MB 29.7 MB/s eta 0:00:12\n",
      "     ----- -------------------------------- 59.4/407.8 MB 28.5 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 60.5/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 61.8/407.8 MB 28.4 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 63.2/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 64.4/407.8 MB 26.2 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 68.2/407.8 MB 20.5 MB/s eta 0:00:17\n",
      "     ------ ------------------------------- 68.7/407.8 MB 19.3 MB/s eta 0:00:18\n",
      "     ------ ------------------------------- 70.7/407.8 MB 20.5 MB/s eta 0:00:17\n",
      "     ------ ------------------------------- 72.3/407.8 MB 21.1 MB/s eta 0:00:16\n",
      "     ------ ------------------------------- 73.4/407.8 MB 20.5 MB/s eta 0:00:17\n",
      "     ------ ------------------------------- 74.4/407.8 MB 19.8 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 75.6/407.8 MB 19.9 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 76.7/407.8 MB 31.2 MB/s eta 0:00:11\n",
      "     ------- ------------------------------ 77.9/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 79.3/407.8 MB 28.5 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 80.6/407.8 MB 27.3 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 82.0/407.8 MB 26.2 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 83.4/407.8 MB 27.3 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 84.9/407.8 MB 28.4 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 85.2/407.8 MB 26.2 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 85.6/407.8 MB 24.2 MB/s eta 0:00:14\n",
      "     -------- ----------------------------- 88.7/407.8 MB 29.7 MB/s eta 0:00:11\n",
      "     -------- ----------------------------- 90.6/407.8 MB 31.2 MB/s eta 0:00:11\n",
      "     -------- ----------------------------- 92.2/407.8 MB 31.2 MB/s eta 0:00:11\n",
      "     -------- ----------------------------- 94.0/407.8 MB 32.7 MB/s eta 0:00:10\n",
      "     -------- ----------------------------- 95.4/407.8 MB 36.3 MB/s eta 0:00:09\n",
      "     --------- ---------------------------- 97.1/407.8 MB 38.5 MB/s eta 0:00:09\n",
      "     --------- ---------------------------- 99.5/407.8 MB 38.5 MB/s eta 0:00:09\n",
      "     --------- --------------------------- 100.9/407.8 MB 38.5 MB/s eta 0:00:08\n",
      "     --------- --------------------------- 103.0/407.8 MB 40.9 MB/s eta 0:00:08\n",
      "     --------- --------------------------- 105.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     --------- --------------------------- 107.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     --------- --------------------------- 109.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ---------- -------------------------- 111.7/407.8 MB 46.7 MB/s eta 0:00:07\n",
      "     ---------- -------------------------- 113.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ---------- -------------------------- 115.4/407.8 MB 46.7 MB/s eta 0:00:07\n",
      "     ---------- -------------------------- 118.1/407.8 MB 50.4 MB/s eta 0:00:06\n",
      "     ---------- -------------------------- 119.8/407.8 MB 46.7 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 121.9/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 124.5/407.8 MB 50.4 MB/s eta 0:00:06\n",
      "     ----------- ------------------------- 125.8/407.8 MB 46.7 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 128.1/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 130.8/407.8 MB 50.4 MB/s eta 0:00:06\n",
      "     ----------- ------------------------- 132.1/407.8 MB 43.5 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 134.1/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 136.8/407.8 MB 46.7 MB/s eta 0:00:06\n",
      "     ------------ ------------------------ 138.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 140.0/407.8 MB 38.6 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 142.8/407.8 MB 46.7 MB/s eta 0:00:06\n",
      "     ------------- ----------------------- 144.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 145.8/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 148.9/407.8 MB 46.7 MB/s eta 0:00:06\n",
      "     ------------- ----------------------- 150.5/407.8 MB 43.5 MB/s eta 0:00:06\n",
      "     ------------- ----------------------- 152.4/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 153.2/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 153.2/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 153.2/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 153.2/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     -------------- ---------------------- 156.1/407.8 MB 27.3 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 156.1/407.8 MB 27.3 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 159.0/407.8 MB 24.2 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 161.7/407.8 MB 27.3 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 164.1/407.8 MB 54.4 MB/s eta 0:00:05\n",
      "     --------------- --------------------- 166.9/407.8 MB 65.2 MB/s eta 0:00:04\n",
      "     --------------- --------------------- 169.5/407.8 MB 59.5 MB/s eta 0:00:05\n",
      "     --------------- --------------------- 172.5/407.8 MB 59.8 MB/s eta 0:00:04\n",
      "     --------------- --------------------- 175.5/407.8 MB 59.5 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 178.1/407.8 MB 59.5 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 181.2/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 184.5/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 187.3/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ----------------- ------------------- 190.3/407.8 MB 65.2 MB/s eta 0:00:04\n",
      "     ----------------- ------------------- 193.0/407.8 MB 65.2 MB/s eta 0:00:04\n",
      "     ----------------- ------------------- 195.9/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 198.8/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 201.8/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 205.1/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 208.1/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------- ----------------- 211.3/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     ------------------- ----------------- 214.3/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------------- ----------------- 217.5/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------------- ----------------- 220.1/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------- ---------------- 222.8/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------- ---------------- 226.2/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------- ---------------- 229.0/407.8 MB 59.5 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 232.5/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     --------------------- --------------- 235.3/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     --------------------- --------------- 238.4/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     --------------------- --------------- 241.9/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 245.0/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 248.3/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 251.9/407.8 MB 73.1 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 255.3/407.8 MB 72.6 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 258.3/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 261.7/407.8 MB 72.6 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 264.9/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 268.0/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 271.8/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     ------------------------ ------------ 274.9/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     ------------------------- ----------- 278.0/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------- ----------- 281.6/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------- ----------- 284.2/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 287.9/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 291.1/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 294.5/407.8 MB 81.8 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 297.2/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 300.9/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 303.7/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 307.3/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 310.3/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 313.8/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 317.3/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 320.1/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 323.1/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 326.2/407.8 MB 65.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 329.4/407.8 MB 65.2 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 332.4/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 335.3/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 337.4/407.8 MB 65.2 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 340.0/407.8 MB 54.7 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 341.4/407.8 MB 46.7 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 345.2/407.8 MB 54.4 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 347.2/407.8 MB 50.4 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 348.9/407.8 MB 50.1 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 350.4/407.8 MB 43.7 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 352.0/407.8 MB 43.7 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 353.5/407.8 MB 38.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 355.2/407.8 MB 38.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 356.9/407.8 MB 36.4 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 358.3/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 359.0/407.8 MB 34.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 361.1/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 362.9/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 364.5/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 365.8/407.8 MB 32.7 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 366.9/407.8 MB 31.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 368.3/407.8 MB 31.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 369.6/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 370.8/407.8 MB 31.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 371.9/407.8 MB 29.7 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 373.5/407.8 MB 28.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 374.6/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 375.9/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 377.0/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 378.3/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 379.8/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 381.1/407.8 MB 28.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 382.5/407.8 MB 28.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 384.0/407.8 MB 28.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 385.8/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 387.4/407.8 MB 31.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 388.6/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 389.8/407.8 MB 29.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 391.3/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 393.1/407.8 MB 32.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 394.3/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 395.5/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  397.1/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  398.3/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  399.9/407.8 MB 29.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  401.8/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  403.1/407.8 MB 29.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  405.0/407.8 MB 34.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  406.5/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- 407.8/407.8 MB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from es-dep-news-trf==3.8.0) (0.3.0)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (0.0.9)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (2.6.0)\n",
      "Requirement already satisfied: regex>=2022 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (2023.10.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (2.1.3)\n",
      "Installing collected packages: es-dep-news-trf\n",
      "Successfully installed es-dep-news-trf-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_dep_news_trf')\n"
     ]
    }
   ],
   "source": [
    "%pip install pylats taaled spacy\n",
    "# English models\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_trf\n",
    "\n",
    "# Spanish models (used as fallback)\n",
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotnine has not been installed.\n",
      "To enable advanced data visualization features, please install plotnine.\n",
      "Attempting to load spacy model: en_core_web_sm\n",
      "Successfully loaded spacy model: en_core_web_sm\n",
      "Attempting to load spacy model: en_core_web_trf\n",
      "Successfully loaded spacy model: en_core_web_trf\n",
      "Attempting to load spacy model: es_core_news_sm\n",
      "Successfully loaded spacy model: es_core_news_sm\n",
      "Attempting to load spacy model: es_dep_news_trf\n",
      "Successfully loaded spacy model: es_dep_news_trf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing MATTR: 100%|██████████| 1805/1805 [06:18<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean MATTR values saved to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from taaled import ld\n",
    "from pylats import lats\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "# Read rows\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "\n",
    "    # Ensure 'mattr' column exists\n",
    "    if \"mattr\" not in fieldnames:\n",
    "        fieldnames.append(\"mattr\")\n",
    "    # Drop 'mattr_reason' if it exists\n",
    "    if \"mattr_reason\" in fieldnames:\n",
    "        fieldnames.remove(\"mattr_reason\")\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Computing MATTR\"):\n",
    "        review_text = row.get(\"review_text\", \"\").strip()\n",
    "        mattr_value = \"\"\n",
    "\n",
    "        try:\n",
    "            cleaned = lats.Normalize(review_text, lats.ld_params_en)\n",
    "            tokens = cleaned.toks\n",
    "            mattr_value = f\"{ld.lexdiv(tokens).mattr:.4f}\"\n",
    "        except Exception as e:\n",
    "            mattr_value = \"\"\n",
    "\n",
    "        row[\"mattr\"] = mattr_value\n",
    "        # Remove 'mattr_reason' if it exists in the row\n",
    "        row.pop(\"mattr_reason\", None)\n",
    "        output_rows.append(row)\n",
    "\n",
    "# Write updated file\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Clean MATTR values saved to review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\soroush\\anaconda3\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in c:\\users\\soroush\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\soroush\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: click in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install transformers torch nltk\n",
    "\n",
    "###########################\n",
    "# Apple silicon support\n",
    "# Uninstall current PyTorch version (if any)\n",
    "# !pip uninstall torch -y\n",
    "\n",
    "# Install PyTorch with MPS (Metal Performance Shaders) support\n",
    "# !pip install torch==2.1.2 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "###########################\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting Questions: 100%|██████████| 1805/1805 [03:15<00:00,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Questions counted and saved in review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "model.eval()\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "# Load review rows\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "    if \"question_count\" not in fieldnames:\n",
    "        fieldnames.append(\"question_count\")\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Detecting Questions\"):\n",
    "        review_text = row.get(\"review_text\", \"\")\n",
    "        question_count = 0\n",
    "\n",
    "        try:\n",
    "            sentences = sent_tokenize(review_text)\n",
    "            for sent in sentences:\n",
    "                inputs = tokenizer(\n",
    "                    sent,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    max_length=64,\n",
    "                    padding=True\n",
    "                )\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    predicted = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "                    # Label 0 = question\n",
    "                    if predicted == 0:\n",
    "                        question_count += 1\n",
    "        except Exception as e:\n",
    "            question_count = \"\"\n",
    "\n",
    "        row[\"question_count\"] = question_count\n",
    "        output_rows.append(row)\n",
    "\n",
    "# Save updated CSV\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Questions counted and saved in review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting Citations: 100%|██████████| 1805/1805 [00:00<00:00, 12740.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Citation counts added to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Citation counting logic ---\n",
    "def count_citations(text):\n",
    "    citation_patterns = [\n",
    "        r'\\[\\d+(?:,\\s*\\d+)*\\]',                         # [1], [1, 2, 3]\n",
    "        r'\\([A-Za-z]+ et al\\.,\\s*\\d{4}\\)',               # (Smith et al., 2020)\n",
    "        r'\\(\\d{4}[a-z]?\\)',                              # (2020), (2020a)\n",
    "        r'\\[[A-Za-z]+\\d{4}[a-z]?\\]',                     # [Smith2020], [Johnson2021a]\n",
    "        r'\\b(?:doi:|arxiv:|https?://[^\\s]+)',             # DOI, arXiv, URLs\n",
    "    ]\n",
    "    pattern = '|'.join(citation_patterns)\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)\n",
    "\n",
    "# --- Load CSV and apply ---\n",
    "output_rows = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "\n",
    "    # Update for citation_count\n",
    "    if \"citation_count\" not in fieldnames:\n",
    "        fieldnames.append(\"citation_count\")\n",
    "    if \"has_citation\" in fieldnames:\n",
    "        fieldnames.remove(\"has_citation\")  # Remove old 'has_citation' if needed\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Counting Citations\"):\n",
    "        review_text = row.get(\"review_text\", \"\")\n",
    "        citation_count = count_citations(review_text)\n",
    "        row[\"citation_count\"] = citation_count\n",
    "        output_rows.append(row)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Citation counts added to review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Total reviews: 1805\n",
      "🔍 Reviews with citations: 110\n",
      "📊 Percentage: 6.09%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(output_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    total = 0\n",
    "    with_citations = 0\n",
    "\n",
    "    for row in reader:\n",
    "        total += 1\n",
    "        if row.get(\"citation_count\") == \"2\":\n",
    "            with_citations += 1\n",
    "\n",
    "print(f\"📄 Total reviews: {total}\")\n",
    "print(f\"🔍 Reviews with citations: {with_citations}\")\n",
    "print(f\"📊 Percentage: {(with_citations / total * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\soroush\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Sentiment: 100%|██████████| 1805/1805 [00:03<00:00, 509.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sentiment polarity added to review_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "# Read and process the file\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "\n",
    "    # Add new column if not already there\n",
    "    if \"sentiment_polarity\" not in fieldnames:\n",
    "        fieldnames.append(\"sentiment_polarity\")\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Analyzing Sentiment\"):\n",
    "        review_text = row.get(\"review_text\", \"\").strip()\n",
    "        try:\n",
    "            blob = TextBlob(review_text)\n",
    "            sentiment = blob.sentiment.polarity\n",
    "        except Exception:\n",
    "            sentiment = \"\"\n",
    "\n",
    "        row[\"sentiment_polarity\"] = sentiment\n",
    "        output_rows.append(row)\n",
    "\n",
    "# Write updated CSV\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Sentiment polarity added to review_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: convokit in c:\\users\\soroush\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (3.8.4)\n",
      "Requirement already satisfied: scipy>1.14 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.15.2)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.2.2)\n",
      "Collecting numpy>=2.0.0 (from convokit)\n",
      "  Using cached numpy-2.2.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: msgpack-numpy>=0.4.3.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.4.8)\n",
      "Requirement already satisfied: spacy>=3.8.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (3.8.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.4.2)\n",
      "Requirement already satisfied: nltk>=3.4 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (3.9.1)\n",
      "Requirement already satisfied: dill>=0.2.9 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.3.8)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.4.2)\n",
      "Requirement already satisfied: clean-text>=0.6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.6.0)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.2.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (4.66.4)\n",
      "Requirement already satisfied: pymongo>=4.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (4.11.3)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (6.0.1)\n",
      "Requirement already satisfied: dnspython>=1.16.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.7.0)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (8.3.4)\n",
      "Requirement already satisfied: h5py==3.12.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (3.12.1)\n",
      "Requirement already satisfied: numexpr>=2.8.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.8.7)\n",
      "Requirement already satisfied: ruff>=0.4.8 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.11.2)\n",
      "Requirement already satisfied: bottleneck in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.3.7)\n",
      "Requirement already satisfied: accelerate in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.5.2)\n",
      "Requirement already satisfied: peft in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.15.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.45.4)\n",
      "Requirement already satisfied: transformers in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (4.49.0)\n",
      "Requirement already satisfied: trl>=0.12.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.16.0)\n",
      "Requirement already satisfied: tensorflow>=2.18.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.19.0)\n",
      "Requirement already satisfied: tf-keras<3.0.0,>=2.17.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.19.0)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from clean-text>=0.6.0->convokit) (1.7.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from clean-text>=0.6.0->convokit) (6.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (2.9.0.post0)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.3)\n",
      "Requirement already satisfied: click in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.4->convokit) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.4->convokit) (2023.10.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->convokit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->convokit) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->convokit) (2.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (0.15.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (69.5.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (3.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (3.9.0)\n",
      "  Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (0.5.1)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->convokit) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->convokit) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->convokit) (0.4.6)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from trl>=0.12.2->convokit) (3.4.1)\n",
      "Requirement already satisfied: rich in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from trl>=0.12.2->convokit) (13.3.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from accelerate->convokit) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from accelerate->convokit) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from accelerate->convokit) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from accelerate->convokit) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers->convokit) (3.13.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers->convokit) (0.21.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->convokit) (0.43.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (19.0.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (3.9.5)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.5)\n",
      "Requirement already satisfied: namex in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.14.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit) (3.0.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate->convokit) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate->convokit) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate->convokit) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from rich->trl>=0.12.2->convokit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from rich->trl>=0.12.2->convokit) (2.15.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->spacy>=3.8.2->convokit) (2.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (1.9.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->trl>=0.12.2->convokit) (0.1.0)\n",
      "Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Soroush\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Soroush\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
      "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 2.1.3 which is incompatible.\n",
      "streamlit 1.32.0 requires numpy<2,>=1.19.3, but you have numpy 2.1.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "      --------------------------------------- 0.2/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.5/12.8 MB 4.0 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.9/12.8 MB 5.7 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.2/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 6.4 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.5/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 8.8 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.5/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 5.1/12.8 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 11.2 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.7/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 8.0/12.8 MB 12.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 13.3 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.4/12.8 MB 15.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.5/12.8 MB 18.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 22.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 21.8 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install convokit\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Downloading training corpus...\n",
      "Dataset already exists at C:\\Users\\Soroush\\.convokit\\saved-corpora\\wiki-politeness-annotated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔧 Preparing Utterances: 100%|██████████| 1805/1805 [00:00<00:00, 257788.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Building test corpus...\n",
      "🧠 Parsing utterances...\n",
      "✨ Extracting politeness strategies...\n",
      "🎓 Training classifier...\n",
      "Initialized default classification model (standard scaled logistic regression).\n",
      "📈 Summarizing scores...\n",
      "🧾 Merging scores into CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔗 Assigning Scores: 1805it [00:00, 54323.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving to review_analysis.csv...\n",
      "✅ All done! Politeness scores are now in your CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "from convokit import Corpus, download, TextParser, PolitenessStrategies, Classifier, Utterance, Speaker\n",
    "\n",
    "# Step 1: Load training corpus\n",
    "print(\"📥 Downloading training corpus...\")\n",
    "train_corpus = Corpus(filename=download('wiki-politeness-annotated'))\n",
    "\n",
    "# Step 2: Load review data and convert to Utterances with dummy speakers\n",
    "review_utterances = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    for idx, row in tqdm(enumerate(reader), desc=\"🔧 Preparing Utterances\", total=1805):  # Adjust total if needed\n",
    "        review_text = row.get(\"review_text\", \"\").strip()\n",
    "        if review_text:\n",
    "            dummy_speaker = Speaker(id=f\"reviewer_{idx}\")\n",
    "            review_utterances.append(\n",
    "                Utterance(id=str(idx), text=review_text, speaker=dummy_speaker, meta={\"orig_row\": row})\n",
    "            )\n",
    "\n",
    "# Step 3: Build test corpus\n",
    "print(\"📦 Building test corpus...\")\n",
    "test_corpus = Corpus(utterances=review_utterances)\n",
    "\n",
    "# Step 4: Parse\n",
    "print(\"🧠 Parsing utterances...\")\n",
    "parser = TextParser()\n",
    "parser.transform(train_corpus)\n",
    "parser.transform(test_corpus)\n",
    "\n",
    "# Step 5: Extract politeness strategies\n",
    "print(\"✨ Extracting politeness strategies...\")\n",
    "ps = PolitenessStrategies()\n",
    "ps.transform(train_corpus)\n",
    "ps.transform(test_corpus)\n",
    "\n",
    "# Step 6: Train classifier\n",
    "print(\"🎓 Training classifier...\")\n",
    "clf = Classifier(obj_type='utterance', pred_feats=['politeness_strategies'],\n",
    "                 labeller=lambda utt: utt.meta.get(\"Binary\") == 1)\n",
    "clf.fit(train_corpus)\n",
    "clf.transform(test_corpus)\n",
    "\n",
    "# Step 7: Summarize results\n",
    "print(\"📈 Summarizing scores...\")\n",
    "results = clf.summarize(test_corpus)\n",
    "\n",
    "# Step 8: Merge back to CSV rows\n",
    "print(\"🧾 Merging scores into CSV...\")\n",
    "output_rows = []\n",
    "fieldnames = list(reader[0].keys())\n",
    "if \"politeness_score\" not in fieldnames:\n",
    "    fieldnames.append(\"politeness_score\")\n",
    "\n",
    "for utt in tqdm(test_corpus.iter_utterances(), desc=\"🔗 Assigning Scores\"):\n",
    "    row = utt.meta[\"orig_row\"]\n",
    "    try:\n",
    "        score = results.loc[utt.id, \"pred_score\"]\n",
    "        row[\"politeness_score\"] = round(score, 4)\n",
    "    except KeyError:\n",
    "        row[\"politeness_score\"] = \"\"\n",
    "    output_rows.append(row)\n",
    "\n",
    "# Step 9: Save\n",
    "print(\"💾 Saving to review_analysis.csv...\")\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ All done! Politeness scores are now in your CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7215288f8404a9ea87ece7655851c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soroush\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Soroush\\.cache\\huggingface\\hub\\models--allenai--specter. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87838764a35d4df3a344b12f23872afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870b2e6c16fb46c894ce1b14d32fec3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730c1c027cc84870b943e9e52ca06606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d227df08774bf99850f10ea3eb8e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Relevance Score:   0%|          | 0/1805 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec188adc3324edd8fe28307029f870e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Relevance Score: 100%|██████████| 1805/1805 [00:53<00:00, 33.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevance scores added to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Load SPECTER model ---\n",
    "model_name = \"allenai/specter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "\n",
    "    if \"similarity_score\" not in fieldnames:\n",
    "        fieldnames.append(\"similarity_score\")\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Computing Relevance Score\"):\n",
    "        review_text = row.get(\"review_text\", \"\")\n",
    "        paper_id = row.get(\"paper_id\", \"\").strip()\n",
    "\n",
    "        try:\n",
    "            # Find matching entry in data\n",
    "            matched_entry = next((entry for entry in data if str(entry.get(\"id\", \"\")).strip() == paper_id), None)\n",
    "\n",
    "            if matched_entry:\n",
    "                title = matched_entry.get(\"title\", \"\")\n",
    "                abstract = matched_entry.get(\"abstract\", \"\")\n",
    "                doc_text = f\"{title} {abstract}\"\n",
    "\n",
    "                # Encode document\n",
    "                doc_inputs = tokenizer(doc_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "                doc_inputs = {k: v.to(device) for k, v in doc_inputs.items()}\n",
    "                with torch.no_grad():\n",
    "                    doc_emb = model(**doc_inputs).last_hidden_state[:, 0, :]  # [CLS]\n",
    "\n",
    "                # Encode review text\n",
    "                review_inputs = tokenizer(review_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "                review_inputs = {k: v.to(device) for k, v in review_inputs.items()}\n",
    "                with torch.no_grad():\n",
    "                    review_emb = model(**review_inputs).last_hidden_state[:, 0, :]  # [CLS]\n",
    "\n",
    "                # Cosine similarity\n",
    "                similarity_score = F.cosine_similarity(doc_emb, review_emb).item()\n",
    "                row[\"similarity_score\"] = similarity_score\n",
    "\n",
    "            else:\n",
    "                row[\"similarity_score\"] = \"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            row[\"similarity_score\"] = \"\"\n",
    "\n",
    "        output_rows.append(row)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Relevance scores added to review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Title and Abstract (Escaping Newlines): 100%|██████████| 1805/1805 [00:00<00:00, 20347.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Title and Abstract (with clean \\n) added to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    original_fieldnames = list(reader[0].keys())\n",
    "\n",
    "    # Insert title and abstract at positions 5 and 6\n",
    "    new_fieldnames = original_fieldnames[:5] + [\"title\", \"abstract\"] + original_fieldnames[5:]\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Adding Title and Abstract (Escaping Newlines)\"):\n",
    "        paper_id = row.get(\"paper_id\", \"\").strip()\n",
    "\n",
    "        # Find matching entry\n",
    "        matched_entry = next((entry for entry in data if str(entry.get(\"id\", \"\")).strip() == paper_id), None)\n",
    "\n",
    "        if matched_entry:\n",
    "            title = matched_entry.get(\"title\", \"\")\n",
    "            abstract = matched_entry.get(\"abstract\", \"\")\n",
    "        else:\n",
    "            title = \"\"\n",
    "            abstract = \"\"\n",
    "\n",
    "        # Escape real newlines in title and abstract\n",
    "        title = title.replace(\"\\r\\n\", \"\\\\n\").replace(\"\\n\", \"\\\\n\")\n",
    "        abstract = abstract.replace(\"\\r\\n\", \"\\\\n\").replace(\"\\n\", \"\\\\n\")\n",
    "\n",
    "        # Build new row\n",
    "        new_row = {}\n",
    "        for idx, field in enumerate(new_fieldnames):\n",
    "            if field == \"title\":\n",
    "                new_row[field] = title\n",
    "            elif field == \"abstract\":\n",
    "                new_row[field] = abstract\n",
    "            else:\n",
    "                # Map original fields\n",
    "                original_field_idx = idx if idx < 5 else idx - 2  # Adjust because we inserted 2 fields\n",
    "                if original_field_idx < len(original_fieldnames):\n",
    "                    original_field = original_fieldnames[original_field_idx]\n",
    "                    new_row[field] = row.get(original_field, \"\")\n",
    "\n",
    "        output_rows.append(new_row)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=new_fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Title and Abstract (with clean \\\\n) added to review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing num_days_before_deadline: 100%|██████████| 1805/1805 [00:00<00:00, 161750.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ num_days_before_deadline added to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Helper: parse dates consistently\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, \"%d/%b/%Y\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    rows = list(reader)\n",
    "    fieldnames = list(rows[0].keys())\n",
    "\n",
    "    if \"num_days_before_deadline\" not in fieldnames:\n",
    "        fieldnames.append(\"num_days_before_deadline\")\n",
    "\n",
    "    # First: find latest review_date per paper_id\n",
    "    latest_review_dates = {}\n",
    "\n",
    "    for row in rows:\n",
    "        paper_id = row[\"paper_id\"]\n",
    "        review_date = parse_date(row[\"review_date\"])\n",
    "\n",
    "        if paper_id and review_date:\n",
    "            if paper_id not in latest_review_dates:\n",
    "                latest_review_dates[paper_id] = review_date\n",
    "            else:\n",
    "                if review_date > latest_review_dates[paper_id]:\n",
    "                    latest_review_dates[paper_id] = review_date\n",
    "\n",
    "    # Second: compute days before deadline for each review\n",
    "    for row in tqdm(rows, desc=\"Computing num_days_before_deadline\"):\n",
    "        paper_id = row[\"paper_id\"]\n",
    "        review_date = parse_date(row[\"review_date\"])\n",
    "        deadline_date = latest_review_dates.get(paper_id)\n",
    "\n",
    "        if review_date and deadline_date:\n",
    "            days_before_deadline = (deadline_date - review_date).days\n",
    "            row[\"num_days_before_deadline\"] = days_before_deadline\n",
    "        else:\n",
    "            row[\"num_days_before_deadline\"] = \"\"\n",
    "\n",
    "        output_rows.append(row)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ num_days_before_deadline added to review_analysis.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
