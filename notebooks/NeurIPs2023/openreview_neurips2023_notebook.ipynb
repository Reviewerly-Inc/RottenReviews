{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V0 - V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openreview-py numpy pandas nltk transformers tqdm torch\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install pylats taaled spacy convokit\n",
    "\n",
    "# English models\n",
    "# %python -m spacy download en_core_web_sm\n",
    "# %python -m spacy download en_core_web_trf\n",
    "# # Spanish models (used as fallback)\n",
    "# %python -m spacy download es_core_news_sm\n",
    "# %python -m spacy download es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available?  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is GPU available? \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/ali/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "/home/ali/Review_Quality_Benchmark/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotnine has not been installed.\n",
      "To enable advanced data visualization features, please install plotnine.\n",
      "Attempting to load spacy model: en_core_web_sm\n",
      "Successfully loaded spacy model: en_core_web_sm\n",
      "Attempting to load spacy model: en_core_web_trf\n",
      "Successfully loaded spacy model: en_core_web_trf\n",
      "Attempting to load spacy model: es_core_news_sm\n",
      "Successfully loaded spacy model: es_core_news_sm\n",
      "Attempting to load spacy model: es_dep_news_trf\n",
      "Successfully loaded spacy model: es_dep_news_trf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "import csv\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "from taaled import ld\n",
    "from pylats import lats\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ICLR 2024\n",
    "# file_path = '/home/ali/Review_Quality_Benchmark/data/raw/OpenReview/ICLR2024/ICLR2024_submissions.pkl'\n",
    "\n",
    "# NEURIPS 2023\n",
    "file_path = '/home/ali/Review_Quality_Benchmark/data/raw/OpenReview/neurips2023/neurips2023_submissions.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as pkl_file:\n",
    "    data = pickle.load(pkl_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to JSON file at: /home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v0.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Replace 'your_file.pkl' with the path to your .pkl file\n",
    "file_path = '/home/ali/Review_Quality_Benchmark/data/raw/OpenReview/neurips2023/neurips2023_submissions.pkl'\n",
    "output_json_path = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v0.json'\n",
    "\n",
    "# Load the .pkl file\n",
    "with open(file_path, 'rb') as pkl_file:\n",
    "    data = pickle.load(pkl_file)\n",
    "\n",
    "# Extract the required fields for each submission\n",
    "extracted_data = []\n",
    "for submission in data:\n",
    "    extracted_data.append({\n",
    "        'number': submission.number if hasattr(submission, 'number') else np.nan,\n",
    "        'id': submission.id if hasattr(submission, 'id') else np.nan,\n",
    "        'content.paperhash': submission.content['paperhash']['value'] if 'paperhash' in submission.content and 'value' in submission.content['paperhash'] else np.nan,\n",
    "        'content.authorids': submission.content['authorids']['value'] if 'authorids' in submission.content and 'value' in submission.content['authorids'] else np.nan,\n",
    "        'cdate': submission.cdate if hasattr(submission, 'cdate') else np.nan,\n",
    "        'content.title': submission.content['title']['value'] if 'title' in submission.content and 'value' in submission.content['title'] else np.nan,\n",
    "        'content.abstract': submission.content['abstract']['value'] if 'abstract' in submission.content and 'value' in submission.content['abstract'] else np.nan,\n",
    "        # 'content.TLDR': submission.content['TLDR']['value'] if 'TLDR' in submission.content and 'value' in submission.content['TLDR'] else np.nan,\n",
    "    })\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Save the DataFrame to a JSON file\n",
    "df.to_json(output_json_path, orient='records', indent=4)\n",
    "\n",
    "print(f\"DataFrame saved to JSON file at: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content.paperhash",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content.authorids",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "content.title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "content.abstract",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a8b7b4ce-637f-4d27-a041-2a1cccece2bd",
       "rows": [
        [
         "0",
         "10819",
         "zyhxRc9bew",
         "sun|what_is_flagged_in_uncertainty_quantification_latent_density_models_for_uncertainty_categorization",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "1683789038840",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark."
        ],
        [
         "1",
         "15594",
         "zyZkaqNnpa",
         "puli|dont_blame_dataset_shift_shortcut_learning_due_to_gradients_and_cross_entropy",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "1683835167534",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks."
        ],
        [
         "2",
         "327",
         "zuXyQsXVLF",
         "xu|enhancing_adversarial_contrastive_learning_via_adversarial_invariant_regularization",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "1682066194522",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR."
        ],
        [
         "3",
         "801",
         "ztqf6bzuqQ",
         "shi|hybrid_distillation_connecting_masked_autoencoders_with_contrastive_learners",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "1682507396411",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks."
        ],
        [
         "4",
         "7411",
         "ztDxO15N7f",
         "scholkemper|an_optimizationbased_approach_to_node_role_discovery_in_networks_approximating_equitable_partitions",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "1683729208530",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way."
        ],
        [
         "5",
         "5668",
         "zsOOqjaj2z",
         "wang|generator_identification_for_linear_sdes_with_additive_and_multiplicative_noise",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "1683686700553",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings."
        ],
        [
         "6",
         "8399",
         "zrUEHZ6s9C",
         "zhang|algorithm_selection_for_deep_active_learning_with_imbalanced_datasets",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "1683746518064",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR."
        ],
        [
         "7",
         "2448",
         "zrLxHYvIFL",
         "wang|discover_and_align_taxonomic_context_priors_for_openworld_semisupervised_learning",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "1683361520146",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA."
        ],
        [
         "8",
         "11147",
         "zrCmeqV3Sz",
         "xia|learning_invariant_representations_of_graph_neural_networks_via_cluster_generalization",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "1683793236823",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance."
        ],
        [
         "9",
         "813",
         "zqyVjCjhYD",
         "bianchi|the_expressive_power_of_pooling_in_graph_neural_networks",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "1682515100473",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test."
        ],
        [
         "10",
         "2649",
         "zqOcW3R9rd",
         "wei|shared_adversarial_unlearning_backdoor_mitigation_by_unlearning_shared_adversarial_examples",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "1683428990794",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore)."
        ],
        [
         "11",
         "8789",
         "zq4vFneRiA",
         "dai|the_crucial_role_of_normalization_in_sharpnessaware_minimization",
         "['~Yan_Dai1', '~Kwangjun_Ahn2', '~Suvrit_Sra1']",
         "1683754773269",
         "The Crucial Role of Normalization in Sharpness-Aware Minimization",
         "Sharpness-Aware Minimization (SAM) is a recently proposed gradient-based optimizer (Foret et al., ICLR 2021) that greatly improves the prediction performance of deep neural networks. Consequently, there has been a surge of interest in explaining its empirical success. We focus, in particular, on understanding ***the role played by normalization***, a key component of the SAM updates. We theoretically and empirically study the effect of normalization in SAM for both convex and non-convex functions, revealing two key roles played by normalization: i) it helps in stabilizing the algorithm; and ii) it enables the algorithm to drift along a continuum (manifold) of minima -- a property identified by recent theoretical works that is the key to better performance. We further argue that these two properties of normalization make SAM robust against the choice of hyper-parameters, supporting the practicality of SAM. Our conclusions are backed by various experiments."
        ],
        [
         "12",
         "8250",
         "zpVCITHknd",
         "wang|towards_personalized_federated_learning_via_heterogeneous_model_reassembly",
         "['~Jiaqi_Wang4', '~Xingyi_Yang1', '~Suhan_Cui1', '~Liwei_Che1', '~Lingjuan_Lyu1', '~Dongkuan_Xu2', '~Fenglong_Ma1']",
         "1683743540260",
         "Towards Personalized Federated Learning via Heterogeneous Model Reassembly",
         "This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. To track this problem, we propose a novel framework called pFedHR, which leverages heterogeneous model reassembly to achieve personalized federated learning. In particular, we approach the problem of heterogeneous model personalization as a model-matching optimization task on the server side. Moreover, pFedHR automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention. Furthermore, our proposed heterogeneous model reassembly technique mitigates the adverse impact introduced by using public data with different distributions from the client data to a certain extent. Experimental results demonstrate that pFedHR outperforms baselines on three datasets under both IID and Non-IID settings. Additionally, pFedHR effectively reduces the adverse impact of using different public data and dynamically generates diverse personalized models in an automated manner."
        ],
        [
         "13",
         "5115",
         "znudaK78u8",
         "hwang|active_learning_for_semantic_segmentation_with_multiclass_label_query",
         "['~Sehyun_Hwang1', '~Sohyun_Lee1', '~Hoyoung_Kim1', '~Minhyeon_Oh1', '~Jungseul_Ok2', '~Suha_Kwak3']",
         "1683654851515",
         "Active Learning for Semantic Segmentation with Multi-class Label Query",
         "This paper proposes a new active learning method for semantic segmentation. The core of our method lies in a new annotation query design. It samples informative local image regions ($\\textit{e.g.}$, superpixels), and for each of such regions, asks an oracle for a multi-hot vector indicating all classes existing in the region. This multi-class labeling strategy is substantially more efficient than existing ones like segmentation, polygon, and even dominant class labeling in terms of annotation time per click. However, it introduces the class ambiguity issue in training as it assigns partial labels ($\\textit{i.e.}$, a set of candidate classes) to individual pixels. We thus propose a new algorithm for learning semantic segmentation while disambiguating the partial labels in two stages. In the first stage, it trains a segmentation model directly with the partial labels through two new loss functions motivated by partial label learning and multiple instance learning. In the second stage, it disambiguates the partial labels by generating pixel-wise pseudo labels, which are used for supervised learning of the model. Equipped with a new acquisition function dedicated to the multi-class labeling, our method outperforms previous work on Cityscapes and PASCAL VOC 2012 while spending less annotation cost. Our code and results are available at [https://github.com/sehyun03/MulActSeg](https://github.com/sehyun03/MulActSeg)."
        ],
        [
         "14",
         "2253",
         "znY173SCxu",
         "kim|timereversed_dissipation_induces_duality_between_minimizing_gradient_norm_and_function_value",
         "['~Jaeyeon_Kim2', '~Asuman_E._Ozdaglar1', '~Chanwoo_Park2', '~Ernest_K._Ryu1']",
         "1683313199054",
         "Time-Reversed Dissipation Induces Duality Between Minimizing Gradient Norm and Function Value",
         "In convex optimization, first-order optimization methods efficiently minimizing function values have been a central subject study since Nesterov's seminal work of 1983. Recently, however, Kim and Fessler's OGM-G and Lee et al.'s FISTA-G have been presented as alternatives that efficiently minimize the gradient magnitude instead. In this paper, we present H-duality, which represents a surprising one-to-one correspondence between methods efficiently minimizing function values and methods efficiently minimizing gradient magnitude. In continuous-time formulations, H-duality corresponds to reversing the time dependence of the dissipation/friction term. To the best of our knowledge, H-duality is different from Lagrange/Fenchel duality and is distinct from any previously known duality or symmetry relations. Using H-duality, we obtain a clearer understanding of the symmetry between Nesterov's method and OGM-G, derive a new class of methods efficiently reducing gradient magnitudes of smooth convex functions, and find a new composite minimization method that is simpler and faster than FISTA-G."
        ],
        [
         "15",
         "4945",
         "znW5jNIOED",
         "zhang|optimizing_over_trained_gnns_via_symmetry_breaking",
         "['~Shiqiang_Zhang1', '~Juan_S_Campos1', '~Christian_Wolfgang_Feldmann1', '~David_Walz1', '~Frederik_Sandfort1', '~Miriam_Mathea1', '~Calvin_Tsay1', '~Ruth_Misener1']",
         "1683646917954",
         "Optimizing over trained GNNs via symmetry breaking",
         "Optimization over trained machine learning models has applications including: verification, minimizing neural acquisition functions, and integrating a trained surrogate into a larger decision-making problem. This paper formulates and solves optimization problems constrained by trained graph neural networks (GNNs). To circumvent the symmetry issue caused by graph isomorphism, we propose two types of symmetry-breaking constraints: one indexing a node 0 and one indexing the remaining nodes by lexicographically ordering their neighbor sets. To guarantee that adding these constraints will not remove all symmetric solutions, we construct a graph indexing algorithm and prove that the resulting graph indexing satisfies the proposed symmetry-breaking constraints. For the classical GNN architectures considered in this paper, optimizing over a GNN with a fixed graph is equivalent to optimizing over a dense neural network. Thus, we study the case where the input graph is not fixed, implying that each edge is a decision variable, and develop two mixed-integer optimization formulations. To test our symmetry-breaking strategies and optimization formulations, we consider an application in molecular design."
        ],
        [
         "16",
         "9206",
         "zn5ihqknGj",
         "xiao|an_alternating_optimization_method_for_bilevel_problems_under_the_polyakojasiewicz_condition",
         "['~Quan_Xiao1', '~Songtao_Lu1', '~Tianyi_Chen5']",
         "1683764248024",
         "An Alternating Optimization Method for Bilevel Problems under the Polyak-Łojasiewicz Condition",
         "Bilevel optimization has recently regained interest owing to its applications in emerging machine learning fields such as hyperparameter optimization, meta-learning, and reinforcement learning. Recent results have shown that simple alternating (implicit) gradient-based algorithms can match the convergence rate of single-level gradient descent (GD) when addressing bilevel problems with a strongly convex lower-level objective. However, it remains unclear whether this result can be generalized to bilevel problems beyond this basic setting. In this paper, we first introduce a stationary metric for the considered bilevel problems, which generalizes the existing metric, for a nonconvex lower-level objective that satisfies the Polyak-Łojasiewicz (PL) condition. We then propose a Generalized ALternating mEthod for bilevel opTimization (GALET) tailored to BLO with convex PL LL problem and establish that GALET achieves an $\\epsilon$-stationary point for the considered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations, which matches the iteration complexity of GD for single-level smooth nonconvex problems."
        ],
        [
         "17",
         "13421",
         "zmWNe1V6jg",
         "rui|scalable_fair_influence_maximization",
         "['~Xiaobin_Rui2', '~Zhixiao_Wang2', '~Jiayu_Zhao2', '~Lichao_Sun1', '~Wei_Chen10']",
         "1683819112745",
         "Scalable Fair Influence Maximization",
         "Given a graph $G$, a community structure $\\mathcal{C}$, and a budget $k$, the fair influence maximization problem aims to select a seed set $S$ ($|S|\\leq k$) that maximizes the influence spread while narrowing the influence gap between different communities. While various fairness notions exist, the welfare fairness notion, which balances fairness level and influence spread, has shown promising effectiveness. However, the lack of efficient algorithms for optimizing the welfare fairness objective function restricts its application to small-scale networks with only a few hundred nodes. In this paper, we adopt the objective function of welfare fairness to maximize the exponentially weighted summation over the influenced fraction of all communities. We first introduce an unbiased estimator for the fractional power of the arithmetic mean. Then, by adapting the reverse influence sampling (RIS) approach, we convert the optimization problem to a weighted maximum coverage problem. We also analyze the number of reverse reachable sets needed to approximate the fair influence at a high probability. Further, we present an efficient algorithm that guarantees $1-1/e - \\varepsilon$ approximation."
        ],
        [
         "18",
         "10441",
         "zkfyOkBVpz",
         "sheybani|curriculum_learning_with_infant_egocentric_videos",
         "['~Saber_Sheybani1', '~Himanshu_Hansaria1', '~Justin_Newell_Wood1', '~Linda_B._Smith1', '~Zoran_Tiganj1']",
         "1683783734526",
         "Curriculum Learning With Infant Egocentric Videos",
         "Infants possess a remarkable ability to rapidly learn and process visual inputs. As an infant's mobility increases, so does the variety and dynamics of their visual inputs. Is this change in the properties of the visual inputs beneficial or even critical for the proper development of the visual system? To address this question, we used video recordings from infants wearing head-mounted cameras to train a variety of self-supervised learning models. Critically, we separated the infant data by age group and evaluated the importance of training with a curriculum aligned with developmental order. We found that initiating learning with the data from the youngest age group provided the strongest learning signal and led to the best learning outcomes in terms of downstream task performance. We then showed that the benefits of the data from the youngest age group are due to the slowness and simplicity of the visual experience. The results provide strong empirical evidence for the importance of the properties of the early infant experience and developmental progression in training. More broadly, our approach and findings take a noteworthy step towards reverse engineering the learning mechanisms in newborn brains using image-computable models from artificial intelligence."
        ],
        [
         "19",
         "8270",
         "zjpjsJeVJZ",
         "tsepenekas|comparing_apples_to_oranges_learning_similarity_functions_for_data_produced_by_different_distributions",
         "['~Leonidas_Tsepenekas1', '~Ivan_Brugere1', '~Freddy_Lecue1', '~Daniele_Magazzeni1']",
         "1683743963779",
         "Comparing Apples to Oranges: Learning Similarity Functions for Data Produced by Different Distributions",
         "Similarity functions measure how comparable pairs of elements are, and play a key role in a wide variety of applications, e.g., notions of Individual Fairness abiding by the seminal paradigm of Dwork et al., as well as Clustering problems. However, access to an accurate similarity function should not always be considered guaranteed, and this point was even raised by Dwork et al. For instance, it is reasonable to assume that when the elements to be compared are produced by different distributions, or in other words belong to different ``demographic'' groups, knowledge of their true similarity might be very difficult to obtain. In this work, we present an efficient sampling framework that learns these across-groups similarity functions, using only a limited amount of experts' feedback. We show analytical results with rigorous theoretical bounds, and empirically validate our algorithms via a large suite of experiments."
        ],
        [
         "20",
         "1026",
         "zfHCKDzzC8",
         "hzl|temporal_causal_mediation_through_a_point_process_direct_and_indirect_effects_of_healthcare_interventions",
         "['~Çağlar_Hızlı1', '~S._T._John1', '~Anne_Tuulikki_Juuti1', '~Tuure_Tapani_Saarinen1', '~Kirsi_Hannele_Pietiläinen1', '~Pekka_Marttinen1']",
         "1682687320755",
         "Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions",
         "Deciding on an appropriate intervention requires a causal model of a treatment, the outcome, and potential mediators. Causal mediation analysis lets us distinguish between direct and indirect effects of the intervention, but has mostly been studied in a static setting. In healthcare, data come in the form of complex, irregularly sampled time-series, with dynamic interdependencies between a treatment, outcomes, and mediators across time. Existing approaches to dynamic causal mediation analysis are limited to regular measurement intervals, simple parametric models, and disregard long-range mediator--outcome interactions. To address these limitations, we propose a non-parametric mediator--outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. With this model, we estimate the direct and indirect effects of an external intervention on the outcome, showing how each of these affects the whole future trajectory. We demonstrate on semi-synthetic data that our method can accurately estimate direct and indirect effects. On real-world healthcare data, our model infers clinically  meaningful direct and indirect effect trajectories for blood glucose after a surgery."
        ],
        [
         "21",
         "12252",
         "zfCNwRQ569",
         "li|interpreting_unsupervised_anomaly_detection_in_security_via_rule_extraction",
         "['~Ruoyu_Li4', '~Qing_Li15', 'eli.yuzhang@gmail.com', '~Dan_Zhao2', '~Yong_Jiang3', '~Yong_Yang8']",
         "1683809116290",
         "Interpreting Unsupervised Anomaly Detection in Security via Rule Extraction",
         "Many security applications require unsupervised anomaly detection, as malicious data are extremely rare and often only unlabeled normal data are available for training (i.e., zero-positive). However, security operators are concerned about the high stakes of trusting black-box models due to their lack of interpretability. In this paper, we propose a post-hoc method to globally explain a black-box unsupervised anomaly detection model via rule extraction.\nFirst, we propose the concept of distribution decomposition rules that decompose the complex distribution of normal data into multiple compositional distributions. To find such rules, we design an unsupervised Interior Clustering Tree that incorporates the model prediction into the splitting criteria. Then, we propose the Compositional Boundary Exploration (CBE) algorithm to obtain the boundary inference rules that estimate the decision boundary of the original model on each compositional distribution. By merging these two types of rules into a rule set, we can present the inferential process of the unsupervised black-box model in a human-understandable way, and build a surrogate rule-based model for online deployment at the same time. \nWe conduct comprehensive experiments on the explanation of four distinct unsupervised anomaly detection models on various real-world datasets. The evaluation shows that our method outperforms existing methods in terms of diverse metrics including fidelity, correctness and robustness."
        ],
        [
         "22",
         "24",
         "zdli6OxpWd",
         "steinke|counting_distinct_elements_under_personlevel_differential_privacy",
         "['~Thomas_Steinke2', '~Alexander_Knop1']",
         "1681869011996",
         "Counting Distinct Elements Under Person-Level Differential Privacy",
         "We study the problem of counting the number of distinct elements in a dataset subject to the constraint of differential privacy. \nWe consider the challenging setting of person-level DP (a.k.a. user-level DP) where each person may contribute an unbounded number of items and hence the sensitivity is unbounded.\n\nOur approach is to compute a bounded-sensitivity version of this query, which reduces to solving a max-flow problem. \nThe sensitivity bound is optimized to balance the noise we must add to privatize the answer against the error of the approximation of the bounded-sensitivity query to the true number of unique elements."
        ],
        [
         "23",
         "14663",
         "zaQ7wV9NOg",
         "liu|optimistic_natural_policy_gradient_a_simple_efficient_policy_optimization_framework_for_online_rl",
         "['~Qinghua_Liu1', '~Gellért_Weisz2', '~András_György2', '~Chi_Jin1', '~Csaba_Szepesvari1']",
         "1683828212146",
         "Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework  for Online RL",
         "While policy optimization algorithms have played an important role in recent empirical success of Reinforcement Learning (RL), the existing theoretical understanding of policy optimization remains rather limited---they are either restricted to tabular MDPs or suffer from highly suboptimal sample complexity, especial in online RL where exploration is necessary. This paper proposes a simple efficient policy optimization framework---Optimistic NPG for online RL. Optimistic NPG can be viewed as simply combining of the classic natural policy gradient (NPG) algorithm [Kakade, 2001]  with optimistic policy evaluation subroutines to encourage exploration. For $d$-dimensional linear MDPs, Optimistic NPG is computationally efficient, and learns an $\\epsilon$-optimal policy within  $\\tilde{\\mathcal{O}}(d^2/\\epsilon^3)$ samples, which is the first computationally efficient algorithm whose sample complexity has the optimal dimension dependence $\\tilde{\\Theta}(d^2)$. It also improves over state-of-the-art results of policy optimization algorithms [Zanette et al., 2021] by a factor of $d$. For general function approximation that subsumes linear MDPs, Optimistic NPG, to our best knowledge, is also the first policy optimization algorithm that achieves the polynomial sample complexity for learning near-optimal policies."
        ],
        [
         "24",
         "13137",
         "zXckveawHa",
         "lin|statistical_limits_of_adaptive_linear_models_lowdimensional_estimation_and_inference",
         "['~Licong_Lin2', '~Mufang_Ying1', '~Suvrojit_Ghosh1', '~Koulik_Khamaru1', '~Cun-Hui_Zhang1']",
         "1683817138834",
         "Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference",
         "Estimation and inference in statistics pose significant challenges when data are collected adaptively. Even in linear models, the Ordinary Least Squares (OLS) estimator may fail to exhibit asymptotic normality for single coordinate estimation and have inflated error. This issue is highlighted by a recent minimax lower bound, which shows that the error of estimating a  single coordinate can be enlarged by a multiple of $\\sqrt{d}$ when data are allowed to be arbitrarily adaptive, compared with the case when they are i.i.d. Our work explores this striking difference in estimation performance between utilizing i.i.d. and adaptive data. We investigate how the degree of adaptivity in data collection impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models. We identify conditions on the data collection mechanism under which the estimation error for a low-dimensional parameter component matches its counterpart in the i.i.d. setting, up to a factor that depends on the degree of adaptivity. We show that OLS or OLS on centered data can achieve this matching error. In addition, we propose a novel estimator for single coordinate inference via solving a Two-stage Adaptive Linear Estimating equation (TALE). Under a weaker form of adaptivity in data collection, we establish an asymptotic normality property of the proposed estimator."
        ],
        [
         "25",
         "10346",
         "zWxKYyW9ik",
         "wang|universality_and_limitations_of_prompt_tuning",
         "['~Yihan_Wang2', '~Jatin_Chauhan3', '~Wei_Wang13', '~Cho-Jui_Hsieh1']",
         "1683782196307",
         "Universality and Limitations of Prompt Tuning",
         "Despite the demonstrated empirical efficacy of prompt tuning to adapt a pretrained language model for a new task, the theoretical underpinnings of the difference between \"tuning parameters before the input\" against \"the tuning of model weights\" are limited. We thus take one of the first steps to understand the role of soft-prompt tuning for transformer-based architectures. By considering a general purpose architecture, we analyze prompt tuning from the lens of both: universal approximation and limitations with finite-depth fixed-weight pretrained transformers for continuous-valued functions. Our universality result guarantees the existence of a strong transformer with a prompt to approximate any sequence-to-sequence function in the set of Lipschitz functions. The limitations of prompt tuning for limited-depth transformers are first proved by constructing a set of datasets, that cannot be memorized by a prompt of any length for a given single encoder layer. We also provide a lower bound on the required number of tunable prompt parameters and compare the result with the number of parameters required for a low-rank update (based on LoRA) for a single-layer setting. We finally extend our analysis to multi-layer settings by providing sufficient conditions under which the transformer can at best learn datasets from invertible functions only. Our theoretical claims are also corroborated by empirical results."
        ],
        [
         "26",
         "5119",
         "zW1uVN6Mbv",
         "sturma|unpaired_multidomain_causal_representation_learning",
         "['~Nils_Sturma1', '~Chandler_Squires1', '~Mathias_Drton2', '~Caroline_Uhler1']",
         "1683655335197",
         "Unpaired Multi-Domain Causal Representation Learning",
         "The goal of causal representation learning is to find a representation of data that consists of causally related latent variables. We consider a setup where one has access to data from multiple domains that potentially share a causal representation. Crucially, observations in different domains are assumed to be unpaired, that is, we only observe the marginal distribution in each domain but not their joint distribution. In this paper, we give sufficient conditions for identifiability of the joint distribution and the shared causal graph in a linear setup. Identifiability holds if we can uniquely recover the joint distribution and the shared causal representation from the marginal distributions in each domain. We transform our results into a practical method to recover the shared latent causal graph."
        ],
        [
         "27",
         "10353",
         "zUYfbdNl1m",
         "jin|s^3_increasing_gpu_utilization_during_generative_inference_for_higher_throughput",
         "['~Yunho_Jin1', '~Chun-Feng_Wu1', '~David_Brooks1', '~Gu-Yeon_Wei1']",
         "1683782302705",
         "$S^3$: Increasing GPU Utilization during Generative Inference for Higher Throughput",
         "Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose $S^3$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49× throughput over those systems that assume the worst case for the output sequence length."
        ],
        [
         "28",
         "12494",
         "zTSlm4nmlH",
         "zhou|beta_diffusion",
         "['~Mingyuan_Zhou1', '~Tianqi_Chen2', '~Zhendong_Wang1', '~Huangjie_Zheng1']",
         "1683811747193",
         "Beta Diffusion",
         "We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization. Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them."
        ],
        [
         "29",
         "9772",
         "zR6V9fPRBn",
         "zheng|exploiting_negative_samples_a_catalyst_for_cohort_discovery_in_healthcare_analytics",
         "['~Kaiping_Zheng1', '~Horng-Ruey_Chua1', '~Melanie_Herschel1', '~H._Jagadish1', '~Beng_Chin_Ooi1', '~James_Wei_Luen_Yip2']",
         "1683774104431",
         "Exploiting Negative Samples: A Catalyst for Cohort Discovery in Healthcare Analytics",
         "Healthcare analytics, particularly binary diagnosis or prognosis problems, present unique challenges due to the inherent asymmetry between positive and negative samples. While positive samples, representing patients who develop a disease, are defined through rigorous medical criteria, negative samples are defined in an open-ended manner, resulting in a vast potential set. Despite this fundamental asymmetry, previous research has underexplored the role of negative samples, possibly due to the enormous challenge of investigating an infinitely large negative sample space. To bridge this gap, we propose an approach to facilitate cohort discovery within negative samples, which could yield valuable insights into the studied disease, as well as its comorbidity and complications. We measure each sample’s contribution using data Shapley values and construct the Negative Sample Shapley Field to model the distribution of all negative samples. Then we transform this field via manifold learning, preserving the data structure information while imposing an isotropy constraint in data Shapley values. Within this transformed space, we identify cohorts of medical interest through density-based clustering. We empirically evaluate the effectiveness of our approach on our hospital’s electronic medical records. The medical insights revealed in the discovered cohorts are validated by clinicians, which affirms the medical value of our proposal in unveiling meaningful insights consistent with existing domain knowledge, thereby bolstering medical research and well-informed clinical decision-making."
        ],
        [
         "30",
         "3702",
         "zQTi3pziFp",
         "xu|sounding_bodies_modeling_3d_spatial_sound_of_humans_using_body_pose_and_audio",
         "['~Xudong_XU1', '~Dejan_Markovic1', 'jasandakly@meta.com', 'toddkeebler@meta.com', '~Steven_Krenn1', '~Alexander_Richard1']",
         "1683568608068",
         "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and Audio",
         "While 3D human body modeling has received much attention in computer vision, modeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by body motion and speech, has fallen short in the community. To close this gap, we present a model that can generate accurate 3D spatial audio for full human bodies. The system consumes, as input, audio signals from headset microphones and body pose, and produces, as output, a 3D sound field surrounding the transmitter's body, from which spatial audio can be rendered at any arbitrary position in the 3D space. We collect a first-of-its-kind multimodal dataset of human bodies, recorded with multiple cameras and a spherical array of 345 microphones. In an empirical evaluation, we demonstrate that our model can produce accurate body-induced sound fields when trained with a suitable loss. Dataset and code are available online."
        ],
        [
         "31",
         "4269",
         "zQOYGDc9pu",
         "chen|optimized_covariance_design_for_ab_test_on_social_network_under_interference",
         "['~Qianyi_Chen2', '~Bo_Li29', '~LU_DENG1', '~Yong_Wang11']",
         "1683616915036",
         "Optimized Covariance Design for AB Test on Social Network under Interference",
         "Online A/B tests have become increasingly popular and important for social platforms. However, accurately estimating the global average treatment effect (GATE) has proven to be challenging due to network interference, which violates the Stable Unit Treatment Value Assumption (SUTVA) and poses great challenge to experimental design. Existing network experimental design research was mostly based on the unbiased Horvitz-Thompson (HT) estimator with substantial data trimming to ensure unbiasedness at the price of high resultant estimation variance. In this paper, we strive to balance the bias and variance in designing randomized network experiments.  Under a potential outcome model with 1-hop interference, we derive the bias and variance of the standard HT estimator and reveal their relation to the network topological structure and the covariance of the treatment assignment vector. We then propose to formulate the experimental design problem as to optimize the covariance matrix of the treatment assignment vector to achieve the bias and variance balance by minimizing the mean squared error (MSE) of the estimator. An efficient projected gradient descent algorithm is presented to the implement of the desired randomization scheme. Finally, we carry out extensive  simulation studies to demonstrate the advantages of our proposed method over other existing methods in many settings, with different levels of model misspecification."
        ],
        [
         "32",
         "11005",
         "zQ4yraDiRe",
         "jeong|multiscale_diffusion_denoised_smoothing",
         "['~Jongheon_Jeong1', '~Jinwoo_Shin1']",
         "1683791397574",
         "Multi-scale Diffusion Denoised Smoothing",
         "Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple \"denoise-and-classify\" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we present scalable methods to address the current trade-off between certified robustness and accuracy in denoised smoothing. Our key idea is to \"selectively\" apply smoothing among multiple noise scales, coined multi-scale smoothing, which can be efficiently implemented with a single diffusion model. This approach also suggests a new objective to compare the collective robustness of multi-scale smoothed classifiers, and questions which representation of diffusion model would maximize the objective. To address this, we propose to further fine-tune diffusion model (a) to perform consistent denoising whenever the original image is recoverable, but (b) to generate rather diverse outputs otherwise. Our experiments show that the proposed multi-scale smoothing scheme, combined with diffusion fine-tuning, not only allows strong certified robustness at high noise scales but also maintains accuracy close to non-smoothed classifiers. Code is available at https://github.com/jh-jeong/smoothing-multiscale."
        ],
        [
         "33",
         "9388",
         "zPYeYv6YYs",
         "angelopoulos|conformal_pid_control_for_time_series_prediction",
         "['~Anastasios_Nikolas_Angelopoulos1', '~Emmanuel_Candes1', '~Ryan_Tibshirani1']",
         "1683768267322",
         "Conformal PID Control for Time Series Prediction",
         "We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use  algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in\nofficial CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules at [this link](http://github.com/aangelopoulos/conformal-time-series)."
        ],
        [
         "34",
         "10567",
         "zOCIKYVaF5",
         "li|residual_alignment_uncovering_the_mechanisms_of_residual_networks",
         "['~Jianing_Li3', '~Vardan_Papyan1']",
         "1683785502007",
         "Residual Alignment: Uncovering the Mechanisms of Residual Networks",
         "The ResNet architecture has been widely adopted in deep learning due to its significant boost to performance through the use of simple skip connections, yet the underlying mechanisms leading to its success remain largely unknown. In this paper, we conduct a thorough empirical study of the ResNet architecture in classification tasks by linearizing its constituent residual blocks using Residual Jacobians and measuring their singular value decompositions. Our measurements ([code](https://colab.research.google.com/drive/1yKjEg2yF616tnZFAfuN0aQ-E9v3JmyjN?usp=sharing)) reveal a process called Residual Alignment (RA) characterized by four properties:\n- **(RA1):** intermediate representations of a given input are *equispaced* on a *line*, embedded in high dimensional space, as observed by Gai and Zhang [2021];\n- **(RA2):** top left and right singular vectors of Residual Jacobians align with each other and across different depths;\n- **(RA3):** Residual Jacobians are at most rank $C$ for fully-connected ResNets, where $C$ is the number of classes; and\n- **(RA4):** top singular values of Residual Jacobians scale inversely with depth.\n\nRA consistently occurs in models that generalize well, in both fully-connected and convolutional architectures, across various depths and widths, for varying numbers of classes, on all tested benchmark datasets, but ceases to occur once the skip connections are removed. It also provably occurs in a novel mathematical model we propose. This phenomenon reveals a strong alignment between residual branches of a ResNet (RA2+4), imparting a highly rigid geometric structure to the intermediate representations as they progress *linearly* through the network (RA1) up to the final layer, where they undergo Neural Collapse."
        ],
        [
         "35",
         "11082",
         "zO2dAQfvHf",
         "white|stabilized_neural_differential_equations_for_learning_dynamics_with_explicit_constraints",
         "['~Alistair_White1', '~Niki_Kilbertus1', 'maximilian.gelbrecht@tum.de', '~Niklas_Boers1']",
         "1683792253262",
         "Stabilized Neural Differential Equations for Learning Dynamics with Explicit Constraints",
         "Many successful methods to learn dynamical systems from data have recently been introduced. However, ensuring that the inferred dynamics preserve known constraints, such as conservation laws or restrictions on the allowed system states, remains challenging. We propose stabilized neural differential equations (SNDEs), a method to enforce arbitrary manifold constraints for neural differential equations. Our approach is based on a stabilization term that, when added to the original dynamics, renders the constraint manifold provably asymptotically stable. Due to its simplicity, our method is compatible with all common neural differential equation (NDE) models and broadly applicable. In extensive empirical evaluations, we demonstrate that SNDEs outperform existing methods while broadening the types of constraints that can be incorporated into NDE training."
        ],
        [
         "36",
         "14484",
         "zNA7u7wtIN",
         "kim|pflow_a_fast_and_dataefficient_zeroshot_tts_through_speech_prompting",
         "['~Sungwon_Kim2', '~Kevin_J._Shih1', '~Rohan_Badlani1', '~Joao_Felipe_Santos2', '~Evelina_Bakhturina1', '~Mikyas_T._Desta1', '~Rafael_Valle1', '~Sungroh_Yoon1', '~Bryan_Catanzaro1']",
         "1683826945702",
         "P-Flow: A Fast and Data-Efficient Zero-Shot TTS through Speech Prompting",
         "While recent large-scale neural codec language models have shown significant improvement in zero-shot TTS by training on thousands of hours of data, they suffer from drawbacks such as a lack of robustness, slow sampling speed similar to previous autoregressive TTS methods, and reliance on pre-trained neural codec representations. Our work proposes P-Flow, a fast and data-efficient zero-shot TTS model that uses speech prompts for speaker adaptation. P-Flow comprises a speech-prompted text encoder for speaker adaptation and a flow matching generative decoder for high-quality and fast speech synthesis. Our speech-prompted text encoder uses speech prompts and text input to generate speaker-conditional text representation. The flow matching generative decoder uses the speaker-conditional output to synthesize high-quality personalized speech significantly faster than in real-time. Unlike the neural codec language models, we specifically train P-Flow on LibriTTS dataset using a continuous mel-representation. Through our training method using continuous speech prompts, P-Flow matches the speaker similarity performance of the large-scale zero-shot TTS models with two orders of magnitude less training data and has more than 20$\\times$ faster sampling speed. Our results show that P-Flow has better pronunciation and is preferred in human likeness and speaker similarity to its recent state-of-the-art counterparts, thus defining P-Flow as an attractive and desirable alternative. We provide audio samples on our demo page: [https://research.nvidia.com/labs/adlr/projects/pflow](https://research.nvidia.com/labs/adlr/projects/pflow)"
        ],
        [
         "37",
         "8897",
         "zMeemcUeXL",
         "liu|famo_fast_adaptive_multitask_optimization",
         "['~Bo_Liu13', '~Yihao_Feng1', '~Peter_Stone1', '~qiang_liu4']",
         "1683756653507",
         "FAMO: Fast Adaptive Multitask Optimization",
         "One of the grand enduring goals of AI is to create generalist agents that can learn multiple different tasks from diverse data via multitask learning (MTL). However, in practice, applying gradient descent (GD) on the average loss across all tasks may yield poor multitask performance due to severe under-optimization of certain tasks. Previous approaches that manipulate task gradients for a more balanced loss decrease require storing and computing all task gradients ($\\mathcal{O}(k)$ space and time where $k$ is the number of tasks), limiting their use in large-scale scenarios. In this work, we introduce Fast Adaptive Multitask Optimization (FAMO), a dynamic weighting method that decreases task losses in a balanced way using $\\mathcal{O}(1)$ space and time. We conduct an extensive set of experiments covering multi-task supervised and reinforcement learning problems. Our results indicate that FAMO achieves comparable or superior performance to state-of-the-art gradient manipulation techniques while offering significant improvements in space and computational efficiency. Code is available at \\url{https://github.com/Cranial-XIX/FAMO}."
        ],
        [
         "38",
         "12836",
         "zMNUNd9zs1",
         "halvagal|implicit_variance_regularization_in_noncontrastive_ssl",
         "['~Manu_Srinath_Halvagal1', '~Axel_Laborieux1', '~Friedemann_Zenke1']",
         "1683814821296",
         "Implicit variance regularization in non-contrastive SSL",
         "Non-contrastive SSL methods like BYOL and SimSiam rely on asymmetric predictor networks to avoid representational collapse without negative samples. Yet, how predictor networks facilitate stable learning is not fully understood. While previous theoretical analyses assumed Euclidean losses, most practical implementations rely on cosine similarity. To gain further theoretical insight into non-contrastive SSL, we analytically study learning dynamics in conjunction with Euclidean and cosine similarity in the eigenspace of closed-form linear predictor networks. We show that both avoid collapse through implicit variance regularization albeit through different dynamical mechanisms. Moreover, we find that the eigenvalues act as effective learning rate multipliers and propose a family of isotropic loss functions (IsoLoss) that equalize convergence rates across eigenmodes. Empirically, IsoLoss speeds up the initial learning dynamics and increases robustness, thereby allowing us to dispense with the EMA target network typically used with non-contrastive methods. Our analysis sheds light on the variance regularization mechanisms of non-contrastive SSL and lays the theoretical grounds for crafting novel loss functions that shape the learning dynamics of the predictor's spectrum."
        ],
        [
         "39",
         "2943",
         "zKjSmbYFZe",
         "xian|efficient_postprocessing_for_equal_opportunity_in_fair_multiclass_classification",
         "['~Ruicheng_Xian1', '~Han_Zhao1']",
         "1683498350258",
         "Efficient Post-Processing for Equal Opportunity in Fair Multi-Class Classification",
         "Fairness in machine learning is of growing concern as more instances of biased model behavior are documented while their adoption continues to rise.  The majority of studies have focused on binary classification settings, despite the fact that many real-world problems are inherently multi-class.  This paper considers fairness in multi-class classification under the notion of parity of true positive rates—an extension of binary class equalized odds—which ensures equal opportunity to qualified individuals regardless of their demographics.  We focus on algorithm design and provide a post-processing method that derives fair classifiers from pre-trained score functions.  The method is developed by analyzing the representation of the optimal fair classifier, and is efficient in both sample and time complexity, as it is implemented by linear programs on finite samples.  We demonstrate its effectiveness at reducing disparity on benchmark datasets, particularly under large numbers of classes, where existing methods fall short."
        ],
        [
         "40",
         "569",
         "zJMutieTgh",
         "huang|inference_attacks_against_face_recognition_model_without_classification_layers",
         "['~Yuanqing_Huang1', '~Yinggui_Wang1', '~Le_Yang6', '~Rui_Lv2', '~Lei_Wang30', '~Tao_Wei5']",
         "1682341133193",
         "Inference Attacks Against Face Recognition Model without Classification Layers",
         "Face recognition (FR) has been applied to nearly every aspect of daily life, but it is always accompanied by the underlying risk of leaking private information. At present, almost all attack models against FR rely heavily on the presence of a classification layer. However, in practice, the FR model can obtain complex feature embedding of the input via the model backbone, and then compare it with the target for inference, which does not explicitly involve the outputs of the classification layer adopting logit or other losses. In this work, we advocate a novel inference attack composed of two stages for practical FR models without a classification layer. The first stage is the membership inference attack. Specifically, We analyze the distances between the intermediate features and batch normalization (BN) parameters. The results indicate that this distance is a critical metric for membership inference. We thus design a simple but effective attack model that can determine whether a face image is from the training data set or not. The second stage is the model inversion attack, where sensitive private data is reconstructed using a pre-trained generative adversarial network (GAN) guided by the attack model in the first stage. To the best of our knowledge, the proposed attack model is the very first in the literature developed for FR models without a classification layer. We illustrate the application of the proposed attack model in the establishment of privacy-preserving FR techniques."
        ],
        [
         "41",
         "3416",
         "zIEaOZ0saA",
         "brand|new_complexitytheoretic_frontiers_of_tractability_for_neural_network_training",
         "['~Cornelius_Brand1', '~Robert_Ganian1', '~Mathis_Rocton1']",
         "1683548215755",
         "New Complexity-Theoretic Frontiers of Tractability for Neural Network Training",
         "In spite of the fundamental role of neural networks in contemporary machine learning research, our understanding of the computational complexity of optimally training neural networks remains limited even when dealing with the simplest kinds of activation functions. Indeed, while there has been a number of very recent results that establish ever-tighter lower bounds for the problem under linear and ReLU activation functions, little progress has been made towards the identification of novel polynomial-time tractable network architectures. In this article we obtain novel algorithmic upper bounds for training linear- and ReLU-activated neural networks to optimality which push the boundaries of tractability for these problems beyond the previous state of the art."
        ],
        [
         "42",
         "2628",
         "zGdH4tKtOW",
         "shen|optimal_treatment_regimes_for_proximal_causal_learning",
         "['~Tao_Shen6', '~Yifan_Cui1']",
         "1683424852457",
         "Optimal Treatment Regimes for Proximal Causal Learning",
         "A common concern when a policymaker draws causal inferences from and makes decisions based on observational data is that the measured covariates are insufficiently rich to account for all sources of confounding, i.e., the standard no confoundedness assumption fails to hold. The recently proposed proximal causal inference framework shows that proxy variables that abound in real-life scenarios can be leveraged to identify causal effects and therefore facilitate decision-making. Building upon this line of work, we propose a novel optimal individualized treatment regime based on so-called outcome and treatment confounding bridges. We then show that the value function of this new optimal treatment regime is superior to that of existing ones in the literature. Theoretical guarantees, including identification, superiority, excess value bound, and consistency of the estimated regime, are established. Furthermore, we demonstrate the proposed optimal regime via numerical experiments and a real data application."
        ],
        [
         "43",
         "7870",
         "zGRWp7yRqd",
         "beretta|multiswap_kmeans",
         "['~Lorenzo_Beretta1', '~Vincent_Cohen-Addad1', '~Silvio_Lattanzi1', '~Nikos_Parotsidis1']",
         "1683736339659",
         "Multi-Swap k-Means++",
         "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often the practitioners' choice algorithm for optimizing the popular $k$-means clustering objective and is known to give an $O(\\log k)$-approximation in expectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML 2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local-search steps obtained through the $k$-means++ sampling distribution to yield a $c$-approximation to the $k$-means clustering problem, where $c$ is a large absolute constant. Here we generalize and extend their local-search algorithm by considering larger and more sophisticated local-search neighborhoods hence allowing to  swap multiple centers at the same time. Our algorithm achieves a $9 + \\varepsilon$ approximation ratio, which is the best possible for local search. Importantly we show that our algorithm is practical, namely easy to implement and fast enough to run on a variety of classic datasets, and outputs solutions of better cost."
        ],
        [
         "44",
         "14705",
         "zEoP4vzFKy",
         "peychev|automated_classification_of_model_errors_on_imagenet",
         "['~Momchil_Peychev1', '~Mark_Niklas_Mueller2', '~Marc_Fischer1', '~Martin_Vechev1']",
         "1683828576628",
         "Automated Classification of Model Errors on ImageNet",
         "While the ImageNet dataset has been driving computer vision research over the past decade, significant label noise and ambiguity have made top-1 accuracy an insufficient measure of further progress. To address this, new label-sets and evaluation protocols have been proposed for ImageNet showing that state-of-the-art models already achieve over 95% accuracy and shifting the focus on investigating why the remaining errors persist.\n\nRecent work in this direction employed a panel of experts to manually categorize all remaining classification errors for two selected models. However, this process is time-consuming, prone to inconsistencies, and requires trained experts, making it unsuitable for regular model evaluation thus limiting its utility. To overcome these limitations, we propose the first automated error classification framework, a valuable tool to study how modeling choices affect error distributions. We use our framework to comprehensively evaluate the error distribution of over 900 models. Perhaps surprisingly, we find that across model architectures, scales, and pre-training corpora, top-1 accuracy is a strong predictor for the *portion* of all error types. In particular, we observe that the portion of severe errors drops significantly with top-1 accuracy indicating that, while it underreports a model's true performance, it remains a valuable performance metric.\n\nWe release all our code at https://github.com/eth-sri/automated-error-analysis."
        ],
        [
         "45",
         "8945",
         "zEm6hF97Pz",
         "choquettechoo|amplified_banded_matrix_factorization_a_unified_approach_to_private_training",
         "['~Christopher_A._Choquette-Choo1', '~Arun_Ganesh1', '~Ryan_McKenna2', '~Hugh_Brendan_McMahan1', '~J_Keith_Rush1', '~Abhradeep_Guha_Thakurta1', '~Zheng_Xu2']",
         "1683757865397",
         "(Amplified) Banded Matrix Factorization: A unified approach to private training",
         "Matrix factorization (MF) mechanisms for differential privacy (DP) have substantially improved the state-of-the-art in privacy-utility-computation tradeoffs for ML applications in a variety of scenarios, but in both the centralized and federated settings there remain instances where either MF cannot be easily applied, or other algorithms provide better tradeoffs (typically, as $\\epsilon$ becomes small).\nIn this work, we show how MF can subsume prior state-of-the-art algorithms in both federated and centralized training settings, across all privacy budgets. The key technique throughout is the construction of MF mechanisms with banded matrices (lower-triangular matrices with at most $\\hat{b}$ nonzero bands including the main diagonal). For cross-device federated learning (FL), this enables multiple-participations with a relaxed device participation schema compatible with practical FL infrastructure (as demonstrated by a production deployment).  In the centralized setting, we prove that banded matrices enjoy the same privacy amplification results as the ubiquitous DP-SGD algorithm, but can provide strictly better performance  in most scenarios---this lets us always at least match DP-SGD, and often outperform it"
        ],
        [
         "46",
         "10291",
         "zDbsSscmuj",
         "guan|leveraging_pretrained_large_language_models_to_construct_and_utilize_world_models_for_modelbased_task_planning",
         "['~Lin_Guan1', '~Karthik_Valmeekam1', '~Sarath_Sreedharan1', '~Subbarao_Kambhampati1']",
         "1683781343548",
         "Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning",
         "There is a growing interest in applying pre-trained large language models (LLMs) to planning problems. However, methods that use LLMs directly as planners are currently impractical due to several factors, including limited correctness of plans, strong reliance on feedback from interactions with simulators or even the actual environment, and the inefficiency in utilizing human feedback. In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners. To address the fact that LLMs may not generate a fully functional PDDL model initially, we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans. For users who lack a background in PDDL, we show that LLMs can translate PDDL into natural language and effectively encode corrective feedback back to the underlying domain model. Our framework not only enjoys the correctness guarantee offered by the external planners but also reduces human involvement by allowing users to correct domain models at the beginning, rather than inspecting and correcting (through interactive prompting) every generated plan as in previous work. On two IPC domains and a Household domain that is more complicated than commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be leveraged to produce high-quality PDDL models for over 40 actions, and the corrected PDDL models are then used to successfully solve 48 challenging planning tasks. Resources, including the source code, are released at: https://guansuns.github.io/pages/llm-dm."
        ],
        [
         "47",
         "278",
         "zD6lXmTPPh",
         "alfano|a_novel_framework_for_policy_mirror_descent_with_general_parameterization_and_linear_convergence",
         "['~Carlo_Alfano1', '~Rui_Yuan1', '~Patrick_Rebeschini1']",
         "1682032528993",
         "A Novel Framework for Policy Mirror Descent with General Parameterization and Linear Convergence",
         "Modern policy optimization methods in reinforcement learning, such as TRPO and PPO, owe their success to the use of parameterized policies. However, while theoretical guarantees have been established for this class of algorithms, especially in the tabular setting, the use of general parameterization schemes remains mostly unjustified. In this work, we introduce a novel framework for policy optimization based on mirror descent that naturally accommodates general parameterizations. The policy class induced by our scheme recovers known classes, e.g., softmax, and generates new ones depending on the choice of mirror map. Using our framework, we obtain the first result that guarantees linear convergence for a policy-gradient-based method involving general parameterization. To demonstrate the ability of our framework to accommodate general parameterization schemes, we provide its sample complexity when using shallow neural networks, show that it represents an improvement upon the previous best results, and empirically validate the effectiveness of our theoretical claims on classic control tasks."
        ],
        [
         "48",
         "5206",
         "zCFfv49MjE",
         "reid|quasimonte_carlo_graph_random_features",
         "['~Isaac_Reid3', '~Krzysztof_Marcin_Choromanski1', '~Adrian_Weller1']",
         "1683659388911",
         "Quasi-Monte Carlo Graph Random Features",
         "We present a novel mechanism to improve the accuracy of the recently-introduced class of graph random features (GRFs). Our method induces negative correlations between the lengths of the algorithm's random walks by imposing antithetic termination: a procedure to sample more diverse random walks which may be of independent interest. It has a trivial drop-in implementation. We derive strong theoretical guarantees on the properties of these quasi-Monte Carlo GRFs (q-GRFs), proving that they yield lower-variance estimators of the $2$-regularised Laplacian kernel under mild conditions. Remarkably, our results hold for any graph topology. We demonstrate empirical accuracy improvements on a variety of tasks including a new practical application: time-efficient approximation of the graph diffusion process. To our knowledge, q-GRFs constitute the first rigorously studied quasi-Monte Carlo scheme for kernels defined on combinatorial objects, inviting new research on correlations between graph random walks."
        ],
        [
         "49",
         "6594",
         "zAXg8dW8ZO",
         "tran|onelineofcode_data_mollification_improves_optimization_of_likelihoodbased_generative_models",
         "['~Ba-Hien_Tran2', '~Giulio_Franzese1', '~Pietro_Michiardi1', '~Maurizio_Filippone1']",
         "1683712170474",
         "One-Line-of-Code Data Mollification Improves Optimization of Likelihood-based Generative Models",
         "Generative Models (GMs) have attracted considerable attention due to their tremendous success in various domains, such as computer vision where they are capable to generate impressive realistic-looking images. Likelihood-based GMs are attractive due to the possibility to generate new data by a single model evaluation. However, they typically achieve lower sample quality compared to state-of-the-art score-based Diffusion Models (DMs). This paper provides a significant step in the direction of addressing this limitation. The idea is to borrow one of the strengths of score-based DMs, which is the ability to perform accurate density estimation in low-density regions and to address manifold overfitting by means of data mollification. We propose a view of data mollification within likelihood-based GMs as a continuation method, whereby the optimization objective smoothly transitions from simple-to-optimize to the original target. Crucially, data mollification can be implemented by adding one line of code in the optimization loop, and we demonstrate that this provides a boost in generation quality of likelihood-based GMs, without computational overheads. We report results on real-world image data sets and UCI benchmarks with popular likelihood-based GMs, including variants of variational autoencoders and normalizing flows, showing large improvements in FID score and density estimation."
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3395
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>id</th>\n",
       "      <th>content.paperhash</th>\n",
       "      <th>content.authorids</th>\n",
       "      <th>cdate</th>\n",
       "      <th>content.title</th>\n",
       "      <th>content.abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10819</td>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>sun|what_is_flagged_in_uncertainty_quantificat...</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15594</td>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>puli|dont_blame_dataset_shift_shortcut_learnin...</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>327</td>\n",
       "      <td>zuXyQsXVLF</td>\n",
       "      <td>xu|enhancing_adversarial_contrastive_learning_...</td>\n",
       "      <td>[~Xilie_Xu1, ~Jingfeng_Zhang1, ~Feng_Liu2, ~Ma...</td>\n",
       "      <td>1682066194522</td>\n",
       "      <td>Enhancing Adversarial Contrastive Learning via...</td>\n",
       "      <td>Adversarial contrastive learning (ACL) is a te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801</td>\n",
       "      <td>ztqf6bzuqQ</td>\n",
       "      <td>shi|hybrid_distillation_connecting_masked_auto...</td>\n",
       "      <td>[~Bowen_Shi2, ~XIAOPENG_ZHANG7, ~Yaoming_Wang1...</td>\n",
       "      <td>1682507396411</td>\n",
       "      <td>Hybrid Distillation: Connecting Masked Autoenc...</td>\n",
       "      <td>Representation learning has been evolving from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7411</td>\n",
       "      <td>ztDxO15N7f</td>\n",
       "      <td>scholkemper|an_optimizationbased_approach_to_n...</td>\n",
       "      <td>[~Michael_Scholkemper1, ~Michael_T_Schaub1]</td>\n",
       "      <td>1683729208530</td>\n",
       "      <td>An Optimization-based Approach To Node Role Di...</td>\n",
       "      <td>Similar to community detection, partitioning t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>12557</td>\n",
       "      <td>05P1U0jk8r</td>\n",
       "      <td>sakos|exploiting_hidden_structures_in_nonconve...</td>\n",
       "      <td>[~Iosif_Sakos1, ~Emmanouil-Vasileios_Vlatakis-...</td>\n",
       "      <td>1683812282551</td>\n",
       "      <td>Exploiting hidden structures in non-convex gam...</td>\n",
       "      <td>A wide array of modern machine learning applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>12654</td>\n",
       "      <td>02Uc0G2Cym</td>\n",
       "      <td>mianjy|robustness_guarantees_for_adversarially...</td>\n",
       "      <td>[~Poorya_Mianjy1, ~Raman_Arora1]</td>\n",
       "      <td>1683813240757</td>\n",
       "      <td>Robustness Guarantees for Adversarially Traine...</td>\n",
       "      <td>We study robust adversarial training of two-la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>1581</td>\n",
       "      <td>01GQK1gwe3</td>\n",
       "      <td>holl|can_neural_networks_improve_classical_opt...</td>\n",
       "      <td>[~Philipp_Holl1, ~Nils_Thuerey1]</td>\n",
       "      <td>1683105912880</td>\n",
       "      <td>Can Neural Networks Improve Classical Optimiza...</td>\n",
       "      <td>Finding the values of model parameters from da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>6838</td>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>hu|complexity_matters_rethinking_the_latent_sp...</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3394</th>\n",
       "      <td>10107</td>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>ghadiri|finite_population_regression_adjustmen...</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3395 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number          id                                  content.paperhash  \\\n",
       "0      10819  zyhxRc9bew  sun|what_is_flagged_in_uncertainty_quantificat...   \n",
       "1      15594  zyZkaqNnpa  puli|dont_blame_dataset_shift_shortcut_learnin...   \n",
       "2        327  zuXyQsXVLF  xu|enhancing_adversarial_contrastive_learning_...   \n",
       "3        801  ztqf6bzuqQ  shi|hybrid_distillation_connecting_masked_auto...   \n",
       "4       7411  ztDxO15N7f  scholkemper|an_optimizationbased_approach_to_n...   \n",
       "...      ...         ...                                                ...   \n",
       "3390   12557  05P1U0jk8r  sakos|exploiting_hidden_structures_in_nonconve...   \n",
       "3391   12654  02Uc0G2Cym  mianjy|robustness_guarantees_for_adversarially...   \n",
       "3392    1581  01GQK1gwe3  holl|can_neural_networks_improve_classical_opt...   \n",
       "3393    6838  00EKYYu3fD  hu|complexity_matters_rethinking_the_latent_sp...   \n",
       "3394   10107  009LK0vLcY  ghadiri|finite_population_regression_adjustmen...   \n",
       "\n",
       "                                      content.authorids          cdate  \\\n",
       "0     [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...  1683789038840   \n",
       "1     [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...  1683835167534   \n",
       "2     [~Xilie_Xu1, ~Jingfeng_Zhang1, ~Feng_Liu2, ~Ma...  1682066194522   \n",
       "3     [~Bowen_Shi2, ~XIAOPENG_ZHANG7, ~Yaoming_Wang1...  1682507396411   \n",
       "4           [~Michael_Scholkemper1, ~Michael_T_Schaub1]  1683729208530   \n",
       "...                                                 ...            ...   \n",
       "3390  [~Iosif_Sakos1, ~Emmanouil-Vasileios_Vlatakis-...  1683812282551   \n",
       "3391                   [~Poorya_Mianjy1, ~Raman_Arora1]  1683813240757   \n",
       "3392                   [~Philipp_Holl1, ~Nils_Thuerey1]  1683105912880   \n",
       "3393  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...  1683719044332   \n",
       "3394  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...  1683778565991   \n",
       "\n",
       "                                          content.title  \\\n",
       "0     What is Flagged in Uncertainty Quantification?...   \n",
       "1     Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "2     Enhancing Adversarial Contrastive Learning via...   \n",
       "3     Hybrid Distillation: Connecting Masked Autoenc...   \n",
       "4     An Optimization-based Approach To Node Role Di...   \n",
       "...                                                 ...   \n",
       "3390  Exploiting hidden structures in non-convex gam...   \n",
       "3391  Robustness Guarantees for Adversarially Traine...   \n",
       "3392  Can Neural Networks Improve Classical Optimiza...   \n",
       "3393  Complexity Matters: Rethinking the Latent Spac...   \n",
       "3394  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                       content.abstract  \n",
       "0     Uncertainty quantification (UQ) is essential f...  \n",
       "1     Common explanations for shortcut learning assu...  \n",
       "2     Adversarial contrastive learning (ACL) is a te...  \n",
       "3     Representation learning has been evolving from...  \n",
       "4     Similar to community detection, partitioning t...  \n",
       "...                                                 ...  \n",
       "3390  A wide array of modern machine learning applic...  \n",
       "3391  We study robust adversarial training of two-la...  \n",
       "3392  Finding the values of model parameters from da...  \n",
       "3393  In generative modeling, numerous successful ap...  \n",
       "3394  The design and analysis of randomized experime...  \n",
       "\n",
       "[3395 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file as a pandas DataFrame\n",
    "df_json = pd.read_json('/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v0.json')\n",
    "\n",
    "# Display the header of the first 5 samples\n",
    "df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the dataframe: (3395, 7)\n",
      "Number of NaN values in each column:\n",
      "number               0\n",
      "id                   0\n",
      "content.paperhash    0\n",
      "content.authorids    0\n",
      "cdate                0\n",
      "content.title        0\n",
      "content.abstract     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of the dataframe\n",
    "print(f\"Dimensions of the dataframe: {df.shape}\")\n",
    "\n",
    "# Count the number of NaN values in each column\n",
    "print(\"Number of NaN values in each column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 4\n",
      "max: 14\n",
      "mean: 6.455670103092784\n",
      "median: 6.0\n",
      "std: 0.905242195033333\n",
      "percentiles: [6. 6. 7. 8. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "# number of review, comments, and meta-reviews for each submission\n",
    "# 3395 is the number of submissions\n",
    "num_of_reviews = [len(data[i].details['directReplies']) for i in range(3395)]\n",
    "print('min:', min(num_of_reviews))\n",
    "print('max:', max(num_of_reviews))\n",
    "print('mean:', np.mean(num_of_reviews))\n",
    "print('median:', np.median(num_of_reviews))\n",
    "print('std:', np.std(num_of_reviews))\n",
    "print('percentiles:', np.percentile(num_of_reviews, [25, 50, 75, 90, 95, 99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Author_Rebuttal', 'Decision', 'Official_Comment', 'Official_Review'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_types = set()\n",
    "for i in range(3395):\n",
    "    for j in range(len(data[i].details['directReplies'])):\n",
    "        comment_types.add(data[i].details['directReplies'][j]['invitations'][0].split('/')[-1])\n",
    "\n",
    "comment_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with reviews saved to JSON file at: /home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v1.json\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each submission in the data\n",
    "new_rows = []\n",
    "for submission in data:\n",
    "    submission_id = submission.id\n",
    "    submission_number = submission.number\n",
    "    submission_title = submission.content['title']['value'] if 'title' in submission.content and 'value' in submission.content['title'] else None\n",
    "    submission_abstract = submission.content['abstract']['value'] if 'abstract' in submission.content and 'value' in submission.content['abstract'] else None\n",
    "    submission_authors = submission.content['authorids']['value'] if 'authorids' in submission.content and 'value' in submission.content['authorids'] else np.nan\n",
    "    submission_creation_date = submission.cdate if hasattr(submission, 'cdate') else np.nan\n",
    "\n",
    "    # Check if 'directReplies' exists in details\n",
    "    if 'directReplies' in submission.details:\n",
    "        for reply in submission.details['directReplies']:\n",
    "            # Check if the invitation is 'Official_Review'\n",
    "            if reply['invitations'][0].split('/')[-1] == 'Official_Review':\n",
    "                # Extract features from the review\n",
    "                reviewer = reply['signatures'][0].split('/')[-1]  # if 'signatures' in reply and len(reply['signatures']) > 0 else None\n",
    "                \n",
    "                #'tcdate', 'cdate', 'tmdate', 'mdate'\n",
    "                review_tcdate = reply['tcdate'] if 'tcdate' in reply else None\n",
    "                review_cdate = reply['cdate'] if 'cdate' in reply else None\n",
    "                review_tmdate = reply['tmdate'] if 'tmdate' in reply else None\n",
    "                review_mdate = reply['mdate'] if 'mdate' in reply else None\n",
    "                \n",
    "                review_rating = int(reply['content']['rating']['value'].split(':')[0]) if 'rating' in reply['content'] and 'value' in reply['content']['rating'] else None\n",
    "                review_confidence = int(reply['content']['confidence']['value'].split(':')[0]) if 'confidence' in reply['content'] and 'value' in reply['content']['confidence'] else None\n",
    "                review_soundness = int(reply['content']['soundness']['value'].split(' ')[0]) if 'soundness' in reply['content'] and 'value' in reply['content']['soundness'] else None\n",
    "                review_presentation = int(reply['content']['presentation']['value'].split(' ')[0]) if 'presentation' in reply['content'] and 'value' in reply['content']['presentation'] else None\n",
    "                review_contribution = int(reply['content']['contribution']['value'].split(' ')[0]) if 'contribution' in reply['content'] and 'value' in reply['content']['contribution'] else None\n",
    "                \n",
    "                review_summary = reply['content']['summary']['value'] if 'summary' in reply['content'] and 'value' in reply['content']['summary'] else None\n",
    "                review_strengths = reply['content']['strengths']['value'] if 'strengths' in reply['content'] and 'value' in reply['content']['strengths'] else None\n",
    "                review_weaknesses = reply['content']['weaknesses']['value'] if 'weaknesses' in reply['content'] and 'value' in reply['content']['weaknesses'] else None\n",
    "                review_questions = reply['content']['questions']['value'] if 'questions' in reply['content'] and 'value' in reply['content']['questions'] else None\n",
    "                review_limitations = reply['content']['limitations']['value'] if 'limitations' in reply['content'] and 'value' in reply['content']['limitations'] else None\n",
    "                \n",
    "                # Create a new row with the extracted features\n",
    "                new_row = {\n",
    "                    'submission_id': submission_id,\n",
    "                    'submission_number': submission_number,\n",
    "                    'submission_creation_date': submission_creation_date,\n",
    "                    'submission_authors': submission_authors,\n",
    "                    \n",
    "                    'submission_title': submission_title,\n",
    "                    'submission_abstract': submission_abstract,\n",
    "                    \n",
    "                    'reviewer': reviewer,\n",
    "                    'review_tcdate': review_tcdate,\n",
    "                    'review_cdate': review_cdate,\n",
    "                    'review_tmdate': review_tmdate,\n",
    "                    'review_mdate': review_mdate,\n",
    "                    \n",
    "                    'review_summary': review_summary,\n",
    "                    'review_strengths': review_strengths,\n",
    "                    'review_weaknesses': review_weaknesses,\n",
    "                    'review_questions': review_questions,\n",
    "                    'review_limitations': review_limitations,\n",
    "                    \n",
    "                    'review_rating': review_rating,\n",
    "                    'review_confidence': review_confidence,\n",
    "                    'review_soundness': review_soundness,\n",
    "                    'review_presentation': review_presentation,\n",
    "                    'review_contribution': review_contribution\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "\n",
    "# Create a new DataFrame from the new rows\n",
    "df_reviews = pd.DataFrame(new_rows)\n",
    "\n",
    "# Save the updated DataFrame to a JSON file\n",
    "output_json_path = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v1.json'\n",
    "df_reviews.to_json(output_json_path, orient='records', indent=4)\n",
    "\n",
    "print(f\"Updated DataFrame with reviews saved to JSON file at: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_strengths",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_weaknesses",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_questions",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_limitations",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4e0f5b89-dc00-4555-a200-c8ac1634ab37",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes.",
         "1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n",
         "1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n",
         "1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n",
         "Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "6",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure. ",
         "In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow.",
         "See questions.",
         "* In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n",
         "Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "6",
         "4",
         "3",
         "3",
         "4"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models.",
         "The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful.",
         "I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\".",
         "1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term?",
         "Yes.",
         "6",
         "4",
         "3",
         "3",
         "2"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models.",
         "To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses)",
         "There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n",
         "- Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n",
         "Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "6",
         "4",
         "2",
         "3",
         "3"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions.",
         "This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning.",
         "The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n",
         "The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "6",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method.",
         "-This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand.",
         "-Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not.",
         "-How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective?",
         "Please see the weaknesses part.",
         "5",
         "3",
         "4",
         "4",
         "4"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets.",
         "* The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements",
         "* I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm.",
         "* The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one?",
         "Not explicitly discussed",
         "6",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks.",
         "* Experiments show good results for their methods.",
         "* The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots.",
         "* How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick?",
         "The authors adequately addressed the limitations.",
         "6",
         "3",
         "3",
         "2",
         "3"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness. ",
         "The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term.",
         "The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8.",
         "See \"Weaknesses\" part.",
         "N.A.",
         "8",
         "4",
         "3",
         "3",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released.",
         "1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n",
         "1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet.",
         "Shown as Weaknesses.",
         "Shown as Weaknesses.",
         "6",
         "4",
         "3",
         "3",
         "3"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines.",
         "1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n",
         "I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n",
         "1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n",
         "The authors have discussed the limitations.",
         "6",
         "4",
         "3",
         "3",
         "3"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100.",
         "- Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations.",
         "- The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021",
         "- It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES).",
         "- There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "4",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach.",
         "The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models.",
         "1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022.",
         "See weakness.",
         "The authors have included discussion on the limited gain over Distill-CLIP.",
         "4",
         "4",
         "3",
         "2",
         "3"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes.",
         "The findings on the relationship between diversity and architecture are interesting",
         "1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners",
         "See above",
         "None",
         "5",
         "5",
         "1",
         "1",
         "2"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties.",
         "* Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written",
         "* When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n",
         "* How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n",
         "* Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "4",
         "3",
         "2",
         "2",
         "2"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n",
         "- The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant.",
         "- The paper has some minor typo errors.\n",
         "1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)?",
         "- Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "5",
         "5",
         "3",
         "3",
         "2"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy.",
         "The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive.",
         "- Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method.",
         "-",
         "-",
         "6",
         "5",
         "4",
         "3",
         "3"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner.",
         "(+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks. ",
         "(-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022.",
         "(-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n",
         "The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "5",
         "3",
         "3",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks.",
         "- The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method.",
         "- Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper.",
         "Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n",
         "No potential negative societal impact.",
         "5",
         "3",
         "2",
         "3",
         "3"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs.",
         "* The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative.",
         "* Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method.",
         "* Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$?",
         "Limitations are sufficiently discussed.",
         "6",
         "4",
         "3",
         "3",
         "2"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model. ",
         "The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery.",
         "The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.  ",
         "1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6).",
         "Yes.",
         "6",
         "3",
         "3",
         "4",
         "3"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n",
         "I think this paper is theoretically sound. ",
         "1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available?",
         "1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes.",
         "1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "7",
         "1",
         "3",
         "2",
         "3"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases. ",
         "The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail. ",
         "My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).  ",
         "How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)? ",
         "Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "4",
         "2",
         "3",
         "2",
         "2"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community.",
         "This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process.",
         "This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24].",
         "Why is this article relevant to the machine learning community?",
         "This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "4",
         "1",
         "3",
         "2",
         "2"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data.",
         "- The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution.",
         "- The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear.",
         "What are the situations where the derived conditions for identifying linear SDEs so useful in practice?",
         "N/A",
         "5",
         "2",
         "2",
         "3",
         "2"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations.",
         "In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial. ",
         "It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community.",
         "- l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined?",
         "Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "4",
         "3",
         "2",
         "3",
         "3"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results.",
         "The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely.",
         "The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper.",
         "You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4.",
         "The authors discuss the limitations of their work. ",
         "7",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n",
         "1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution.",
         "1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting.",
         "1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness. ",
         "See Weaknesses.",
         "7",
         "3",
         "4",
         "4",
         "4"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting.",
         "1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting.",
         "1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table.",
         "1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?",
         "N/A",
         "6",
         "3",
         "3",
         "3",
         "2"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art.",
         "Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods.",
         "I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n",
         "1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n",
         "No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "6",
         "2",
         "3",
         "3",
         "3"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy. ",
         "* Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof.",
         "* The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n",
         "* For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1?",
         "The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "5",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms. ",
         "The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported. ",
         "The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n",
         "Please see the weaknesses above.",
         "N/A",
         "3",
         "3",
         "2",
         "1",
         "2"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n",
         "* This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n",
         "a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n",
         "Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors.",
         "Limitations are discussed in the paper.",
         "5",
         "3",
         "2",
         "3",
         "3"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art.",
         "1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material.",
         "1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section.",
         "1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.",
         "In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "6",
         "3",
         "3",
         "3",
         "2"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions. ",
         "1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced.",
         "1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class.",
         "1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced. ",
         "The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "5",
         "4",
         "2",
         "2",
         "2"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. ",
         "1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow.",
         "The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value. ",
         "Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing?",
         "The authors addressed the limitations. ",
         "5",
         "3",
         "3",
         "2",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges.",
         "+ Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow.",
         "- The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs.",
         "Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs? ",
         "The reviewer does not see potential negative social impact of the work.",
         "4",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score. ",
         "- The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n",
         "- **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu.",
         "- The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios?",
         "The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "6",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism.",
         "Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n",
         "No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently. ",
         "1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n",
         "N/A",
         "7",
         "4",
         "3",
         "3",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective.",
         "1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n",
         "1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n",
         "It would be beneficial to answer the questions in weakness.",
         "N/A",
         "7",
         "5",
         "3",
         "3",
         "4"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence.",
         "- The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors.",
         "- The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability.",
         "- In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022.",
         "The authors have discussed the limitation and potential negative societal impact.",
         "7",
         "5",
         "4",
         "3",
         "4"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated.",
         "The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n",
         "The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating.",
         "I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n",
         "The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "6",
         "3",
         "3",
         "3",
         "3"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries.",
         "1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n",
         "1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n",
         "\n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket.",
         "The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "7",
         "4",
         "4",
         "4",
         "3"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings.",
         "1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided.",
         "1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.  ",
         "1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved.",
         "- ",
         "6",
         "5",
         "3",
         "3",
         "2"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs.",
         "**Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators.",
         "- Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020.",
         "- I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results?",
         "The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "6",
         "4",
         "3",
         "4",
         "3"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n",
         "1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n",
         "1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n",
         "Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]).",
         "yes",
         "4",
         "4",
         "2",
         "2",
         "2"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model.",
         "- Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n",
         "- Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n",
         "Refer to the weaknesses mentioned above.",
         "Refer to the weaknesses mentioned above.",
         "6",
         "5",
         "3",
         "3",
         "2"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label.",
         "- This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read.",
         "- Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022.",
         "- Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n",
         "The authors have discussed the limitations.",
         "4",
         "4",
         "3",
         "3",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model. ",
         "1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method. ",
         "1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021.",
         "Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022",
         "After the part of conclusion, the authors discussed the limitation of this work. ",
         "3",
         "4",
         "2",
         "3",
         "2"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n",
         "The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n",
         "\n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n",
         "*  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n",
         "* Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "5",
         "3",
         "3",
         "2",
         "2"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>...</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_strengths</th>\n",
       "      <th>review_weaknesses</th>\n",
       "      <th>review_questions</th>\n",
       "      <th>review_limitations</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>1. This paper focuses on samples that remain s...</td>\n",
       "      <td>1. Why are the uncertain samples of the model ...</td>\n",
       "      <td>1. Checking some details in the paper, such as...</td>\n",
       "      <td>Is DAUC a model-agnostic approach that can be ...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>...</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>In my opinion, this categorization process of ...</td>\n",
       "      <td>See questions.</td>\n",
       "      <td>* In my opinion, at a high level, this method ...</td>\n",
       "      <td>Yes, the limitations have been listed by the a...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>...</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>The paper is very well written overall, I enjo...</td>\n",
       "      <td>I find it quite difficult to judge the technic...</td>\n",
       "      <td>1. Can the proposed method be applied to datas...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>...</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>To my knowledge, paper presents a novel approa...</td>\n",
       "      <td>There are some weaknesses that could further i...</td>\n",
       "      <td>- Table 1: Could you ellaborate why other rela...</td>\n",
       "      <td>Some of the assumptions and limitations of pro...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>This paper analyzes shortcut learning theoreti...</td>\n",
       "      <td>The theory itself has limited applicability du...</td>\n",
       "      <td>It seems that this paper forcus on a theoretic...</td>\n",
       "      <td>The theory itself has limited applicability du...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>The strengths of this paper are :\\n- It is a s...</td>\n",
       "      <td>The main weakness is that most of the paper is...</td>\n",
       "      <td>l.146 the link between the ideal $P_z$ and a l...</td>\n",
       "      <td>The conclusion is a list of limitations that i...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>...</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>The main strength of this paper is a finite sa...</td>\n",
       "      <td>The paper has a few minor issues, but I believ...</td>\n",
       "      <td>- Can you address my comment on conditional ve...</td>\n",
       "      <td>yes</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>- The main strength of the paper is that it pr...</td>\n",
       "      <td>- To my reading of the paper, the most importa...</td>\n",
       "      <td>- Is there any chance to obtain lower bounds f...</td>\n",
       "      <td>One important limitation that is not mentioned...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>The paper demonstrates several strengths that ...</td>\n",
       "      <td>While  the paper demonstrates strengths, there...</td>\n",
       "      <td>1.  I would like to request the authors to add...</td>\n",
       "      <td>It would be valuable for the authors to provid...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>...</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>To the best of my knowledge, using leverage sc...</td>\n",
       "      <td>The idea of the paper is overall good, but the...</td>\n",
       "      <td>* How is the random vector in Key Challenge 2 ...</td>\n",
       "      <td>I was unable to find a discussion by the autho...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate  ...  \\\n",
       "0      1688368213177  1688368213177  1702411303415  ...   \n",
       "1      1688505633161  1688505633161  1702411303319  ...   \n",
       "2      1688552936677  1688552936677  1702411303221  ...   \n",
       "3      1688657604892  1688657604892  1702411303144  ...   \n",
       "4      1688617232745  1688617232745  1702411520565  ...   \n",
       "...              ...            ...            ...  ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  ...   \n",
       "15171  1688449656890  1688449656890  1702411268900  ...   \n",
       "15172  1688485585833  1688485585833  1702411268818  ...   \n",
       "15173  1688665406904  1688665406904  1702411268706  ...   \n",
       "15174  1688755793651  1688755793651  1702411268608  ...   \n",
       "\n",
       "                                          review_summary  \\\n",
       "0      This paper proposes a model-agnostic framework...   \n",
       "1      In this paper, the authors present a unique ap...   \n",
       "2      I have read the other reviews and all rebuttal...   \n",
       "3      Paper introduces a framework to detect and cat...   \n",
       "4      This paper theoretecally and empirically showe...   \n",
       "...                                                  ...   \n",
       "15170  This paper proposes an asymmetric training sch...   \n",
       "15171  In this paper, authors present regression adju...   \n",
       "15172  This paper focuses on estimation of individual...   \n",
       "15173  This paper explores the design and analysis of...   \n",
       "15174  The paper addresses the problem of ATE and ITE...   \n",
       "\n",
       "                                        review_strengths  \\\n",
       "0      1. This paper focuses on samples that remain s...   \n",
       "1      In my opinion, this categorization process of ...   \n",
       "2      The paper is very well written overall, I enjo...   \n",
       "3      To my knowledge, paper presents a novel approa...   \n",
       "4      This paper analyzes shortcut learning theoreti...   \n",
       "...                                                  ...   \n",
       "15170  The strengths of this paper are :\\n- It is a s...   \n",
       "15171  The main strength of this paper is a finite sa...   \n",
       "15172  - The main strength of the paper is that it pr...   \n",
       "15173  The paper demonstrates several strengths that ...   \n",
       "15174  To the best of my knowledge, using leverage sc...   \n",
       "\n",
       "                                       review_weaknesses  \\\n",
       "0      1. Why are the uncertain samples of the model ...   \n",
       "1                                         See questions.   \n",
       "2      I find it quite difficult to judge the technic...   \n",
       "3      There are some weaknesses that could further i...   \n",
       "4      The theory itself has limited applicability du...   \n",
       "...                                                  ...   \n",
       "15170  The main weakness is that most of the paper is...   \n",
       "15171  The paper has a few minor issues, but I believ...   \n",
       "15172  - To my reading of the paper, the most importa...   \n",
       "15173  While  the paper demonstrates strengths, there...   \n",
       "15174  The idea of the paper is overall good, but the...   \n",
       "\n",
       "                                        review_questions  \\\n",
       "0      1. Checking some details in the paper, such as...   \n",
       "1      * In my opinion, at a high level, this method ...   \n",
       "2      1. Can the proposed method be applied to datas...   \n",
       "3      - Table 1: Could you ellaborate why other rela...   \n",
       "4      It seems that this paper forcus on a theoretic...   \n",
       "...                                                  ...   \n",
       "15170  l.146 the link between the ideal $P_z$ and a l...   \n",
       "15171  - Can you address my comment on conditional ve...   \n",
       "15172  - Is there any chance to obtain lower bounds f...   \n",
       "15173  1.  I would like to request the authors to add...   \n",
       "15174  * How is the random vector in Key Challenge 2 ...   \n",
       "\n",
       "                                      review_limitations review_rating  \\\n",
       "0      Is DAUC a model-agnostic approach that can be ...             6   \n",
       "1      Yes, the limitations have been listed by the a...             6   \n",
       "2                                                   Yes.             6   \n",
       "3      Some of the assumptions and limitations of pro...             6   \n",
       "4      The theory itself has limited applicability du...             6   \n",
       "...                                                  ...           ...   \n",
       "15170  The conclusion is a list of limitations that i...             6   \n",
       "15171                                                yes             7   \n",
       "15172  One important limitation that is not mentioned...             5   \n",
       "15173  It would be valuable for the authors to provid...             4   \n",
       "15174  I was unable to find a discussion by the autho...             4   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      3                 3                    3   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 3                    3   \n",
       "3                      4                 2                    3   \n",
       "4                      3                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "15170                  4                 3                    3   \n",
       "15171                  5                 3                    3   \n",
       "15172                  3                 2                    2   \n",
       "15173                  3                 2                    1   \n",
       "15174                  3                 3                    2   \n",
       "\n",
       "       review_contribution  \n",
       "0                        3  \n",
       "1                        4  \n",
       "2                        2  \n",
       "3                        3  \n",
       "4                        3  \n",
       "...                    ...  \n",
       "15170                    3  \n",
       "15171                    3  \n",
       "15172                    2  \n",
       "15173                    3  \n",
       "15174                    2  \n",
       "\n",
       "[15175 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file as a pandas DataFrame\n",
    "df_reviews = pd.read_json('/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v1.json')\n",
    "\n",
    "# Display the header of the first 5 samples\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame with 'total_review' column saved to JSON file at: /home/ali/Review_Quality_Benchmark/data/processed/openreview_ICLR2024_total_review.json\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the specified columns into a single column named 'total_review'\n",
    "df_reviews['total_review'] = df_reviews[['review_summary', 'review_strengths', 'review_weaknesses', 'review_questions', 'review_limitations']].apply(\n",
    "    lambda row: ' '.join(row.dropna()), axis=1\n",
    ")\n",
    "\n",
    "# Drop the original columns to reduce redundancy\n",
    "df_reviews = df_reviews.drop(columns=['review_summary', 'review_strengths', 'review_weaknesses', 'review_questions', 'review_limitations'])\n",
    "# Create a new column 'length_words' to count the number of words in the 'total_review' column\n",
    "df_reviews['length_words'] = df_reviews['total_review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "# Save the new DataFrame to a different JSON file\n",
    "new_output_json_path = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_ICLR2024_total_review.json'\n",
    "df_reviews.to_json(new_output_json_path, orient='records', indent=4)\n",
    "\n",
    "print(f\"New DataFrame with 'total_review' column saved to JSON file at: {new_output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dc4701bd-a01e-4e00-92a9-ddadc4d3482c",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>review_mdate</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate   review_mdate  \\\n",
       "0      1688368213177  1688368213177  1702411303415  1702411303415   \n",
       "1      1688505633161  1688505633161  1702411303319  1702411303319   \n",
       "2      1688552936677  1688552936677  1702411303221  1702411303221   \n",
       "3      1688657604892  1688657604892  1702411303144  1702411303144   \n",
       "4      1688617232745  1688617232745  1702411520565  1702411520565   \n",
       "...              ...            ...            ...            ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  1702411081106   \n",
       "15171  1688449656890  1688449656890  1702411268900  1702411268900   \n",
       "15172  1688485585833  1688485585833  1702411268818  1702411268818   \n",
       "15173  1688665406904  1688665406904  1702411268706  1702411268706   \n",
       "15174  1688755793651  1688755793651  1702411268608  1702411268608   \n",
       "\n",
       "       review_rating  review_confidence  review_soundness  \\\n",
       "0                  6                  3                 3   \n",
       "1                  6                  4                 3   \n",
       "2                  6                  4                 3   \n",
       "3                  6                  4                 2   \n",
       "4                  6                  3                 3   \n",
       "...              ...                ...               ...   \n",
       "15170              6                  4                 3   \n",
       "15171              7                  5                 3   \n",
       "15172              5                  3                 2   \n",
       "15173              4                  3                 2   \n",
       "15174              4                  3                 3   \n",
       "\n",
       "       review_presentation  review_contribution  \\\n",
       "0                        3                    3   \n",
       "1                        3                    4   \n",
       "2                        3                    2   \n",
       "3                        3                    3   \n",
       "4                        3                    3   \n",
       "...                    ...                  ...   \n",
       "15170                    3                    3   \n",
       "15171                    3                    3   \n",
       "15172                    2                    2   \n",
       "15173                    1                    3   \n",
       "15174                    2                    2   \n",
       "\n",
       "                                            total_review  length_words  \n",
       "0      This paper proposes a model-agnostic framework...           225  \n",
       "1      In this paper, the authors present a unique ap...           513  \n",
       "2      I have read the other reviews and all rebuttal...           650  \n",
       "3      Paper introduces a framework to detect and cat...           453  \n",
       "4      This paper theoretecally and empirically showe...           307  \n",
       "...                                                  ...           ...  \n",
       "15170  This paper proposes an asymmetric training sch...           574  \n",
       "15171  In this paper, authors present regression adju...          1063  \n",
       "15172  This paper focuses on estimation of individual...           519  \n",
       "15173  This paper explores the design and analysis of...          1546  \n",
       "15174  The paper addresses the problem of ATE and ITE...           358  \n",
       "\n",
       "[15175 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2e1a90c0-8134-47f0-b914-cfe20fab4bb4",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>review_mdate</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate   review_mdate  \\\n",
       "0      1688368213177  1688368213177  1702411303415  1702411303415   \n",
       "1      1688505633161  1688505633161  1702411303319  1702411303319   \n",
       "2      1688552936677  1688552936677  1702411303221  1702411303221   \n",
       "3      1688657604892  1688657604892  1702411303144  1702411303144   \n",
       "4      1688617232745  1688617232745  1702411520565  1702411520565   \n",
       "...              ...            ...            ...            ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  1702411081106   \n",
       "15171  1688449656890  1688449656890  1702411268900  1702411268900   \n",
       "15172  1688485585833  1688485585833  1702411268818  1702411268818   \n",
       "15173  1688665406904  1688665406904  1702411268706  1702411268706   \n",
       "15174  1688755793651  1688755793651  1702411268608  1702411268608   \n",
       "\n",
       "       review_rating  review_confidence  review_soundness  \\\n",
       "0                  6                  3                 3   \n",
       "1                  6                  4                 3   \n",
       "2                  6                  4                 3   \n",
       "3                  6                  4                 2   \n",
       "4                  6                  3                 3   \n",
       "...              ...                ...               ...   \n",
       "15170              6                  4                 3   \n",
       "15171              7                  5                 3   \n",
       "15172              5                  3                 2   \n",
       "15173              4                  3                 2   \n",
       "15174              4                  3                 3   \n",
       "\n",
       "       review_presentation  review_contribution  \\\n",
       "0                        3                    3   \n",
       "1                        3                    4   \n",
       "2                        3                    2   \n",
       "3                        3                    3   \n",
       "4                        3                    3   \n",
       "...                    ...                  ...   \n",
       "15170                    3                    3   \n",
       "15171                    3                    3   \n",
       "15172                    2                    2   \n",
       "15173                    1                    3   \n",
       "15174                    2                    2   \n",
       "\n",
       "                                            total_review  length_words  \\\n",
       "0      This paper proposes a model-agnostic framework...           225   \n",
       "1      In this paper, the authors present a unique ap...           513   \n",
       "2      I have read the other reviews and all rebuttal...           650   \n",
       "3      Paper introduces a framework to detect and cat...           453   \n",
       "4      This paper theoretecally and empirically showe...           307   \n",
       "...                                                  ...           ...   \n",
       "15170  This paper proposes an asymmetric training sch...           574   \n",
       "15171  In this paper, authors present regression adju...          1063   \n",
       "15172  This paper focuses on estimation of individual...           519   \n",
       "15173  This paper explores the design and analysis of...          1546   \n",
       "15174  The paper addresses the problem of ATE and ITE...           358   \n",
       "\n",
       "       citation_count  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "15170               0  \n",
       "15171               1  \n",
       "15172               3  \n",
       "15173               3  \n",
       "15174               0  \n",
       "\n",
       "[15175 rows x 19 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def count_citations(text):\n",
    "    citation_patterns = [\n",
    "        r'\\[\\d+(?:,\\s*\\d+)*\\]',                         # [1], [1, 2, 3]\n",
    "        r'\\([A-Za-z]+ et al\\.,\\s*\\d{4}\\)',               # (Smith et al., 2020)\n",
    "        r'\\(\\d{4}[a-z]?\\)',                              # (2020), (2020a)\n",
    "        r'\\[[A-Za-z]+\\d{4}[a-z]?\\]',                     # [Smith2020], [Johnson2021a]\n",
    "        r'\\b(?:doi:|arxiv:|https?://[^\\s]+)',             # DOI, arXiv, URLs\n",
    "    ]\n",
    "    pattern = '|'.join(citation_patterns)\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)\n",
    "\n",
    "\n",
    "# Apply the count_citations function to the 'total_review' column and create a new column 'citation_count'\n",
    "df_reviews['citation_count'] = df_reviews['total_review'].apply(count_citations)\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 14:15:26.522604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746728126.544830 3911350 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746728126.551650 3911350 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746728126.571549 3911350 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746728126.571568 3911350 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746728126.571570 3911350 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746728126.571572 3911350 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 14:15:26.578010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Processing reviews: 100%|██████████| 15175/15175 [18:33<00:00, 13.63it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "64ea5b0a-213a-414b-bf6e-cae37c062a2e",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>review_mdate</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate   review_mdate  \\\n",
       "0      1688368213177  1688368213177  1702411303415  1702411303415   \n",
       "1      1688505633161  1688505633161  1702411303319  1702411303319   \n",
       "2      1688552936677  1688552936677  1702411303221  1702411303221   \n",
       "3      1688657604892  1688657604892  1702411303144  1702411303144   \n",
       "4      1688617232745  1688617232745  1702411520565  1702411520565   \n",
       "...              ...            ...            ...            ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  1702411081106   \n",
       "15171  1688449656890  1688449656890  1702411268900  1702411268900   \n",
       "15172  1688485585833  1688485585833  1702411268818  1702411268818   \n",
       "15173  1688665406904  1688665406904  1702411268706  1702411268706   \n",
       "15174  1688755793651  1688755793651  1702411268608  1702411268608   \n",
       "\n",
       "       review_rating  review_confidence  review_soundness  \\\n",
       "0                  6                  3                 3   \n",
       "1                  6                  4                 3   \n",
       "2                  6                  4                 3   \n",
       "3                  6                  4                 2   \n",
       "4                  6                  3                 3   \n",
       "...              ...                ...               ...   \n",
       "15170              6                  4                 3   \n",
       "15171              7                  5                 3   \n",
       "15172              5                  3                 2   \n",
       "15173              4                  3                 2   \n",
       "15174              4                  3                 3   \n",
       "\n",
       "       review_presentation  review_contribution  \\\n",
       "0                        3                    3   \n",
       "1                        3                    4   \n",
       "2                        3                    2   \n",
       "3                        3                    3   \n",
       "4                        3                    3   \n",
       "...                    ...                  ...   \n",
       "15170                    3                    3   \n",
       "15171                    3                    3   \n",
       "15172                    2                    2   \n",
       "15173                    1                    3   \n",
       "15174                    2                    2   \n",
       "\n",
       "                                            total_review  length_words  \\\n",
       "0      This paper proposes a model-agnostic framework...           225   \n",
       "1      In this paper, the authors present a unique ap...           513   \n",
       "2      I have read the other reviews and all rebuttal...           650   \n",
       "3      Paper introduces a framework to detect and cat...           453   \n",
       "4      This paper theoretecally and empirically showe...           307   \n",
       "...                                                  ...           ...   \n",
       "15170  This paper proposes an asymmetric training sch...           574   \n",
       "15171  In this paper, authors present regression adju...          1063   \n",
       "15172  This paper focuses on estimation of individual...           519   \n",
       "15173  This paper explores the design and analysis of...          1546   \n",
       "15174  The paper addresses the problem of ATE and ITE...           358   \n",
       "\n",
       "       citation_count  question_count  \n",
       "0                   0               8  \n",
       "1                   0               1  \n",
       "2                   0               6  \n",
       "3                   0               1  \n",
       "4                   0               0  \n",
       "...               ...             ...  \n",
       "15170               0               3  \n",
       "15171               1               1  \n",
       "15172               3               2  \n",
       "15173               3               9  \n",
       "15174               0               0  \n",
       "\n",
       "[15175 rows x 20 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def count_questions(review_text):\n",
    "    \n",
    "    if review_text:\n",
    "        question_count = 0\n",
    "\n",
    "        sentences = sent_tokenize(review_text)\n",
    "        for sent in sentences:\n",
    "            inputs = tokenizer(\n",
    "                sent,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=64,\n",
    "                padding=True\n",
    "            ).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                predicted = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "                # Label 0 = question\n",
    "                if predicted == 0:\n",
    "                    question_count += 1\n",
    "\n",
    "    return question_count\n",
    "\n",
    "\n",
    "df_reviews['question_count'] = [\n",
    "    count_questions(row['total_review']) for row in tqdm(df_reviews.to_dict('records'), desc=\"Processing reviews\")\n",
    "]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_tcdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_cdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_tmdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_mdate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "78ea15a4-454f-4641-8de8-514ba1fca365",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1688368213177",
         "1702411303415",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1688505633161",
         "1702411303319",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1688552936677",
         "1702411303221",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1688657604892",
         "1702411303144",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1688617232745",
         "1702411520565",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1688644377742",
         "1702411520475",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1688686540169",
         "1702411520381",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1688704489779",
         "1702411520262",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1687187527651",
         "1702410739080",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1687405291359",
         "1702410738990",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1688468187665",
         "1702410738918",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1688722500298",
         "1702410738854",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1687462207886",
         "1702410758348",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1688577265853",
         "1702410758259",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1688582035480",
         "1702410758195",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1689767626743",
         "1702410758135",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1690326191085",
         "1702410758029",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1688626829175",
         "1702411111578",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1688663151312",
         "1702411111496",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1688681107832",
         "1702411111399",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1688707829469",
         "1702411111310",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1688427159321",
         "1702411021240",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1689117977974",
         "1702411021146",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1689578555570",
         "1702411021035",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1689916941492",
         "1702411020935",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1690365639585",
         "1702411020852",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1690401961859",
         "1702411020671",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1688240864746",
         "1702411167395",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1688396827585",
         "1702411167288",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1688408837735",
         "1702411167213",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1689050502893",
         "1702411167124",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1690252533966",
         "1702411167025",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1687715443736",
         "1702410835214",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1688548941955",
         "1702410835139",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1688653581641",
         "1702410835057",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1688701236273",
         "1702410834962",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1688445958696",
         "1702411317487",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1688448571574",
         "1702411317410",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1688589616718",
         "1702411317319",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1688604914709",
         "1702411317217",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1688742468644",
         "1702411317111",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1688225043645",
         "1702410758906",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1688466543628",
         "1702410758835",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1688531384966",
         "1702410758770",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1690491959653",
         "1702410758696",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1690766417890",
         "1702410758593",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1688541118141",
         "1702410854876",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1688677891394",
         "1702410854754",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1688690695941",
         "1702410854663",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1688783633741",
         "1702410854548",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_tcdate</th>\n",
       "      <th>review_cdate</th>\n",
       "      <th>review_tmdate</th>\n",
       "      <th>review_mdate</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       review_tcdate   review_cdate  review_tmdate   review_mdate  \\\n",
       "0      1688368213177  1688368213177  1702411303415  1702411303415   \n",
       "1      1688505633161  1688505633161  1702411303319  1702411303319   \n",
       "2      1688552936677  1688552936677  1702411303221  1702411303221   \n",
       "3      1688657604892  1688657604892  1702411303144  1702411303144   \n",
       "4      1688617232745  1688617232745  1702411520565  1702411520565   \n",
       "...              ...            ...            ...            ...   \n",
       "15170  1688676041356  1688676041356  1702411081106  1702411081106   \n",
       "15171  1688449656890  1688449656890  1702411268900  1702411268900   \n",
       "15172  1688485585833  1688485585833  1702411268818  1702411268818   \n",
       "15173  1688665406904  1688665406904  1702411268706  1702411268706   \n",
       "15174  1688755793651  1688755793651  1702411268608  1702411268608   \n",
       "\n",
       "       review_rating  review_confidence  review_soundness  \\\n",
       "0                  6                  3                 3   \n",
       "1                  6                  4                 3   \n",
       "2                  6                  4                 3   \n",
       "3                  6                  4                 2   \n",
       "4                  6                  3                 3   \n",
       "...              ...                ...               ...   \n",
       "15170              6                  4                 3   \n",
       "15171              7                  5                 3   \n",
       "15172              5                  3                 2   \n",
       "15173              4                  3                 2   \n",
       "15174              4                  3                 3   \n",
       "\n",
       "       review_presentation  review_contribution  \\\n",
       "0                        3                    3   \n",
       "1                        3                    4   \n",
       "2                        3                    2   \n",
       "3                        3                    3   \n",
       "4                        3                    3   \n",
       "...                    ...                  ...   \n",
       "15170                    3                    3   \n",
       "15171                    3                    3   \n",
       "15172                    2                    2   \n",
       "15173                    1                    3   \n",
       "15174                    2                    2   \n",
       "\n",
       "                                            total_review  length_words  \\\n",
       "0      This paper proposes a model-agnostic framework...           225   \n",
       "1      In this paper, the authors present a unique ap...           513   \n",
       "2      I have read the other reviews and all rebuttal...           650   \n",
       "3      Paper introduces a framework to detect and cat...           453   \n",
       "4      This paper theoretecally and empirically showe...           307   \n",
       "...                                                  ...           ...   \n",
       "15170  This paper proposes an asymmetric training sch...           574   \n",
       "15171  In this paper, authors present regression adju...          1063   \n",
       "15172  This paper focuses on estimation of individual...           519   \n",
       "15173  This paper explores the design and analysis of...          1546   \n",
       "15174  The paper addresses the problem of ATE and ITE...           358   \n",
       "\n",
       "       citation_count  question_count  \n",
       "0                   0               8  \n",
       "1                   0               1  \n",
       "2                   0               6  \n",
       "3                   0               1  \n",
       "4                   0               0  \n",
       "...               ...             ...  \n",
       "15170               0               3  \n",
       "15171               1               1  \n",
       "15172               3               2  \n",
       "15173               3               9  \n",
       "15174               0               0  \n",
       "\n",
       "[15175 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdate and tcdate equal: 15175\n",
      "cdate and tcdate not equal: 0\n",
      "tmdate and mdate equal: 15175\n",
      "tmdate and mdate not equal: 0\n"
     ]
    }
   ],
   "source": [
    "# Count rows where cdate and tcdate are equal or not equal\n",
    "cdate_tcdate_equal = (df_reviews['review_cdate'] == df_reviews['review_tcdate']).sum()\n",
    "cdate_tcdate_not_equal = (df_reviews['review_cdate'] != df_reviews['review_tcdate']).sum()\n",
    "\n",
    "# Count rows where tmdate and mdate are equal or not equal\n",
    "tmdate_mdate_equal = (df_reviews['review_tmdate'] == df_reviews['review_mdate']).sum()\n",
    "tmdate_mdate_not_equal = (df_reviews['review_tmdate'] != df_reviews['review_mdate']).sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"cdate and tcdate equal: {cdate_tcdate_equal}\")\n",
    "print(f\"cdate and tcdate not equal: {cdate_tcdate_not_equal}\")\n",
    "print(f\"tmdate and mdate equal: {tmdate_mdate_equal}\")\n",
    "print(f\"tmdate and mdate not equal: {tmdate_mdate_not_equal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "63af6ad9-0eb3-474f-a1f7-3913890fb747",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  \\\n",
       "0      1688368213177           1702411303415              6   \n",
       "1      1688505633161           1702411303319              6   \n",
       "2      1688552936677           1702411303221              6   \n",
       "3      1688657604892           1702411303144              6   \n",
       "4      1688617232745           1702411520565              6   \n",
       "...              ...                     ...            ...   \n",
       "15170  1688676041356           1702411081106              6   \n",
       "15171  1688449656890           1702411268900              7   \n",
       "15172  1688485585833           1702411268818              5   \n",
       "15173  1688665406904           1702411268706              4   \n",
       "15174  1688755793651           1702411268608              4   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      3                 3                    3   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 3                    3   \n",
       "3                      4                 2                    3   \n",
       "4                      3                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "15170                  4                 3                    3   \n",
       "15171                  5                 3                    3   \n",
       "15172                  3                 2                    2   \n",
       "15173                  3                 2                    1   \n",
       "15174                  3                 3                    2   \n",
       "\n",
       "       review_contribution                                       total_review  \\\n",
       "0                        3  This paper proposes a model-agnostic framework...   \n",
       "1                        4  In this paper, the authors present a unique ap...   \n",
       "2                        2  I have read the other reviews and all rebuttal...   \n",
       "3                        3  Paper introduces a framework to detect and cat...   \n",
       "4                        3  This paper theoretecally and empirically showe...   \n",
       "...                    ...                                                ...   \n",
       "15170                    3  This paper proposes an asymmetric training sch...   \n",
       "15171                    3  In this paper, authors present regression adju...   \n",
       "15172                    2  This paper focuses on estimation of individual...   \n",
       "15173                    3  This paper explores the design and analysis of...   \n",
       "15174                    2  The paper addresses the problem of ATE and ITE...   \n",
       "\n",
       "       length_words  citation_count  question_count  \n",
       "0               225               0               8  \n",
       "1               513               0               1  \n",
       "2               650               0               6  \n",
       "3               453               0               1  \n",
       "4               307               0               0  \n",
       "...             ...             ...             ...  \n",
       "15170           574               0               3  \n",
       "15171          1063               1               1  \n",
       "15172           519               3               2  \n",
       "15173          1546               3               9  \n",
       "15174           358               0               0  \n",
       "\n",
       "[15175 rows x 18 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'tcdate' and 'tmdate' columns\n",
    "df_reviews = df_reviews.drop(columns=['review_tcdate', 'review_tmdate'])\n",
    "\n",
    "# Rename 'cdate' to 'creation_date' and 'mdate' to 'last_modification_date'\n",
    "df_reviews = df_reviews.rename(columns={'review_cdate': 'creation_date', 'review_mdate': 'last_modification_date'})\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to a different JSON file\n",
    "out = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v2.json'\n",
    "df_reviews.to_json(out, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4 - V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy\n",
    "\n",
    "# English models\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_trf\n",
    "# # Spanish models (used as fallback)\n",
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "231889d5-302f-4c26-aae3-8350a55f6e67",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  \\\n",
       "0      1688368213177           1702411303415              6   \n",
       "1      1688505633161           1702411303319              6   \n",
       "2      1688552936677           1702411303221              6   \n",
       "3      1688657604892           1702411303144              6   \n",
       "4      1688617232745           1702411520565              6   \n",
       "...              ...                     ...            ...   \n",
       "15170  1688676041356           1702411081106              6   \n",
       "15171  1688449656890           1702411268900              7   \n",
       "15172  1688485585833           1702411268818              5   \n",
       "15173  1688665406904           1702411268706              4   \n",
       "15174  1688755793651           1702411268608              4   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      3                 3                    3   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 3                    3   \n",
       "3                      4                 2                    3   \n",
       "4                      3                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "15170                  4                 3                    3   \n",
       "15171                  5                 3                    3   \n",
       "15172                  3                 2                    2   \n",
       "15173                  3                 2                    1   \n",
       "15174                  3                 3                    2   \n",
       "\n",
       "       review_contribution                                       total_review  \\\n",
       "0                        3  This paper proposes a model-agnostic framework...   \n",
       "1                        4  In this paper, the authors present a unique ap...   \n",
       "2                        2  I have read the other reviews and all rebuttal...   \n",
       "3                        3  Paper introduces a framework to detect and cat...   \n",
       "4                        3  This paper theoretecally and empirically showe...   \n",
       "...                    ...                                                ...   \n",
       "15170                    3  This paper proposes an asymmetric training sch...   \n",
       "15171                    3  In this paper, authors present regression adju...   \n",
       "15172                    2  This paper focuses on estimation of individual...   \n",
       "15173                    3  This paper explores the design and analysis of...   \n",
       "15174                    2  The paper addresses the problem of ATE and ITE...   \n",
       "\n",
       "       length_words  citation_count  question_count  \n",
       "0               225               0               8  \n",
       "1               513               0               1  \n",
       "2               650               0               6  \n",
       "3               453               0               1  \n",
       "4               307               0               0  \n",
       "...             ...             ...             ...  \n",
       "15170           574               0               3  \n",
       "15171          1063               1               1  \n",
       "15172           519               3               2  \n",
       "15173          1546               3               9  \n",
       "15174           358               0               0  \n",
       "\n",
       "[15175 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the JSON file as a pandas DataFrame\n",
    "df_reviews = pd.read_json('/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v2.json')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews: 100%|██████████| 15175/15175 [40:43<00:00,  6.21it/s]  \n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "34f9bac7-4848-4e2c-b42a-fe8cd16b99b1",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8",
         "0.7494"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1",
         "0.7788"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6",
         "0.7975"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1",
         "0.8136"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0",
         "0.8162"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0",
         "0.7880"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1",
         "0.7687"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0",
         "0.7917"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2",
         "0.7698"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7",
         "0.6733"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6",
         "0.7925"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0",
         "0.8056"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8",
         "0.7690"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4",
         "0.7735"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0",
         "0.6853"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5",
         "0.7703"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1",
         "0.8080"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3",
         "0.8097"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11",
         "0.7875"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0",
         "0.7567"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1",
         "0.7503"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5",
         "0.7613"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0",
         "0.7991"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1",
         "0.7780"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1",
         "0.7458"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8",
         "0.7748"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0",
         "0.7532"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9",
         "0.7770"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10",
         "0.7563"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2",
         "0.8039"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0",
         "0.8072"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10",
         "0.7563"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2",
         "0.7377"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16",
         "0.8414"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13",
         "0.7270"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3",
         "0.7317"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0",
         "0.7436"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2",
         "0.7798"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4",
         "0.7577"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7",
         "0.7752"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1",
         "0.7790"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0",
         "0.7543"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8",
         "0.7494"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1",
         "0.7439"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1",
         "0.7637"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7",
         "0.7825"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0",
         "0.7950"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3",
         "0.7529"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4",
         "0.7637"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1",
         "0.7872"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  \\\n",
       "0      1688368213177           1702411303415              6   \n",
       "1      1688505633161           1702411303319              6   \n",
       "2      1688552936677           1702411303221              6   \n",
       "3      1688657604892           1702411303144              6   \n",
       "4      1688617232745           1702411520565              6   \n",
       "...              ...                     ...            ...   \n",
       "15170  1688676041356           1702411081106              6   \n",
       "15171  1688449656890           1702411268900              7   \n",
       "15172  1688485585833           1702411268818              5   \n",
       "15173  1688665406904           1702411268706              4   \n",
       "15174  1688755793651           1702411268608              4   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      3                 3                    3   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 3                    3   \n",
       "3                      4                 2                    3   \n",
       "4                      3                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "15170                  4                 3                    3   \n",
       "15171                  5                 3                    3   \n",
       "15172                  3                 2                    2   \n",
       "15173                  3                 2                    1   \n",
       "15174                  3                 3                    2   \n",
       "\n",
       "       review_contribution                                       total_review  \\\n",
       "0                        3  This paper proposes a model-agnostic framework...   \n",
       "1                        4  In this paper, the authors present a unique ap...   \n",
       "2                        2  I have read the other reviews and all rebuttal...   \n",
       "3                        3  Paper introduces a framework to detect and cat...   \n",
       "4                        3  This paper theoretecally and empirically showe...   \n",
       "...                    ...                                                ...   \n",
       "15170                    3  This paper proposes an asymmetric training sch...   \n",
       "15171                    3  In this paper, authors present regression adju...   \n",
       "15172                    2  This paper focuses on estimation of individual...   \n",
       "15173                    3  This paper explores the design and analysis of...   \n",
       "15174                    2  The paper addresses the problem of ATE and ITE...   \n",
       "\n",
       "       length_words  citation_count  question_count   mattr  \n",
       "0               225               0               8  0.7494  \n",
       "1               513               0               1  0.7788  \n",
       "2               650               0               6  0.7975  \n",
       "3               453               0               1  0.8136  \n",
       "4               307               0               0  0.8162  \n",
       "...             ...             ...             ...     ...  \n",
       "15170           574               0               3  0.7740  \n",
       "15171          1063               1               1  0.8006  \n",
       "15172           519               3               2  0.7540  \n",
       "15173          1546               3               9  0.7824  \n",
       "15174           358               0               0  0.7663  \n",
       "\n",
       "[15175 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from taaled import ld\n",
    "from pylats import lats\n",
    "\n",
    "\n",
    "def compute_mattr(review_text):\n",
    "    mattr_value = \"\"\n",
    "    if review_text is not None:\n",
    "        review_text = review_text.strip()  # Remove leading/trailing whitespace\n",
    "        review_text = review_text.replace('\\n', '')  # Replace newlines with spaces\n",
    "        try:\n",
    "            cleaned = lats.Normalize(review_text, lats.ld_params_en)\n",
    "            tokens = cleaned.toks\n",
    "            mattr_value = f\"{ld.lexdiv(tokens).mattr:.4f}\"\n",
    "        except Exception as e:\n",
    "            mattr_value = \"\"\n",
    "    return mattr_value\n",
    "\n",
    "\n",
    "df_reviews['mattr'] = [\n",
    "    compute_mattr(row['total_review']) for row in tqdm(df_reviews.to_dict('records'), desc=\"Processing reviews\")\n",
    "]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to a different JSON file\n",
    "out = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v3.json'\n",
    "df_reviews.to_json(out, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews: 100%|██████████| 15175/15175 [00:29<00:00, 510.35it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "84ed15c1-0a86-4308-b6f0-1b78415b8d49",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8",
         "0.7494",
         "0.041666666666666664"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1",
         "0.7788",
         "0.1071362433862434"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6",
         "0.7975",
         "0.09338761238761237"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1",
         "0.8136",
         "0.11303841991341992"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0",
         "0.8162",
         "0.024398749398749406"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0",
         "0.7880",
         "0.15018518518518517"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1",
         "0.7687",
         "0.22584054834054837"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0",
         "0.7917",
         "0.08435672514619882"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2",
         "0.7698",
         "0.1875"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7",
         "0.6733",
         "0.21619047619047618"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6",
         "0.7925",
         "0.06439393939393939"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0",
         "0.8056",
         "0.17096774193548392"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8",
         "0.7690",
         "0.08568699416525505"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4",
         "0.7735",
         "0.03233405483405483"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0",
         "0.6853",
         "0.15091991341991343"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5",
         "0.7703",
         "0.125"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1",
         "0.8080",
         "0.10309523809523809"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3",
         "0.8097",
         "0.12557781201848994"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11",
         "0.7875",
         "0.10175047175047176"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0",
         "0.7567",
         "0.16250000000000003"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1",
         "0.7503",
         "-0.017045454545454555"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5",
         "0.7613",
         "0.05416666666666668"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0",
         "0.7991",
         "0.05830357006827594"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1",
         "0.7780",
         "0.14054687500000002"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1",
         "0.7458",
         "0.2506493506493506"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8",
         "0.7748",
         "0.038915256892230576"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0",
         "0.7532",
         "0.06302655677655679"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9",
         "0.7770",
         "0.14410884353741496"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10",
         "0.7563",
         "0.16060397935397935"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2",
         "0.8039",
         "0.07234848484848484"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0",
         "0.8072",
         "0.13673469387755102"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10",
         "0.7563",
         "0.03054280489625319"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2",
         "0.7377",
         "0.08354978354978355"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16",
         "0.8414",
         "0.04605142332415061"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13",
         "0.7270",
         "-0.04411764705882354"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3",
         "0.7317",
         "0.10633608815426997"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0",
         "0.7436",
         "-0.020564516129032255"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2",
         "0.7798",
         "0.12095959595959596"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4",
         "0.7577",
         "0.11652494331065759"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7",
         "0.7752",
         "0.17777777777777778"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1",
         "0.7790",
         "0.1302469135802469"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0",
         "0.7543",
         "0.12186849146224149"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8",
         "0.7494",
         "0.08366666666666667"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1",
         "0.7439",
         "0.20677083333333335"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1",
         "0.7637",
         "0.12499414999414993"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7",
         "0.7825",
         "0.19568452380952378"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0",
         "0.7950",
         "0.13990542066629025"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3",
         "0.7529",
         "0.20957393483709277"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4",
         "0.7637",
         "0.22755952380952382"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1",
         "0.7872",
         "0.06666666666666665"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.107136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.093388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.113038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.024399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.212049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8006</td>\n",
       "      <td>0.095406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>0.099046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7824</td>\n",
       "      <td>0.090550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7663</td>\n",
       "      <td>0.017634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  \\\n",
       "0      1688368213177           1702411303415              6   \n",
       "1      1688505633161           1702411303319              6   \n",
       "2      1688552936677           1702411303221              6   \n",
       "3      1688657604892           1702411303144              6   \n",
       "4      1688617232745           1702411520565              6   \n",
       "...              ...                     ...            ...   \n",
       "15170  1688676041356           1702411081106              6   \n",
       "15171  1688449656890           1702411268900              7   \n",
       "15172  1688485585833           1702411268818              5   \n",
       "15173  1688665406904           1702411268706              4   \n",
       "15174  1688755793651           1702411268608              4   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      3                 3                    3   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 3                    3   \n",
       "3                      4                 2                    3   \n",
       "4                      3                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "15170                  4                 3                    3   \n",
       "15171                  5                 3                    3   \n",
       "15172                  3                 2                    2   \n",
       "15173                  3                 2                    1   \n",
       "15174                  3                 3                    2   \n",
       "\n",
       "       review_contribution                                       total_review  \\\n",
       "0                        3  This paper proposes a model-agnostic framework...   \n",
       "1                        4  In this paper, the authors present a unique ap...   \n",
       "2                        2  I have read the other reviews and all rebuttal...   \n",
       "3                        3  Paper introduces a framework to detect and cat...   \n",
       "4                        3  This paper theoretecally and empirically showe...   \n",
       "...                    ...                                                ...   \n",
       "15170                    3  This paper proposes an asymmetric training sch...   \n",
       "15171                    3  In this paper, authors present regression adju...   \n",
       "15172                    2  This paper focuses on estimation of individual...   \n",
       "15173                    3  This paper explores the design and analysis of...   \n",
       "15174                    2  The paper addresses the problem of ATE and ITE...   \n",
       "\n",
       "       length_words  citation_count  question_count   mattr  \\\n",
       "0               225               0               8  0.7494   \n",
       "1               513               0               1  0.7788   \n",
       "2               650               0               6  0.7975   \n",
       "3               453               0               1  0.8136   \n",
       "4               307               0               0  0.8162   \n",
       "...             ...             ...             ...     ...   \n",
       "15170           574               0               3  0.7740   \n",
       "15171          1063               1               1  0.8006   \n",
       "15172           519               3               2  0.7540   \n",
       "15173          1546               3               9  0.7824   \n",
       "15174           358               0               0  0.7663   \n",
       "\n",
       "       sentiment_polarity  \n",
       "0                0.041667  \n",
       "1                0.107136  \n",
       "2                0.093388  \n",
       "3                0.113038  \n",
       "4                0.024399  \n",
       "...                   ...  \n",
       "15170            0.212049  \n",
       "15171            0.095406  \n",
       "15172            0.099046  \n",
       "15173            0.090550  \n",
       "15174            0.017634  \n",
       "\n",
       "[15175 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_sentiment_polarity(review_text):\n",
    "    review_text = review_text.strip()\n",
    "    try:\n",
    "        blob = TextBlob(review_text)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "    except Exception:\n",
    "        sentiment = \"\"\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "df_reviews['sentiment_polarity'] = [\n",
    "    compute_sentiment_polarity(row['total_review']) for row in tqdm(df_reviews.to_dict('records'), desc=\"Processing reviews\")\n",
    "]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to a different JSON file\n",
    "out = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v4.json'\n",
    "df_reviews.to_json(out, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d4b53561-c5f8-4780-9891-896c0deeb7d9",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8",
         "0.7494",
         "0.0416666667"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1",
         "0.7788",
         "0.1071362434"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6",
         "0.7975",
         "0.0933876124"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1",
         "0.8136",
         "0.1130384199"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0",
         "0.8162",
         "0.0243987494"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0",
         "0.788",
         "0.15018518520000002"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1",
         "0.7687",
         "0.2258405483"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0",
         "0.7917",
         "0.0843567251"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2",
         "0.7698",
         "0.1875"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7",
         "0.6733",
         "0.2161904762"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6",
         "0.7925",
         "0.0643939394"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0",
         "0.8056",
         "0.1709677419"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8",
         "0.769",
         "0.0856869942"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4",
         "0.7735",
         "0.0323340548"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0",
         "0.6853",
         "0.1509199134"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5",
         "0.7703",
         "0.125"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1",
         "0.808",
         "0.1030952381"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3",
         "0.8097",
         "0.125577812"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11",
         "0.7875",
         "0.1017504718"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0",
         "0.7567",
         "0.1625"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1",
         "0.7503",
         "-0.0170454545"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5",
         "0.7613",
         "0.054166666700000005"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0",
         "0.7991",
         "0.0583035701"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1",
         "0.778",
         "0.14054687500000002"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1",
         "0.7458",
         "0.2506493506"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8",
         "0.7748",
         "0.0389152569"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0",
         "0.7532",
         "0.06302655680000001"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9",
         "0.777",
         "0.1441088435"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10",
         "0.7563",
         "0.1606039794"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2",
         "0.8039",
         "0.0723484848"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0",
         "0.8072",
         "0.1367346939"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10",
         "0.7563",
         "0.0305428049"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2",
         "0.7377",
         "0.0835497835"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16",
         "0.8414",
         "0.046051423300000005"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13",
         "0.727",
         "-0.044117647100000004"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3",
         "0.7317",
         "0.1063360882"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0",
         "0.7436",
         "-0.0205645161"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2",
         "0.7798",
         "0.120959596"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4",
         "0.7577",
         "0.1165249433"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7",
         "0.7752",
         "0.1777777778"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1",
         "0.779",
         "0.1302469136"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0",
         "0.7543",
         "0.12186849150000001"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8",
         "0.7494",
         "0.0836666667"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1",
         "0.7439",
         "0.2067708333"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1",
         "0.7637",
         "0.12499415"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7",
         "0.7825",
         "0.1956845238"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0",
         "0.795",
         "0.1399054207"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3",
         "0.7529",
         "0.2095739348"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4",
         "0.7637",
         "0.2275595238"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1",
         "0.7872",
         "0.0666666667"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.107136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.093388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.113038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.024399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.212049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8006</td>\n",
       "      <td>0.095406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>0.099046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7824</td>\n",
       "      <td>0.090550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7663</td>\n",
       "      <td>0.017634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  \\\n",
       "0      1688368213177           1702411303415              6   \n",
       "1      1688505633161           1702411303319              6   \n",
       "2      1688552936677           1702411303221              6   \n",
       "3      1688657604892           1702411303144              6   \n",
       "4      1688617232745           1702411520565              6   \n",
       "...              ...                     ...            ...   \n",
       "15170  1688676041356           1702411081106              6   \n",
       "15171  1688449656890           1702411268900              7   \n",
       "15172  1688485585833           1702411268818              5   \n",
       "15173  1688665406904           1702411268706              4   \n",
       "15174  1688755793651           1702411268608              4   \n",
       "\n",
       "       review_confidence  review_soundness  review_presentation  \\\n",
       "0                      3                 3                    3   \n",
       "1                      4                 3                    3   \n",
       "2                      4                 3                    3   \n",
       "3                      4                 2                    3   \n",
       "4                      3                 3                    3   \n",
       "...                  ...               ...                  ...   \n",
       "15170                  4                 3                    3   \n",
       "15171                  5                 3                    3   \n",
       "15172                  3                 2                    2   \n",
       "15173                  3                 2                    1   \n",
       "15174                  3                 3                    2   \n",
       "\n",
       "       review_contribution                                       total_review  \\\n",
       "0                        3  This paper proposes a model-agnostic framework...   \n",
       "1                        4  In this paper, the authors present a unique ap...   \n",
       "2                        2  I have read the other reviews and all rebuttal...   \n",
       "3                        3  Paper introduces a framework to detect and cat...   \n",
       "4                        3  This paper theoretecally and empirically showe...   \n",
       "...                    ...                                                ...   \n",
       "15170                    3  This paper proposes an asymmetric training sch...   \n",
       "15171                    3  In this paper, authors present regression adju...   \n",
       "15172                    2  This paper focuses on estimation of individual...   \n",
       "15173                    3  This paper explores the design and analysis of...   \n",
       "15174                    2  The paper addresses the problem of ATE and ITE...   \n",
       "\n",
       "       length_words  citation_count  question_count   mattr  \\\n",
       "0               225               0               8  0.7494   \n",
       "1               513               0               1  0.7788   \n",
       "2               650               0               6  0.7975   \n",
       "3               453               0               1  0.8136   \n",
       "4               307               0               0  0.8162   \n",
       "...             ...             ...             ...     ...   \n",
       "15170           574               0               3  0.7740   \n",
       "15171          1063               1               1  0.8006   \n",
       "15172           519               3               2  0.7540   \n",
       "15173          1546               3               9  0.7824   \n",
       "15174           358               0               0  0.7663   \n",
       "\n",
       "       sentiment_polarity  \n",
       "0                0.041667  \n",
       "1                0.107136  \n",
       "2                0.093388  \n",
       "3                0.113038  \n",
       "4                0.024399  \n",
       "...                   ...  \n",
       "15170            0.212049  \n",
       "15171            0.095406  \n",
       "15172            0.099046  \n",
       "15173            0.090550  \n",
       "15174            0.017634  \n",
       "\n",
       "[15175 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the JSON file as a pandas DataFrame\n",
    "df_reviews = pd.read_json('/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v4.json')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 16:43:24.962472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746737004.984484 1212053 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746737004.991224 1212053 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746737005.010641 1212053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746737005.010667 1212053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746737005.010669 1212053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746737005.010671 1212053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 16:43:25.016349: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Computing similarity scores: 100%|██████████| 15175/15175 [04:15<00:00, 59.28it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "46a7cf3c-c227-4569-9723-65f38a03cdab",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8",
         "0.7494",
         "0.0416666667",
         "0.9411299228668213"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1",
         "0.7788",
         "0.1071362434",
         "0.9471733570098877"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6",
         "0.7975",
         "0.0933876124",
         "0.8911411762237549"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1",
         "0.8136",
         "0.1130384199",
         "0.8543175458908081"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0",
         "0.8162",
         "0.0243987494",
         "0.9466578960418701"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0",
         "0.788",
         "0.15018518520000002",
         "0.9463365077972412"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1",
         "0.7687",
         "0.2258405483",
         "0.9238996505737305"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0",
         "0.7917",
         "0.0843567251",
         "0.8677315711975098"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2",
         "0.7698",
         "0.1875",
         "0.899429440498352"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7",
         "0.6733",
         "0.2161904762",
         "0.882093608379364"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6",
         "0.7925",
         "0.0643939394",
         "0.9252514839172363"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0",
         "0.8056",
         "0.1709677419",
         "0.9168287515640259"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8",
         "0.769",
         "0.0856869942",
         "0.8494880199432373"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n[2] DINOv2: Learning Robust Visual Features without Supervision\n\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4",
         "0.7735",
         "0.0323340548",
         "0.8710070252418518"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0",
         "0.6853",
         "0.1509199134",
         "0.8459879159927368"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch [e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5",
         "0.7703",
         "0.125",
         "0.8415295481681824"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1",
         "0.808",
         "0.1030952381",
         "0.8639517426490784"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references [26] and [43]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3",
         "0.8097",
         "0.125577812",
         "0.9384059906005859"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB [1] and RIDRs [2]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in [3].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX [4] and struc2vec [3]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n[1] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels[J]. Advances in neural information processing systems, 2008, 21.\n\n[2] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy[C]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n[3] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs[C]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n[4] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity[C]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11",
         "0.7875",
         "0.1017504718",
         "0.9667627811431885"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0",
         "0.7567",
         "0.1625",
         "0.9054954051971436"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1",
         "0.7503",
         "-0.0170454545",
         "0.9454556107521057"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5",
         "0.7613",
         "0.054166666700000005",
         "0.9666213393211365"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0",
         "0.7991",
         "0.0583035701",
         "0.9081530570983887"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1",
         "0.778",
         "0.14054687500000002",
         "0.8547609448432922"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1",
         "0.7458",
         "0.2506493506",
         "0.8731790781021118"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8",
         "0.7748",
         "0.0389152569",
         "0.8465107679367065"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0",
         "0.7532",
         "0.06302655680000001",
         "0.9268480539321899"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9",
         "0.777",
         "0.1441088435",
         "0.9163020849227905"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10",
         "0.7563",
         "0.1606039794",
         "0.9120497703552246"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2",
         "0.8039",
         "0.0723484848",
         "0.9104201793670654"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0",
         "0.8072",
         "0.1367346939",
         "0.902364194393158"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \n[1] “Adaptive Active Learning for Image Classification”. 2013. \n[2] “Active Learning with Multi-label SVM Classification”. 2013. \n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10",
         "0.7563",
         "0.0305428049",
         "0.8611335754394531"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2",
         "0.7377",
         "0.0835497835",
         "0.9506004452705383"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used [1] to extract such priors among categories.\n\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with [2] in detail?\n\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with [2] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16",
         "0.8414",
         "0.046051423300000005",
         "0.9489502906799316"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\n\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13",
         "0.727",
         "-0.044117647100000004",
         "0.932502031326294"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3",
         "0.7317",
         "0.1063360882",
         "0.9010543823242188"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0",
         "0.7436",
         "-0.0205645161",
         "0.9308603405952454"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2",
         "0.7798",
         "0.120959596",
         "0.9181414246559143"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4",
         "0.7577",
         "0.1165249433",
         "0.9456864595413208"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7",
         "0.7752",
         "0.1777777778",
         "0.92433762550354"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in [1]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n[1] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1",
         "0.779",
         "0.1302469136",
         "0.9419665336608887"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from [37] and [40] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of [37] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of [37] and [40].",
         "909",
         "5",
         "0",
         "0.7543",
         "0.12186849150000001",
         "0.9009177684783936"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8",
         "0.7494",
         "0.0836666667",
         "0.943513810634613"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1",
         "0.7439",
         "0.2067708333",
         "0.9592400789260864"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1",
         "0.7637",
         "0.12499415",
         "0.9655532240867615"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper [27]). yes",
         "384",
         "1",
         "7",
         "0.7825",
         "0.1956845238",
         "0.9658693075180054"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0",
         "0.795",
         "0.1399054207",
         "0.891801655292511"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3",
         "0.7529",
         "0.2095739348",
         "0.9313436150550842"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper [1]. \nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning [4], which is a more practical setting. \n\n[4] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4",
         "0.7637",
         "0.2275595238",
         "0.8652505874633789"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1",
         "0.7872",
         "0.0666666667",
         "0.9156908988952637"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>review_presentation</th>\n",
       "      <th>review_contribution</th>\n",
       "      <th>total_review</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes a model-agnostic framework...</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.941130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>In this paper, the authors present a unique ap...</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.107136</td>\n",
       "      <td>0.947173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read the other reviews and all rebuttal...</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.093388</td>\n",
       "      <td>0.891141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Paper introduces a framework to detect and cat...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>0.113038</td>\n",
       "      <td>0.854318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper theoretecally and empirically showe...</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.024399</td>\n",
       "      <td>0.946658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper proposes an asymmetric training sch...</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.212049</td>\n",
       "      <td>0.856897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In this paper, authors present regression adju...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8006</td>\n",
       "      <td>0.095406</td>\n",
       "      <td>0.902801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper focuses on estimation of individual...</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.894719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper explores the design and analysis of...</td>\n",
       "      <td>1546</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7824</td>\n",
       "      <td>0.090550</td>\n",
       "      <td>0.948687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The paper addresses the problem of ATE and ITE...</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7663</td>\n",
       "      <td>0.017634</td>\n",
       "      <td>0.885202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1688368213177           1702411303415              6  ...   \n",
       "1      1688505633161           1702411303319              6  ...   \n",
       "2      1688552936677           1702411303221              6  ...   \n",
       "3      1688657604892           1702411303144              6  ...   \n",
       "4      1688617232745           1702411520565              6  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "15170  1688676041356           1702411081106              6  ...   \n",
       "15171  1688449656890           1702411268900              7  ...   \n",
       "15172  1688485585833           1702411268818              5  ...   \n",
       "15173  1688665406904           1702411268706              4  ...   \n",
       "15174  1688755793651           1702411268608              4  ...   \n",
       "\n",
       "       review_soundness  review_presentation  review_contribution  \\\n",
       "0                     3                    3                    3   \n",
       "1                     3                    3                    4   \n",
       "2                     3                    3                    2   \n",
       "3                     2                    3                    3   \n",
       "4                     3                    3                    3   \n",
       "...                 ...                  ...                  ...   \n",
       "15170                 3                    3                    3   \n",
       "15171                 3                    3                    3   \n",
       "15172                 2                    2                    2   \n",
       "15173                 2                    1                    3   \n",
       "15174                 3                    2                    2   \n",
       "\n",
       "                                            total_review length_words  \\\n",
       "0      This paper proposes a model-agnostic framework...          225   \n",
       "1      In this paper, the authors present a unique ap...          513   \n",
       "2      I have read the other reviews and all rebuttal...          650   \n",
       "3      Paper introduces a framework to detect and cat...          453   \n",
       "4      This paper theoretecally and empirically showe...          307   \n",
       "...                                                  ...          ...   \n",
       "15170  This paper proposes an asymmetric training sch...          574   \n",
       "15171  In this paper, authors present regression adju...         1063   \n",
       "15172  This paper focuses on estimation of individual...          519   \n",
       "15173  This paper explores the design and analysis of...         1546   \n",
       "15174  The paper addresses the problem of ATE and ITE...          358   \n",
       "\n",
       "       citation_count  question_count   mattr  sentiment_polarity  \\\n",
       "0                   0               8  0.7494            0.041667   \n",
       "1                   0               1  0.7788            0.107136   \n",
       "2                   0               6  0.7975            0.093388   \n",
       "3                   0               1  0.8136            0.113038   \n",
       "4                   0               0  0.8162            0.024399   \n",
       "...               ...             ...     ...                 ...   \n",
       "15170               0               3  0.7740            0.212049   \n",
       "15171               1               1  0.8006            0.095406   \n",
       "15172               3               2  0.7540            0.099046   \n",
       "15173               3               9  0.7824            0.090550   \n",
       "15174               0               0  0.7663            0.017634   \n",
       "\n",
       "       similarity_score  \n",
       "0              0.941130  \n",
       "1              0.947173  \n",
       "2              0.891141  \n",
       "3              0.854318  \n",
       "4              0.946658  \n",
       "...                 ...  \n",
       "15170          0.856897  \n",
       "15171          0.902801  \n",
       "15172          0.894719  \n",
       "15173          0.948687  \n",
       "15174          0.885202  \n",
       "\n",
       "[15175 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Load SPECTER model ---\n",
    "model_name = \"allenai/specter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def encoding_text(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def compute_relevance_score(review_text, title, abstract):\n",
    "    # Encode document\n",
    "    doc_emb = encoding_text(f\"{title} {abstract}\")\n",
    "\n",
    "    # Encode review text\n",
    "    review_emb = encoding_text(review_text)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return F.cosine_similarity(doc_emb, review_emb).item()\n",
    "\n",
    "\n",
    "# Compute similarity score for each row with progress bar\n",
    "df_reviews['similarity_score'] = [\n",
    "    compute_relevance_score(row['total_review'], row['submission_title'], row['submission_abstract'])\n",
    "    for row in tqdm(df_reviews.to_dict('records'), desc=\"Computing similarity scores\")\n",
    "]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to a different JSON file\n",
    "out = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_neurips2023_v5.json'\n",
    "df_reviews.to_json(out, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from tqdm import tqdm\n",
    "# from convokit import Corpus, download, TextParser, PolitenessStrategies, Classifier, Utterance, Speaker\n",
    "\n",
    "# # Step 1: Load training corpus\n",
    "# print(\"📥 Downloading training corpus...\")\n",
    "# train_corpus = Corpus(filename=download('wiki-politeness-annotated'))\n",
    "\n",
    "# # Step 2: Load review data and convert to Utterances with dummy speakers\n",
    "# review_utterances = []\n",
    "\n",
    "# with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "#     reader = list(csv.DictReader(f))\n",
    "#     for idx, row in tqdm(enumerate(reader), desc=\"🔧 Preparing Utterances\", total=1805):  # Adjust total if needed\n",
    "#         review_text = row.get(\"review_text\", \"\").strip()\n",
    "#         if review_text:\n",
    "#             dummy_speaker = Speaker(id=f\"reviewer_{idx}\")\n",
    "#             review_utterances.append(\n",
    "#                 Utterance(id=str(idx), text=review_text, speaker=dummy_speaker, meta={\"orig_row\": row})\n",
    "#             )\n",
    "\n",
    "# # Step 3: Build test corpus\n",
    "# print(\"📦 Building test corpus...\")\n",
    "# test_corpus = Corpus(utterances=review_utterances)\n",
    "\n",
    "# # Step 4: Parse\n",
    "# print(\"🧠 Parsing utterances...\")\n",
    "# parser = TextParser()\n",
    "# parser.transform(train_corpus)\n",
    "# parser.transform(test_corpus)\n",
    "\n",
    "# # Step 5: Extract politeness strategies\n",
    "# print(\"✨ Extracting politeness strategies...\")\n",
    "# ps = PolitenessStrategies()\n",
    "# ps.transform(train_corpus)\n",
    "# ps.transform(test_corpus)\n",
    "\n",
    "# # Step 6: Train classifier\n",
    "# print(\"🎓 Training classifier...\")\n",
    "# clf = Classifier(obj_type='utterance', pred_feats=['politeness_strategies'],\n",
    "#                  labeller=lambda utt: utt.meta.get(\"Binary\") == 1)\n",
    "# clf.fit(train_corpus)\n",
    "# clf.transform(test_corpus)\n",
    "\n",
    "# # Step 7: Summarize results\n",
    "# print(\"📈 Summarizing scores...\")\n",
    "# results = clf.summarize(test_corpus)\n",
    "\n",
    "# # Step 8: Merge back to CSV rows\n",
    "# print(\"🧾 Merging scores into CSV...\")\n",
    "# output_rows = []\n",
    "# fieldnames = list(reader[0].keys())\n",
    "# if \"politeness_score\" not in fieldnames:\n",
    "#     fieldnames.append(\"politeness_score\")\n",
    "\n",
    "# for utt in tqdm(test_corpus.iter_utterances(), desc=\"🔗 Assigning Scores\"):\n",
    "#     row = utt.meta[\"orig_row\"]\n",
    "#     try:\n",
    "#         score = results.loc[utt.id, \"pred_score\"]\n",
    "#         row[\"politeness_score\"] = round(score, 4)\n",
    "#     except KeyError:\n",
    "#         row[\"politeness_score\"] = \"\"\n",
    "#     output_rows.append(row)\n",
    "\n",
    "# # Step 9: Save\n",
    "# print(\"💾 Saving to review_analysis.csv...\")\n",
    "# with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(output_rows)\n",
    "\n",
    "# print(\"✅ All done! Politeness scores are now in your CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOROUSH's CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace with your own path\n",
    "output_file = \"../data/XXXXX.csv\"\n",
    "input_file = output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Note' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m----> 8\u001b[0m     paper_id \u001b[38;5;241m=\u001b[39m \u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m paper_id\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNK\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paper_id:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Note' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "rows = []\n",
    "\n",
    "for paper in data:\n",
    "    paper_id = paper.get(\"id\", \"\").strip()\n",
    "    if paper_id.upper() == \"UNK\" or not paper_id:\n",
    "        continue\n",
    "\n",
    "    paper_date_str = paper.get(\"date\", \"\")\n",
    "    try:\n",
    "        paper_date = datetime.strptime(paper_date_str, \"%m/%d/%Y\")\n",
    "    except Exception:\n",
    "        paper_date = None\n",
    "\n",
    "    for review in paper.get(\"reviews\", []):\n",
    "        reviewer = review.get(\"reviewer\", \"Anonymous\").strip()\n",
    "        review_date_str = review.get(\"date\", \"\").strip()\n",
    "\n",
    "        # Clean review text\n",
    "        review_text = review.get(\"comment\", \"\")\n",
    "        review_text = review_text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "        review_suggestion = review.get(\"suggestion\", \"\")\n",
    "\n",
    "        length_words = len(review_text.split())\n",
    "\n",
    "        try:\n",
    "            review_date = datetime.strptime(review_date_str, \"%d/%b/%Y\")\n",
    "            days_to_submit = (review_date - paper_date).days if paper_date else None\n",
    "        except Exception:\n",
    "            days_to_submit = None\n",
    "\n",
    "        rows.append({\n",
    "            \"paper_id\": paper_id,\n",
    "            \"reviewer\": reviewer,\n",
    "            \"review_date\": review_date_str,\n",
    "            \"review_suggestion\": review_suggestion,\n",
    "            \"length_words\": length_words,\n",
    "            \"days_to_submit\": days_to_submit,\n",
    "            \"review_text\": review_text\n",
    "        })\n",
    "\n",
    "# Save to CSV with proper quoting\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=rows[0].keys(), quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"✅ Cleaned and saved {len(rows)} reviews with full text to review_analysis.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pylats taaled spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting taaled\n",
      "  Downloading taaled-0.32.tar.gz (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.0/1.5 MB 653.6 kB/s eta 0:00:03\n",
      "     -------------- ------------------------- 0.5/1.5 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.4/1.5 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 9.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pylats\n",
      "  Downloading pylats-0.37.tar.gz (4.6 MB)\n",
      "     ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.6/4.6 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.4/4.6 MB 17.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 2.4/4.6 MB 18.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.6/4.6 MB 21.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.5/4.6 MB 20.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.6/4.6 MB 19.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: spacy in c:\\users\\soroush\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Building wheels for collected packages: taaled, pylats\n",
      "  Building wheel for taaled (setup.py): started\n",
      "  Building wheel for taaled (setup.py): finished with status 'done'\n",
      "  Created wheel for taaled: filename=taaled-0.32-py3-none-any.whl size=1478311 sha256=c506d55eaafed3e29bc232435d9c5f6427263851b7b6789e1cc5c9babcdcd668\n",
      "  Stored in directory: c:\\users\\soroush\\appdata\\local\\pip\\cache\\wheels\\7c\\02\\9d\\a4b381628668e3a1b37cf6466f2de260c96c281ea5494cd067\n",
      "  Building wheel for pylats (setup.py): started\n",
      "  Building wheel for pylats (setup.py): finished with status 'done'\n",
      "  Created wheel for pylats: filename=pylats-0.37-py3-none-any.whl size=4725036 sha256=6a1927d3c335e95e123deb8d9263259d0fdd5b7d535bc340c49a45865e90d528\n",
      "  Stored in directory: c:\\users\\soroush\\appdata\\local\\pip\\cache\\wheels\\cf\\07\\05\\223a18327f4040b164c92b33a97cafb0a2edd9b2a3ed0c2c04\n",
      "Successfully built taaled pylats\n",
      "Installing collected packages: pylats, taaled\n",
      "Successfully installed pylats-0.37 taaled-0.32\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 660.6 kB/s eta 0:00:20\n",
      "      --------------------------------------- 0.3/12.8 MB 3.8 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.9/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 8.2 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.4/12.8 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.1/12.8 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.0/12.8 MB 14.0 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 14.8 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 15.7 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.2/12.8 MB 16.4 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 17.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.7/12.8 MB 20.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 12.1/12.8 MB 23.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 22.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 21.8 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
      "     ---------------------------------------- 0.0/457.4 MB ? eta -:--:--\n",
      "     -------------------------------------- 0.0/457.4 MB 660.6 kB/s eta 0:11:33\n",
      "     ---------------------------------------- 0.3/457.4 MB 3.7 MB/s eta 0:02:05\n",
      "     ---------------------------------------- 0.8/457.4 MB 6.3 MB/s eta 0:01:13\n",
      "     --------------------------------------- 1.9/457.4 MB 10.8 MB/s eta 0:00:43\n",
      "     --------------------------------------- 2.7/457.4 MB 12.1 MB/s eta 0:00:38\n",
      "     --------------------------------------- 3.8/457.4 MB 14.3 MB/s eta 0:00:32\n",
      "     --------------------------------------- 4.6/457.4 MB 15.5 MB/s eta 0:00:30\n",
      "     --------------------------------------- 5.0/457.4 MB 14.6 MB/s eta 0:00:32\n",
      "     --------------------------------------- 5.6/457.4 MB 13.7 MB/s eta 0:00:33\n",
      "      -------------------------------------- 6.2/457.4 MB 14.2 MB/s eta 0:00:32\n",
      "      -------------------------------------- 7.6/457.4 MB 15.1 MB/s eta 0:00:30\n",
      "      -------------------------------------- 8.7/457.4 MB 15.9 MB/s eta 0:00:29\n",
      "      ------------------------------------- 10.0/457.4 MB 16.9 MB/s eta 0:00:27\n",
      "      ------------------------------------- 11.3/457.4 MB 20.5 MB/s eta 0:00:22\n",
      "      ------------------------------------- 11.7/457.4 MB 19.8 MB/s eta 0:00:23\n",
      "     - ------------------------------------ 12.9/457.4 MB 19.9 MB/s eta 0:00:23\n",
      "     - ------------------------------------ 13.9/457.4 MB 19.9 MB/s eta 0:00:23\n",
      "     - ------------------------------------ 15.3/457.4 MB 22.6 MB/s eta 0:00:20\n",
      "     - ------------------------------------ 17.4/457.4 MB 27.3 MB/s eta 0:00:17\n",
      "     - ------------------------------------ 18.7/457.4 MB 27.3 MB/s eta 0:00:17\n",
      "     - ------------------------------------ 20.4/457.4 MB 27.3 MB/s eta 0:00:17\n",
      "     - ------------------------------------ 21.9/457.4 MB 29.7 MB/s eta 0:00:15\n",
      "     - ------------------------------------ 23.1/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 24.2/457.4 MB 32.7 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 26.2/457.4 MB 32.8 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 27.7/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 28.9/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 30.5/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 31.8/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 32.9/457.4 MB 29.7 MB/s eta 0:00:15\n",
      "     -- ----------------------------------- 34.2/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     -- ----------------------------------- 35.9/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 37.4/457.4 MB 29.7 MB/s eta 0:00:15\n",
      "     --- ---------------------------------- 39.4/457.4 MB 32.8 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 41.0/457.4 MB 32.8 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 42.1/457.4 MB 32.8 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 43.2/457.4 MB 32.8 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 44.7/457.4 MB 32.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 46.4/457.4 MB 32.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 47.6/457.4 MB 31.2 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 49.0/457.4 MB 29.7 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 50.6/457.4 MB 29.8 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 51.7/457.4 MB 28.5 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 52.9/457.4 MB 29.7 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 54.6/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ---- --------------------------------- 55.6/457.4 MB 28.5 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 57.3/457.4 MB 29.7 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 58.4/457.4 MB 28.4 MB/s eta 0:00:15\n",
      "     ---- --------------------------------- 59.6/457.4 MB 28.4 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 60.8/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 62.0/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 63.5/457.4 MB 28.5 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 64.7/457.4 MB 28.5 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 66.0/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 67.4/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 68.5/457.4 MB 27.3 MB/s eta 0:00:15\n",
      "     ----- -------------------------------- 70.0/457.4 MB 28.5 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 71.6/457.4 MB 29.7 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 73.3/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 74.9/457.4 MB 31.1 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 76.1/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 77.4/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 78.9/457.4 MB 32.8 MB/s eta 0:00:12\n",
      "     ------ ------------------------------- 80.6/457.4 MB 32.8 MB/s eta 0:00:12\n",
      "     ------ ------------------------------- 81.6/457.4 MB 31.2 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 82.7/457.4 MB 28.4 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 84.2/457.4 MB 29.7 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 85.6/457.4 MB 28.4 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 86.6/457.4 MB 31.2 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 86.6/457.4 MB 31.2 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 86.6/457.4 MB 31.2 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 88.2/457.4 MB 22.6 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 89.4/457.4 MB 22.6 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 90.8/457.4 MB 21.8 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 92.4/457.4 MB 22.6 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 93.5/457.4 MB 22.5 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 94.5/457.4 MB 23.4 MB/s eta 0:00:16\n",
      "     ------- ------------------------------ 95.7/457.4 MB 21.9 MB/s eta 0:00:17\n",
      "     -------- ----------------------------- 97.2/457.4 MB 29.7 MB/s eta 0:00:13\n",
      "     -------- ----------------------------- 98.5/457.4 MB 27.3 MB/s eta 0:00:14\n",
      "     -------- ----------------------------- 99.8/457.4 MB 28.5 MB/s eta 0:00:13\n",
      "     -------- ---------------------------- 101.0/457.4 MB 27.3 MB/s eta 0:00:14\n",
      "     -------- ---------------------------- 102.8/457.4 MB 28.4 MB/s eta 0:00:13\n",
      "     -------- ---------------------------- 103.9/457.4 MB 28.4 MB/s eta 0:00:13\n",
      "     -------- ---------------------------- 104.8/457.4 MB 29.7 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 106.5/457.4 MB 28.5 MB/s eta 0:00:13\n",
      "     -------- ---------------------------- 108.3/457.4 MB 31.1 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 108.8/457.4 MB 29.7 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 108.8/457.4 MB 29.7 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 110.0/457.4 MB 24.2 MB/s eta 0:00:15\n",
      "     --------- --------------------------- 112.7/457.4 MB 27.3 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 114.3/457.4 MB 28.5 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 115.2/457.4 MB 28.4 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 116.7/457.4 MB 27.3 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 118.2/457.4 MB 27.3 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 119.6/457.4 MB 34.4 MB/s eta 0:00:10\n",
      "     --------- --------------------------- 121.6/457.4 MB 32.8 MB/s eta 0:00:11\n",
      "     --------- --------------------------- 122.9/457.4 MB 31.2 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 124.1/457.4 MB 31.2 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 125.5/457.4 MB 32.7 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 127.2/457.4 MB 34.4 MB/s eta 0:00:10\n",
      "     ---------- -------------------------- 128.9/457.4 MB 32.7 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 130.1/457.4 MB 32.7 MB/s eta 0:00:11\n",
      "     ---------- -------------------------- 131.8/457.4 MB 32.8 MB/s eta 0:00:10\n",
      "     ---------- -------------------------- 133.9/457.4 MB 34.4 MB/s eta 0:00:10\n",
      "     ---------- -------------------------- 135.8/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 137.3/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 138.8/457.4 MB 34.4 MB/s eta 0:00:10\n",
      "     ----------- ------------------------- 141.0/457.4 MB 38.5 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 142.8/457.4 MB 38.5 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 144.6/457.4 MB 38.5 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 146.2/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ----------- ------------------------- 147.5/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ------------ ------------------------ 149.2/457.4 MB 38.6 MB/s eta 0:00:08\n",
      "     ------------ ------------------------ 151.7/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     ------------ ------------------------ 153.2/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     ------------ ------------------------ 155.1/457.4 MB 36.4 MB/s eta 0:00:09\n",
      "     ------------ ------------------------ 157.2/457.4 MB 40.9 MB/s eta 0:00:08\n",
      "     ------------ ------------------------ 158.7/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 160.8/457.4 MB 40.9 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 162.4/457.4 MB 38.6 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 164.4/457.4 MB 38.6 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 166.7/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 168.8/457.4 MB 43.7 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 170.3/457.4 MB 40.9 MB/s eta 0:00:08\n",
      "     ------------- ----------------------- 172.5/457.4 MB 40.9 MB/s eta 0:00:07\n",
      "     -------------- ---------------------- 174.0/457.4 MB 40.9 MB/s eta 0:00:07\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 175.0/457.4 MB 38.5 MB/s eta 0:00:08\n",
      "     -------------- ---------------------- 177.9/457.4 MB 22.6 MB/s eta 0:00:13\n",
      "     -------------- ---------------------- 177.9/457.4 MB 22.6 MB/s eta 0:00:13\n",
      "     -------------- ---------------------- 177.9/457.4 MB 22.6 MB/s eta 0:00:13\n",
      "     -------------- ---------------------- 177.9/457.4 MB 22.6 MB/s eta 0:00:13\n",
      "     -------------- ---------------------- 179.0/457.4 MB 16.8 MB/s eta 0:00:17\n",
      "     -------------- ---------------------- 182.6/457.4 MB 18.2 MB/s eta 0:00:16\n",
      "     -------------- ---------------------- 183.2/457.4 MB 17.2 MB/s eta 0:00:16\n",
      "     -------------- ---------------------- 185.3/457.4 MB 28.5 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 185.4/457.4 MB 28.5 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 185.4/457.4 MB 28.5 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 185.4/457.4 MB 28.5 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 188.4/457.4 MB 29.7 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 188.4/457.4 MB 29.7 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 188.4/457.4 MB 29.7 MB/s eta 0:00:10\n",
      "     --------------- --------------------- 191.4/457.4 MB 21.8 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 192.6/457.4 MB 21.9 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 194.9/457.4 MB 16.4 MB/s eta 0:00:17\n",
      "     --------------- --------------------- 195.4/457.4 MB 15.6 MB/s eta 0:00:17\n",
      "     --------------- --------------------- 195.9/457.4 MB 18.7 MB/s eta 0:00:14\n",
      "     --------------- --------------------- 197.4/457.4 MB 18.2 MB/s eta 0:00:15\n",
      "     --------------- --------------------- 197.4/457.4 MB 16.0 MB/s eta 0:00:17\n",
      "     ---------------- -------------------- 199.6/457.4 MB 18.7 MB/s eta 0:00:14\n",
      "     ---------------- -------------------- 201.4/457.4 MB 17.7 MB/s eta 0:00:15\n",
      "     ---------------- -------------------- 202.4/457.4 MB 17.3 MB/s eta 0:00:15\n",
      "     ---------------- -------------------- 203.8/457.4 MB 26.2 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 205.5/457.4 MB 26.2 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 206.8/457.4 MB 29.8 MB/s eta 0:00:09\n",
      "     ---------------- -------------------- 208.3/457.4 MB 34.4 MB/s eta 0:00:08\n",
      "     ---------------- -------------------- 209.9/457.4 MB 32.8 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 211.5/457.4 MB 31.2 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 213.0/457.4 MB 34.4 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 214.4/457.4 MB 34.4 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 216.1/457.4 MB 32.7 MB/s eta 0:00:08\n",
      "     ----------------- ------------------- 217.8/457.4 MB 34.4 MB/s eta 0:00:07\n",
      "     ----------------- ------------------- 219.5/457.4 MB 34.6 MB/s eta 0:00:07\n",
      "     ----------------- ------------------- 220.4/457.4 MB 34.4 MB/s eta 0:00:07\n",
      "     ----------------- ------------------- 221.9/457.4 MB 32.8 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 223.1/457.4 MB 34.4 MB/s eta 0:00:07\n",
      "     ------------------ ------------------ 223.7/457.4 MB 28.5 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 226.2/457.4 MB 32.8 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 227.7/457.4 MB 29.7 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 229.1/457.4 MB 29.7 MB/s eta 0:00:08\n",
      "     ------------------ ------------------ 231.1/457.4 MB 36.4 MB/s eta 0:00:07\n",
      "     ------------------ ------------------ 232.8/457.4 MB 32.7 MB/s eta 0:00:07\n",
      "     ------------------ ------------------ 234.2/457.4 MB 38.5 MB/s eta 0:00:06\n",
      "     ------------------- ----------------- 235.6/457.4 MB 34.6 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 237.8/457.4 MB 36.4 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 239.1/457.4 MB 36.4 MB/s eta 0:00:06\n",
      "     ------------------- ----------------- 240.6/457.4 MB 36.4 MB/s eta 0:00:06\n",
      "     ------------------- ----------------- 242.0/457.4 MB 32.7 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 243.5/457.4 MB 32.7 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 244.0/457.4 MB 34.6 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 244.0/457.4 MB 34.6 MB/s eta 0:00:07\n",
      "     ------------------- ----------------- 246.1/457.4 MB 28.5 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 246.1/457.4 MB 28.5 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 247.5/457.4 MB 24.2 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 247.5/457.4 MB 24.2 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 249.1/457.4 MB 21.8 MB/s eta 0:00:10\n",
      "     -------------------- ---------------- 249.1/457.4 MB 21.8 MB/s eta 0:00:10\n",
      "     -------------------- ---------------- 250.0/457.4 MB 19.2 MB/s eta 0:00:11\n",
      "     -------------------- ---------------- 252.1/457.4 MB 19.8 MB/s eta 0:00:11\n",
      "     -------------------- ---------------- 253.2/457.4 MB 19.3 MB/s eta 0:00:11\n",
      "     -------------------- ---------------- 254.4/457.4 MB 22.6 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 255.5/457.4 MB 21.1 MB/s eta 0:00:10\n",
      "     -------------------- ---------------- 256.7/457.4 MB 23.4 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 257.8/457.4 MB 27.3 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 259.1/457.4 MB 24.2 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 260.7/457.4 MB 28.5 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 262.8/457.4 MB 29.7 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 263.9/457.4 MB 29.7 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 265.5/457.4 MB 31.2 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 267.4/457.4 MB 34.4 MB/s eta 0:00:06\n",
      "     --------------------- --------------- 268.8/457.4 MB 34.6 MB/s eta 0:00:06\n",
      "     --------------------- --------------- 270.2/457.4 MB 34.4 MB/s eta 0:00:06\n",
      "     --------------------- --------------- 271.5/457.4 MB 34.4 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 272.6/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 273.8/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 275.7/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 277.0/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 278.2/457.4 MB 29.7 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 278.9/457.4 MB 27.3 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 281.4/457.4 MB 29.8 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 282.0/457.4 MB 32.8 MB/s eta 0:00:06\n",
      "     ---------------------- -------------- 283.5/457.4 MB 29.7 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 285.7/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 287.0/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 288.4/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 289.7/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ----------------------- ------------- 291.0/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 292.5/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ----------------------- ------------- 293.9/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 295.5/457.4 MB 29.7 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 297.2/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 298.4/457.4 MB 29.7 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 300.2/457.4 MB 31.2 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 301.8/457.4 MB 32.7 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 303.2/457.4 MB 32.8 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 304.9/457.4 MB 32.8 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 306.6/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 308.3/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 309.6/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 311.3/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 313.0/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 314.4/457.4 MB 32.7 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 316.1/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 318.1/457.4 MB 34.4 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 319.6/457.4 MB 36.3 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 321.5/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 323.6/457.4 MB 38.6 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 325.1/457.4 MB 38.6 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 326.8/457.4 MB 40.9 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 328.5/457.4 MB 38.5 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 330.2/457.4 MB 38.5 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 331.8/457.4 MB 38.5 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 333.9/457.4 MB 38.5 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 335.4/457.4 MB 38.6 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 336.9/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 338.5/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 339.9/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 341.6/457.4 MB 34.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 343.7/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 345.7/457.4 MB 38.5 MB/s eta 0:00:03\n",
      "     ---------------------------- -------- 347.2/457.4 MB 36.3 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 348.0/457.4 MB 36.4 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 348.2/457.4 MB 29.8 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 351.4/457.4 MB 34.4 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 354.6/457.4 MB 38.5 MB/s eta 0:00:03\n",
      "     ---------------------------- -------- 357.7/457.4 MB 46.7 MB/s eta 0:00:03\n",
      "     ----------------------------- ------- 361.1/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 364.0/457.4 MB 65.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 367.1/457.4 MB 65.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 370.1/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 373.2/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 376.3/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 379.0/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 382.0/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 385.2/457.4 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 388.0/457.4 MB 65.2 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 391.5/457.4 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ----- 394.3/457.4 MB 65.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 397.4/457.4 MB 65.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 399.0/457.4 MB 59.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 402.2/457.4 MB 59.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 402.2/457.4 MB 59.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 404.9/457.4 MB 46.7 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 406.7/457.4 MB 40.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 407.6/457.4 MB 38.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 407.6/457.4 MB 38.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 407.6/457.4 MB 38.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 407.6/457.4 MB 38.5 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 409.4/457.4 MB 24.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 410.8/457.4 MB 22.6 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 411.4/457.4 MB 21.1 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 412.9/457.4 MB 22.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 412.9/457.4 MB 22.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 415.0/457.4 MB 19.3 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 415.0/457.4 MB 19.3 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 416.8/457.4 MB 18.2 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 419.3/457.4 MB 26.2 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 420.5/457.4 MB 24.2 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 421.6/457.4 MB 26.2 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 423.1/457.4 MB 26.2 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 424.6/457.4 MB 29.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 426.1/457.4 MB 34.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 427.5/457.4 MB 31.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 428.6/457.4 MB 29.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 430.4/457.4 MB 29.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 432.1/457.4 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 433.3/457.4 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 434.9/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 436.2/457.4 MB 29.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 437.9/457.4 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 439.0/457.4 MB 32.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 440.7/457.4 MB 32.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 442.2/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 443.9/457.4 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  445.5/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  446.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.8/457.4 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  450.8/457.4 MB 19.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  451.2/457.4 MB 18.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  451.8/457.4 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  454.6/457.4 MB 18.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.5/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.0/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.4/457.4 MB 18.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 457.4/457.4 MB 9.4 MB/s eta 0:00:00\n",
      "Collecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
      "  Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
      "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
      "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
      "  Downloading curated_tokenizers-0.0.9-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.6.0)\n",
      "Requirement already satisfied: regex>=2022 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2023.10.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.1.3)\n",
      "Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl (236 kB)\n",
      "   ---------------------------------------- 0.0/236.3 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/236.3 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 236.3/236.3 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading curated_tokenizers-0.0.9-cp312-cp312-win_amd64.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.5/731.5 kB 23.3 MB/s eta 0:00:00\n",
      "Downloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
      "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 spacy-curated-transformers-0.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n",
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.9 MB 1.7 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.1/12.9 MB 13.4 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 2.4/12.9 MB 19.5 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.3/12.9 MB 25.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.3/12.9 MB 28.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.9 MB 32.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.3/12.9 MB 43.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.9/12.9 MB 46.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 43.7 MB/s eta 0:00:00\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "Collecting es-dep-news-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_dep_news_trf-3.8.0/es_dep_news_trf-3.8.0-py3-none-any.whl (407.8 MB)\n",
      "     ---------------------------------------- 0.0/407.8 MB ? eta -:--:--\n",
      "     -------------------------------------- 0.0/407.8 MB 653.6 kB/s eta 0:10:24\n",
      "     ---------------------------------------- 0.2/407.8 MB 2.3 MB/s eta 0:02:59\n",
      "     ---------------------------------------- 1.0/407.8 MB 6.9 MB/s eta 0:00:59\n",
      "     ---------------------------------------- 1.6/407.8 MB 8.4 MB/s eta 0:00:49\n",
      "     ---------------------------------------- 2.3/407.8 MB 9.9 MB/s eta 0:00:41\n",
      "     --------------------------------------- 3.4/407.8 MB 12.2 MB/s eta 0:00:34\n",
      "     --------------------------------------- 4.3/407.8 MB 13.0 MB/s eta 0:00:32\n",
      "     --------------------------------------- 5.1/407.8 MB 14.1 MB/s eta 0:00:29\n",
      "      -------------------------------------- 6.6/407.8 MB 15.6 MB/s eta 0:00:26\n",
      "      -------------------------------------- 7.9/407.8 MB 16.7 MB/s eta 0:00:24\n",
      "      -------------------------------------- 9.0/407.8 MB 18.0 MB/s eta 0:00:23\n",
      "     - ------------------------------------ 10.8/407.8 MB 23.4 MB/s eta 0:00:17\n",
      "     - ------------------------------------ 12.7/407.8 MB 28.5 MB/s eta 0:00:14\n",
      "     - ------------------------------------ 14.5/407.8 MB 32.7 MB/s eta 0:00:13\n",
      "     - ------------------------------------ 16.2/407.8 MB 34.4 MB/s eta 0:00:12\n",
      "     - ------------------------------------ 18.2/407.8 MB 38.5 MB/s eta 0:00:11\n",
      "     - ------------------------------------ 19.4/407.8 MB 38.5 MB/s eta 0:00:11\n",
      "     - ------------------------------------ 20.5/407.8 MB 32.8 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 22.1/407.8 MB 34.4 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 24.4/407.8 MB 36.4 MB/s eta 0:00:11\n",
      "     -- ----------------------------------- 25.5/407.8 MB 32.8 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 26.9/407.8 MB 32.7 MB/s eta 0:00:12\n",
      "     -- ----------------------------------- 28.2/407.8 MB 31.2 MB/s eta 0:00:13\n",
      "     -- ----------------------------------- 29.3/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     -- ----------------------------------- 30.7/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     -- ----------------------------------- 31.9/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 33.2/407.8 MB 27.3 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 34.7/407.8 MB 28.5 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 36.2/407.8 MB 28.5 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 37.6/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 39.2/407.8 MB 29.7 MB/s eta 0:00:13\n",
      "     --- ---------------------------------- 40.5/407.8 MB 31.2 MB/s eta 0:00:12\n",
      "     --- ---------------------------------- 42.1/407.8 MB 31.1 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 43.2/407.8 MB 31.2 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 45.1/407.8 MB 32.8 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 46.8/407.8 MB 32.8 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 48.7/407.8 MB 34.4 MB/s eta 0:00:11\n",
      "     ---- --------------------------------- 50.3/407.8 MB 34.4 MB/s eta 0:00:11\n",
      "     ---- --------------------------------- 51.4/407.8 MB 34.4 MB/s eta 0:00:11\n",
      "     ---- --------------------------------- 52.8/407.8 MB 32.7 MB/s eta 0:00:11\n",
      "     ----- -------------------------------- 54.6/407.8 MB 34.4 MB/s eta 0:00:11\n",
      "     ----- -------------------------------- 55.9/407.8 MB 32.8 MB/s eta 0:00:11\n",
      "     ----- -------------------------------- 56.8/407.8 MB 29.8 MB/s eta 0:00:12\n",
      "     ----- -------------------------------- 58.1/407.8 MB 29.7 MB/s eta 0:00:12\n",
      "     ----- -------------------------------- 59.4/407.8 MB 28.5 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 60.5/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 61.8/407.8 MB 28.4 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 63.2/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 64.4/407.8 MB 26.2 MB/s eta 0:00:14\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 66.0/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 68.2/407.8 MB 20.5 MB/s eta 0:00:17\n",
      "     ------ ------------------------------- 68.7/407.8 MB 19.3 MB/s eta 0:00:18\n",
      "     ------ ------------------------------- 70.7/407.8 MB 20.5 MB/s eta 0:00:17\n",
      "     ------ ------------------------------- 72.3/407.8 MB 21.1 MB/s eta 0:00:16\n",
      "     ------ ------------------------------- 73.4/407.8 MB 20.5 MB/s eta 0:00:17\n",
      "     ------ ------------------------------- 74.4/407.8 MB 19.8 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 75.6/407.8 MB 19.9 MB/s eta 0:00:17\n",
      "     ------- ------------------------------ 76.7/407.8 MB 31.2 MB/s eta 0:00:11\n",
      "     ------- ------------------------------ 77.9/407.8 MB 27.3 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 79.3/407.8 MB 28.5 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 80.6/407.8 MB 27.3 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 82.0/407.8 MB 26.2 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 83.4/407.8 MB 27.3 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 84.9/407.8 MB 28.4 MB/s eta 0:00:12\n",
      "     ------- ------------------------------ 85.2/407.8 MB 26.2 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 85.6/407.8 MB 24.2 MB/s eta 0:00:14\n",
      "     -------- ----------------------------- 88.7/407.8 MB 29.7 MB/s eta 0:00:11\n",
      "     -------- ----------------------------- 90.6/407.8 MB 31.2 MB/s eta 0:00:11\n",
      "     -------- ----------------------------- 92.2/407.8 MB 31.2 MB/s eta 0:00:11\n",
      "     -------- ----------------------------- 94.0/407.8 MB 32.7 MB/s eta 0:00:10\n",
      "     -------- ----------------------------- 95.4/407.8 MB 36.3 MB/s eta 0:00:09\n",
      "     --------- ---------------------------- 97.1/407.8 MB 38.5 MB/s eta 0:00:09\n",
      "     --------- ---------------------------- 99.5/407.8 MB 38.5 MB/s eta 0:00:09\n",
      "     --------- --------------------------- 100.9/407.8 MB 38.5 MB/s eta 0:00:08\n",
      "     --------- --------------------------- 103.0/407.8 MB 40.9 MB/s eta 0:00:08\n",
      "     --------- --------------------------- 105.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     --------- --------------------------- 107.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     --------- --------------------------- 109.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ---------- -------------------------- 111.7/407.8 MB 46.7 MB/s eta 0:00:07\n",
      "     ---------- -------------------------- 113.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ---------- -------------------------- 115.4/407.8 MB 46.7 MB/s eta 0:00:07\n",
      "     ---------- -------------------------- 118.1/407.8 MB 50.4 MB/s eta 0:00:06\n",
      "     ---------- -------------------------- 119.8/407.8 MB 46.7 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 121.9/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 124.5/407.8 MB 50.4 MB/s eta 0:00:06\n",
      "     ----------- ------------------------- 125.8/407.8 MB 46.7 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 128.1/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 130.8/407.8 MB 50.4 MB/s eta 0:00:06\n",
      "     ----------- ------------------------- 132.1/407.8 MB 43.5 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 134.1/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 136.8/407.8 MB 46.7 MB/s eta 0:00:06\n",
      "     ------------ ------------------------ 138.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 140.0/407.8 MB 38.6 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 142.8/407.8 MB 46.7 MB/s eta 0:00:06\n",
      "     ------------- ----------------------- 144.2/407.8 MB 43.7 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 145.8/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 148.9/407.8 MB 46.7 MB/s eta 0:00:06\n",
      "     ------------- ----------------------- 150.5/407.8 MB 43.5 MB/s eta 0:00:06\n",
      "     ------------- ----------------------- 152.4/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 153.2/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 153.2/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 153.2/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 153.2/407.8 MB 40.9 MB/s eta 0:00:07\n",
      "     -------------- ---------------------- 156.1/407.8 MB 27.3 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 156.1/407.8 MB 27.3 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 159.0/407.8 MB 24.2 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 161.7/407.8 MB 27.3 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 164.1/407.8 MB 54.4 MB/s eta 0:00:05\n",
      "     --------------- --------------------- 166.9/407.8 MB 65.2 MB/s eta 0:00:04\n",
      "     --------------- --------------------- 169.5/407.8 MB 59.5 MB/s eta 0:00:05\n",
      "     --------------- --------------------- 172.5/407.8 MB 59.8 MB/s eta 0:00:04\n",
      "     --------------- --------------------- 175.5/407.8 MB 59.5 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 178.1/407.8 MB 59.5 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 181.2/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 184.5/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 187.3/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ----------------- ------------------- 190.3/407.8 MB 65.2 MB/s eta 0:00:04\n",
      "     ----------------- ------------------- 193.0/407.8 MB 65.2 MB/s eta 0:00:04\n",
      "     ----------------- ------------------- 195.9/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 198.8/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 201.8/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 205.1/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 208.1/407.8 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------- ----------------- 211.3/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     ------------------- ----------------- 214.3/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------------- ----------------- 217.5/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------------- ----------------- 220.1/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------- ---------------- 222.8/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------- ---------------- 226.2/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------- ---------------- 229.0/407.8 MB 59.5 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 232.5/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     --------------------- --------------- 235.3/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     --------------------- --------------- 238.4/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     --------------------- --------------- 241.9/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 245.0/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 248.3/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 251.9/407.8 MB 73.1 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 255.3/407.8 MB 72.6 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 258.3/407.8 MB 65.6 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 261.7/407.8 MB 72.6 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 264.9/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 268.0/407.8 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 271.8/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     ------------------------ ------------ 274.9/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     ------------------------- ----------- 278.0/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------- ----------- 281.6/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------- ----------- 284.2/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 287.9/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 291.1/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 294.5/407.8 MB 81.8 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 297.2/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 300.9/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 303.7/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 307.3/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 310.3/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 313.8/407.8 MB 73.1 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 317.3/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 320.1/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 323.1/407.8 MB 72.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 326.2/407.8 MB 65.2 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 329.4/407.8 MB 65.2 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 332.4/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 335.3/407.8 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 337.4/407.8 MB 65.2 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 340.0/407.8 MB 54.7 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 341.4/407.8 MB 46.7 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 345.2/407.8 MB 54.4 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 347.2/407.8 MB 50.4 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 348.9/407.8 MB 50.1 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 350.4/407.8 MB 43.7 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 352.0/407.8 MB 43.7 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 353.5/407.8 MB 38.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 355.2/407.8 MB 38.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 356.9/407.8 MB 36.4 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 358.3/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 359.0/407.8 MB 34.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 361.1/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 362.9/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 364.5/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 365.8/407.8 MB 32.7 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 366.9/407.8 MB 31.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 368.3/407.8 MB 31.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 369.6/407.8 MB 34.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 370.8/407.8 MB 31.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 371.9/407.8 MB 29.7 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 373.5/407.8 MB 28.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 374.6/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 375.9/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 377.0/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 378.3/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 379.8/407.8 MB 27.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 381.1/407.8 MB 28.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 382.5/407.8 MB 28.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 384.0/407.8 MB 28.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 385.8/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 387.4/407.8 MB 31.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 388.6/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 389.8/407.8 MB 29.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 391.3/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 393.1/407.8 MB 32.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 394.3/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 395.5/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  397.1/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  398.3/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  399.9/407.8 MB 29.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  401.8/407.8 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  403.1/407.8 MB 29.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  405.0/407.8 MB 34.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  406.5/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  407.8/407.8 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- 407.8/407.8 MB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from es-dep-news-trf==3.8.0) (0.3.0)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (0.0.9)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (2.6.0)\n",
      "Requirement already satisfied: regex>=2022 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (2023.10.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->es-dep-news-trf==3.8.0) (2.1.3)\n",
      "Installing collected packages: es-dep-news-trf\n",
      "Successfully installed es-dep-news-trf-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_dep_news_trf')\n"
     ]
    }
   ],
   "source": [
    "%pip install pylats taaled spacy\n",
    "# English models\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_trf\n",
    "\n",
    "# Spanish models (used as fallback)\n",
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotnine has not been installed.\n",
      "To enable advanced data visualization features, please install plotnine.\n",
      "Attempting to load spacy model: en_core_web_sm\n",
      "Successfully loaded spacy model: en_core_web_sm\n",
      "Attempting to load spacy model: en_core_web_trf\n",
      "Successfully loaded spacy model: en_core_web_trf\n",
      "Attempting to load spacy model: es_core_news_sm\n",
      "Successfully loaded spacy model: es_core_news_sm\n",
      "Attempting to load spacy model: es_dep_news_trf\n",
      "Successfully loaded spacy model: es_dep_news_trf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing MATTR: 100%|██████████| 1805/1805 [06:18<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean MATTR values saved to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from taaled import ld\n",
    "from pylats import lats\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "# Read rows\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "\n",
    "    # Ensure 'mattr' column exists\n",
    "    if \"mattr\" not in fieldnames:\n",
    "        fieldnames.append(\"mattr\")\n",
    "    # Drop 'mattr_reason' if it exists\n",
    "    if \"mattr_reason\" in fieldnames:\n",
    "        fieldnames.remove(\"mattr_reason\")\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Computing MATTR\"):\n",
    "        review_text = row.get(\"review_text\", \"\").strip()\n",
    "        mattr_value = \"\"\n",
    "\n",
    "        try:\n",
    "            cleaned = lats.Normalize(review_text, lats.ld_params_en)\n",
    "            tokens = cleaned.toks\n",
    "            mattr_value = f\"{ld.lexdiv(tokens).mattr:.4f}\"\n",
    "        except Exception as e:\n",
    "            mattr_value = \"\"\n",
    "\n",
    "        row[\"mattr\"] = mattr_value\n",
    "        # Remove 'mattr_reason' if it exists in the row\n",
    "        row.pop(\"mattr_reason\", None)\n",
    "        output_rows.append(row)\n",
    "\n",
    "# Write updated file\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Clean MATTR values saved to review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\soroush\\anaconda3\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in c:\\users\\soroush\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\soroush\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: click in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install transformers torch nltk\n",
    "\n",
    "###########################\n",
    "# Apple silicon support\n",
    "# Uninstall current PyTorch version (if any)\n",
    "# !pip uninstall torch -y\n",
    "\n",
    "# Install PyTorch with MPS (Metal Performance Shaders) support\n",
    "# !pip install torch==2.1.2 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "###########################\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting Questions: 100%|██████████| 1805/1805 [03:15<00:00,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Questions counted and saved in review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "model.eval()\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "# Load review rows\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "    if \"question_count\" not in fieldnames:\n",
    "        fieldnames.append(\"question_count\")\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Detecting Questions\"):\n",
    "        review_text = row.get(\"review_text\", \"\")\n",
    "        question_count = 0\n",
    "\n",
    "        try:\n",
    "            sentences = sent_tokenize(review_text)\n",
    "            for sent in sentences:\n",
    "                inputs = tokenizer(\n",
    "                    sent,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    max_length=64,\n",
    "                    padding=True\n",
    "                )\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    predicted = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "                    # Label 0 = question\n",
    "                    if predicted == 0:\n",
    "                        question_count += 1\n",
    "        except Exception as e:\n",
    "            question_count = \"\"\n",
    "\n",
    "        row[\"question_count\"] = question_count\n",
    "        output_rows.append(row)\n",
    "\n",
    "# Save updated CSV\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Questions counted and saved in review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting Citations: 100%|██████████| 1805/1805 [00:00<00:00, 12740.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Citation counts added to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Citation counting logic ---\n",
    "def count_citations(text):\n",
    "    citation_patterns = [\n",
    "        r'\\[\\d+(?:,\\s*\\d+)*\\]',                         # [1], [1, 2, 3]\n",
    "        r'\\([A-Za-z]+ et al\\.,\\s*\\d{4}\\)',               # (Smith et al., 2020)\n",
    "        r'\\(\\d{4}[a-z]?\\)',                              # (2020), (2020a)\n",
    "        r'\\[[A-Za-z]+\\d{4}[a-z]?\\]',                     # [Smith2020], [Johnson2021a]\n",
    "        r'\\b(?:doi:|arxiv:|https?://[^\\s]+)',             # DOI, arXiv, URLs\n",
    "    ]\n",
    "    pattern = '|'.join(citation_patterns)\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)\n",
    "\n",
    "# --- Load CSV and apply ---\n",
    "output_rows = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "\n",
    "    # Update for citation_count\n",
    "    if \"citation_count\" not in fieldnames:\n",
    "        fieldnames.append(\"citation_count\")\n",
    "    if \"has_citation\" in fieldnames:\n",
    "        fieldnames.remove(\"has_citation\")  # Remove old 'has_citation' if needed\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Counting Citations\"):\n",
    "        review_text = row.get(\"review_text\", \"\")\n",
    "        citation_count = count_citations(review_text)\n",
    "        row[\"citation_count\"] = citation_count\n",
    "        output_rows.append(row)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Citation counts added to review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Total reviews: 1805\n",
      "🔍 Reviews with citations: 110\n",
      "📊 Percentage: 6.09%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(output_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    total = 0\n",
    "    with_citations = 0\n",
    "\n",
    "    for row in reader:\n",
    "        total += 1\n",
    "        if row.get(\"citation_count\") == \"2\":\n",
    "            with_citations += 1\n",
    "\n",
    "print(f\"📄 Total reviews: {total}\")\n",
    "print(f\"🔍 Reviews with citations: {with_citations}\")\n",
    "print(f\"📊 Percentage: {(with_citations / total * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\soroush\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Soroush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Sentiment: 100%|██████████| 1805/1805 [00:03<00:00, 509.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sentiment polarity added to review_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "# Read and process the file\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "\n",
    "    # Add new column if not already there\n",
    "    if \"sentiment_polarity\" not in fieldnames:\n",
    "        fieldnames.append(\"sentiment_polarity\")\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Analyzing Sentiment\"):\n",
    "        review_text = row.get(\"review_text\", \"\").strip()\n",
    "        try:\n",
    "            blob = TextBlob(review_text)\n",
    "            sentiment = blob.sentiment.polarity\n",
    "        except Exception:\n",
    "            sentiment = \"\"\n",
    "\n",
    "        row[\"sentiment_polarity\"] = sentiment\n",
    "        output_rows.append(row)\n",
    "\n",
    "# Write updated CSV\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Sentiment polarity added to review_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: convokit in c:\\users\\soroush\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (3.8.4)\n",
      "Requirement already satisfied: scipy>1.14 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.15.2)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.2.2)\n",
      "Collecting numpy>=2.0.0 (from convokit)\n",
      "  Using cached numpy-2.2.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: msgpack-numpy>=0.4.3.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.4.8)\n",
      "Requirement already satisfied: spacy>=3.8.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (3.8.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.4.2)\n",
      "Requirement already satisfied: nltk>=3.4 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (3.9.1)\n",
      "Requirement already satisfied: dill>=0.2.9 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.3.8)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.4.2)\n",
      "Requirement already satisfied: clean-text>=0.6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.6.0)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.2.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (4.66.4)\n",
      "Requirement already satisfied: pymongo>=4.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (4.11.3)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (6.0.1)\n",
      "Requirement already satisfied: dnspython>=1.16.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.7.0)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (8.3.4)\n",
      "Requirement already satisfied: h5py==3.12.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (3.12.1)\n",
      "Requirement already satisfied: numexpr>=2.8.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.8.7)\n",
      "Requirement already satisfied: ruff>=0.4.8 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.11.2)\n",
      "Requirement already satisfied: bottleneck in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.3.7)\n",
      "Requirement already satisfied: accelerate in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (1.5.2)\n",
      "Requirement already satisfied: peft in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.15.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.45.4)\n",
      "Requirement already satisfied: transformers in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (4.49.0)\n",
      "Requirement already satisfied: trl>=0.12.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (0.16.0)\n",
      "Requirement already satisfied: tensorflow>=2.18.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.19.0)\n",
      "Requirement already satisfied: tf-keras<3.0.0,>=2.17.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from convokit) (2.19.0)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from clean-text>=0.6.0->convokit) (1.7.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from clean-text>=0.6.0->convokit) (6.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->convokit) (2.9.0.post0)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.3)\n",
      "Requirement already satisfied: click in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.4->convokit) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from nltk>=3.4->convokit) (2023.10.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->convokit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->convokit) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->convokit) (2.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (0.15.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (69.5.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from spacy>=3.8.2->convokit) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (3.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (3.9.0)\n",
      "  Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorflow>=2.18.0->convokit) (0.5.1)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->convokit) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->convokit) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->convokit) (0.4.6)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from trl>=0.12.2->convokit) (3.4.1)\n",
      "Requirement already satisfied: rich in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from trl>=0.12.2->convokit) (13.3.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from accelerate->convokit) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from accelerate->convokit) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from accelerate->convokit) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from accelerate->convokit) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers->convokit) (3.13.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from transformers->convokit) (0.21.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->convokit) (0.43.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (19.0.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (3.9.5)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.5)\n",
      "Requirement already satisfied: namex in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.14.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit) (3.0.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate->convokit) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate->convokit) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate->convokit) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from rich->trl>=0.12.2->convokit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from rich->trl>=0.12.2->convokit) (2.15.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from jinja2->spacy>=3.8.2->convokit) (2.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=3.0.0->trl>=0.12.2->convokit) (1.9.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soroush\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->trl>=0.12.2->convokit) (0.1.0)\n",
      "Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Soroush\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Soroush\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
      "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 2.1.3 which is incompatible.\n",
      "streamlit 1.32.0 requires numpy<2,>=1.19.3, but you have numpy 2.1.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "      --------------------------------------- 0.2/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.5/12.8 MB 4.0 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.9/12.8 MB 5.7 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.2/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 6.4 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.5/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 8.8 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.5/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 5.1/12.8 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 11.2 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.7/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 8.0/12.8 MB 12.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 13.3 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.4/12.8 MB 15.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.5/12.8 MB 18.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 22.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 21.8 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install convokit\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Downloading training corpus...\n",
      "Dataset already exists at C:\\Users\\Soroush\\.convokit\\saved-corpora\\wiki-politeness-annotated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔧 Preparing Utterances: 100%|██████████| 1805/1805 [00:00<00:00, 257788.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Building test corpus...\n",
      "🧠 Parsing utterances...\n",
      "✨ Extracting politeness strategies...\n",
      "🎓 Training classifier...\n",
      "Initialized default classification model (standard scaled logistic regression).\n",
      "📈 Summarizing scores...\n",
      "🧾 Merging scores into CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔗 Assigning Scores: 1805it [00:00, 54323.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving to review_analysis.csv...\n",
      "✅ All done! Politeness scores are now in your CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "from convokit import Corpus, download, TextParser, PolitenessStrategies, Classifier, Utterance, Speaker\n",
    "\n",
    "# Step 1: Load training corpus\n",
    "print(\"📥 Downloading training corpus...\")\n",
    "train_corpus = Corpus(filename=download('wiki-politeness-annotated'))\n",
    "\n",
    "# Step 2: Load review data and convert to Utterances with dummy speakers\n",
    "review_utterances = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    for idx, row in tqdm(enumerate(reader), desc=\"🔧 Preparing Utterances\", total=1805):  # Adjust total if needed\n",
    "        review_text = row.get(\"review_text\", \"\").strip()\n",
    "        if review_text:\n",
    "            dummy_speaker = Speaker(id=f\"reviewer_{idx}\")\n",
    "            review_utterances.append(\n",
    "                Utterance(id=str(idx), text=review_text, speaker=dummy_speaker, meta={\"orig_row\": row})\n",
    "            )\n",
    "\n",
    "# Step 3: Build test corpus\n",
    "print(\"📦 Building test corpus...\")\n",
    "test_corpus = Corpus(utterances=review_utterances)\n",
    "\n",
    "# Step 4: Parse\n",
    "print(\"🧠 Parsing utterances...\")\n",
    "parser = TextParser()\n",
    "parser.transform(train_corpus)\n",
    "parser.transform(test_corpus)\n",
    "\n",
    "# Step 5: Extract politeness strategies\n",
    "print(\"✨ Extracting politeness strategies...\")\n",
    "ps = PolitenessStrategies()\n",
    "ps.transform(train_corpus)\n",
    "ps.transform(test_corpus)\n",
    "\n",
    "# Step 6: Train classifier\n",
    "print(\"🎓 Training classifier...\")\n",
    "clf = Classifier(obj_type='utterance', pred_feats=['politeness_strategies'],\n",
    "                 labeller=lambda utt: utt.meta.get(\"Binary\") == 1)\n",
    "clf.fit(train_corpus)\n",
    "clf.transform(test_corpus)\n",
    "\n",
    "# Step 7: Summarize results\n",
    "print(\"📈 Summarizing scores...\")\n",
    "results = clf.summarize(test_corpus)\n",
    "\n",
    "# Step 8: Merge back to CSV rows\n",
    "print(\"🧾 Merging scores into CSV...\")\n",
    "output_rows = []\n",
    "fieldnames = list(reader[0].keys())\n",
    "if \"politeness_score\" not in fieldnames:\n",
    "    fieldnames.append(\"politeness_score\")\n",
    "\n",
    "for utt in tqdm(test_corpus.iter_utterances(), desc=\"🔗 Assigning Scores\"):\n",
    "    row = utt.meta[\"orig_row\"]\n",
    "    try:\n",
    "        score = results.loc[utt.id, \"pred_score\"]\n",
    "        row[\"politeness_score\"] = round(score, 4)\n",
    "    except KeyError:\n",
    "        row[\"politeness_score\"] = \"\"\n",
    "    output_rows.append(row)\n",
    "\n",
    "# Step 9: Save\n",
    "print(\"💾 Saving to review_analysis.csv...\")\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ All done! Politeness scores are now in your CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7215288f8404a9ea87ece7655851c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soroush\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Soroush\\.cache\\huggingface\\hub\\models--allenai--specter. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87838764a35d4df3a344b12f23872afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870b2e6c16fb46c894ce1b14d32fec3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730c1c027cc84870b943e9e52ca06606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d227df08774bf99850f10ea3eb8e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Relevance Score:   0%|          | 0/1805 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec188adc3324edd8fe28307029f870e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Relevance Score: 100%|██████████| 1805/1805 [00:53<00:00, 33.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevance scores added to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Load SPECTER model ---\n",
    "model_name = \"allenai/specter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    fieldnames = list(reader[0].keys())\n",
    "\n",
    "    if \"similarity_score\" not in fieldnames:\n",
    "        fieldnames.append(\"similarity_score\")\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Computing Relevance Score\"):\n",
    "        review_text = row.get(\"review_text\", \"\")\n",
    "        paper_id = row.get(\"paper_id\", \"\").strip()\n",
    "\n",
    "        try:\n",
    "            # Find matching entry in data\n",
    "            matched_entry = next((entry for entry in data if str(entry.get(\"id\", \"\")).strip() == paper_id), None)\n",
    "\n",
    "            if matched_entry:\n",
    "                title = matched_entry.get(\"title\", \"\")\n",
    "                abstract = matched_entry.get(\"abstract\", \"\")\n",
    "                doc_text = f\"{title} {abstract}\"\n",
    "\n",
    "                # Encode document\n",
    "                doc_inputs = tokenizer(doc_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "                doc_inputs = {k: v.to(device) for k, v in doc_inputs.items()}\n",
    "                with torch.no_grad():\n",
    "                    doc_emb = model(**doc_inputs).last_hidden_state[:, 0, :]  # [CLS]\n",
    "\n",
    "                # Encode review text\n",
    "                review_inputs = tokenizer(review_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "                review_inputs = {k: v.to(device) for k, v in review_inputs.items()}\n",
    "                with torch.no_grad():\n",
    "                    review_emb = model(**review_inputs).last_hidden_state[:, 0, :]  # [CLS]\n",
    "\n",
    "                # Cosine similarity\n",
    "                similarity_score = F.cosine_similarity(doc_emb, review_emb).item()\n",
    "                row[\"similarity_score\"] = similarity_score\n",
    "\n",
    "            else:\n",
    "                row[\"similarity_score\"] = \"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            row[\"similarity_score\"] = \"\"\n",
    "\n",
    "        output_rows.append(row)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Relevance scores added to review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Title and Abstract (Escaping Newlines): 100%|██████████| 1805/1805 [00:00<00:00, 20347.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Title and Abstract (with clean \\n) added to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    original_fieldnames = list(reader[0].keys())\n",
    "\n",
    "    # Insert title and abstract at positions 5 and 6\n",
    "    new_fieldnames = original_fieldnames[:5] + [\"title\", \"abstract\"] + original_fieldnames[5:]\n",
    "\n",
    "    for row in tqdm(reader, desc=\"Adding Title and Abstract (Escaping Newlines)\"):\n",
    "        paper_id = row.get(\"paper_id\", \"\").strip()\n",
    "\n",
    "        # Find matching entry\n",
    "        matched_entry = next((entry for entry in data if str(entry.get(\"id\", \"\")).strip() == paper_id), None)\n",
    "\n",
    "        if matched_entry:\n",
    "            title = matched_entry.get(\"title\", \"\")\n",
    "            abstract = matched_entry.get(\"abstract\", \"\")\n",
    "        else:\n",
    "            title = \"\"\n",
    "            abstract = \"\"\n",
    "\n",
    "        # Escape real newlines in title and abstract\n",
    "        title = title.replace(\"\\r\\n\", \"\\\\n\").replace(\"\\n\", \"\\\\n\")\n",
    "        abstract = abstract.replace(\"\\r\\n\", \"\\\\n\").replace(\"\\n\", \"\\\\n\")\n",
    "\n",
    "        # Build new row\n",
    "        new_row = {}\n",
    "        for idx, field in enumerate(new_fieldnames):\n",
    "            if field == \"title\":\n",
    "                new_row[field] = title\n",
    "            elif field == \"abstract\":\n",
    "                new_row[field] = abstract\n",
    "            else:\n",
    "                # Map original fields\n",
    "                original_field_idx = idx if idx < 5 else idx - 2  # Adjust because we inserted 2 fields\n",
    "                if original_field_idx < len(original_fieldnames):\n",
    "                    original_field = original_fieldnames[original_field_idx]\n",
    "                    new_row[field] = row.get(original_field, \"\")\n",
    "\n",
    "        output_rows.append(new_row)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=new_fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ Title and Abstract (with clean \\\\n) added to review_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing num_days_before_deadline: 100%|██████████| 1805/1805 [00:00<00:00, 161750.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ num_days_before_deadline added to review_analysis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Helper: parse dates consistently\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, \"%d/%b/%Y\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "with open(input_file, mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    reader = list(csv.DictReader(f))\n",
    "    rows = list(reader)\n",
    "    fieldnames = list(rows[0].keys())\n",
    "\n",
    "    if \"num_days_before_deadline\" not in fieldnames:\n",
    "        fieldnames.append(\"num_days_before_deadline\")\n",
    "\n",
    "    # First: find latest review_date per paper_id\n",
    "    latest_review_dates = {}\n",
    "\n",
    "    for row in rows:\n",
    "        paper_id = row[\"paper_id\"]\n",
    "        review_date = parse_date(row[\"review_date\"])\n",
    "\n",
    "        if paper_id and review_date:\n",
    "            if paper_id not in latest_review_dates:\n",
    "                latest_review_dates[paper_id] = review_date\n",
    "            else:\n",
    "                if review_date > latest_review_dates[paper_id]:\n",
    "                    latest_review_dates[paper_id] = review_date\n",
    "\n",
    "    # Second: compute days before deadline for each review\n",
    "    for row in tqdm(rows, desc=\"Computing num_days_before_deadline\"):\n",
    "        paper_id = row[\"paper_id\"]\n",
    "        review_date = parse_date(row[\"review_date\"])\n",
    "        deadline_date = latest_review_dates.get(paper_id)\n",
    "\n",
    "        if review_date and deadline_date:\n",
    "            days_before_deadline = (deadline_date - review_date).days\n",
    "            row[\"num_days_before_deadline\"] = days_before_deadline\n",
    "        else:\n",
    "            row[\"num_days_before_deadline\"] = \"\"\n",
    "\n",
    "        output_rows.append(row)\n",
    "\n",
    "# --- Save updated CSV ---\n",
    "with open(input_file, mode='w', newline='', encoding='utf-8', errors='ignore') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_rows)\n",
    "\n",
    "print(\"✅ num_days_before_deadline added to review_analysis.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
