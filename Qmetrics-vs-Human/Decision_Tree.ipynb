{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_soundness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_presentation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_contribution",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "7591902f-ef5e-44c1-918e-74f7d3ed52ac",
       "rows": [
        [
         "0",
         "123",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "**Summary:** \nThis paper presents an open-source toolkit based on LoRa. I believe this work might be more appropriate for the \"benchmarking and datasets\" track. Positioned here, it's challenging for me to evaluate the innovation this paper offers. **Remarks:** \nWhile the improvements and variants on LoRa are relatively straightforward, the theoretical part of the paper seems sound. **Recommendation:** \nI would advise the authors to provide clear insights through experiments and offer some specific suggestions. I cannot evaluate this paper because I believe it is proper for a benchmarking and dataset track, not the main track.",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Reviewer_EGJf",
         "1701662567826",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "2.0",
         "94",
         "0",
         "0",
         "0.7561",
         "0.2401515152",
         "0.7697365284000001",
         "75",
         "42.4333",
         "11.2328",
         "14.7773",
         "13.5591",
         "13.3105",
         "0.2025",
         "77",
         "1",
         "2",
         "0",
         "0",
         "iclr"
        ],
        [
         "1",
         "123",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "This paper proposes a comprehensive library for evaluating text-to-image finetuning methods, typically based on LoRA. In addition to different algorithms, it also provides comprehensive evaluation criteria. Finally, some experimental results provide some insight about different finetuning methods. 1. This is a good engineering paper that provides a library for text-to-image finetuning methods evaluation.\n2. It support different matrix factorization techniques such as LoRA, LoHa, LoKr, DyLoRA, GLoRA, GLoKr and so on.\n3. This paper also consider comprehensive evaluation metrics, including fieldity, controllability, diversity, base model preservation and image quality. 1. This paper mainly focus on LoRA-based finetuing strategies, can it be expanded to other parameter-efficient finetuning methods such as \\[1\\] and \\[2\\]? It doesn't provide a clear explanation.\n2. The conclusion about the performance of different finetuning methods is not clearly presented in the experimental section. Maybe some tables can more straightforwardly represent your final conclusions. \n\n\\[1\\] Qiu, Zeju, et al. \"Controlling Text-to-Image Diffusion by Orthogonal Finetuning.\" arXiv preprint arXiv:2306.07280 (2023).\n\\[2\\] Xie, Enze, et al. \"DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning.\" arXiv preprint arXiv:2304.06648 (2023). Please refer to the weakness section.",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Reviewer_DWom",
         "1699636125239",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "187",
         "6",
         "9",
         "0.8365",
         "0.053061224500000004",
         "0.9117403030000001",
         "52",
         "16.9695",
         "13.6251",
         "15.3091",
         "13.6811",
         "14.7228",
         "0.2131",
         "78",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "2",
         "123",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "This author introduces LyCORIS, an open source library dedicated to fine-tuning of Stable Diffusion, which integrates a comprehensive range of finetuning methods. For rigorous comparisons between the implemented methods, the author proposes a comprehensive evaluation framework that incorporates a wide range of metrics. Based on the evaluation framework, the author performs extensive experiments to compare different fine-tuning algorithms and to assess the impact of the hyperparameters (i.e, training epochs, learning rate, trained layers, et al). Overall, the experiments, comparisons, analyses, and results of the entire paper are very well-rounded and thorough. 1. Developing an open-source library is of great significance in fostering the advancement of a particular field. After comparing the existing open-source libraries available online, the LyCORIS library offers a relatively more comprehensive set of algorithms.\n\n2. The author has developed a comprehensive benchmark to evaluate various algorithms from multiple perspectives, addressing a significant gap in the text-to-image field. This thorough evaluation and comparison of existing finetuning methods have been lacking in the domain until now.\n\n3. The author conducted comprehensive experiments for different algorithms and parameters; in addition, the author also provided a detailed analysis of the current mainstream fine-tuning algorithms. 1. HuggingFace has also released the PEFT library, which supports a wider range of pre-trained models and includes the methods mentioned in the paper. Therefore, what are the advantages of the LyCORIS library compared to PEFT?\n\n2. The paper conducted a multitude of experiments and comparisons on existing methods and various hyperparameters, leading to certain conclusions. Based on these findings, could there be a more optimal algorithm or design compared to previous ones? For this kind of paper that builds benchmarks based on a certain field, I would recommend the author to submit to a journal.",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Reviewer_PnHf",
         "1699636125143",
         "6.0",
         "4.0",
         "4.0",
         "4.0",
         "3.0",
         "289",
         "0",
         "5",
         "0.7676000000000001",
         "0.17214285710000002",
         "0.8675829172",
         "52",
         "20.4212",
         "15.1974",
         "18.2257",
         "16.5672",
         "16.3167",
         "0.1213",
         "86",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "3",
         "123",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "The authors propose LyCORIS, an open-source library that contains multiple fine-tuning techniques for Stable Diffusion. The authors also explore many improved fine-tuning techniques such as LoCon, LoHa and LoKr. This paper also presents evaluations for different fine-tuning techniques using multiple metrics and prompt types. (1) The theory and experiments are both solid. The paper has over 57 pages devoted to analyzing the fine-tuning techniques.\n(2) The details for experiments are very clear.\n(3) In addition to the framework, the authors also explore other fine-tuning techniques. (1) The results of this framework combined with ControlNet can be presented in this paper.\n(2) Efficiency (time and GPU memory cost) of different approaches are not provided and analyzed. (1) Please refer to the main questions in the weakness section.\n(2) A minor question: It will be better if the authors provide the results on other versions of stable diffusion, such as SD2.0 and SDXL.",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Reviewer_ekPo",
         "1699636125075",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "4.0",
         "151",
         "0",
         "0",
         "0.7539",
         "0.0711904762",
         "0.7818619609",
         "52",
         "48.9543",
         "9.5572",
         "10.8611",
         "11.3747",
         "10.6575",
         "0.1844",
         "84",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "4",
         "0",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "This paper introduces ν-ensembles, a novel deep ensemble algorithm that achieves both efficiency and conceptual simplicity. When presented with an unlabeled dataset, ν-ensembles generate distinct labelings for each ensemble member and subsequently fit both the training data and the randomly labeled data. The strength of ν-ensembles lies in their ability to enhance deep ensemble diversity and calibration without significantly increasing computational demands. Key strengths include improved calibration in both in-distribution and out-of-distribution settings, achieved without complex implementation or extensive hyperparameter tuning. This method maintains the efficiency of standard deep ensembles, ensuring diversity through a straightforward process of assigning random labels to unlabeled data points. The theoretical grounding via PAC-Bayesian analysis provides a guarantee of diversity, accuracy, and calibration on test data, making ν-ensembles a promising and efficient technique for enhancing deep neural network ensembles. 1. The paper lacks the related works of other calibration method such as train time calibration loss, and post hoc calibration which is very important in this domain.\n2. From my experience, the ECE measurement could be very unstable when classification accuracy is low. For experiments in table 1 for CIFAR100, the accuracy is very low, and the results may not reliable.\n3. The experiments lack the comparison with SOTA methods such as Focal Loss Calibration and Adaptive Label Smoothing. In table 1, how many times does the author run the experiments? Since the ECE measurement can be very stable among low prediction accuracy models, the ECE reported in Table can have very large variance. Please report the variance of multiple runs to verify the effectiveness of your method.\n\nThe experiment is limited to CIFAR10 datasets. Since the authors mention that the small dataset regime often happens in medical area. It is better to verify your algorithm on the small medical datasets.",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "Reviewer_HFRa",
         "1699636992453",
         "3.0",
         "4.0",
         "2.0",
         "2.0",
         "1.0",
         "296",
         "0",
         "3",
         "0.7848",
         "0.052918367300000005",
         "0.9382253885",
         "47",
         "22.8589",
         "14.6669",
         "18.2108",
         "15.9828",
         "15.2685",
         "0.2519",
         "90",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "5",
         "0",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "This paper introduces an ensembling technique for making use of unlabeled data in $k$-class classification. Namely, the authors suggest training $k$ models, each of which see a different (randomly selected without replacement) label for each unlabeled data point. In this way, at least one model is guaranteed to have trained on a correct data point (since we exhaust all labels). The authors show that this approach can have benefits with respect to calibration metrics such as ECE when compared to other ensembling approaches on small-scale datasets. - **Originality:** Although the proposed method is quite simple, to the best of my knowledge I have not seen a similar approach analyzed empirically or theoretically in the literature on ensembling. \n- **Quality:** The paper motivates the proposed method with a simple example and attempts to provide theoretical justification with a PAC-Bayes bound and related analysis. The algorithm and associated experiments in the paper are described well, but I have reservations about the quality of experiments as detailed in weaknesses below.\n- **Clarity:** The experiments in the paper are easy to follow, but the theoretical aspect of the work is not as clear.\n- **Significance:** Improving ensembles is an important problem, and the idea of diversifying ensembles has received much attention over the past few years. As such, the paper considers a significant problem, but I question the progress made on this problem by the proposed method. ## Main Weaknesses\n1. **Insufficient experimental setup for proposed method.** \n    The authors claim that for small-scale datasets their method preserves the performance boost of standard ensembling but results in better calibration, while maintaining the same level of efficiency (as opposed to joint training methods that are compared to). However, this comparison seems incomplete - firstly, my understanding is that the compared-to ensembling approaches do not make use of the additional unlabeled data (at least standard ensembling does not). In Table 1 (the main table in the paper) the results are with respect to a training size of 1000 data points, but the unlabeled data size and validation size are 5000 points each. As a result, this comparison seems unfair - one should at least consider some other pseudo-labeling scheme for the unlabeled data, since it makes up the majority of the data being considered.\n\n    Additionally, even this part aside, the authors should compare the method to training ensembles with some kind of data augmentation (label smoothing \\[1\\], Mixup \\[2\\], etc.) since these methods are not only known to improve feature learning diversity but also regularize predicted confidences. Furthermore, training with these methods is going to be even more efficient than the proposed approach, and I expect would perform better. My reasons for expecting this are two-fold: firstly, the proposed approach intuitively regularizes confidence by having the ensemble uncertainty be high on the unlabeled data (essentially these points should be predicted uniformly randomly based on how the ensembles are trained), but Mixup and label smoothing are approaches that can do this as well. Additionally, and more importantly, the authors themselves note that their approach does not work (and can even hurt) for larger dataset sizes, but the aforementioned data augmentations are known to improve calibration even in that regime.\n\n2. **Theoretical approach needs greater clarity.** The theory here needs significantly more clarification in my view. For example, the authors define $\\hat{\\rho}$ to be a uniform combination of point masses on different weights (and even here the notation should be made more precise, $\\delta$ is not defined a priori) and then claim that $\\hat{V}$ is the empirical variance of $\\hat{\\rho}$, but that is not what it represents from Equation (2), which is the variance of the predictive distribution of the ensemble when evaluated with respect to the true labels of data points in $U$. Furthermore, for the predictive distribution the authors use $p(y \\mid x, f)$ in Equation (2) and it should be clarified at this point that $y$ corresponds to the true label of $x$ (which the authors mention later). More importantly, the proof of Proposition 1 is very hard to make sense of. What is the indicator variable of $y$ not being in the random labels? Aren't the random labels supposed to be exhaustive? Even ignoring this, how does the second term become zero when passing from the first line to the second line? \n\n## Recommendation\nOverall I do not think the merits of the proposed approach are significant enough to merit acceptance, so my recommendation is **reject**. It is possible I misunderstood some aspects of the theory and I am happy to correct some of my statements here upon author clarification, but I feel even with that the authors would need more comprehensive experimental comparisons to emphasize the usefulness of the approach. My main questions are stated above as part of weaknesses.",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "Reviewer_bec4",
         "1699636992323",
         "3.0",
         "3.0",
         "2.0",
         "2.0",
         "1.0",
         "796",
         "2",
         "3",
         "0.7691",
         "0.11389269410000001",
         "0.9224106073",
         "47",
         "35.7231",
         "14.3942",
         "17.0581",
         "15.4976",
         "15.9236",
         "0.1932",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "6",
         "0",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "The paper proposes a very neat method for improving the diversity of deep ensembles: It assigns random labels to a set of unlabelled data and lets each ensemble component fit different random labels such that these ensemble components can be diverse. The paper further provides theoretical guarantees for the resulting ensembles' behavior on test samples. The empirical results further show that the method acquires significantly better calibration on small training dataset regime, without sacrificing accuracy. Importantly, the method only introduces little extra training overhead while outperforming baseline approaches that are way more complicated. Overall, I think the proposed idea is novel, interesting, easy-to-use, and could be of great impact. - The proposed method is easy! It is much easier and efficient to implement than other methods for enhancing ensemble diversity, such as Stein-based methods.\n\n- The proposed method comes with theoretical guarantees: Although the method sounds like some heuristic, the author provides PAC-Bayes bounds for its performance on test data.\n\n- The empirical performance improvement is significant: The results show that the proposed method improves the calibration error to a great extent for both in-distribution test data and out-of-distribution data (i.e. corrupted data), without hurting the accuracy. - The method \"Sample y randomly without replacement\", however, when the number of ensemble is larger than the number of classes, it is unclear to me how the method should be applied.\n\n- Since the method assumes having access to a validation dataset, a baseline worth considering would be temperature scaling.\n\n- The presentation of the results can be improved: There is no legend for the lines in Figure. 2; The usage of bold font is not consistent and confusing in Table. 1 Why the method becomes less effective when we have access to more data?\n\nIf I understand correctly, the method assigns random labels to **in-distribution** data, this sounds weird to me, as it implies that the ensemble would have high uncertainty on these in-distribution samples. I think one can also consider introducing OOD samples into training and assigning random labels to them for each ensemble member.",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "Reviewer_i38b",
         "1699636992166",
         "6.0",
         "4.0",
         "4.0",
         "4.0",
         "4.0",
         "345",
         "0",
         "0",
         "0.7883",
         "0.061763565900000005",
         "0.9469445348000001",
         "47",
         "33.8655",
         "13.4897",
         "15.7641",
         "14.8858",
         "14.3705",
         "0.1932",
         "99",
         "1",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "7",
         "0",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "The authors present a method for improving the calibration of deep neural network ensembles in the small data regime when access to an unlabelled data set is assumed. In particular, they propose the counterintuitive idea of randomly labelling the unlabelled dataset (distinctly for each ensemble member) and training the deep ensemble on the joint supervised and randomly labelled data. The randomly labelled data promotes ensemble diversity. A PAC bound which relates generalisation performance to ensemble diversity is derived while the diversity of the ensemble is demonstrated to be related to the ensemble size. Experiments on various slices of CIFAR-10 and CIFAR-100 show that while the method does not improve accuracy relative to standard ensembles, there are substantial gains on calibration. Calibration does not improve consistently over more complicated/expensive diversity promoting ensemble methods. - The paper is very well written and clear.\n- The idea for the method, of using randomly labelled unsupervised data to promote ensemble diversity is simple, cheap and easy to implement and in so far as promoting diversity makes sense.\n- Some theoretical results are presented in which the ensemble diversity is related via a PAC bound to the generalization performance (I have some other comments on these results below).\n- The experimental results are convincing that at least in the small data regime with relatively little unsupervised data the calibration relative to standard ensembles is significantly improved. Please see my questions in the section below for potential weaknesses that can be addressed through further experiments.\n\n- The method is targeted solely at the small data regime, gains in calibration go to zero as the amount of labelled data increases.\n- The method introduces a new $\\beta$ hyperparameter which must be tuned.\n- The experiments are presented without error bars and it is unclear if they come from a single run or are averaged over multiple seeds, standard practice, especially when considering the relative small datasets considered in this paper is to run experiments with multiple random seeds and present averages and standard deviations of the metrics of interest (or better yet other forms of statistical test of the significance of the results).\n- Experiments are conducted on small slices of CIFAR-10 and CIFAR-100, while performance in the large data regime is alluded to in the paper, an experimental evaluation of this setting (for example ImageNet is fairly standard in the ensemble literature) would be much appreciated.\n- From equation 3, it seems to be the case that as the number of classes (c) increases the gains in ensemble diversity go to zero, so the method is both likely to give no gains in the large data and large number of classes regime.\n- The primary theoretical motivation for the method is equation 1, which is a PAC bound on the generalization performance, it is difficult to get a sense of how tight this bound is and to what extent there is a competition between the various terms in the bound.\n\nSmall things (didn't effect rating):\n- Typo: \"coincides we standard weight decay\" -> \"coincides with standard weight decay\"\n- It took me a while when reading the paper printed out to realise that there are two colours plotted in the left hand side of Figure 2 - as the orange is almost fully hidden by the red, making this clear in the figure or caption would be helpful to readers. - While the experimental results do not show big drops in accuracy, I am quite concerned that given vastly more unlabelled data the method would lead to overfitting the random labels and thereby harm test set accuracy (as is a well known phenomenon in the noisy label literature). More formally one could imagine that vast amounts of unlabelled data would promote the diversity term in the RHS of equation 1, but I given results in the noisy labels literature, I would find it hard to believe that this would not come at a corresponding cost in the first term on the RHS of equation 1. Could the authors please comment on this concern? Experimentally, I would be interested in seeing an experiment on ImageNet, for example, where the labelled set is of size 50k and the unlabelled set is 950k examples, a standard resnet50 or similar capacity model is used with 4 ensemble members (as per other papers in the literature) and a comparison to standard ensembles in terms of accuracy and calibration is given. This is a significant concern for me, as usually with methods that make use of an unsupervised dataset, the expectation is that as the unlabelled dataset grows, the gains from using it grow to. I fear this will not be the case for this method, which would limit the method to the small dataset, small number of classes and small unlabelled dataset regime. I recognise that the $\\beta$ hyperparameter can to a certain extent control this trade-off, so if further experiments are conducted to address this concern, please report the results over the $\\beta$ hyperparameter range.",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "Reviewer_My8L",
         "1699636992048",
         "5.0",
         "4.0",
         "3.0",
         "4.0",
         "2.0",
         "835",
         "0",
         "0",
         "0.7756000000000001",
         "0.0024741462",
         "0.9451873302",
         "47",
         "28.0723",
         "17.4922",
         "20.681",
         "17.4907",
         "18.7118",
         "0.5162",
         "99",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "8",
         "0",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "The paper introduces a method to enhance the calibration of deep ensembles, particularly in situations where there is a small amount of labeled data and some unlabeled data. For each point in the unlabeled dataset, the ensemble members are trained with different randomly selected labels. The authors provide a theoretical justification for this approach, drawing on PAC-Bayes bounds to argue that it leads to lower negative log-likelihood and higher ensemble diversity on test samples. Empirically, they demonstrate that ν-ensembles outperform standard ensembles in terms of diversity and calibration, especially when the training dataset is small or moderate in size. - The paper gives a method to improve calibration error for deep ensembles using unlabeled data. The use of unlabeled data to improve calibration error of deep ensembles has not been explored much before as most of the works have focused on joint training approaches which can be memory and computationally expensive.\n- The paper is overall well written and easy to understand. \n- The paper presents supports their method with both theoretical and experiments. - One major weakness of the paper is that their method only improves calibration error not accuracy but they have not compared to any other calibration technique like temperature sampling. \n- The other issue is that the method appears very similar to the Agree to disagree work mentioned in the paper where they also use unlabeled data to maximize diversity and the idea seem incremental. Can the authors please explain in detail how exactly Agree to disagree maximizes diversity on the unlabeled set?\n- Another limitation is that this method only improves calibration in the small data regime. \n- Another limitation is that there are only two datasets used in the paper - CIFAR-10 and CIFAR-100. It would be nice to have additional datasets. - The paper says that the labels for unlabeled data points are chosen without replacement. What happens if we sample with replacement? One should expect the same empirical results to hold but maybe the theoretical argument will not hold?\n- I understand the text written at bottom of the Figure 1 but I don’t understand the figure. What are the 3 columns in the figure?\n- One part that is not clear to me is when we are forcing the models to make random predictions on unlabeled data which is from the same distribution, why we are not hurting the accuracy or the cross entropy loss of the model? When training data is small and unlabeled data set is bigger, can the authors share their regularization parameters and if they had to give small weights on the regularization term?\n- The colors used in figure 2 and 3 are very similar and it is hard to distinguish different lines. \n- There are other works which also use this idea of diversifying using unlabeled datapoint for other problems. For example, DIVERSIFY AND DISAMBIGUATE: OUT-OF-DISTRIBUTION ROBUSTNESS VIA DISAGREEMENT. Can the authors please compare to this work also?\n- Did the authors try using the unlabeled data from different distributions like random Gaussian noise. One benefit would be that fitting random labels on this dataset will not interfere with the learning on the original distribution.",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "Reviewer_3iBP",
         "1699636991904",
         "5.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "530",
         "0",
         "0",
         "0.7822",
         "-0.026552287600000002",
         "0.9537856579",
         "47",
         "40.043",
         "12.4219",
         "14.9313",
         "14.341",
         "12.1643",
         "0.12560000000000002",
         "92",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "9",
         "65",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "The submission focuses on the backdoor attacks in data-constrained scenarios. By leveraging CLIP-based technologies, the proposed CLIP-CFE (CLIP for Clean Feature Erasing) suppresses clean features while amplifying poisoning features to achieve more efficient attack with limited poisoning samples. + The submission presents a novel method, which introduces the optimized feature erasing noise to effectively suppress benign features. Besides, it enhances the poisoning features through contrastive learning and amplifies the existing backdoor attacks efficiently in data-constrained scenarios.\n\n+ The experimental results demonstrate the effectiveness of the CLIP-based attacks in data-constrained scenarios. Across various real-world constraints such as *number-constrained, class-constrained*, and *domain-constrained* conditions, the proposed backdoor attack consistently achieves a high attack success rate while maintaining the benign accuracy. + **Insufficient experimental results**\n\nThe submission should take more recent backdoor attack and defense mechanisms into consideration while discussing the adaptive defenses more thoroughly, e.g., the noise used for erasing benign features might be unlearned \\[1, 2\\]. Besides, it is necessary to compare the effectiveness of utilizing different proxy extractors other than CLIP.\n\n\n+ **Ambiguous expressions**\n\nSeveral points in the submission need further explanation, e.g., the reason and effect of choosing the overall attack process relying on the style of CLIP within the feature space, and the analysis of erasing benign features compared to the semantic-agnostic out-of-domain samples.\n\nReferences:\n\n\\[1\\]: Li Y, Li Y, Wu B, et al. Invisible backdoor attack with sample-specific triggers. Proceedings of the IEEE/CVF international conference on computer vision. 2021: 16463-16472.\n\n\\[2\\]: Akhtar N, Liu J, Mian A. Defense against universal adversarial perturbations. Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 3389-3398. Given that the submission's motivation is related to data-constrained scenarios, the author may provide more empirical evidence regarding to the occurrence of these backdoor attacks in real-world scenarios.",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Reviewer_tXy3",
         "1699636055179",
         "6.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "295",
         "3",
         "2",
         "0.806",
         "0.15949633700000002",
         "0.8649680018",
         "53",
         "17.1557",
         "14.8827",
         "18.7003",
         "15.9032",
         "17.3402",
         "0.0999",
         "79",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "10",
         "65",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "This paper proposes a new backdoor attack that performs well in data-constraint conditions that are more akin to real-world scenarios. The attack uses the CLIP model as a feature extractor to diminish the entanglement between benign and poison features. The experiment results show significant improvement compared to previous methods in these more realistic conductions. - A novel approach to backdoor attack\n- Comprehensive evaluations - CLIP limits the application domain\n- Defense discussion missing\n- Runtime information missing The authors present a novel backdoor attack that utilizes the pre-trained CLIP model as a feature extractor to suppress benign features and accentuate poison features. The attack also relaxes previous assumptions that having knowledge of the training datasets and the target models trained on datasets from one distribution. The authors show previous methods do not perform well in these more realistic scenarios but their new method is consistently effective and the trigger is hard to detect visually. Overall, the paper is well-written and the evaluation is comprehensive. However, there are a few points I would like to see the authors to further address.\n\n- The usage of the CLIP model for backdoor attacks is indeed novel. However, this also limits the domains of possible application of the attack. While the method seems to perform well on datasets with natural sceneries, such as CIFAR-100, CIFAR-10, and ImageNet-50, the performance cannot be guaranteed on datasets where the domain drastically differs from CLIP’s training set, such as medical scans, satellite imageries, etc. Additionally, even for similar domains, it would be interesting to see if the feature extraction capabilities transfer onto fine-grained datasets, such as CUB-200-2011, Stanford-Cars, Oxford-Flowers, etc. The authors should consider including results on more diverse datasets.\n\n- The target models used in this paper are all relatively simple/small (experimental settings focused). They also differ drastically from the CLIP model both in terms of architecture and performance. The authors have already pointed out the effect of model architecture in Section 5.1. Evaluating the attack on more advanced and larger architectures, such as ViT, can further prove the author’s claim for applicability in real-world scenarios.\n\n- Discussion regarding potential defenses is also missing. It would be interesting to see how this new attack performs against backdoor detection or defense methods. Since the optimization suppresses the clean features and augments the poison features, defense/detection methods that rely on optimization, such as Neural Cleanse\\[1\\] could potentially be more effective (compared to defending against traditional backdoor attacks). Furthermore, a recent work\\[2\\] on backdoor defense seems to use similar intuition (detangling benign and poison features). It would be interesting to see how this defense performs against an attack that is intuitively similar.  \n\\[1\\]Wang et al. Neural cleanse: Identifying and mitigating backdoor attacks in neural networks. 2019. In IEEE Symposium on Security and Privacy (S&P).  \n\\[2\\]Min et al. Towards Stable Backdoor Purification through Feature Shift Tuning. 2023. arXiv preprint arXiv:2310.01875.\n\n- Considering the optimization process needed to conduct this attack, the authors should consider including relevant runtime information. Since the focus of this paper is on presenting a backdoor attack that is applicable in real-world scenarios, the computing resource required can be another limiting factor. \n\nMinors:\n\n- Fonts in figures are too small to be legible\n- Page 8, VGG-16 datasets? (should be models)",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Reviewer_kSYS",
         "1699636055090",
         "8.0",
         "2.0",
         "3.0",
         "3.0",
         "3.0",
         "544",
         "4",
         "5",
         "0.8294",
         "0.1282828283",
         "0.8720514774",
         "53",
         "30.8873",
         "13.0891",
         "15.2929",
         "14.3292",
         "14.0499",
         "0.1262",
         "93",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "11",
         "65",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "This paper assumed a threat model for backdoor attacks, so-called as ‘data-constrained backdoor attacks’, where the attacker doesn’t have access to the entire training dataset. Then, the authors claimed that the exiting backdoor attacks are inefficient in this new threat model. The authors considered an interesting topic on AI security, specifically, how to improve the backdoor efficiency in a data-constrained scenario. First, the authors only provided the empirical results to support the performance decline when the exiting backdoor attack in the new threat model, as shown in Fig.2. I highly recommend that the authors give a possible theoretical analysis to this phenomenon.\n\nSecondly, the new proposed 'clip-guided backdoor attack' method includes two components: clean feature suppression and poisoning feature augmentation. Specifically, the main idea is to exploit adversarial example to generate the noise to suppress the clean feature or amplify the poison feature. Unfortunately, as far as I know this idea has been exploited by many published papers, for instance, as shown as follows. The main difference of this paper is that it is based on a novel pre-trained model CLIP.\n\n\\[1\\] Zhao, Shihao, et al. \"Clean-label backdoor attacks on video recognition models.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\\[2\\] Turner, D. Tsipras, and A. Madry, “Label-consistent backdoor attacks,” arXiv preprint arXiv:1912.02771, 2019.\n\nIn summary, the main idea has been exploited already, which will significantly reduce the contribution of this paper. What is the main difference between the 'clip-guided backdoor attack' with the existing references which have been mentioned in the 'weaknesses'",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Reviewer_nLdg",
         "1699636055014",
         "3.0",
         "5.0",
         "2.0",
         "3.0",
         "1.0",
         "258",
         "2",
         "2",
         "0.7959",
         "0.1806709957",
         "0.8726058006",
         "53",
         "38.9541",
         "11.5963",
         "13.3574",
         "13.4046",
         "13.2499",
         "0.0795",
         "86",
         "2",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "12",
         "65",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "This paper addresses an important and practical backdoor attack scenario called data-constrained backdoor attacks. The key insight is that in real-world settings, attackers often do not have full access to a victim's entire training dataset, which spans multiple sources. The paper clearly defines three variants of data-constrained attacks based on restrictions on the number of poisoning samples, classes, or domains.\nA thorough set of experiments on CIFAR and ImageNet datasets demonstrates that existing backdoor methods like BadNets and Blended attacks fail under data constraints, due to entanglement between benign and poisoning features. The analysis of this entanglement issue is a nice contribution. To address this limitation, the authors cleverly utilize CLIP in two ways: 1. Clean feature suppression via CLIP-CFE to erase benign features.\n2. Poisoning feature augmentation via CLIP-UAP and CLIP-CFA to amplify poisoning features.\nThe introduction of CLIP for backdoor attacks is novel. Results show CLIP-UAP and CLIP-CFA consistently outperform baseline triggers across constraints, architectures, and datasets. CLIP-CFE provides further improvements in attack success rate. The attacks remain stealthy and do not impact benign accuracy. 1.\tAddresses a highly practical attack scenario of data-constrained backdoor attacks that reflects real-world training environments where attackers have limited data control.\n2.\tProvides a clear taxonomy of data-constrained attacks based on restrictions to number of samples, classes, and domains.\n3.\tIdentifies through analysis and experiments that existing attacks fail under data constraints due to entanglement of benign and poisoning features. This is an important insight. 1.\tWhile the data-constrained scenario is practical, the specific sub-variants of number, class, and domain constraints may not fully capture all real-world limitations an attacker could face. More complex constraints could be studied.\n2.\tThe computational overhead and time required for the CLIP optimization process is not extensively analyzed. This could be a limitation for realistic attacks.\n3.\tThe stealthiness metrics mainly rely on signal processing based measures like PSNR and SSIM. More rigorous stealthiness analysis like visualizations and defense evaluations may be beneficial. see in weakness",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Reviewer_rJBe",
         "1699636054933",
         "6.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "330",
         "0",
         "8",
         "0.8079000000000001",
         "0.10107993200000001",
         "0.9159598351",
         "53",
         "30.2501",
         "12.6044",
         "15.1937",
         "13.8498",
         "14.4178",
         "0.0999",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "13",
         "168",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "The paper presents a new framework for semi-supervised domain adaptation (SSDA) that establishes an upper bound on target error. This framework introduces a method called Joint Error-based Triplet Alignment (JTA), which performs alignments not only between the labeled source domain and the unlabeled target domain but also between the labeled source domain and the labeled target domain. As a result, their empirical studies demonstrate that JTA can reduce domain gaps and enhance feature learning by explicitly considering the alignment for the labeled target data. The paper also introduces a dissimilarity metric known as Maximum Cross Margin Discrepancy (MCMD) to bridge the gap between theory and algorithm, ensuring the consistency of the target error bound. The main problem of this paper is the lack of sufficient details to understand and follow their motivation and derivation. Given the promising empirical results presented in the paper, I strongly recommend that the authors consider a complete rewrite of the paper, focusing on delivering a clear and well-motivated presentation. This should involve providing comprehensive derivations with sufficient details or citations, ensuring that each step of each equation is transparently explained for the benefit of the reader's understanding. The performance of the proposed work is promising. 1. I find the paper's motivation unclear. To be specific, the upper bound of the hypothesis regarding the unlabeled target domain should be the most crucial starting point for readers to comprehend what the proposed method aims to address. However, the lack of an explanation for the proof of Equation (1) makes it extremely difficult for me to grasp and follow. Concerning D.1, I am unsure how the first equation of the unlabeled target error bound was derived. If it stems from Ben David's theorem (assuming my recollection is accurate, Ben David did not derive any error bound under semi-supervised settings) or the work of others, it would be beneficial to provide citations so that readers can fully contextualize and understand the subject matter.\n\n2. What is the source of the intractability, particularly for f_{S} and f_{V}? Given that both S and V are fully labeled, it seems reasonable to assume that a straightforward optimization approach like empirical risk minimization (ERM) could yield a reasonable approximation for f_{S} and f_{V). The mention of intractability is often made within the framework of variational inference, where certain integrations cannot be feasibly solved. Providing a clear explanation of this intractability would significantly enhance the paper's motivation.\n\n3. How is the reduction of the error term achieved between two fixed true labeling functions? I want to emphasize that \"true\" here means unchanging or fixed. The paper is proving a complex upper bound derivation, and its clarity is hindered by inconsistent definitions throughout, making it difficult to follow.\n\n4. The t-SNE visualization, without any indications of the class labels for each data sample, fails to convey meaningful information. In fact, I find the t-SNE visualization rather perplexing. I recommend that the authors consider sharing the code for their implementation with the reviewers. This would serve not only to confirm the reproducibility of their work but also to enhance the reviewers' understanding of the proposed methodology.\n\n5. The experimental setup lacks clarity, particularly in the context of semi-supervised domain adaptation, where the number of labeled target samples and the way to select the labeled target sample are crucial. It is important to provide sufficient details regarding the sample selection process. \n\n6. The authors assert that \\[1\\] violates the triangle inequality without providing a thorough explanation or derivation. This is a strong claim, as it implies \\[1\\] is a departure from well-established theoretical foundations, especially considering that \\[1\\] is published on a top tire. To support their claim, the authors should conduct in-depth elaboration and studies.\n\n### Reference\n\n\\[1\\] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for domain adaptation. In Proceedings of the 36th International Conference on Machine Learning, volume 97, pp. 7404–7413. PMLR, 2019. 1. Could you please clarify what is meant by the conditional distribution referred to in Section 3.1? To be specific, which random variables are conditioned on which other random variables? Based on the authors’ preliminary at the beginning of the section that both f_{S} and f_{V} are true labeling functions (true means fixed and deterministic). Meanwhile, I am confused by the idea of describing a mapping function (mapping function is normally deterministic) as a distribution (sampling from a distribution is stochastic). How come a stochastic term can be used to describe a deterministic notation? Can you elaborate on this?\n\n2. To me, the loss introduced in this work appears to be an extension of the one (MDD) presented in \\[1\\] to the semi-supervised setting. I would appreciate it if the authors could offer a comprehensive discussion outlining the primary distinctions between \\[1\\] and their proposed approach, excluding the consideration of the semi-supervised setting and the violation of the triangle inequality. \n\n### Reference\n\n\\[1\\] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for domain adaptation. In Proceedings of the 36th International Conference on Machine Learning, volume 97, pp. 7404–7413. PMLR, 2019.",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Reviewer_XYg3",
         "1699636353905",
         "3.0",
         "4.0",
         "3.0",
         "1.0",
         "2.0",
         "849",
         "7",
         "12",
         "0.7813",
         "0.0869150691",
         "0.9562900662",
         "49",
         "35.4208",
         "13.2123",
         "16.0491",
         "14.7848",
         "14.7039",
         "0.9511000000000001",
         "96",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "14",
         "168",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "The paper at hand proposes a method for domain adaptation by including some labeled data from the target domain. A \"triplet alignment\" is introduce which aims for aligning feature distributions as well as minimizing classification error. + relevant problem - The paper is quite hard to read and understand. Figures are rather small. Honesty speaking Fig. 1 even confused me more than it helped me to understand the approach.\n- Experimental results are hard to interpret and judge. If I read it correctly, the effect of data augmentation seems significant. When comparing without data augmentation  (ours* in Tab. 1) the advantages over previously proposes approaches seems marginal (if at all). I also miss confidence intervals. - What are clear advantages of the approach -- e.g., the claim that \"data augmentation is not nessaccary for our approach\" (besides still having a significant impact) is not well motivated.\n- What are limitation of the approach?",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Reviewer_tePx",
         "1699636353828",
         "3.0",
         "3.0",
         "2.0",
         "2.0",
         "1.0",
         "153",
         "0",
         "1",
         "0.8190000000000001",
         "0.0409090909",
         "0.9198144674000001",
         "49",
         "44.2428",
         "9.6968",
         "12.6354",
         "11.8999",
         "8.5706",
         "0.1932",
         "97",
         "0",
         "1",
         "0",
         "1",
         "iclr"
        ],
        [
         "15",
         "168",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "This paper proposed a joint error based triplet alignment approach to solve the semi-supervised domain adaptation problem. They evaluated on several cross-domain benchmarks by comparing with several methods. Generally, the paper is easy to follow. However, the novelty is not enough. This paper proposed a joint error based triplet alignment approach to solve the semi-supervised domain adaptation problem. They evaluated on several cross-domain benchmarks by comparing with several methods. Generally, the paper is easy to follow. They show various results to examine their methods. The novelty is not enough. The joint error based triplet alignment is not new, which is an extension of maximum cross margin discrepancy to three subsets, source, labeled target and unlabeled target. Eventual model is also very complicated. \n\nThe model performance is not good enough. Especially compared with DECOTA in Table 1 & 2, it is very comparable. Also for semi-supervised setting, the selected target samples are very essential. There is no standard variance. Also t-test is needed to examine the significance. The clarification of model novelty.\nThe performance improvement.",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Reviewer_hsiV",
         "1699636353732",
         "1.0",
         "5.0",
         "3.0",
         "3.0",
         "1.0",
         "174",
         "0",
         "0",
         "0.7846000000000001",
         "0.0049242424",
         "0.9568377137",
         "49",
         "38.6381",
         "10.2578",
         "12.8618",
         "11.645199999999999",
         "10.255",
         "0.0999",
         "100",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "16",
         "168",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "This work introduces a Triplet Alignment approach for semi-supervised domain adaptation. It simultaneously minimizes the joint error among different domains and the error rate on labeled data. 1.\tThe motivation for this work is clear. It aims to address the challenge of semi-supervised domain adaptation, particularly when only a limited number of annotated examples are available in the target domain. The proposed method optimizes both the classification loss and the joint error across source, labeled, and unlabeled target domains simultaneously.\n2.\tThe proposed models are presented in a clear and comprehensible manner. 1.\tThe proposed model, to the best of my knowledge, lacks significant novelty as it closely resembles the approach in \\[2\\]. It would be helpful to explicitly identify the main difference.\n2.\tThe choice of baseline methods in this work appears to be less competitive. Given the recent progress in semi-supervised domain adaptation (SSDA), including \\[1\\]\\[2\\], it is advisable to compare the proposed method with these contemporary approaches. Furthermore, while the use of t-SNE for feature space visualization is commendable, the comparisons are made with older methods like ENT (Grandvalet & Bengio, 2005), MJE (Zhang & Harada, 2019), and MME (Saito et al., 2019). It is imperative to include comparisons with more recent methods to provide a comprehensive evaluation.\n\\[1\\]  Yu, Yu-Chu, and Hsuan-Tien Lin. \"Semi-Supervised Domain Adaptation with Source Label Adaptation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\\[2\\] Rahman, Md Mahmudur, Rameswar Panda, and Mohammad Arif Ul Alam. \"Semi-Supervised Domain Adaptation with Auto-Encoder via Simultaneous Learning.\" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2023. Please see \"Weaknesses\"",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Reviewer_TnGf",
         "1699636353588",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "2.0",
         "270",
         "6",
         "7",
         "0.776",
         "0.1943277311",
         "0.9432914257",
         "49",
         "34.3667",
         "11.97",
         "14.4481",
         "13.3652",
         "13.0976",
         "0.1719",
         "94",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "17",
         "106",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "This paper presents the Ranking-Constrained Actor-Critic algorithm, an offline reinforcement learning approach for optimizing Mixed Integer Linear Programs (MILPs). Traditional MILP solvers depend on hand-crafted heuristics for branching, limiting their efficiency and generalizability. Recent deep learning methods rely on high-quality training data, which can be scarce, particularly for large problems. The key contributions of the paper are the development of the new RL algorithm and its ability to efficiently learn branching strategies even from sub-optimal training data. The algorithm outperforms previous methods in terms of prediction accuracy and computational efficiency across various MILP problems, addressing the limitations of traditional solvers. This paper claims to be innovative by being the first to apply offline reinforcement learning algorithms in branch-and-bound methods. Furthermore, the essence of the proposed method lies in further refining the dataset, specifically selecting the top-k actions in the set Gω for Bellman operator operations. This can effectively enhance the performance of the branching strategy. I believe this perspective can also be inspiring for similar problems in other domains. This paper proposes training branch-and-bound strategies using offline reinforcement learning. However, in practice, interacting with solvers is relatively straightforward, and under these circumstances, using online reinforcement learning may yield better performance. The authors need to clarify the necessity of utilizing offline reinforcement learning. •\tConsidering that interacting with solvers online is convenient, is there a necessity to use offline reinforcement learning to train branch-and-bound strategies?\n•\tIn Equation 7, when k is small, the distribution of Q-values over the dataset will be centered around -δ, which is unfavorable for training. How do the authors ensure training effectiveness in this scenario?\n•\tI believe that the essence of the method proposed by the authors lies in further refining the dataset, specifically selecting the top-k actions in Gω for Bellman operator operations. I am curious to know if, after obtaining the top-k actions in Gω, simple imitation learning on these state-action pairs would yield similar results as the current approach. In other words, my question is whether the key to the effectiveness of this algorithm lies in the dataset refinement rather than offline reinforcement learning. I suggest that the authors conduct further ablation experiments to validate this idea.",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Reviewer_pc5v",
         "1699636458715",
         "5.0",
         "5.0",
         "2.0",
         "3.0",
         "2.0",
         "365",
         "0",
         "0",
         "0.804",
         "0.07807720060000001",
         "0.9679618478",
         "49",
         "20.8673",
         "15.082",
         "18.2288",
         "16.1033",
         "16.537",
         "0.1507",
         "84",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "18",
         "106",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "This work proposes the usage of offline reinforcement learning for variable selection in the branch-and-bound algorithm. To do so, they introduce a novel offline algorithm that uses a classifier to determine whether a state-action pair is in the offline dataset. Their offline Q-values are now restricted towards picking only the top-k most likely actions for each state. The usage of offline reinforcement learning seems more fitting than current imitation learning algorithms due to its lack of reliance on high quality demonstrations. - The paper is a little unclear at some points. For instance, in the last paragraph of Section 2.2: Which variables are the selected ones? Just from the node chosen by the node selection policy, or all variables across the entire tree? In general, the distinction between node selection and variable selection doesn’t become clear: Does the method also do node selection (by picking variables from the entire tree), or just variable selection?\n- Further, it is not exactly clear whether there is a single model trained and evaluated on all instances, or multiple independent models trained on and evaluated on individual datasets.\n- One missing benchmark is the utilization of an off-the-shelf offline RL algorithm, such as conservative Q-learning as a baseline for the specific utility of RCAC over more established offline-RL algorithms (I.e. is the improvement in performance due to offline-RL or RCAC specifically?).\n- The testing set is also rather small: 10k training instances, 2k validation instances and, 20 test instances is a strange ratio.\n- The reward function is also a little bit strange: Why consider the dual bound, but ignore the primal one completely? Further, these bounds are not scale-invariant, meaning that the same problem, modulo a constant scalar, could have different dual bound improvements. Even if one takes care to normalize the objective vector c beforehand, most solvers like SCIP rescale this vector for increased numerical stability. Depending on which problems are chosen, the range of rewards across different instances might also be massive depending on the duality gap. However, we agree with the authors that this metric is still better than tree-size or number of nodes.\n\nSome minor points:\n- Abstract: hand-craft\\[ed\\]\n- Intro: The sentence “All of these models are trained…” needs a re-write\n- Intro: “To our knowledge, … to apply offline RL to MILP solving” (re-write)\n- Sec. 2: typo pseudocsot\n- Sec. 2.2. A\\[n\\] MDP\n- Equation 4: one closing brace is too much (after $Q_\\theta$)\n- Sec. 3.1: when a\\[n\\] MILP instance\n- Sec 3.1: discounted factor $\\rightarrow$ discount factor\n- Sec 3.3: citation of Gasse et al.: use cite instead of citep; same again happened in Sec. 4.1\n- Sec. 4.1: please use cite and citep depending on how you add these citations into the text\n- Sec. 5.2 does not add any benefit to the paper and can be omitted in its current state - Which set of variables if being selected from?\n- What is the performance of other offline-RL algorithms?\n- Can you evaluate on a larger testset?\n- Why only look at the dual bound improvement (alternative: optimality gap between primal and dual)?\n- In Sec 3.2. “In fact, a good action does no harm to policy optimization even if it is an OOD action” – can you please elaborate on this a bit more?",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Reviewer_s5Ux",
         "1699636458619",
         "3.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "553",
         "0",
         "4",
         "0.8156",
         "0.0484206349",
         "0.8696163893000001",
         "49",
         "48.758",
         "10.5731",
         "13.5684",
         "13.0239",
         "10.5035",
         "0.25670000000000004",
         "96",
         "0",
         "2",
         "2",
         "0",
         "iclr"
        ],
        [
         "19",
         "106",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "This paper studies the problem of learning variable selection policies for mixed-integer linear programming (MILP). The authors propose an offline reinforcement learning (RL) approach to learn branching strategies from sub-optimal or inadequate training signals. Experiments demonstrate the proposed method outperforms baselines on various benchmarks. 1.\tThe paper is easy to follow.\n2.\tExperiments demonstrate the proposed method outperforms baselines on various benchmarks. 1.\tThe novelty of the proposed method is incremental, as the proposed method is a simple application of offline reinforcement learning methods to branching strategies learning.\n2.\tThe authors claim that the proposed method is the first attempt to apply the offline RL algorithms to MILP solving. However, I found one previous work \\[1\\] applies offline RL methods to branching strategies learning as well. \n3.\tThe authors may want to explain the novelty of their method over the work \\[1\\] in detail.  \n4.\tThe experiments are insufficient. First, the authors may want to evaluate their method on the load balancing dataset from the ML4CO competition as well. Second, the baselines are insufficient. The authors may want to compare their method to the work \\[1\\]. Third, the authors may want to evaluate the generalization ability of the learned models.\n\n\\[1\\] Huang, Zeren, et al. \"Branch Ranking for Efficient Mixed-Integer Programming via Offline Ranking-Based Policy Learning.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Cham: Springer Nature Switzerland, 2022. Please refer to Weaknesses for my questions.",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Reviewer_3oNR",
         "1699636458528",
         "3.0",
         "4.0",
         "2.0",
         "3.0",
         "2.0",
         "239",
         "4",
         "8",
         "0.6839000000000001",
         "0.0766666667",
         "0.89818573",
         "49",
         "40.7962",
         "10.694",
         "13.0651",
         "12.3033",
         "11.9765",
         "0.1719",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "20",
         "106",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "The paper considers the problem of learning to select branching strategies while solving mixed integer programs via branch and bound algorithm. The key idea is to collect offline training dataset using full strong branching as behavior policy and learn an offline RL algorithm to generate the learned branching policy. Improvement of the dual bound is chosen as the reward function. Experiments are performed on four synthetic and two real world problems. - Using offline RL for branching policies seems like a natural idea that should do better than pure imitation learning. I am surprised that this wasn't tried earlier and commend the paper for making this simple but natural idea work well. \n\n- The description of the problem and solution is written clearly and easy to understand.\n\n- The proposed approach performs well on multiple benchmarks. - A large part of the paper talks about sub-optimality of the FSB policy. For example, this statement \"Although FSB generally achieves high-quality branching, it could still become sub-optimal when the linear programming relaxation is uninformative or there exists dual degeneracy\" Is there more justified argument for this backed by some evidence?\n\n- why choose the proposed algorithm over any existing offline RL algorithm like CQL\\[1\\], IQL etc.?\n\n\\[1\\] Kumar, A., Zhou, A., Tucker, G., & Levine, S. (2020). Conservative q-learning for offline reinforcement learning. Advances in Neural Information Processing Systems, 33, 1179-1191. - What are connections of equation 6 to reward weighed regression?",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Reviewer_nNZN",
         "1699636458444",
         "8.0",
         "3.0",
         "3.0",
         "3.0",
         "2.0",
         "240",
         "3",
         "2",
         "0.8317",
         "0.1780952381",
         "0.9082451463000001",
         "49",
         "39.297",
         "11.6371",
         "14.282",
         "13.6629",
         "11.9277",
         "0.12",
         "109",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "21",
         "106",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "The authors propose an offline Reinforcement Learning (RL) framework for learning to branch (L2B) which reportedly exhibits superior performance with a sub-optimal dataset compared to existing methods that require extensive, high-quality datasets. This advantage is particularly notable in reducing the time to collect datasets for training the models. The reported performance on the MIP instances also indicates the effectiveness of the framework. 1. **Innovative Formulation:** The novel formulation of L2B as an Offline RL approach using a sub-optimal dataset is a significant departure from traditional methods.\n2. **Efficiency in Data Collection:** The framework requires significantly less time to collect its dataset, enhancing its practicality.\n3. **Performance:** The proposed framework improved performance compared to the GGCN framework on smaller dataset sizes, which is commendable. Despite the novelty of the work, I have reservations about the robustness of its results. These concerns are expanded upon in this section and further detailed in the questions that follow. \n\n1. **Lack of Scaling-Generalization Results:** A key aim of collecting datasets on smaller instances is to develop policies that excel on larger, more complex instances. It would be beneficial to see how various models perform on scaled-up versions of instances in various problem categories like SC, MIS, CA, or CFL. How do these policies perform on Medium or Hard instances (scaled-up versions) in SC, MIS, CA, or CFL? Does RCAC retain its performance advantage on scaling up to larger instances?\n\n2. **Insufficient Comparison with Existing Methods:** \n- The paper lacks a thorough comparison with recent advancements in the GGCN framework, particularly the augmented loss function introduced in \"Lookback for Learning to Branch\" (Gupta et al. 2022, https://arxiv.org/abs/2206.14987). It would be insightful to see how RCAC compares to this improved GGCN variant. \n - If I understand correctly, RCAC (S) and GGCN (S) primarily differ in their approach to training despite similarities in other aspects, such as dataset collection. Specifically, GGCN (S) employs a Cross-Entropy loss function, while RCAC (S) is focused on learning a Q-function (and a corresponding policy). The distinctiveness of the RCAC framework lies in its utilization of rewards instead of directly using FSB selections, as is the case with GGCN. However, an alternative comparison could involve integrating rewards into the GGCN framework as an additional signal. This could be achieved, for instance, by employing rewards to modulate the Cross-Entropy loss at each node, similar to how node depth might be used. Demonstrating RCAC's superior performance in this modified context would further reinforce the effectiveness of its RL-based approach as formulated in the study. \n    - It would be valuable to have the values of \\( k \\) specified for each model. I am particularly curious to know whether \\( k > 1 \\) for RCAC(S).\n- Comparisons with other RL methods, especially in terms of dataset size and time efficiency, would also be valuable. Clarifications:\n\n1. **Section 3.3:** Should \"representation of the B&B tree\" be replaced with \"representation of the B&B node\" for accuracy? \n2. **Training Dataset for GGCN (H) and RCAC (H):** Are these models trained on the same dataset? Is GGCN (H) trained on a separate dataset collected as specified in the Appendix?\n3. **VHB Dataset Transitions:** Could the authors clarify what constitutes a 'transition' in this context? Does the transition include (s,a,s’) even when FSB is not employed in VHB, which is 0.05 times? Do you discard any transition? How is it ensured that you explore a wide array of instances before 100K transitions are collected?\n4. **S Method Training:** Is the S method trained with only 5K transitions? \n5. **Reward Distribution:** Could the authors provide details on the distribution of reward values in the dataset, perhaps in the Appendix? Information on how this varies with tree depth and how normalization is handled would be valuable.\n6. **Figure 3 Clarity:** What is the specific problem family represented in Figure 3?\n7. **Practicality of H dataset collection:** Given that VHB takes longer than FSB (as indicated in column 2), is it still a practical choice since the performance is worse than S?\n8. **GGCN Expansion:** Could the authors clarify the abbreviation GGCN? It seems to be a variation of GCNN (Graph Convolutional Neural Networks) as used in Gasse et al. 2019.\n9. **Inference Procedure in RCAC:** Are there two forward passes $G_\\omega\\$ and $\\pi_\\phi$ during inference in RCAC? How does this differ from the inference process in GGCN?\n10. **Hyperparameter \\(k\\):** Figure 3 suggests that \\(k\\) has a significant impact on RCAC's performance. Could the authors provide the \\(k\\) values used for each model and dataset?\n\n11. **Aggregation in Table 4:** How are scores aggregated across 20 instances in Table 4? Assuming this is a cumulative sum, RCAC appears to outperform in WA but not against RPB in AP. Can the authors speculate on which problem types might be more amenable to improvement by RCAC?\n\n12. **Reward Ablation:** Could the authors discuss the rationale behind choosing dual bound improvement over primal-dual gap improvement? Understanding the preference for one metric over the other would be enlightening.\n\n\nSuggestions:\n1. **Dataset Comparison:** I think it will be pretty helpful to have a section or a figure demonstrating the difference (transition vs. individual nodes) between the dataset collected using the standard IL methods and the one proposed in this work. \n2. **Statistical Significance:** Please include p-values to indicate the statistical significance of differences in Tables 2 and 3.\n3. **Evaluation Methodology:** Given that 20 seems a relatively small sample size for testing, it's common practice to evaluate each instance with multiple seeds, as demonstrated in Gasse et al. 2019. Could the authors clarify whether a similar approach can be employed in their study?",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Reviewer_9gri",
         "1699636458378",
         "5.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "936",
         "1",
         "23",
         "0.7754000000000001",
         "0.0670068027",
         "0.8958138227",
         "49",
         "40.0849",
         "12.1838",
         "15.6848",
         "14.5266",
         "13.367",
         "0.30210000000000004",
         "86",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "22",
         "117",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "Offline reinforcement learning (RL) suffers from the extrapolation error. There are numerous model-free and model-based offline RL algorithms that aim to tackle this challenge. Among them, model-based offline RL algorithms often learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, such quantifications are often inaccurate. This paper addresses this issue by training bidirectional dynamics models and rollout policies, and design a conservative rollout method that selects those synthetic transitions with the smallest reconstruction loss. The authors provide some theoretical analysis of their method and build their method upon some off-the-shelf model-free offline RL algorithms. # Strengths\n\nThe strengths can be summarized below:\n\n- this paper is well-motivated, and the whole paper structure is clear\n\n- the logic flow of this paper is clear, and it is easy to follow and understand\n\n- the authors provide theoretical analysis to support their method # Weaknesses\n\nDespite the aforementioned strengths, this paper has some flaws in novelty, empirical evaluation, and theoretical analysis. Based on these considerations, I can confirm that this paper is clearly under the acceptance bar of this venue. Please see the detailed comments below.\n\n- (major) The core idea presented in this paper is NOT new. A highly relevant paper is published previously \\[x\\]. In \\[x\\], the authors also train bidirectional dynamics models and bidirectional rollout policies for offline data augmentation. Thus, the technical parts of this paper have a huge overlap with \\[x\\], making the contribution and significance of this paper quite weak. The differences are, that this paper selects the transitions with reconstruction loss while \\[x\\] selects reliable transitions via the proposed double check mechanism. It is doubtable whether the data selection approach adopted in this paper is better than the double check method, as intuitively, the reconstruction loss may not be reliable for forward/backward horizon larger than 1 (where no true next/previous states are available)\n\n\\[x\\] Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination. NeurIPS 2022.\n\n- (major) The empirical evaluations are limited and somewhat weak. The baseline algorithms this paper adopts are very old. It is somewhat confusing why the authors only choose to compare against these very weak algorithms. More advanced and recent offline RL algorithms ought to be included as the baselines (e.g., TD3BC, IQL, Decision Transformer, LAPO, etc.). The authors build their method upon CQL, BCQ, and BEAR. Can your method benefit more advanced offline RL algorithms?\n\n- (major) This paper does not consider statistical significance. Written statements and the presentation of the results as tables (often without standard deviations) obscure this flaw. In fact, ALL tables in this paper does not include any signal of statistical significance, e.g., std, IQM. We have reached a point of maturity in the field where claims need to be made in reference to actual statistical evidence, which seems to be lacking in the current presentation.\n\n- (major) The theoretical analysis is also not new. Similar techniques are adopted in the MBPO paper. Specifically, one online model-based RL algorithm BMPO \\[y\\] theoretically shows that the error of the bidirectional models is smaller than unidirectional models, making the theoretical insights of this paper less appealing and unsurprising.\n\n\\[y\\] Bidirectional model-based policy optimization. ICML 2020.\n\n- (minor) The authors ought to specify the version of the D4RL datasets they use in the paper. In Table 1, your evaluated scores in halfcheetah-medium-expert are questionably low, why is that?\n\n- (minor) This paper does not do a good job in the related work part, the authors include too few recent offline model-based/model-free offline RL papers Please refer to the the weaknesses part.",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Reviewer_MDsd",
         "1699636034553",
         "3.0",
         "5.0",
         "2.0",
         "3.0",
         "1.0",
         "603",
         "0",
         "3",
         "0.7867000000000001",
         "0.0567165212",
         "0.9565235972",
         "53",
         "32.288",
         "13.2124",
         "15.5541",
         "14.3361",
         "14.0344",
         "0.3178",
         "87",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "23",
         "117",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "This paper presents a new model-based method for offline reinforcement learning. The key technical contributions of the proposed model include: 1) It learns the bidirectional rollouts of the state transitions and the reward functions; 2) It learns forward and backward offline policies, following the BCQ method. With the learned bidirectional dynamics model and the corresponding policies, given a pivotal data point drawn from the offline dataset, the replay buffer can be augmented with the generated data trajectories. \n\nAdditionally, the paper provides a theoretical analysis, establishing a tighter bound on the rollout error for the conservative bidirectional rollouts compared to unidirectional approaches. \n\nFinally, the empirical findings on the D4RL benchmark demonstrate the effectiveness of the proposed method. 1. The proposed method is simple, reasonable, and effective on the existing D4RL benchmark, showing great potential for practical offline RL applications. \n2. The paper is well-written and easy to follow. The overall design of the proposed method is presented in a clear and thoroughly motivated manner. \n3. The method seems to be a highly versatile framework. As shown in the paper, it can be easily integrated with existing model-free offline RL approaches. 1. My primary concern with this paper is about the novelty of the proposed bidirectional rollout technique. At NeurIPS 2022, a paper titled \"Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination\" by Lyu et al. introduces a conceptually similar idea. In both papers, forward and backward models are trained to augment the offline dataset. It is crucial for the authors to address this similarity and provide a comprehensive comparison between COBiMO and the method presented by Lyu et al., considering aspects such as model design and empirical results.\n2. In the experiment section, the authors present averaged results of 6 random seeds. To enhance the statistical robustness of their findings, it would be better to include the standard deviations over multiple runs in Tables 1-3. \n3. The paper primarily compares COBiMO with approaches that were proposed 2-3 years ago. It would be beneficial for the authors to extend their comparisons to include more recent advances in offline RL to provide a comprehensive evaluation of COBiMO's performance in the context of the most current state of the field.\n4. In Section 5.3, there is an absence of an explanation regarding the factors that lead to performance degradation in certain tasks when COBiMO is applied (which can be reasonable but needs more analysis). Besides, as claimed in Section 5.3, the proposed method outperforms the original algorithms significantly in 10/12 tasks. However, it's essential to ensure that all relevant results supporting this claim are presented, as only a partial subset of the results is currently shown in Table 3.\n5. Typos:\n- In the first paragraph of Section 5.1, \"...from three domain\" should be corrected to \"...from three domains\".\n- In the third paragraph of page 4, \"...represents a gaussian distribution...\" should be \"...represents a Gaussian distribution...\". In summary, my primary concerns include the technical novelty in comparison to the missing reference (major), and some finer details of the provided experimental results (minor).",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Reviewer_qiBS",
         "1699636034488",
         "5.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "513",
         "0",
         "8",
         "0.7682",
         "0.1505058522",
         "0.9512968659000001",
         "53",
         "35.9958",
         "12.2057",
         "14.9981",
         "13.9117",
         "12.7486",
         "0.30110000000000003",
         "96",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "24",
         "117",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "This paper studies the model-based offline reinforcement learning problem. The authors propose to learn bidirectional model and bidirectional behavioral policies and use them to generate rollout trajectories. The output policy is obtained by a model-free offline reinforcement learning on the augmented dataset. The paper provides theory and empirical study to justify the proposed algorithm. 1. The paper is clearly written and easy to follow. 1. The Related Work misses important paper. For instance, this paper is not the first to use bidirectional model in offline learning. Confidence-aware Bidirectional Offline Model-based Imagination is the first to apply this idea to the best of my knowledge.\n2. I cannot recognize the algorithmic novelty of the algorithm. Forward imagination is widely used in model-based offline learning and Reverse Imagination was first proposed in ROMI. This paper seems to just combine these two ideas directly without justifying why it can substantially improve the performance\n3. The theory seems to be trivial.\n4. The experiment misses important baselines, such as ROMI and Confidence-aware Bidirectional Offline Model-based Imagination which share similar ideas. Besides, the performance does not seem compelling if one also look at the performance in ROMI and Confidence-aware Bidirectional Offline Model-based Imagination paper. 1. What is the main intuition behind using bidirectional imagination? Why should we expect it provide substantial improvement?\n2. What does the theory part tell us, is there any interesting insight?\n3. How does the algorithm perform compared to other later model-based algorithms? How does the algorithm perform on other tasks in D4RL?",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Reviewer_7BFv",
         "1699636034401",
         "3.0",
         "4.0",
         "2.0",
         "3.0",
         "1.0",
         "252",
         "0",
         "7",
         "0.7828",
         "0.1666666667",
         "0.9260005355",
         "53",
         "30.2158",
         "12.3398",
         "14.5116",
         "13.4487",
         "12.3402",
         "0.1199",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "25",
         "9",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Reviewer_KmBd",
         "1699637128872",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "487",
         "0",
         "1",
         "0.732",
         "0.1304191468",
         "0.9185432792",
         "47",
         "29.0538",
         "13.6602",
         "16.2613",
         "15.0211",
         "14.0811",
         "0.1695",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "26",
         "9",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Reviewer_3zCE",
         "1699637128739",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "1.0",
         "480",
         "0",
         "0",
         "0.8331000000000001",
         "0.09343537410000001",
         "0.9183989763",
         "47",
         "39.3732",
         "11.51",
         "13.8202",
         "13.2344",
         "11.9386",
         "0.1932",
         "87",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "27",
         "9",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Reviewer_y5kB",
         "1699642867494",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "41.9389",
         "11.9311",
         "14.8075",
         "13.9683",
         "12.4911",
         "0.050100000000000006",
         "104",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "28",
         "9",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Reviewer_XNx6",
         "1700672717423",
         "6.0",
         "4.0",
         "2.0",
         "2.0",
         "3.0",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.9159082770000001",
         "59",
         "42.2021",
         "12.1002",
         "14.7586",
         "13.9683",
         "12.0852",
         "0.929",
         "90",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "29",
         "73",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "The paper proposes a method to obtain Gaussian approximations of posterior distributions in Bayesian deep learning. The experiments compare the proposed method against several related approaches on toy experiments as well as classification on CIFAR-10/100 and ImageNet. The authors report that their method tends to produce samples quicker than competitor methods. The paper is definitely still a work in progress and not ready for publication at a conference like ICLR.\nThus, I vote for rejection and encourage the authors to completely revise their manuscript and submit to another venue.\n\nThe writing style and organization of the paper is very bad, which makes it extremely hard to follow. In particular, the theoretical exposition is lacking:\n- The theory is mixed with the related work (Eqs. (1)-(3), last Sec. of 1.1)\n- Central notions and symbols are not introduced, the exposition remains very handwavy. To name only a few examples:\n  - what do the authors mean by \"transforming a pretrained into a Bayesian model\"?\n  - background on MCMC, Metropolis-Hastings corrections\n  - definition of a \"perfect sampler\"\n  - how do the authors define a \"mode-specific MH\"\n  - it remains unclear in which sense the proposed method better deals with multi-modal posteriors than related work\n  - definition of notion of time step $t$ and $\\theta_t$ in Eq. (4)\n  - definition of $D_x$, $D_y$ in Eq. (15, 16)\n  - definition of $\\mathrm{Conf}$ in Eq. (20)\n  - ...\n- The experimental evaluation is not convincing.\n  - While the authors report fast sampling, their approach is outperformed by competitor methods most of the time.\n  - On the simplest toy example (unimodal Gaussian posterior), the authors report good results in terms of effective sample size (which is not very surprising because they use the correct approximation). However, they do not report ESS on the mixture model (Figure 2 RHS). \n  - The authors argue that their method deals well with multi-modal posteriors. Thus, they should compare\n against other methods that capture multiple modes, i.p., Deep Ensembles \\[1\\] and Multi-SWAG \\[2\\].\n  - As the authors employ a Gaussian posterior approximations, they should compare against variational Gaussian approximations, e.g., BayesByBackprop \\[3\\].\n\n\\[1\\] Lakshminarayanan et al., \"Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles\", NeurIPS 2017\n\n\\[2\\] Wilson & Izmailov, \"Bayesian Deep Learning and a Probabilistic Perspective of Generalization\", NeurIPS 2020\n\n\\[3\\] Blundell et al., \"Weight Uncertainty in Neural Networks\", ICML 2015 Please elaborate on the concerns raised below \"Weaknesses\".",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Reviewer_XKu5",
         "1699672907827",
         "1.0",
         "3.0",
         "1.0",
         "1.0",
         "1.0",
         "399",
         "6",
         "1",
         "0.8017000000000001",
         "0.055785256400000004",
         "0.9074112773",
         "49",
         "40.3959",
         "11.5687",
         "14.224",
         "13.3617",
         "12.3358",
         "0.2383",
         "104",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "30",
         "73",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "This paper proposes an adaptive proposal sampling (APS), a mode seeking sampler that adapts the proposal to match a posterior mode. The proposed ``adaptive proposal sampler'' appears to be new in the literature. 1. Extension of the proposed sampler to high-dimensional problems is questionable. As mentioned in the paper, the parameters are regarded as independent of each other, making the proposed sampler less accurate and thus less attractive. \n\n2. When the modes of the target distribution are well separated, it is difficult to believe that the proposed sampler can efficiently traverse the entire energy landscape because, similar to the Metropolis-Hastings algorithm, the proposed sampler lacks a mode-escaping mechanism. \n\n3. For the exact Gaussian proposal sampler, the acceptance rate can be low when the dimension of \\theta is high. 1. If the exact GPS is applied to the numerical examples of the paper, will the reported results be improved? How much?   \n\n2. The proposed method needs to compare with more baseline methods, such as SGHMC \\[1\\]  and adaptively weighted SGLD \\[2\\], on multi-modal and high-dimensional problems.\n\nReferences: \n\n\\[1\\] Chen et al. (2014) Stochastic Gradient Hamiltonian Monte Carlo. ICML 2014. \n\n\\[2\\]  Deng et al. (2022) An adaptively weighted stochastic gradient MCMC algorithm\nfor Monte Carlo simulation and global optimization. Statistics and Computing, 32:58.",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Reviewer_xaq1",
         "1699636558195",
         "3.0",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "211",
         "6",
         "9",
         "0.7536",
         "0.06515948960000001",
         "0.9111343622",
         "49",
         "38.8025",
         "11.8793",
         "15.971",
         "14.332699999999999",
         "12.8694",
         "0.0751",
         "96",
         "2",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "31",
         "73",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "The paper proposes a new sampling algorithm for multi-modal distributions, especially deep neural network posteriors. Specifically, the authors learn an adaptive Gaussian proposal along with sampling. Several experiments, including synthetic distributions and deep learning tasks, are conducted to test the proposed method. 1.\tThe studied topic of sampling on multi-modal distributions is important.\n2.\tThe proposed algorithm is simple to implement in practice. 1.\tThe proposed method does not achieve what it claims to “having both exactness and effectiveness”. Apparently, the method is not exact without the MH correction step. The method is only exact when the target distribution is a Gaussian with a diagonal covariance, which is a trivial case. I’m not sure what “perfect sampler” means in the paper. Overall, I think many claims need to be modified in order to be accurate and rigorous. \n2.\tThe methodology of the proposed method is confusing. The algorithm does not have a component to encourage exploring multiple modes. It is unclear to me how the method manages to find diverse modes. \n3.\tAlgorithm 1 seems to find a Gaussian distribution to approximate the target distribution. How is it different from variational inference? What are the advantages?\n4.\tWhy does the proposed method require a pretrained solution, theta_MAP? Will it work if training from scratch? \n8.\tI do not follow the reason for introducing the variance limit lambda. Why does the method need it?\n9.\tThe experimental setups and results are confusing. It is unclear if the authors also use a pre-trained solution for the baseline NUTS in S3.1. If not, then it is unfair to claim faster convergence of the proposed method than NUTS. Besides, given that the method uses a pre-trained solution, it is unsurprising that “We found that a-GPS converges so fast that a burn-in period was unnecessary”. For the time comparison, it is unclear if the authors include pre-training time.\n10.\tFor deep learning experiments, it will be better to include MCMC baselines, e.g. Zhang et al, as the proposed method belongs to MCMC methods. To show the samples are from diverse modes, the authors can visualize weight space and function space, similar to those in Zhang et al.\n\n\nZhang et al, Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning, ICLR 2020 1.\tWhy is LA’s inference time even less than MAP? Why is the proposed method’s inference time less than SWAG? Does the proposed method use Bayesian model averaging during inference?",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Reviewer_zCTz",
         "1699636558088",
         "3.0",
         "4.0",
         "1.0",
         "2.0",
         "2.0",
         "405",
         "0",
         "9",
         "0.7441",
         "0.0309343434",
         "0.9304510951",
         "49",
         "53.1978",
         "8.9835",
         "12.1736",
         "11.8164",
         "9.3087",
         "0.1932",
         "96",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "32",
         "73",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "The paper proposes a sampler that samples weights via traversing the loss landscape of a pre-trained deep neural network via a series of normal distributions. The approach is evaluated on a series of classification and out-of-distribution detection tasks. The paper proposes a sampler that samples weights via traversing the loss landscape of a pre-trained deep neural network via a series of normal distributions. The approach is evaluated on a series of classification and out-of-distribution detection tasks. - The main weakness of the paper is in the experimental evaluation. The experiments show convincingly that the proposal works with several architectures and several classification data sets (no regression tasks were evaluated). What it does not show is that it works better than its baselines, i.e., why should it be used instead of SWAG, or SGD-MC? E.g., SGD-MC almost always outperforms it (it is missing from Table 4, but the results in Table 13, show that it clearly performs better), except for the strange behavior in Table 6.   \n\n\n- The presentation of the paper is rather sub-optimal. E.g.,\n    - parameters such as $c$ and $\\lambda$ appear in the text long before they are even introduced, if at all. The important $\\lambda$, e.g., only is further detailed in Algorithm 1.\n    - The writing contains a lot of typos, e.g., for the first paragraph on the second page\n        - \"full-gradient MCMC similar **to** SG-MCMC\"\n        - \"SGLD **has** fast computations but **suffers** form inefficient explorations\"\n        - \"Previous **works** on state dependent\"\n    - Dropout's absence in most of the results is not explained in the main text but only appears in the one table where it is present rather than absent\n    - The writing is somewhat repetitive\n    - The reference list is full of arxiv preprints instead of the actual publications \n    - Table 4 contains wrong highlights in two columns (ECE and NLL), the same is true for several tables in the appendix.\n    - On the positive side, however, other details, like definitions of performance metrics are highlighted prominently\n\n### Minor\n- SGD-MC is mentioned in the text for Table 4 but not in the actual results\n- LA is missing in Table 3 without an explanation\n- Sec 2.1: \"the loss function, ..., typically cross-entropy is interpreted as the negative log-likelihood\". Cross-entropy is typical for classification tasks, but not for any other tasks. And in this case, it is not just interpreted as a negative log-likelihood, _it is_ the negative of a categorical distribution. \n- For the posterior in  (15). A Gaussian prior is $\\exp(-||\\theta||)$, similarly for the loss factor. This directly provides you with (17) instead of having to redefine anything.\n- Sec 3.2.2 \"separated by high loss area\". As Draxler et al. (2018) and Garipos et al. (2018) show there are a lot of paths of similar loss between a lot of maxima instead of a clear separation. (These motivated the SWA baseline of the present work)\n\n\n\n_____\nDraxler et al., _Essentially no Barriers in Neural Network Energy Landscape_, ICML 2018  \nGaripov et al., _Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs_, NeurIPS 2018 - The conclusion only discusses a-GPS' performance with respect to SWAG and Laplace. Can the authors additionally provide a deeper discussion on their relation to SGD-MC and in general summarize why their approach should be picked instead of these established baselines?\n- SGLD is mentioned in the related work, but never used in the experiments. Can the authors comment on this lack of comparison? Especially since they cite Izmailov et al. (2021) who showed good results for this approach.\n- A lot of approaches and networks diverged or failed otherwise throughout the experiments. Can the authors give further details? E.g., it seems rather strange that a simple model such as VGG should diverge on a straight-forward classification task such as CIFAR100.\n- The method was only tested on classification tasks. What about regression problems? Do the authors expect a similar performance? \n- How is the split in CIFAR10 and CIFAR 100 in 5/50 classes decided? _(Apologies if I missed it somewhere in the appendix)_",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Reviewer_RZPX",
         "1699636557963",
         "3.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "675",
         "3",
         "1",
         "0.7542",
         "0.0275083022",
         "0.8832126856",
         "49",
         "51.8979",
         "9.7817",
         "12.2617",
         "12.0985",
         "10.234",
         "0.077",
         "101",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "33",
         "49",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "The paper introduces the Cross-Guided Ensemble of Tokens (CrossGET), which is designed to enhance the efficiency of vision-language Transformers. It tackles the significant challenge of mitigating the computational costs and latency associated with vision-language models. Within this framework, two essential components come into play: Cross-Guided Matching and Ensemble, orchestrating the fusion of tokens guided by cross-modal cues, and Complete-Graph Soft Matching, contributing to the refinement of token matching outcomes. 1.Comprehensive Experimentation and Solid Theoretical Foundation: The paper's strength lies in its extensive and well-documented experiments, combined with a rigorous theoretical underpinning for the proposed method. This makes the work sound and reliable, both in terms of its theoretical framework and practical applicability.\n2. Relevance of the Addressed Problem: The choice of the problem addressed in the paper holds significant value, especially in the context of the substantial computational overhead associated with many state-of-the-art multimodal models. This highlights the practical importance of the research. However, it is recommended that the authors extend their analysis and experimentation to encompass a broader range of models, moving beyond the initial exploration with BLIP-2. This would further enhance the paper's contribution and generalizability. 1. Cross-Modal Guidance Utilization: In the paper, the emphasis is placed on the ability of CrossGET to be applied to modality-dependent models like BLIP and BLIP2. The approach involves learning a cross-token to serve as guidance for another modality. However, there are concerns about this approach. Taking BLIP as an example, it appears that it may not fully harness textual guidance. In scenarios like visual grounding, where different textual descriptions highlight various aspects of the same image, it raises questions about how CrossGET selects tokens from different texts to focus on.\n2. Unfair Experimental Comparisons: The paper contains instances of unfair comparisons in the experiments. For example, in section 4.1, the authors directly compare retrieval results of models such as TRIPS and UPOP. Yet, these models vary significantly in terms of training data and model parameter sizes, making the comparison less meaningful. To provide a clearer perspective, the paper should emphasize how much TRIPS, or similar acceleration methods, improve over the baseline, and how much the proposed method accelerates and enhances performance compared to the baseline.\n3. Limited Model Performance Improvement: The paper reports only marginal improvements in model performance while introducing a relatively complex method. Moreover, the acceleration achieved by the proposed method appears similar to that of ToMe. Given the relative complexity of the proposed approach, the effectiveness of this work may be questioned, especially if the gains in performance and acceleration are not substantial. 1. Implementation of Token Reduction in BLIP-2: It would be beneficial for the authors to provide more detailed information on how they specifically implemented token reduction in BLIP-2 within the context of their method. A more elaborate explanation of the process and its impact on BLIP-2's performance would enhance the clarity and completeness of the paper.\n2. Impact of CrossGET on OPT in BLIP-2: A notable aspect of this work is the introduction of CrossGET into the frozen OPT component of BLIP-2 for token reduction. However, it's important to consider that OPT is a decoder-only model. The paper should address how this approach might affect the inference capabilities of OPT and whether any experiments were conducted to analyze and verify why image captioning performance appears to be minimally impacted. Further insight into this aspect of the methodology would enhance the paper's robustness and contribute to a better understanding of the results.Im glad to improve my score if my   concerns be addressed.",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "Reviewer_Uwik",
         "1699636664998",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "586",
         "0",
         "6",
         "0.7977000000000001",
         "0.1171066253",
         "0.94465065",
         "48",
         "25.0653",
         "14.7832",
         "17.2295",
         "15.7704",
         "16.3387",
         "0.1262",
         "77",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "34",
         "49",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "This paper introduces CrossGET, a token reduction-based strategy, to accelerate vision-language transformers. The key contributions of CrossGET can be summarized as follows: 1) CrossGET incorporates cross-modal guided information through cross-modal tokens. 2) CrossGET employs the Complete-Graph Soft Matching (CGSM) strategy, which offers more reliable token-matching results compared to existing bipartite soft matching strategies. Experimental evaluations conducted across multiple models, datasets, and tasks demonstrate the superior performance of the proposed method. The acceleration of VL models is highly relevant for their practical deployment. While this paper presents promising results and extensive evaluations, there are important concerns that should be addressed before publication.\n1. Some experimental results are perplexing. Table 1 suggests that ToMe performs worse when equipped with Adapter or ExtraToken. However, Adapter and VPT are parameter-efficient tuning methods that enhance performance with minimal additional parameters. It is unclear how they could instead degrade performance. I suspect there may be errors in the implementations. It is recommended to double-check the results or provide convincing explanations. Additionally, the upper-right subfigure in Figure 4 is also confusing. In my understanding, CrossGET and ToMe have close GFLOPs under the same configuration (as evident from the left subfigure). Therefore, the significant differences in GFLOPs for each data point pair in the upper-right subfigure indicate that they are compared under different configurations. A reasonable explanation should be provided here. Moreover, the down-right subfigure seems to be unusual as well. How is it possible for the model to achieve even better performance (nearly 86) with only 1/10 GFLOPs? Are the settings the same as in other figures?\n\n2. The contribution of the Complete-Graph Soft Matching (CGSM) appears to be minor. For instance, Table 1 suggests that ToMe and CrossGET $\\Delta$ perform similarly in different metrics, indicating that the proposed CGSM may have little impact. ToMe employs the bipartite soft matching strategy for its efficiency and simplicity, and the ToMe paper demonstrates that this strategy can approximate optimal matching through extensive combination experiments. This paper should provide more evidence (visualizations, analytical experiments) to justify the effectiveness of the proposed CGSM.\n\n3. Most experiments in this paper focus on Image-Text retrieval tasks. Is the proposed method equally effective in other VL tasks, such as the CoOP benchmark or open vocabulary segmentation?\n\n4. This paper lacks an important comparison. \\[1\\] proposes reducing the number of tokens through clustering and demonstrates better performance than ToMe in accelerating transformers. However, this paper only briefly mentions it in the introduction without further discussion or comparisons. It is recommended to include more comparisons (\\[1\\] vs. CrossGET $\\Delta$, \\[1\\] + CGM&CGE vs. CrossGET $\\star$, etc., better in dense prediction tasks) with \\[1\\].\n\nI am glad to increase my rating if my concerns are addressed.\n\n\\[1\\]. Weicong Liang, Yuhui Yuan, Henghui Ding, Xiao Luo, Weihong Lin, Ding Jia, Zheng Zhang, Chao Zhang, and Han Hu. \"Expediting large-scale vision transformer for dense prediction without fine-tuning.\" Advances in Neural Information Processing Systems, 35:35462–35477, 2022a. No other questions.",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "Reviewer_4d9L",
         "1702028039451",
         "6.0",
         "5.0",
         "3.0",
         "3.0",
         "3.0",
         "489",
         "5",
         "6",
         "0.8278000000000001",
         "0.1423076923",
         "0.9290834665000001",
         "76",
         "31.5291",
         "12.1382",
         "15.0298",
         "13.6713",
         "13.8195",
         "0.1507",
         "76",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "35",
         "49",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "This paper proposes cross guided matching and cross guided ensemble as cross-modal importance indicator. Besides, a Complete-Graph Soft Matching algorithm is proposed as an improved version of ToME's bipartite soft matching. 1. Both Cross Guided Matching (CGM) and Complete-Graph Soft Matching (CGSM) is well motivated and proved to be effective.\n2. Extensive experiments are conducted on several vision language tasks for both modal indenpendent VL model (CLIP) and modal dependent VL model (BLIP2). I do recognize the amount of work that went into this submission. 1. The proposed approach is named as Cross-Guided Ensemble of Tokens, however, I find that the proposed Cross-Guided Ensemble (CGE) is not that useful as illustrated in Table 1. So, I think the paper should re-organize the structure and highlight the really useful designs.\n2. The proposed Complete-Graph Soft Matching is not specialized for cross-modal tasks, so does it outperform the ToMe algorithm in general visual recognition tasks? The proposed method can improve the model efficiency after training with little performance loss, and I am curious if the proposed method can also accelerate the training of multi-modal tasks.",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "Reviewer_oYGw",
         "1699636664735",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "183",
         "0",
         "4",
         "0.7942",
         "0.08515625",
         "0.9441901445",
         "48",
         "40.5737",
         "12.6515",
         "15.565",
         "14.5546",
         "14.8862",
         "0.0529",
         "73",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "36",
         "49",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "The paper proposes CrossGET to accelerate VLM by token merging. Specifically, this work introduces complete-graph matching to partition tokens and merge/reduce tokens based on similarities. The experimental results on common vision-language tasks demonstrate some effectiveness of the proposed method. The paper is well-organized and the presentation is good. The motivation of accelerating VLMs is clear. 1. The major issue is novelty. CrossGET is incremental over ToMe by replacing ToMe's matching algorithm, adding learnable tokens and adapt unimodal ToMe to the multimodal setting.\n2. As shown in Table 1, the newly proposed matching algorithm has marginal improvements.\n3. CrossGET is proposed to accelerate heavy VLMs. However, majority of experiments are carried out on relatively light-weighted BLIP. There's only a small section for the truly heavy BLIP2, which is a stronger VLM that really needs acceleration.\n4. CrossGET requires fine-tuning of VLMs. (1) In most cases, when models need fine-tuning, they are relatively small (acceleration is not demanding). (2) Huge VLMs that are really heavy can be used as zero-shot in different tasks or different datasets of a same task. In this sense, CrossGET which does not apply to pre-training stage is a bottleneck.\n5. The paper fails to compare or adapt relevant works \\[1\\]\\[2\\].\n\n\\[1\\] DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification, NeurIPS 2021\n\n\\[2\\] Not all patches are what you need: Expediting vision transformers via token reorganizations. ICLR 2022\n\n**Final recommendation**: I agree the paper is improved by additional experiments and extensive analysis, and thus I raise my rating to 5. When CrossGET is applying to Flamingo or BLIP2 which uses frozen LLMs, it reduces to accelerating only vision encoders? Then, there will be a bunch of alternative approaches in accelerating ViTs?",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "Reviewer_Yt1v",
         "1701806853489",
         "5.0",
         "4.0",
         "2.0",
         "3.0",
         "2.0",
         "283",
         "4",
         "5",
         "0.8172",
         "0.0279545455",
         "0.9102016687000001",
         "74",
         "38.8176",
         "11.3603",
         "13.9992",
         "13.1874",
         "12.0743",
         "0.049",
         "81",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "37",
         "145",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "This work considers training an agent without online interaction or abundant offline data but only with the reward function of the target environment. Borrowing the idea of rehearsal from the cognitive mechanism, this work proposes policy rehearsal. In detail, this work hopes to train an array of models to imitate the target model. Theoretical analyses indicate that the target environment performance gap between the policy trained in these imitated models and the optimal policy can be bounded by three terms, which are further summarized as diversity and eligibility. Based on these two criteria, this work proposes two corresponding reward functions for training imitated models and then uses these models to train the policy. Also, the proposed ReDM can easily combined with offline datasets. Extensive results show the effectiveness of ReDM. - The ideas about the setting are novel and important, minimizing interaction with the environment as much as possible is an important problem in the RL community. Also, introducing rehearsal into RL is novel and enlightening.\n\n- The writing of Sec 3.2 is clear and solid, I have roughly read all the proofs, which are written quite clearly.\n\n- The proposed ReDM utilizes two novel terms for learning an imitated model, which is interesting and helpful.\n\nCurrently, my evaluation of this paper is really Boardline. If authors can address my concerns in Weaknesses and Questions, or point out what I have misunderstood, I'd like to update my scores accordingly. Also, I will keep active in the following discussion stage. - The connection between diversity and controlling $\\epsilon_e, \\epsilon_a$ is unclear. For example, if all environments are the same, i.e., there is no diversity, it is obvious that $\\epsilon_a=0$ is minimal. There also needs more explanation about why $\\epsilon_e$ can be controlled via diversity.\n\n- Based on the previous points, one of my major concerns is why the proposed methods can help optimize the gap calculated in Thm 3.3. The authors have summarized the three errors in Thm 3.3 as diversity and eligibility, which indeed provides insights for analyzing this problem. But I think a more direct connection, like whether the objective in Sec 3.3 can be proven to directly control the three errors in Thm 3.3, will make the analyses more solid.\n\n- In experiments, providing the results directly trained in the target environments as the reference will better show the results.\n\n- Lack of some related works, like utilizing model-based methods for improving generalization \\[1-3\\], and finding diverse skills for unsupervised RL \\[4-6\\] as this work hopes to find diverse models.\n\n\\[1\\] Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning\n\n\\[2\\] Task Aware Dreamer for Task Generalization in Reinforcement Learning\n\n\\[3\\] The Benefits of Model-Based Generalization in Reinforcement Learning\n\n\\[4\\] Diversity is All You Need: Learning Skills without a Reward Function\n\n\\[5\\] Effective diversity in population based reinforcement learning - In my opinion, the considered setting is that the agent can only get the reward function of the target task but has no knowledge about the dynamic of the target task. Is it right? Given the offline data, it is understandable that the agent can learn the dynamic to some degree. But without an offline dataset, it seems that there is no idea for the agent to learn the dynamic of the target task. \n\n- Based on the previous question, I'm confused about the setting of Experiment 4.1 \" ReDM With no Interaction Data\". As there are no data about the environment and the agent can not interact with the environment, how does the agent to learn about the environment?\n\n- As Unsupervised RL considers training an agent in the environment without reward, in my opinion, the setting in this work is like training an agent and models in the environment with reward but without dynamic. As the dynamic of the target environment will vary a lot, whether finetuning the agent (as well as the model) in the target environment with few steps will be more reasonable?\n\n- About $r_e$ for Eligibility. The proposed method is to randomly sample N trajectories and estimate the biggest return. Is this inefficient as the state space and action space are continuous in experiments? Also, what is the choice of N in experiments?\n\n- I'm curious about the performance of ReDM in the D4RL setting (Sec. 4.3) but without any Interaction Data.",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Reviewer_AWzJ",
         "1700464672733",
         "6.0",
         "4.0",
         "3.0",
         "2.0",
         "3.0",
         "720",
         "5",
         "0",
         "0.7541",
         "0.0956459436",
         "0.9084495306",
         "57",
         "42.3274",
         "11.5374",
         "14.2015",
         "13.5218",
         "11.3151",
         "0.0512",
         "109",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "38",
         "145",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "This paper presents a pretty interesting idea called rehearsal, which is able to **initialize or warm up a generalizable policy with zero interaction data or limited mismatched offline data**. Concretely, the proposed method, *ReDM*, takes as input a reward function and a termination function and generates a set of transition functions or models. Imaginary trajectories can thus be generated by rolling out these transition models and used to warm up the policy. As some of the models may produce data close to the target environment dynamics, the policy warmed up with these data can have a good initialization when deployed to the target environment, which is helpful for subsequent fine-tuning. Additionally, the method can be modified for offline-RL settings, allowing it to learn a robust and generalizable policy even with a small amount of offline data mismatched with target environment dynamics. \n\nThe method is motivated theoretically and contains lots of analysis like performance bound, laying foundations for future study in this new direction. Besides, the experiments on the standard gym and D4RL environment empirically prove the effectiveness of the method for both online and offline policy learning. 1. The idea is novel unlike traditional model-based RL, this new idea suggests learning a bunch of transition models from reward function and termination functions, exempting the need for interaction data. \n2. In terms of soundness, it proves empirically and theoretically that the transition models learned in this way can help warm up the policy and improve its performance when deployed in environments with diverse transition dynamics. 1. The paper writing is not attractive. In my perspective, the main paper contains too much tedious content regarding the theoretical analysis and lacks an explanation for the rehearsal framework. My suggestion would be to move some theoretical content to the appendix and include at least one figure to explain the procedures of this new rehearsal framework and what it can achieve or why we need it. People don't care about the theoretical stuff until they are attracted by the idea and want to dive into it. Thus I suggest making some figures to explain the idea or the method.\n2. No standard deviation is included for experiments in Table 1. Also, there is no error bar in Figure 7. \n3. What is the $D_{TV}$ should be explained in the main paper. It is strongly related to your main theorem but without definition.\n4. What is relative performance? Is it calculated through minus the baseline performance?\n5. The axis *Number of models* in Figure 3 should be \\[0, 10, 20, 30, 40\\], right? 1. How about replacing the random model for calculating the eligible reward with a human-crafted planner? It is supposed to be helpful for improving the performance as well. I guess this can be a good direction for exploration and to make this method more practical. A simple rule-based planner is also as easily accessible as a reward function in most practical settings like robotics. \n2. In the zero interaction data setting, the method indeed works well in three simple gym environments. I wonder if the method still works well in the more complex Mujoco environment without any pre-collected interaction data. I am curious about its performance on high-dimensional control tasks.",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Reviewer_GFGi",
         "1699637116619",
         "8.0",
         "3.0",
         "4.0",
         "2.0",
         "4.0",
         "537",
         "1",
         "9",
         "0.7805000000000001",
         "0.12279079620000001",
         "0.9027240276",
         "47",
         "39.5944",
         "12.5012",
         "14.9712",
         "14.2443",
         "12.6653",
         "0.2889",
         "94",
         "0",
         "2",
         "0",
         "0",
         "iclr"
        ],
        [
         "39",
         "145",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "The paper proposes a method for offline model-based reinforcement learning. The idea is to generate a set of candidate dynamics models and learn an adaptive policy that optimizes the original reward on this candidate set. If the true dynamics are in the distribution of the candidate set, the adaptive policy should perform well on the true task. The central problem lies in generating a candidate set of dynamics models. The authors propose optimizing over dynamics models with RL using a reward that incentivizes (1) diversity among the set and (2) the tendency for random trajectories to achieve high reward. The method alternates between optimizing for a new dynamics model to add to the set and optimizing for a new adaptive policy given the current set. When interaction data from the true task is available, it is used to regularize the optimization over dynamics models. Experiments show the method can work with no interaction data on low-dimensional continuous control tasks (inverted pendulum, mountain car, acrobot). On two D4RL tasks (hopper, half-cheetah) with a small amount of random interaction data, the method outperforms prior offline model-free and model-based RL methods. The method is similar to MAPLE but replaces the dynamics model generation process with a more directed procedure (RL on a custom reward vs learning an ensemble of models). The reward used in the dynamics model generation process is well motivated by formal analysis of error bounds. The different components of the method are analyzed/ablated. My main concern is the limited applicability of this method beyond low-dimensional benchmark tasks due to some significant assumptions. The method assumes access to a query-able reward/termination function and the initial state distribution. Though more importantly, the method assumes that the dynamics can be easily parameterized and optimized over with RL. Additionally, the method assumes that random plans through the candidate dynamics models will achieve some non-zero reward (to optimize the dynamics models for the eligibility reward). These assumptions makes the method difficult to apply (if not impossible) in sparse-reward or high-dimensional (e.g image-based) environments. In principle these issues could be solved by providing the method with enough interaction data to learn a good dynamics model initialization. However, then prior offline model-based or model-free methods might also work well. Additionally, this still wouldn't make the method applicable to sparse reward problems. \n\nAnother concern is the limited scope of the experiments relative to prior work. The evaluations on InvertedPendulum, MountainCar, and Acrobot are good for analyzing the method, however for the comparison to prior work, experiments are only shown for HalfCheetah and Hopper. It would be good to additionally include at least Walker2d. Additionally, the experiments with interaction data only test random interaction data and relatively small amounts of data (200 and 5000 transitions). While it is understandable that this is the setting where the proposed method would excel, it would be good to also show comparison to prior work with interaction data of varying optimality and amounts (including the full D4RL datsets). \n\nThere is no discussion of MAPLE in the related work section. MAPLE is very related (just a different model generation process) so the similarities and differences should be addressed here. It would also be good to include a brief mention of meta-learning in the related work as the proposed method uses similar concepts when optimizing for the adaptive policy.\n\nSmaller comments:\n- Algorithm 1 does not say a lot about the method. It could be replaced by algorithms 5/6 from the appendix. \n- Figure 1 should use a more descriptive x-axis label like \"Tasks\".\n- Figure 3 needs a more descriptive caption that explains what \"model loss\" means here.\n- The locations of Figure 2 and 3 should be switched. - The explanation of the optimal policy gap is confusing. Specifically this sentence: \"This discrepancy highlights the candidate model set’s capability to derive a proficient policy in the model itself.\" Does \"model\" here mean the true dynamics?\n- \"we conjecture that a diversified dynamics model set will correspond to a smaller ϵa since recognizing the dynamics is much easier\" It's not clear to me why a more diverse candidate model would lower the adaptation cost. Could you explain this?\n- In Figure 6, what is the shown performance relative to? Is this the performance of the policy at each iteration in the model at that iteration minus the performance of the policy at that iteration in the ground truth model?\n- Figure 7: Are these results averaged over Hopper and HalfCheetah and averaged over each gravity level?",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Reviewer_anZu",
         "1700596735397",
         "8.0",
         "3.0",
         "3.0",
         "2.0",
         "3.0",
         "752",
         "0",
         "0",
         "0.7605000000000001",
         "0.1021203666",
         "0.8813570142",
         "58",
         "35.9155",
         "12.6506",
         "15.7954",
         "14.5885",
         "12.6808",
         "0.5623",
         "98",
         "0",
         "0",
         "0",
         "2",
         "iclr"
        ],
        [
         "40",
         "145",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, the authors introduce the idea of *rehearsal* into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, they propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to natually generalize to previously unseen environments. Their experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with zero interaction data. Besides, they further extend ReDM to scenarios where limited or mismatched interaction data is available. The provided empirical results reveal that ReDM produces high-performing policies compared with other offline RL baselines. 1. The problem of policy rehearsing in offline reinforcement learning is interesting and challenging as an academic topic.\n2. The description to the problem modeling and the methods is clear and generally easy-understanding.\n3. The proposed method is well motivated by comprehensive preliminary theoretical analysis.\n4. The experiment analysis is in-depth and insightful, which helps the readers bettere understand the effectiveness and underlying mechanism of the propose methods. 1. The environments used in the experiments are still limited. I encourage to supplement more environments to demonstrate the applicability of your proposed method is possible. Otherwise, we may argue if the solution can only be effective on some specific kinds of tasks.\n2. Considering the proposed method needs to train the new dynamics models and meta-policy simultaneously, the complexity of this method and the training stability/convegence are encouraged to be clarified and analyzed.\n3. The assumed accessibility to the task reward function and initial state distribution is often unrealistic in the real applications. 1. I am curious if totally no interaction data, how can the generated dynamics model approximates the real dynamics in the target environment. It seems there lacks enough grounding points to support this potential. Does there exist the probability that the generated dynamics models are far from the dynamics in the target environment? I hope to see more analysis on this during the rebuttal.\n2. The D4RL benchmark in your experiments is all Mujoco tasks with low input dimensions. Could you please consider incorporating some more high-dimensional task, in which the hypothesis space is too large to narrow down?\n3. In the paper, you claim that the interaction data is only used to narrow down the hypothesis space. But could you please consider how to utilize these interaction data in a more direct way to better facilitate the policy learning as the complement to the purely dynamics model learning, like finetuning the learned meta policy? Besides, I cannot agree the statement that the biasedness in the interaction data will somehow hinder the policy optimization in traditional offline RL methods. If such pre-collected trajectories are expert ones or near-optimal ones, such *biasedness* can actually help avoid some low-value and dangerous states.\n4. Considering your method encourages the diversity in the model learning part, some learned dynamics models may be unreasonable though the meta policy can still achieve high returns via planning in such models, like violating the physics laws or economics laws. And I can hardly expect the *eligibility* part in your method can help alleviate this 'short-path' issue. More explanations and discussions are encouaged during the rebuttal phase.",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Reviewer_YzNF",
         "1700708716647",
         "8.0",
         "3.0",
         "2.0",
         "3.0",
         "3.0",
         "614",
         "0",
         "11",
         "0.7928000000000001",
         "0.0638390498",
         "0.9844013453",
         "59",
         "22.4917",
         "15.0427",
         "18.6066",
         "16.5463",
         "15.3218",
         "0.4435",
         "102",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "41",
         "101",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "The paper focuses on the problem of \"censorship\" in large language models (LLM). Specifically, the paper argues that it is unfeasible to address this issue by relying on ancillary \"machine learning\" (ML) techniques, and that it should rather be tackled via mechanisms belonging to the security domain. To support such a position, the paper presents detailed theoretical arguments demonstrating that LLM censorship is an \"undecidable problem\", thereby revealing that using ML-based techniques, such as, e.g., another language model (LM), will never provide a foolproof solution. ## High-level\n\n+ Outstanding writing\n+ Relevant Problem (for both research and practice)\n+ The theoretical arguments are well-founded\n\n## Comment\n\nI deeply thank the authors for writing this piece and submitting it to ICLR'24. I've loved reading it, and I was genuinely pleased by the outstanding writing quality: out of the papers I reviewed for ICLR'24, this one is by far the best written one. Moreover, the paper tackles a very open issue and the \"conclusion\" can be leveraged by researchers and practitioners alike: the latter can benefit by integrating additional security mechanisms in their products, whereas the former would be provided with \"clear evidence\" that tackling censorship by means of traditional ML methods will never provide a foolproof solution. Indeed, the theoretical arguments made in this paper are well-rooted, and I particularly appreciated connecting LLM to Turing Machines and the application of the Rice Theorem as a scaffold to support the paper's main claims. \n\nHowever, despite all such strengths, the paper also presents (imho) various weaknesses, which are discussed below. ## High-level\n- It suffers from an \"identity crisis\" (it feels more like a \"position\" paper)\n- Lack of a concrete experiment \n- Some statements require further evidence to be supported\n- The paper is built on a strong assumption that does not seem to have been accounted for\n- The \"mosaic prompts\" are not really novel\n- Some pieces of the text are unclear\n\n\n## Comment \n\nDespite my appreciation, I do have concerns about the suitability of this paper to ICLR'24. Before I discuss such concerns, however, I want to emphasize that my remarks are _my opinions_. I couldn't spot any technical or methodological flaw in the paper (which is also well-written): hence, my critiques are mostly directed at the \"significance\" aspect of the paper, and I endorse the authors to reflect on the following remarks. Ultimately, my goal is to help them make this paper as a noteworthy contribution to the state-of-the-art (be it for ICLR'24, or for any other venue).\n\n### **Identity Crisis (Lack of a concrete experiment)**\n\nThe most prominent weakness is that, IMHO, the paper suffers from an \"identity crisis\" -- which is rooted on the fact that the paper touches both the \"security\" and \"ML\" domains.\n\nOn the \"security\" hand, all the considerations made in the paper are \"obvious\". The fact that, e.g., an attacker can bypass censorship mechanisms by inducing a LLM to output a \"malicious set of actions\" through individual prompts is \"not new\", and the fact that a similar strategy can fool essentially any precaution is \"not surprising\". Indeed, this is a well-known problem in reality, and the only way to solve this problem is by reading the attacker's minds. Plus, ultimately, LLM are just \"tools\": whether they are used in good- or bad-will is a different manner (and this had been known since the development of cryptographic protocols, since they also aid attackers in preventing their messages from being interpreted). So, to summarise, as a \"security\" researcher, the conclusion of this paper was already known, and the supporting theoretical arguments were hence somewhat redundant.\n\nOn the \"ML\" hand, the paper lacks a clear experiment that demonstrates at least one of the scenarios described in the ```practical implications```. Indeed, after introducing some definitions and demonstrating a given theorem, the paper merely limits to provide \"thought experiments\" discussing how an hypothetical attacker can achieve their goal. Yet, all such discussions are textual: there is an excessive usage of the words \"can\" \"could\" \"may\" \"it is possible that\". The paper does provide some references (e.g., \"The authors of... showed that this can be done\") but the lack of a concrete experiment is still hard to overlook. Such a lack is further aggravated by the additional what-ifs which project LLM into the future (e.g., ```these risks could become even more problematic```). I acknowledge that \"anything can happen\", but this is a weak argument. \n\nHence, I feel that the lack of a \"hard\" experiment is a significant weakness of this paper, which affects both its appeal to the security domain, as well as the one to the ML domain. For instance, I would have appreciated a clear demonstration of Figure 2 (I've spent ~30 minutes trying to have ChatGPT to process similar instructions, but I've never been successful).\n\nPut differently, the paper currently reads as a \"visionary paper\" or a \"position paper\" rather than a true research paper. **However** do note that I am not saying that the paper is devoid of merit: providing \"theoretical evidence\" that it is not possible to craft \"perfect\" ML-based censorship mechanisms is a strong message.\n\n\n### **Lack of evidence for some statements**\n\nOne of the major points in support of the \"value\" of this paper is that the current way to address censorship in LLM is by means of \"ML-based mechanisms\", and --after demonstrating that doing so will never guarantee 100% protection-- the suggestion that censorship should be treated as a security problem.\n\nIndeed, to quote the abstract:\n\n> Commonly employed censorship approaches treat the issue as a machine learning\nproblem and rely on another LM to detect undesirable content in LLM outputs.\n\nThe following was also stated in the Introduction:\n\n> Such methods range from fine-tuning LLMs (OpenAI, 2023) to make them more aligned, to employing external censorship mechanisms to detect and filter impermissible inputs or outputs (Markov et al., 2023; Chockalingam and Varshney, 2023; Greshake et al., 2023).\n\nHowever, I only see 4 works listed here. Hence, I wonder: is it really true that ML-based methods are the \"way-to\" address censorship problems? For instance, even Greshake et al. state ```Unfortunately, it is currently hard to imagine a foolproof solution for the adversarial prompting vulnerability```; moreover, the authors of NeMo Guardrails (used by NVIDIA (Chockalingam and Varshney, 2023)) state the following in their \\[GitHub repo\\](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/security/guidelines.md):\n\n> Integrating external resources into LLMs can dramatically improve their capabilities and make them significantly more valuable to end users. However, any increase in expressive power comes with an increase in potential risk. To avoid potentially catastrophic risks, including unauthorized information disclosure all the way up to remote code execution, the interfaces that allow LLMs to access these external resources must be carefully and thoughtfully designed from a security-first perspective.\n\nTo me, the impression is that these mechanisms are proposed as a \"partial\" solution, since even the respective authors advocate for security principles to be followed. In light of this, the underlying \"message\" of the paper partially loses its value (at least imho). It would be enticing to carry out of more profound analysis of current works on approaches for LLM censorship, and pinpointing how many of such works truly claim to address censorship in an ML-only way, without making any security consideration: doing so would dramatically improve the contribution of this paper.\n\n\n### **A strong assumption**\n\nBy looking at the definition of \"censorship mechanism\", the impression I have is that the paper assumes that censorship is always applied \"a-posteriori\". That is: the LLM receives an input, elaborates a response, and then --right before providing the response to the user-- it checks whether the response is permissible or not by means of some censorship. I wonder: is this really true?\n\nBecause, if this is not the case (i.e., there is some censorship applied to some \"intermediate process\" of the response), then the censorship would work, since it would be applied before the application of the transformation which makes the text encrypted. \n\nIn light of this, I invite the authors to provide evidence that this assumption holds _in reality_ (plus, I conjecture that such an observation CAN be used to develop some more effective defenses!). Otherwise, the authors should acknowledge that their analysis only applies to a specific use-case of censorship (do note that, however, this would decrease the impact of the paper). Alternatively, the authors can provide evidence (theoretical and, possibly, practical) that the envisioned analysis/findings hold even in these intermediate cases.\n\n### **Naming of Mosaic prompts**\n\nWhile I appreciate the name \"Mosaic Prompts\", I feel the way it is presented to be \"excessive\". Indeed, the described procedure is exactly the same as the \"divide et impera\" (or \"divide and conquer\") which is the de-facto praxis in computer science (and already associated to LLM, see \\[here\\](https://medium.com/@finomeno/exploring-large-language-models-insights-for-architects-393600dae131) and \\[here\\](https://medium.com/@digitalmiike/chatgpt-guide-10-effective-prompt-strategies-for-enhanced-output-979c8032eaaa)).\n\nHence, I endorse the authors to tone down this name, or at least acknowledge that it is just a renaming of a popular technique in computer science. (I am stating this also in light of the \"acknowledgment\" made in Footnote-1 -- which I greatly appreciated!)\n\n### **Some pieces of text are unclear**\n\nAlthough the paper is excellently written, I had issues in understanding some parts of the text. In what follows, I will directly quote each of these \"problematic\" parts, and explain the problems I encountered---starting from the Introduction.\n\n> Such constraints can be semantic, e.g. does not provide instructions on how to perform illegal activities, or syntactic, e.g. does not contain any ethnic slurs from a provided set.\n\nI did not understand the provided examples -- or rather, it is hard to determine the subject of the examples. I recommend rephrasing to, e.g., \"the output must not provide...\"\n\n> methods against malicious attackers.\n\nAre there attackers who are not malicious? (this redundancy occurs many times in the paper)\n\n> restricting the string x to the set of permissible strings P\n\nI recommend being more specific: \"the string x to the set of permissible strings P that can be constructed by the LLM model\" (otherwise, it may be confused with a string written by an user)\n\n> demonstrated in Fig. 1\n\nThe caption states \"Figure\" (and not Fig.)\n\n> typically defined by the language recognised it recognises\n\nThis is unclear \n\n> descriptions of Turing machines can be viewed as a programming language, capable of being interpreted by a universal Turing machine capable of emulating them.\n\nPlease revise this statement as it is very confusing.\n\n> As the semantic censorship impossibility result that we established by connecting the problem of semantic censorship to Rice’s Theorem doesn’t fully capture real world censorship settings where inputs and outputs are bounded we seek to provide another result on the impossibility of censorship that does.\n\nMake this shorter, especially since the same message was written two lines before.\n\n> we assert that given an invertible string transformation g\n\nIs this \"g\" supposed to be the \"bijective transformation\"? Still, I am slightly confused about this \"g\" here; perhaps an example would be useful.\n\n> it is capable of applying g to its output x to instead output g(x).\n\nThis is very unclear. Do you mean g(g(x))?\n\n> either nothing is be permissible\n\nTypo\n\n> While existing LLMs are good at \\[...\\] Yuan et al. (2023)\n\nThis paragraph appers to be disconnected from the \"Practical Implications\". Or rather, it does not align well with the way the previous paragraph ended. Actually, I do not see any \"practical implications\" that are truly compellling here.\n\n> While our results describe adversaries which can instruct\n\nWhich results? \n\n> For example, users could provide \\[...\\] running the model\n\nIt would be wonderful if the authors showcased a way to do so in practice _today_. \n\n> In an extreme setting where there exist only 2 permissible output strings\n\nWhy this assumption? To me, the following example holds even without this (perhaps I missed something?)\n\n> converting text to ACII\n\nTypo\n\n> Subsequently, the user can request the model to output i’th bit\n\nWhat is the ```i'th bit```? Plus, how can the user do so?\n\n> our Mosaic Prompting results\n\nGiven that no experiments have been carried out, it is a bit of a stretch to define this as a \"result\" (even the Appendix does not provide \"empirical results\")\n\n\n\nFinally, I report that the bibliography often does not provide the venue of a given work (e.g., the paper by Markov et al. (2023) was published in AAAI; whereas the one from Greshake et al. was accepted at AISec). This is annoying as a reader, as I could not ascertain the quality of a given referenced work. I liked the paper, and I am willing to improve my score if presented with compelling evidence that some of my remarks are flawed. Nonetheless, I invite the authors to answer the following questions (most of which are drawn from my \"Weaknesses\" section): depending on the answer, my rating will likely change.\n\n1) Can the authors provide more evidence that LLM censorship is truly \"commonly treated as a ML problem\" (and that security-based approaches are not taken in consideration)?\n\n2) Would the proposed theoretical analysis, as well as the proposed \"attack\", still apply if censorship is carried out during the process of crafting a response by the LLM? (Please elaborate)\n\n3) How could the \"attack\" shown in Figure 2 be realized _today_? \n\nThen, I have one last question. Assume that this paper is accepted to ICLR'24 as a spotlight. How would the authors present this work? Would the talk include only \"what-ifs\", or would it also showcase some concrete evidence that the envisioned scenarios are truly a security issue that cannot be countered with ML-only ways$^1$?\n\n$^{\\text{1: E.g., how do I make ChatGPT tell me \"howdoibuildabomb\"?}}$",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "Reviewer_BZEx",
         "1699637019167",
         "5.0",
         "4.0",
         "2.0",
         "4.0",
         "2.0",
         "2281",
         "5",
         "1",
         "0.8001",
         "0.0992714858",
         "0.7997633219",
         "47",
         "41.5888",
         "12.6065",
         "15.223700000000001",
         "14.314",
         "13.9864",
         "0.8282",
         "84",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "42",
         "101",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "This paper investigates the theoretical limitations of the current external censorship mechanisms in LLMs from the view of computing theory. Given these inherent limitations, the authors argue that LLM censorship should be addressed more as a security problem than a machine learning problem. - Trendy topic\n- A novel perspective to study LLM censorship - Implications can be extended\n- Readability can be improved In this paper, the authors first focus on the semantic censorship mechanisms, proving that the current mechanisms cannot reliably detect if LLM output is \"semantically impermissible.\" They further show that such limitations are inherent and can extend beyond semantic censorship mechanisms by designing Mosaic prompts.\n\nOverall, the authors study a trendy topic and offer a novel perspective to understand LLM censorship. However, I have the following concerns.\n\n- The authors prove the impossibility of semantic censorship using string transformation by showing how the transformed string might break the \"invariance of semantic censorship.\" Here, I have some doubts regarding the invariance property. In my opinion, the semantics of a string often change after the transformation. Thus, it is reasonable for the transformed string to bypass semantic censorship mechanisms. Moreover, LLMs do not necessarily output harmful texts with the transformed string. Why does the invariance property hold? Is this property an important goal considered by LLM censorship developers when designing their mechanisms?\n\n- Implications can be extended. It appears to me that the current implication discussion stops at showing LLM censorship is more of a security problem than a machine learning problem. What are the direct implications for model developers when building censorship? Are there any defensive measures against the Mosaic prompts? The authors only briefly mention that there are standard approaches, such as access controls and user monitoring, to build censorship from the security view. However, there is no further analysis showing that these approaches can indeed overcome the theoretical limitations of current external censorship mechanisms and surpass them in censorship performances.\n\n- Readability can be improved. Many sentences are too long and difficult to read. For example, \"Thus, we can understand censorship as a method of determining permissibility of a string and censorship mechanisms can be described as a function, f(x), restricting the string x to the set of permissible strings P by transforming it to another string x' ∈ P if necessary, e.g. x' ='I am unable to answer.'\"",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "Reviewer_ST3b",
         "1699637019047",
         "5.0",
         "2.0",
         "3.0",
         "2.0",
         "2.0",
         "394",
         "0",
         "0",
         "0.787",
         "0.08387096770000001",
         "0.8256777525000001",
         "47",
         "29.8058",
         "13.2713",
         "16.9721",
         "15.3932",
         "13.4282",
         "0.1199",
         "100",
         "0",
         "0",
         "2",
         "0",
         "iclr"
        ],
        [
         "43",
         "101",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "The paper's topic studying censorship and its effectiveness is interesting, ie. what kinds of knowledge can be extracted from LLMs and whether protection mechanisms can be circumvented. But the paper contributes little of practical value. It also lacks a proper evaluation to claims and conceptual illustrations. The theoretical treatment would be interesting, but the paper claims are mostly direct implications of existing theorems or require minor enhancements. Overall, the contribution appears marginal.\n\nDetails:\n* abstract:  LM -> LLM or define it.\n*  The example, Figure 1 is not of any practical value and might be conceptually it is flawed - the three steps are the least challenge in making successful ransomware attack (deploying it is much more of an issue, avoiding being detected too). The Mosaic prompt is also not very convincing. Both should be shown to be actually working.\n* The idea to use encryption (Appendix A) is interesting, but is this a practical concern? Does it add to the discussion of how protection mechanisms can be circumvented? It might, if it was shown to work. But as is, it seems incomplete.\n* On a high level, the paper argues that censorship cannot work because a malicious person might not directly asked for censored actions, but for steps needed for these actions, which might not be censored. But this holds for almost anything in our world and is nothing new. Any technological knowledge can be abused.  A knife can be used to kill or to save a life (doctor during surgery).  A motor can power an ambulance saving life or a truck performing a terrorist act. This is general knowledge. The paper seems to sell this as a novel aspect. The fundamental question is: Should knowledge and technology be made available that can be abused?  This is also not really a security question as the paper argues. Obviously any abuse relates to security, but I don't see, why the paper's claim to say \"LLM censorship (ie. avoiding censorship through attacks) is a security concern\" should be a new insight. see above see above see above",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "Reviewer_3fNc",
         "1699637018926",
         "3.0",
         "3.0",
         "2.0",
         "2.0",
         "1.0",
         "346",
         "0",
         "1",
         "0.7665000000000001",
         "0.09049690690000001",
         "0.7391343713",
         "47",
         "52.9766",
         "9.1188",
         "11.819",
         "11.950800000000001",
         "8.4543",
         "0.0291",
         "95",
         "0",
         "1",
         "1",
         "1",
         "iclr"
        ],
        [
         "44",
         "101",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "This paper explores some of the theoretical limitations of LLM censorship, the problem of identifying permissible inputs and outputs to language models. In particular, the paper focuses on the limitations of semantic censorship, or filtering of strings based on their meaning. First, the paper shows that determining whether a “program” output by an LLM is permissible is an undecidable problem. Then, the paper discusses the impossibility of semantic censorship by showing that strings can undergo transformations which preserve their semantic meaning but are otherwise unintelligible except to a user who knows how to invert the transformation. Finally, the paper introduces Mosaic Prompts, a way of breaking up an impermissible prompt into permissible pieces. This paper’s primary strength is that it identifies an important issue to focus on that has been unexplored in the literature - what are the theoretical limits on the ability to filter LLM inputs or outputs based on their semantic meaning? The paper is a good exposition of this problem and the theoretical settings it considers highlight some important limitations for the task. The figures and tables also do a good job of clarifying some of the concepts in the text. Overall, the authors’ assertion that syntactic censorship is likely to be more successful than semantic censorship is well-taken from this work. This paper’s primary weakness is the number of assumptions and limitations that come into the different theoretical treatments that the paper covers. First, the paper itself admits that the treatment of Rice’s theorem for programs on Turing Machines is not generally applicable to the bounded inputs and outputs case of LLMs. Second, in the section 2.2 on the invertible transform, I believe there may be a flaw in the reasoning of the proof. Under assumption 1, the authors assume that the model is capable of following instructions such that it can produce the transformation $g$. This assumption is explicitly stated. It seems that the proof also requires that the LLM (or corresponding companion LLM that is doing censorship) is unable to compute the inverse transformation $g^{-1}$. If it were, then it could check the semantics of the un-transformed string for permissibility. This assumption weakens the power of the impossibility result in my opinion. Finally, while I think that the Mosaic Prompt approach is interesting, I do think the paper underestimates the LLM’s ability to attend to previous prompts. While in the mosaic approach the model is likely to answer early prompts, it is conceivable that once enough of the pieces of the impermissible prompt are present, one would be able to detect the impermissibility of the conversation overall. Does the impossibility result in Section 2.2 require an assumption that $g^-1$ is not computable by the permissibility model?\n\nIs the problem space simplified at all by considering the compositionality of strings? For example, if there is an impermissible substring within a larger string, does that make the larger string automatically impermissible as well?\n\nDoes something like “fuzzy” permissibility fit into this framework at all? For example, many prompts and outputs would be considered “borderline” or have some level of “toxicity” if sent to a human rater, rather than a bright-line permissible vs. not rule. Does that make the problem any easier or harder?",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "Reviewer_xHLz",
         "1699637018817",
         "5.0",
         "3.0",
         "2.0",
         "4.0",
         "3.0",
         "537",
         "0",
         "0",
         "0.7747",
         "0.1567073171",
         "0.8508368134000001",
         "47",
         "36.7413",
         "13.0664",
         "15.4781",
         "14.6074",
         "13.6159",
         "0.06570000000000001",
         "99",
         "0",
         "0",
         "1",
         "0",
         "iclr"
        ],
        [
         "45",
         "39",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "This paper delves into the challenges presented by multivariate long-term time series forecasting (MLTSF), specifically the difficulty of capturing cross-channel dependencies and temporal order information using current Transformer-based models. Despite the achievements of Transformer models in various fields, their application in MLTSF reveals certain inadequacies. Models like Informer, Autoformer, and FEDformer, while advanced, still face challenges in understanding intricate channel relationships in multivariate time series. \n\nTo address these issues, the authors propose the GRformer model. This innovative solution combines the strengths of Graph Neural Networks (GNN) and position encoding derived from Recurrent Neural Networks (RNN). The inclusion of a mix-hop propagation layer within a feedforward neural network promotes efficient interaction between different time series data points. Additionally, by leveraging a multi-layer RNN, the model recursively generates positional embeddings, emphasizing the importance of sequence order. \n\nThe paper's empirical tests, conducted on eight real-world datasets, demonstrate the GRformer's superior predictive accuracy in MLTSF tasks, underlining its potential as a novel solution in the field of time series forecasting. **Strengths**:\n\n1. **Originality**: \n   - The GRformer presents a unique fusion of GNN and RNN-based position encoding within a Transformer framework, addressing gaps in MLTSF.\n   - The incorporation of the Pearson correlation coefficient for graph structure is a notable innovation.\n\n2. **Quality**: \n   - Rigorous empirical validation is conducted on eight real-world datasets, ensuring robustness.\n   - The model's design is comprehensive, with the mix-hop propagation layer and RNN-based position encoding as highlights.\n\n3. **Clarity**: \n   - The paper delineates complex concepts coherently, facilitating reader understanding.\n   - Distinctive features and advantages of GRformer over existing models are clearly articulated.\n\n4. **Significance**: \n   - The GRformer's advancements in capturing cross-channel dependencies have potential broad impacts in time series forecasting.\n   - The paper paves the way for future research by highlighting existing challenges and areas of improvement.\n\nIn essence, the paper excels in its innovative methodology, thorough validation, lucid presentation, and relevance in the field. 1. **Mathematical Notation Consistency**:\n   - The authors' use of mathematical notation appears inconsistent. For instance, function names should ideally be presented in regular typeface rather than italic. Proper notation ensures clarity and avoids potential confusion.\n\n2. **Graph Construction Using Pearson Coefficient**:\n   - While the authors opted for the Pearson correlation coefficient for graph construction, which subsequently serves as the foundational structure for the GNN, one might question the exclusion of making GNN parameters learnable. This adaptability could potentially offer more flexibility to the model.\n\n3. **Assumption of Homoscedasticity**:\n   - The Pearson coefficient assumes homoscedasticity in the data. It's unclear if the authors verified this assumption across their datasets. Such checks are crucial to ensure the validity of the chosen coefficient.\n\n4. **Alternative Correlation Metrics**:\n   - The paper doesn't seem to explore or discuss other potentially beneficial correlation coefficients like Time-Lagged Cross-Correlation (TLCC) or Dynamic Time Warping (DTW). An exploration or justification of the chosen metric over others could have added depth to their methodology. **Hyperparameter Selection in Graph Construction**:\n   - The methodology introduced by the authors involves several hyperparameters, which seemingly have a significant impact on the model's outcomes. Specifically, when constructing the graph structure:\n     - How was the threshold value of 0.8 determined?\n     - Regarding the 'topk' selection, how was the value of \\( k \\) chosen, and does it correlate with the number of variables?\n\n **Mix-hop Propagation Parameter**:\n   - How was the value for the EMA parameter \\( \\alpha \\) in the mix-hop propagation process determined?",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Reviewer_qMLP",
         "1699636047386",
         "6.0",
         "2.0",
         "3.0",
         "3.0",
         "3.0",
         "562",
         "0",
         "9",
         "0.8096",
         "0.1543367347",
         "0.9348136187",
         "53",
         "12.8649",
         "15.8084",
         "19.5397",
         "16.5463",
         "17.2062",
         "0.1041",
         "83",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "46",
         "39",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "This paper enhances Transformer with GNN and position embedding generated by RNN for multivariate time series forecasting. The proposed GRformer constructs graph by pearson correlation and uses a mix-hop propagation GNN layer to capture cross-channel dependency. For temporal dependency, it uses an RNN to recursively generate positional embeddings. Experiments on eight real-world datasets show that the proposed GRformer is on compare with SOTA model, PatchTST. - This paper is well-written and easy to follow.\n- Using pearson correlation for graph constructing is reasonable and efficient. My main concern is that the novelty is limited:\n\n- For RNN-based position embedding: \n  1. The idea of enhance Transformer with RNN is not new\\[1\\].\n  2. RNN operates recursively and cannot be parallelized, which offsets the efficiency advantages of Transformers that can be highly parallelized.\n  3. Ablation study in Table 3 shows that the improvement of RNN against previous learnable position embedding is not significant.\n- For Mix-hop propagation: \n    1. The mix-hop propagation layer is **exactly the same** as that in \\[2\\] and there is no explicit reference to it in Section 3.2.3.\n    2. Besides the graph construction via Pearson correlation, this is a direct combination of PatchTST and \"Connecting the dots\".\n\n\\[1\\] Qin, Yao, et al. \"A dual-stage attention-based recurrent neural network for time series prediction.\" arXiv preprint arXiv:1704.02971 (2017).\n\n\\[2\\] Wu, Zonghan, et al. \"Connecting the dots: Multivariate time series forecasting with graph neural networks.\" Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining. 2020. - What is the authors' primary objective in visualizing the weights of the MLP in Figure 1(b), given that it only reflects the correlation among hidden states? \n- Could you provide a comparison of the computational efficiency between your RNN-based position embedding and a learnable position embedding, particularly in relation to varying sequence lengths?\n- How were the hyperparameters (0.8 and $k$) in Equations (2) and (3) chosen, and what impact do these specific values have on the model's performance and behavior?",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Reviewer_Evwp",
         "1699636047317",
         "3.0",
         "4.0",
         "2.0",
         "3.0",
         "2.0",
         "329",
         "5",
         "7",
         "0.7978000000000001",
         "0.0755532213",
         "0.936165452",
         "53",
         "36.6467",
         "11.615",
         "15.9253",
         "14.0465",
         "12.0187",
         "0.38480000000000003",
         "74",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "47",
         "39",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "This paper proposes GRformer, a new neural architecture for multivariate long-term time series forecasting (MLTSF). The authors propose a hybrid architecture that consists of a Transformer-based graph neural network to model cross-channel dependencies and a recurrent neural network to model temporal dependencies. The proposed model shows promising performance on eight benchmarks. However, the motivation and reasoning behind the criticism of the Transformer-based approach are difficult to understand. Some of the claims are made without proper evidence, or by simply citing previous work, without providing any further detailed study or analysis. Additionally, the performance improvements on the benchmarks seem to outperform the baselines. However, I believe the claim of achieving a performance improvement with a 5.7% decrease in MSE and 6.1% decrease in MAE is misleading. These numbers are calculated by averaging MSE and MAE without considering the scales between different benchmarks and metrics. ILI has much higher mean squared errors (MSEs) and mean absolute errors (MAEs) than other benchmarks. This means that if you compute the average score in this way, the average score can be dominated by the relative improvement in this specific dataset. The tone reporting the improvement suggests that the model showed around a 6% decrease in errors on all benchmarks, but the average relative improvement for each benchmark at different metrics is actually 2.55% for MSE and 4.96% for MAE. The model achieves improvements over 7 different benchmarks using 4 metrics for each benchmark dataset. The experiments are done extensively with ablation on different positional encoding strategies. This however raises a question on why the RNN is needed (Table 3. R: the first column vs L: the second column show a very minor difference). I am not sure what I am seeing in Figure 1(b), and I don’t understand how to interpret the authors' claim that cross-channel interaction is chaotic based on simply visualizing the weight matrices of the Transformer's dense layer (internal MLP).\n\nI am not sure I understand the authors' point about positional encoding not being able to represent temporal orders well. RNNs have their own problems, such as vanishing gradients when modeling long-term temporal dependencies. Are you suggesting that RNNs outperform Transformers in multivariate long-term time series forecasting (MLTSF)?\n-> Are the ablation results in Table 3 the experiments to back this claim? If that's the case, the performance difference between an RNN-based positional encoding (?) vs a learned positional embedding is almost 0.\n\nWhat exactly is the RNN-based position encoding method? In the caption for Figure 2, it says \"The multi-layer RNN injects temporal order information.\" However, RNNs are not just injecting temporal order information as some sort of advanced positional encoding method; they can actually learn temporal dependencies. I am not sure if you are distinguishing between positional encoding and learning temporal representation.\n\nFigure 2 (b) is hard to understand, at least explain the operator signs in the caption, arrows are not clear. What is the main evidence that Transformer-based models are ineffective at capturing cross-channel dependencies and temporal orders? If Transformers were bad at capturing temporal orders, they would not have become as popular as they are today. I am curious why the authors make such claims, as I do not see any plausible supporting evidence in the manuscript.\n\nThe authors mentioned that they used multi-layered RNNs, however in the appendix, it's said 1-layer RNN was used. Can you clarify the details of the RNN architecture?\n\n“To properly capture temporal dependencies, we consider using a multilayer RNN to encode the positions in the time series.” Why deep RNNs can properly capture temporal dependencies while Transformers can’t?",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Reviewer_rJkP",
         "1699636047246",
         "3.0",
         "4.0",
         "1.0",
         "2.0",
         "1.0",
         "596",
         "0",
         "0",
         "0.7782",
         "0.0033277217000000003",
         "0.9233770967",
         "53",
         "40.7114",
         "11.4642",
         "15.2089",
         "14.4033",
         "12.5358",
         "0.1958",
         "93",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "48",
         "89",
         "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling",
         "High accuracy, low latency and high energy efficiency represent a set of contradictory goals when searching for  system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduce camera refresh rates, and increase the volume of data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, saccade mechanism observed in the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from foveal and peripheral vision, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90\\% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our study demonstrates a 5\\% higher image recognition accuracy compared to state-of-the-art foveal-peripheral vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches.",
         "This paper presents a new algorithm for sequential foveated visual sampling of an image.\n\nThe main claims of the paper are that \n\n- the required input pixels per frame are reduced by 90% without losing image recognition performance\n- 5% higher recognition accuracy compared to existing foveal sampling models with matching pixel number input\n- higher data efficiency in training\n\nI find the algorithm to be interesting and novel, and that the second and third claims above are supported.\nI am confused where to find evidence for the first claim.\n\nOverall I think this paper is a borderline accept. I find the method simple and useful, with interesting potential application. \nIt is appealing that the method seems to be suitable for existing classification models (no retraining). ## Major\n\nI am confused how the image information from the sequential glimpses is passed and integrated in the predictive reconstruction model. Much more space is spent on the background to the hybrid loss function than actually making explicit how the sequential image information is used to improve reconstruction.\n\nIn addition, the abstract states \"our model reduces the required input pixels by over 90% per frame while maintaining the same level of performance in image recognition as with the original images.\" I don't understand where to find support for this claim in the results. For example, in Figure 3, all subsampled models perform worse than the original. The data in Figure 4 are coming closest to the original; is this what is meant?\n\nAlso, please clarify whether the experiments in Figure 3 are conducted with the trained saccade control model (which one?). \n\n\n## Minor\n\n- Instead of \"continuous saccades\" a better terminology would be \"sequential saccades\" or \"scanpaths\". See e.g. \\[2, 3, 4\\]\n- There are now known to be three types of photosensitive cells: rods, cones and intrinsically-photosensitive ganglion cells \\[1, 8\\]\n- You use SSIM but the relevant paper(s) are not cited (e.g. \\[7\\]).\n- Heading 3.1 \"Periphrl\"\n\n## Literature\n\n1. Do, M. T. H., & Yau, K.-W. (2010). Intrinsically Photosensitive Retinal Ganglion Cells. Physiol Rev, 90.\n\n1. Hoppe, D., & Rothkopf, C. A. (2019). Multi-step planning of eye movements in visual search. Scientific Reports, 9(1), 144. https://doi.org/10.1038/s41598-018-37536-0\n\n1. Kümmerer, M., & Bethge, M. (2021). State-of-the-Art in Human Scanpath Prediction (arXiv:2102.12239). arXiv. http://arxiv.org/abs/2102.12239\n\n1. Kümmerer, M., Bethge, M., & Wallis, T. S. A. (2022). DeepGaze III: Modeling free-viewing human scanpaths with deep learning. Journal of Vision, 22(5), 7. https://doi.org/10.1167/jov.22.5.7\n\n1. Rosenholtz, R. (2016). Capabilities and Limitations of Peripheral Vision. Annual Review of Vision Science, 2(1), 437–457. https://doi.org/10.1146/annurev-vision-082114-035733\n\n1. Watson, A. B. (2014). A formula for human retinal ganglion cell receptive field density as a function of visual field location. Journal of Vision, 14(7), 15. https://doi.org/10.1167/14.7.15\n\n1. Wang, Z., Simoncelli, E. P., & Bovik, A. C. (2003). Multiscale structural similarity for image quality assessment. The Thirty-Seventh Asilomar Conference on Signals, Systems & Computers, 2003, 1398–1402. https://doi.org/10.1109/ACSSC.2003.1292216\n\n1. Zele, A. J., Feigl, B., Adhikari, P., Maynard, M. L., & Cao, D. (2018). Melanopsin photoreception contributes to human visual detection, temporal and colour processing. Scientific Reports, 8(1), 3842. https://doi.org/10.1038/s41598-018-22197-w - I would like to see how the hybrid reconstruction loss changes over timestep, and not just classification accuracy.\n- The sampling of the periphery of individual pixels with small probability is not very like human vision. Effectively this is providing low pass information. Have the authors considered how the sampling density could be approximated more plausibly (e.g. \\[6\\])?\n- Have the authors considered comparing scanpath strategies learned in this model to human scanpaths (e.g. \\[3, 4\\])?",
         "['~Jiayang_Liu2', '~Yiming_Bu1', '~Daniel_Tso1', '~Qinru_Qiu1']",
         "Reviewer_7Zf9",
         "1699637050853",
         "8.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "591",
         "20",
         "22",
         "0.8122",
         "0.1227193813",
         "0.9176356196000001",
         "47",
         "42.1304",
         "11.3233",
         "14.4005",
         "13.4718",
         "13.597",
         "0.3629",
         "108",
         "1",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "49",
         "89",
         "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling",
         "High accuracy, low latency and high energy efficiency represent a set of contradictory goals when searching for  system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduce camera refresh rates, and increase the volume of data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, saccade mechanism observed in the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from foveal and peripheral vision, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90\\% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our study demonstrates a 5\\% higher image recognition accuracy compared to state-of-the-art foveal-peripheral vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches.",
         "This paper aims to reconstruct the original image from multiple subsampled views, using reinforcement learning and neural network models for scan control and image reconstruction, respectively. The paper conducts numerous experiments to demonstrate that the proposed algorithm can maintain detection task accuracy, reasonable saccade control, and high reconstruction quality under high data efficiency. However, the motivation for the work is not well-founded, and there are possible improvements in the experiments. 1. The task addressed in the paper is novel, as it is the first in the industry to reconstruct an image from continuous central foveal subsampled images. Other methods focus on single-sample images and proceed directly to downstream tasks without reconstructing the original image, making this work unique.\n2. The methods used are innovative, employing an actor-critic model for saccade control, which can achieve near-original image classification accuracy in just five scans.\n3. The writing style of the paper is easy to understand, especially in describing the proposed methods. 1. While the task is novel, it lacks a convincing real-world application, as it simulates the process of multiple eye samplings without addressing practical problems.\n2. The experimental comparisons are not entirely fair. The uniform control group uses an 8% sampling probability, while the 1/16+2% group differs by 0.25%, indicating an unequal amount of information that might affect performance.\n3. Using classification model metrics to assess the quality of reconstruction is questionable, as classification tasks do not focus on texture details. If this method was to downsample the original image with the same number of sampled pixels, how much better is the method in terms of performance compared to this? see weaknesses",
         "['~Jiayang_Liu2', '~Yiming_Bu1', '~Daniel_Tso1', '~Qinru_Qiu1']",
         "Reviewer_rEUv",
         "1700663753570",
         "6.0",
         "4.0",
         "2.0",
         "3.0",
         "3.0",
         "271",
         "0",
         "7",
         "0.7977000000000001",
         "0.1371333333",
         "0.8944661021",
         "59",
         "26.1536",
         "14.7902",
         "17.6374",
         "16.0982",
         "16.0539",
         "0.0999",
         "95",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ]
       ],
       "shape": {
        "columns": 31,
        "rows": 661
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>review_text</th>\n",
       "      <th>authors</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_confidence</th>\n",
       "      <th>review_soundness</th>\n",
       "      <th>...</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>**Summary:** \\nThis paper presents an open-sou...</td>\n",
       "      <td>['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhido...</td>\n",
       "      <td>Reviewer_EGJf</td>\n",
       "      <td>1701662567826</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7773</td>\n",
       "      <td>13.5591</td>\n",
       "      <td>13.3105</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>This paper proposes a comprehensive library fo...</td>\n",
       "      <td>['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhido...</td>\n",
       "      <td>Reviewer_DWom</td>\n",
       "      <td>1699636125239</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3091</td>\n",
       "      <td>13.6811</td>\n",
       "      <td>14.7228</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>This author introduces LyCORIS, an open source...</td>\n",
       "      <td>['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhido...</td>\n",
       "      <td>Reviewer_PnHf</td>\n",
       "      <td>1699636125143</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2257</td>\n",
       "      <td>16.5672</td>\n",
       "      <td>16.3167</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>The authors propose LyCORIS, an open-source li...</td>\n",
       "      <td>['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhido...</td>\n",
       "      <td>Reviewer_ekPo</td>\n",
       "      <td>1699636125075</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8611</td>\n",
       "      <td>11.3747</td>\n",
       "      <td>10.6575</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>$\\nu$-ensembles: Improving deep ensemble calib...</td>\n",
       "      <td>We present a method to improve the calibration...</td>\n",
       "      <td>This paper introduces ν-ensembles, a novel dee...</td>\n",
       "      <td>['~Konstantinos_Pitas1', '~Julyan_Arbel1']</td>\n",
       "      <td>Reviewer_HFRa</td>\n",
       "      <td>1699636992453</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2108</td>\n",
       "      <td>15.9828</td>\n",
       "      <td>15.2685</td>\n",
       "      <td>0.2519</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>118</td>\n",
       "      <td>Module Extraction for Efficient Object Query o...</td>\n",
       "      <td>The extraction of logically-independent fragme...</td>\n",
       "      <td>The submission addresses the problem of partit...</td>\n",
       "      <td>None</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>03/May/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.4900</td>\n",
       "      <td>13.8000</td>\n",
       "      <td>12.6000</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>61</td>\n",
       "      <td>EARTh: an Environmental Application Reference ...</td>\n",
       "      <td>The paper aims at providing a description of E...</td>\n",
       "      <td>This revision addresses my concerns. I am part...</td>\n",
       "      <td>None</td>\n",
       "      <td>Natasha Noy</td>\n",
       "      <td>22/Jul/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.6300</td>\n",
       "      <td>9.7000</td>\n",
       "      <td>7.9000</td>\n",
       "      <td>0.1858</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>76</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>The paper presents and compares RDF/XML (in th...</td>\n",
       "      <td>None</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>15/Jun/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7700</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>10.1000</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>76</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>This paper investigates two different approach...</td>\n",
       "      <td>None</td>\n",
       "      <td>Ghislain Hachey</td>\n",
       "      <td>17/Jun/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7000</td>\n",
       "      <td>13.3000</td>\n",
       "      <td>11.4000</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>76</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>This paper has a number of minor flaws, but my...</td>\n",
       "      <td>None</td>\n",
       "      <td>Ian Dickinson</td>\n",
       "      <td>18/Jun/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.1400</td>\n",
       "      <td>12.7000</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>661 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                              title  \\\n",
       "0         123  Navigating Text-To-Image Customization: From L...   \n",
       "1         123  Navigating Text-To-Image Customization: From L...   \n",
       "2         123  Navigating Text-To-Image Customization: From L...   \n",
       "3         123  Navigating Text-To-Image Customization: From L...   \n",
       "4           0  $\\nu$-ensembles: Improving deep ensemble calib...   \n",
       "..        ...                                                ...   \n",
       "656       118  Module Extraction for Efficient Object Query o...   \n",
       "657        61  EARTh: an Environmental Application Reference ...   \n",
       "658        76  Facilitating Data Discovery by Connecting Rela...   \n",
       "659        76  Facilitating Data Discovery by Connecting Rela...   \n",
       "660        76  Facilitating Data Discovery by Connecting Rela...   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    Text-to-image generative models have garnered ...   \n",
       "1    Text-to-image generative models have garnered ...   \n",
       "2    Text-to-image generative models have garnered ...   \n",
       "3    Text-to-image generative models have garnered ...   \n",
       "4    We present a method to improve the calibration...   \n",
       "..                                                 ...   \n",
       "656  The extraction of logically-independent fragme...   \n",
       "657  The paper aims at providing a description of E...   \n",
       "658  In this study, we investigate two approaches t...   \n",
       "659  In this study, we investigate two approaches t...   \n",
       "660  In this study, we investigate two approaches t...   \n",
       "\n",
       "                                           review_text  \\\n",
       "0    **Summary:** \\nThis paper presents an open-sou...   \n",
       "1    This paper proposes a comprehensive library fo...   \n",
       "2    This author introduces LyCORIS, an open source...   \n",
       "3    The authors propose LyCORIS, an open-source li...   \n",
       "4    This paper introduces ν-ensembles, a novel dee...   \n",
       "..                                                 ...   \n",
       "656  The submission addresses the problem of partit...   \n",
       "657  This revision addresses my concerns. I am part...   \n",
       "658  The paper presents and compares RDF/XML (in th...   \n",
       "659  This paper investigates two different approach...   \n",
       "660  This paper has a number of minor flaws, but my...   \n",
       "\n",
       "                                               authors         reviewer  \\\n",
       "0    ['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhido...    Reviewer_EGJf   \n",
       "1    ['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhido...    Reviewer_DWom   \n",
       "2    ['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhido...    Reviewer_PnHf   \n",
       "3    ['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhido...    Reviewer_ekPo   \n",
       "4           ['~Konstantinos_Pitas1', '~Julyan_Arbel1']    Reviewer_HFRa   \n",
       "..                                                 ...              ...   \n",
       "656                                               None        Anonymous   \n",
       "657                                               None      Natasha Noy   \n",
       "658                                               None        Anonymous   \n",
       "659                                               None  Ghislain Hachey   \n",
       "660                                               None    Ian Dickinson   \n",
       "\n",
       "       review_date  review_rating  review_confidence  review_soundness  ...  \\\n",
       "0    1701662567826            6.0                3.0               3.0  ...   \n",
       "1    1699636125239            6.0                3.0               3.0  ...   \n",
       "2    1699636125143            6.0                4.0               4.0  ...   \n",
       "3    1699636125075            8.0                4.0               3.0  ...   \n",
       "4    1699636992453            3.0                4.0               2.0  ...   \n",
       "..             ...            ...                ...               ...  ...   \n",
       "656    03/May/2014            NaN                NaN               NaN  ...   \n",
       "657    22/Jul/2013            NaN                NaN               NaN  ...   \n",
       "658    15/Jun/2013            NaN                NaN               NaN  ...   \n",
       "659    17/Jun/2013            NaN                NaN               NaN  ...   \n",
       "660    18/Jun/2013            NaN                NaN               NaN  ...   \n",
       "\n",
       "     gunning_fog  smog_index  automated_readability_index  politeness_score  \\\n",
       "0        14.7773     13.5591                      13.3105            0.2025   \n",
       "1        15.3091     13.6811                      14.7228            0.2131   \n",
       "2        18.2257     16.5672                      16.3167            0.1213   \n",
       "3        10.8611     11.3747                      10.6575            0.1844   \n",
       "4        18.2108     15.9828                      15.2685            0.2519   \n",
       "..           ...         ...                          ...               ...   \n",
       "656      13.4900     13.8000                      12.6000            0.1386   \n",
       "657       9.6300      9.7000                       7.9000            0.1858   \n",
       "658      11.7700     13.0000                      10.1000            0.0845   \n",
       "659      11.7000     13.3000                      11.4000            0.0376   \n",
       "660      11.1400     12.7000                      10.5000            0.2025   \n",
       "\n",
       "     hedge_C  hedge_D  hedge_E  hedge_I  hedge_N        venue  \n",
       "0         77        1        2        0        0         iclr  \n",
       "1         78        0        0        0        0         iclr  \n",
       "2         86        0        0        0        0         iclr  \n",
       "3         84        0        0        0        0         iclr  \n",
       "4         90        0        0        0        0         iclr  \n",
       "..       ...      ...      ...      ...      ...          ...  \n",
       "656       96        0        1        0        0  semanticweb  \n",
       "657       26        0        0        0        0  semanticweb  \n",
       "658       93        0        0        0        0  semanticweb  \n",
       "659       95        1        0        0        0  semanticweb  \n",
       "660       96        0        0        0        0  semanticweb  \n",
       "\n",
       "[661 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_reviews = pd.read_json('../Human_Annotation/merged_200_papers.json', orient='records', lines=True)\n",
    "df_reviews = df_reviews.iloc[:, :31]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "assessor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "43ff42cb-8267-446a-8507-0f4f760015a1",
       "rows": [
        [
         "0",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-7mFW",
         "2",
         "4",
         "factual",
         "neutral",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "67"
        ],
        [
         "1",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-FAWm",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "5",
         "5",
         "5",
         "4",
         "86"
        ],
        [
         "2",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-kjkr",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "5",
         "5",
         "4",
         "5",
         "75"
        ],
        [
         "3",
         "100",
         "Seyed",
         "Enrico-Daga",
         "3",
         "2",
         "factual",
         "positive",
         "polite",
         "none",
         "4",
         "5",
         "4",
         "4",
         "4",
         "4",
         "80"
        ],
        [
         "4",
         "100",
         "Seyed",
         "Julia-Bosque",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "5",
         "4",
         "87"
        ],
        [
         "5",
         "100",
         "Seyed",
         "Thierry-Declerck",
         "3",
         "1",
         "partially factual",
         "positive",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "4",
         "3",
         "4",
         "60"
        ],
        [
         "6",
         "74",
         "Sonny",
         "Reviewer-HZXU",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "3",
         "80"
        ],
        [
         "7",
         "74",
         "Sonny",
         "Reviewer-itVg",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "4",
         "85"
        ],
        [
         "8",
         "74",
         "Sonny",
         "Reviewer-bNPg",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "3",
         "4",
         "4",
         "3",
         "90"
        ],
        [
         "9",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-GDNX",
         "3",
         "5",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "80"
        ],
        [
         "10",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-j1mL",
         "4",
         "4",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "3",
         "70"
        ],
        [
         "11",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-cMiu",
         "4",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "80"
        ],
        [
         "12",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-ky3t",
         "2",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "70"
        ],
        [
         "13",
         "38",
         "Seyed",
         "Reviewer-vqBu",
         "3",
         "2",
         "unfactual",
         "neutral",
         "polite",
         "low",
         "2",
         "2",
         "3",
         "2",
         "3",
         "4",
         "60"
        ],
        [
         "14",
         "38",
         "Seyed",
         "Reviewer-3sWQ",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "2",
         "1",
         "3",
         "3",
         "60"
        ],
        [
         "15",
         "38",
         "Seyed",
         "Reviewer-pTVu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "3",
         "4",
         "4",
         "4",
         "60"
        ],
        [
         "16",
         "38",
         "Seyed",
         "Reviewer-CnQu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "moderate",
         "2",
         "2",
         "1",
         "1",
         "3",
         "4",
         "50"
        ],
        [
         "17",
         "13",
         "Mana",
         "Joseph-philipraj",
         "5",
         "5",
         "factual",
         "positive",
         "polite",
         "low",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "95"
        ],
        [
         "18",
         "13",
         "Mana",
         "Muhammad-Faruk",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "93"
        ],
        [
         "19",
         "181",
         "Hideaki-Joko",
         "Reviewer-sna7",
         "2",
         "2",
         "factual",
         "positive",
         "neutral",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70"
        ],
        [
         "20",
         "181",
         "Hideaki-Joko",
         "Reviewer-HLbG",
         "3",
         "3",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "80"
        ],
        [
         "21",
         "181",
         "Hideaki-Joko",
         "Reviewer-c3Sg",
         "4",
         "3",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "4",
         "3",
         "3",
         "4",
         "70"
        ],
        [
         "22",
         "181",
         "Hideaki-Joko",
         "Reviewer-ebFz",
         "2",
         "2",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "65"
        ],
        [
         "24",
         "9",
         "Seyed",
         "Reviewer-KmBd",
         "4",
         "4",
         "factual",
         "neutral",
         "neutral",
         "none",
         "4",
         "3",
         "4",
         "4",
         "3",
         "3",
         "90"
        ],
        [
         "25",
         "9",
         "Seyed",
         "Reviewer-3zCE",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80"
        ],
        [
         "26",
         "9",
         "Seyed",
         "Reviewer-y5kB",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85"
        ],
        [
         "27",
         "9",
         "Seyed",
         "Reviewer-XNx6",
         "5",
         "4",
         "factual",
         "neutral",
         "neutral",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "88"
        ],
        [
         "28",
         "81",
         "Emperatoor",
         "Gatot-Soepriyanto",
         "3",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70"
        ],
        [
         "29",
         "81",
         "Emperatoor",
         "Toni-Šušak",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80"
        ],
        [
         "31",
         "24",
         "Sajad-Ebrahimi",
         "Silvio-Buscemi",
         "1",
         "1",
         "unfactual",
         "negative",
         "polite",
         "extreme",
         "1",
         "3",
         "1",
         "2",
         "3",
         "3",
         "48"
        ],
        [
         "34",
         "77",
         "Mohammad-Hossein-Saliminabi",
         "Houcemeddine-Turki",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "85"
        ],
        [
         "35",
         "77",
         "Mohammad-Hossein-Saliminabi",
         "Anonymous",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80"
        ],
        [
         "38",
         "67",
         "Emperatoor",
         "Reviewer-um1j",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "4",
         "5",
         "3",
         "4",
         "4",
         "70"
        ],
        [
         "39",
         "67",
         "Emperatoor",
         "Reviewer-YmDt",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "5",
         "4",
         "5",
         "5",
         "80"
        ],
        [
         "40",
         "67",
         "Emperatoor",
         "Reviewer-8RW7",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85"
        ],
        [
         "41",
         "67",
         "Emperatoor",
         "Reviewer-YYfR",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "70"
        ],
        [
         "42",
         "171",
         "Sajad-Ebrahimi",
         "Magdalena-Czlapka-Matyasik",
         "1",
         "1",
         "unfactual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "35"
        ],
        [
         "43",
         "171",
         "Sajad-Ebrahimi",
         "Wanshui-Yang",
         "1",
         "0",
         "unfactual",
         "negative",
         "impolite",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "40"
        ],
        [
         "44",
         "187",
         "Emperatoor",
         "Reviewer-2CBB",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "4",
         "4",
         "4",
         "4",
         "4",
         "70"
        ],
        [
         "45",
         "187",
         "Emperatoor",
         "Reviewer-yUvs",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "5",
         "3",
         "4",
         "3",
         "4",
         "75"
        ],
        [
         "46",
         "187",
         "Emperatoor",
         "Reviewer-PMap",
         "1",
         "3",
         "partially factual",
         "negative",
         "polite",
         "moderate",
         "2",
         "2",
         "2",
         "3",
         "3",
         "4",
         "30"
        ],
        [
         "47",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-NRqK",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "5",
         "5",
         "5",
         "4",
         "5",
         "94"
        ],
        [
         "48",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-36E8",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "3",
         "3",
         "4",
         "4",
         "80"
        ],
        [
         "49",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-dCJp",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "83"
        ],
        [
         "50",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-gKE9",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "none",
         "5",
         "4",
         "4",
         "4",
         "4",
         "5",
         "89"
        ],
        [
         "51",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-xxEb",
         "2",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "50"
        ],
        [
         "52",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-4kdr",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "65"
        ],
        [
         "53",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-H6rR",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "2",
         "80"
        ],
        [
         "54",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-639w",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "90"
        ],
        [
         "55",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-9sGD",
         "4",
         "4",
         "factual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "85"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 478
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>assessor</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>Comprehensiveness</th>\n",
       "      <th>Usage_of_Technical_Terms</th>\n",
       "      <th>Factuality</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Politeness</th>\n",
       "      <th>Vagueness</th>\n",
       "      <th>Objectivity</th>\n",
       "      <th>Fairness</th>\n",
       "      <th>Actionability</th>\n",
       "      <th>Constructiveness</th>\n",
       "      <th>Relevance_Alignment</th>\n",
       "      <th>Clarity_and_Readability</th>\n",
       "      <th>Overall_Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-7mFW</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-FAWm</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-kjkr</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Enrico-Daga</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Julia-Bosque</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-s437</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-mMGf</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>negative</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-AtQ2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-v6cq</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>5</td>\n",
       "      <td>Sonny</td>\n",
       "      <td>Alison-Kutywayo</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id         assessor         reviewer  Comprehensiveness  \\\n",
       "0        166   Sajad-Ebrahimi    Reviewer-7mFW                  2   \n",
       "1        166   Sajad-Ebrahimi    Reviewer-FAWm                  4   \n",
       "2        166   Sajad-Ebrahimi    Reviewer-kjkr                  3   \n",
       "3        100            Seyed      Enrico-Daga                  3   \n",
       "4        100            Seyed     Julia-Bosque                  5   \n",
       "..       ...              ...              ...                ...   \n",
       "522       75  Ali-Ghorbanpour    Reviewer-s437                  3   \n",
       "523       75  Ali-Ghorbanpour    Reviewer-mMGf                  4   \n",
       "524       75  Ali-Ghorbanpour    Reviewer-AtQ2                  5   \n",
       "525       75  Ali-Ghorbanpour    Reviewer-v6cq                  2   \n",
       "528        5            Sonny  Alison-Kutywayo                  3   \n",
       "\n",
       "     Usage_of_Technical_Terms         Factuality Sentiment_Polarity  \\\n",
       "0                           4            factual            neutral   \n",
       "1                           4            factual            neutral   \n",
       "2                           4            factual            neutral   \n",
       "3                           2            factual           positive   \n",
       "4                           4            factual           positive   \n",
       "..                        ...                ...                ...   \n",
       "522                         3  partially factual            neutral   \n",
       "523                         4            factual           negative   \n",
       "524                         4            factual           positive   \n",
       "525                         3  partially factual           positive   \n",
       "528                         4            factual            neutral   \n",
       "\n",
       "    Politeness Vagueness  Objectivity  Fairness  Actionability  \\\n",
       "0       polite      high            4         4              4   \n",
       "1       polite      none            4         4              5   \n",
       "2       polite       low            4         4              5   \n",
       "3       polite      none            4         5              4   \n",
       "4       polite       low            4         4              4   \n",
       "..         ...       ...          ...       ...            ...   \n",
       "522     polite       low            2         3              2   \n",
       "523     polite      none            4         4              4   \n",
       "524     polite      none            4         4              3   \n",
       "525     polite  moderate            3         3              2   \n",
       "528     polite  moderate            4         4              2   \n",
       "\n",
       "     Constructiveness  Relevance_Alignment  Clarity_and_Readability  \\\n",
       "0                   3                    4                        4   \n",
       "1                   5                    5                        4   \n",
       "2                   5                    4                        5   \n",
       "3                   4                    4                        4   \n",
       "4                   4                    5                        4   \n",
       "..                ...                  ...                      ...   \n",
       "522                 3                    3                        3   \n",
       "523                 5                    4                        4   \n",
       "524                 4                    4                        5   \n",
       "525                 3                    3                        3   \n",
       "528                 2                    4                        3   \n",
       "\n",
       "     Overall_Quality  \n",
       "0                 67  \n",
       "1                 86  \n",
       "2                 75  \n",
       "3                 80  \n",
       "4                 87  \n",
       "..               ...  \n",
       "522               55  \n",
       "523               80  \n",
       "524               90  \n",
       "525               50  \n",
       "528               75  \n",
       "\n",
       "[478 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_reviews(folder_path):\n",
    "    rows = []\n",
    "    # find all JSON files in the folder\n",
    "    for file_path in glob.glob(os.path.join(folder_path, '*.json')):\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        paper_id = data.get('paper_id')\n",
    "        assessor = data.get('assessor')\n",
    "        metrics = data.get('metrics', {})\n",
    "        \n",
    "        # group metrics by reviewer name\n",
    "        reviewer_metrics = {}\n",
    "        for key, value in metrics.items():\n",
    "            # only process keys that start with \"review_\"\n",
    "            if not key.startswith('review_'):\n",
    "                continue\n",
    "            parts = key.split('_')\n",
    "            reviewer = parts[1]                          # e.g. \"Palwinder-Singh\"\n",
    "            metric_name = '_'.join(parts[2:])            # e.g. \"Comprehensiveness\"\n",
    "            \n",
    "            reviewer_metrics.setdefault(reviewer, {})\n",
    "            reviewer_metrics[reviewer][metric_name] = value\n",
    "        \n",
    "        # turn each reviewer’s metrics into a row\n",
    "        for reviewer, mdict in reviewer_metrics.items():\n",
    "            row = {\n",
    "                'paper_id': paper_id,\n",
    "                'assessor': assessor,\n",
    "                'reviewer': reviewer\n",
    "            }\n",
    "            row.update(mdict)\n",
    "            rows.append(row)\n",
    "    \n",
    "    # build the final DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "folder = '../Human_Annotation_Data'\n",
    "df_human = load_reviews(folder)\n",
    "\n",
    "# show the first few rows\n",
    "df_human = df_human[df_human['Overall_Quality'] > 10]\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "assessor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_soundness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_presentation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_contribution",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "dec2698e-b024-419c-b98f-ee200d74a7a8",
       "rows": [
        [
         "0",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-7mFW",
         "2",
         "4",
         "factual",
         "neutral",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "67",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This work focuses on the Q-function value overestimation issue. Observing that the overestimation issue will latter becomes underestimation during the learning process. Thus motivated, this work proposes the Blended Exploitation and Exploration (BEE) operator to take advantage of the historical best-perforation actions. The proposed operator is then used in both model-free and model-based settings and show better performance than previous methods. 1. The proposed BEE operator utilizes the Bellman exploitation operator and exploration operator to address the under-exploitation issue. The proposed operator can be easily incorporated into the RL algorithms.\n2. The experiments show that the proposed operator can effectively reduce the estimation error and achieve better performance comparing with other RL algorithms. 1. The terminology can be misleading. The overestimation issue in the Q-value approximation generally is due to the changing order of expectation and $\\max$. It is incorrect to say that  the $Q$-function will have \"underestimation when encountering successes\" in Fig 1 (a). The authors need to clarify the context and difference of the statement in order to avoid confusion.\n2. In order to investigate on the under-exploitation, the metric $\\Delta(\\cdot,\\cdot)$ is defined on the current Q-function approximation. Intuitively,   $\\Delta(\\cdot,\\cdot)$ shows that the current Q-function approximation can be either overestimate or underestimate given different policy, i.e., $\\mu_k$ and $\\pi_k$. It is unclear what is the meaning of this metric. Considering most of the algorithm will update the policy and Q-function approximation at the same time, e.g., Actor-Critic, the Q-function should be evaluated under the current policy instead of the policy obtained earlier. The authors need to clarify why the definition here makes sense for the under-exploitation investigation. See the weakness above.",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1699636492844",
         "6.0",
         "3.0",
         "3.0",
         "2.0",
         "2.0",
         "273",
         "0",
         "5",
         "0.7173",
         "0.12450980390000001",
         "0.8775630593",
         "49",
         "22.7412",
         "13.6569",
         "16.1503",
         "14.3268",
         "14.1695",
         "0.0999",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "1",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-FAWm",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "5",
         "5",
         "5",
         "4",
         "86",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This paper presents the Blended Exploitation and Exploration (BEE) operator, which addresses the issue of value underestimation during the exploitation phase in off-policy actor-critic methods. The paper highlights the importance of incorporating past successes to improve Q-value estimation and policy learning. The proposed BAC and MB-BAC algorithms outperform existing methods in various continuous control tasks and demonstrate strong performance in real-world robot tasks. - The paper addresses an important issue in off-policy actor-critic methods and proposes a novel approach to improve Q-value estimation and policy learning. \n- The BEE operator is simple yet effective and can be easily integrated into existing off-policy actor-critic frameworks.\n- The experimental results demonstrate the superiority of the proposed algorithms in various continuous control tasks and real-world robot tasks. 1. The novelty of the proposed approach is limited. \n2. The choice of $\\lambda$ is largely empirical and requires extra manipulation in new tasks.\n3. The paper only provides basic theoretical analysis, such as the accurate policy evaluation and the guarantee of policy improvement. The benefit of linearly combining two Q-value functions is not discussed theoretically.\n4. The experiments are conducted in continuous control tasks with dense rewards. The exploration ability can be better evaluated in environments with sparse rewards.\n5. There is a lack of discussions with related papers (See Question 3). 1. Emprically, the BAC algoithm will only be more efficient in exploiting the replay buffer. The exploration still rely on the maximum-extropy formulation in SAC. Then why can BAC perform significantly better than SAC in failure-prone scenarios such as HumanoidStandup, as if BAC can better explore the unknown regions?\n2. Can you discuss or exhibit the performance of BAC in some tasks with sparse rewards? This can demonstrate the generalizability of the proposed approach.\n3. What are the advantages of BAC compared with prioritized replay methods \\[1,2\\] or advantage-based methods \\[3\\]? These methods are related to BAC in that they also exploit the replay buffer with inductive bias, so they should be mentioned in the paper.\n\n\\[1\\] Sinha, S., Song, J., Garg, A. &amp; Ermon, S.. (2022). Experience Replay with Likelihood-free Importance Weights. Proceedings of The 4th Annual Learning for Dynamics and Control Conference.\n\n\\[2\\] Liu, X. H., Xue, Z., Pang, J., Jiang, S., Xu, F., & Yu, Y. (2021). Regret minimization experience replay in off-policy reinforcement learning. Advances in Neural Information Processing Systems, 34, 17604-17615.\n\n\\[3\\] Nair, A., Gupta, A., Dalal, M., & Levine, S. (2020). Awac: Accelerating online reinforcement learning with offline datasets. arXiv preprint arXiv:2006.09359.\n\n\nI am willing to raise my score if my concerns for weaknesses and questions are adequately discussed.",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1700565416102",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "432",
         "8",
         "14",
         "0.7996000000000001",
         "0.1588311688",
         "0.8829935789000001",
         "60",
         "31.9755",
         "12.2213",
         "15.4394",
         "13.7425",
         "12.4851",
         "0.1565",
         "89",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "2",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-kjkr",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "5",
         "5",
         "4",
         "5",
         "75",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "Motivated by the problem of underestimating values in the training of SAC, this paper introduces the Blended Exploitation and Exploration (BEE) operator, which calculates the TD target based on a combination of the standard TD target and a high expectile of the return distribution. The authors integrate this operator in both model-free and model-based scenarios, followed by a comprehensive experimental evaluation. 1. The paper contains extensive experiment results on both simulation and real-world environments.\n2. The paper is written clearly and easy to follow. Figure 1 provides a decent visualization of the underestimation issue. 1. The BAC method tunes its $\\lambda$ and $\\tau$ differently for tasks in MuJoCo and DMC (Table 1 & 5). It's questionable to claim superiority over other state-of-the-art (SOTA) methods like SAC and TD3, which use consistent hyperparameters (HP) across tasks. Adjusting HP for each task can inflate results as seen in Figure 5, which can be misleading. Why not showcase the automatic $\\lambda$ tuning methods from Appendix B.3.3 in the main text if they're effective?\n\n2. Figure 23 reveals that SAC, without the double-Q-trick, still underestimates in the Humanoid task. It's unclear if this is universally true. More convincing results would come from testing this across multiple tasks and providing absolute Q value estimates. I still suspect that Q underestimation largely stems from the double Q techniques, as suggested by the RL community \\[1\\]. For instance, OAC \\[1\\] introduces $\\beta_{\\text{LB}}$ to manage value estimation issues.\n\n3. Presuming the Q value underestimation problem is widely recognized (which I invite the authors to contest), the paper seems to lack innovation. The BEE operator, at its core, appears to be a fusion of existing Bellman operators.\n\n4. The statement \"BEE exhibits no extra overestimation\" seems conditional on specific $\\lambda$ and $\\tau$ values. For instance, using $\\lambda = 1$ and $\\tau = 1$ could induce overestimation.\n\n\\[1\\] Ciosek, Kamil, et al. \"Better exploration with optimistic actor critic.\" Advances in Neural Information Processing Systems 32 (2019). See Weakness",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1700668216355",
         "6.0",
         "5.0",
         "3.0",
         "4.0",
         "2.0",
         "328",
         "4",
         "8",
         "0.8027000000000001",
         "0.1464980159",
         "0.8531657457",
         "61",
         "35.3958",
         "11.9923",
         "14.4014",
         "13.2462",
         "12.1773",
         "0.1507",
         "93",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "3",
         "100",
         "Seyed",
         "Enrico-Daga",
         "3",
         "2",
         "factual",
         "positive",
         "polite",
         "none",
         "4",
         "5",
         "4",
         "4",
         "4",
         "4",
         "80",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "The authors have performed significant changes to the content, which significantly improve the article with respect to the previous submission. Following the four SWJ criteria for survey articles, the current version is indeed a good (1) introductory text, targeted at researchers, PhD students, or practitioners, to get started on the covered topic.  The addition of a methodology section gives reasonable justification for (2) how comprehensive and how balanced are the presentation and coverage. However, a few more details about the sources of the survey would be useful, especially if mentioning keywords and phrases used in the search (Scopus? Google Scholar? Microsoft Academia? …). In addition, it is still a bit opaque what is intended with \"refining and balancing the structure of the covered areas\" - end of Section 2. However, I consider these minor issues that can be fixed during the preparation of the camera-ready. Finally, the article is readable and clear (3) and the content is relevant to the community (4).",
         null,
         "21/Sep/2021",
         null,
         null,
         null,
         null,
         null,
         "162",
         "0",
         "1",
         "0.8103",
         "0.1645833333",
         "0.6678649187",
         "60",
         "31.31",
         "14.6",
         "17.41",
         "16.6",
         "15.5",
         "0.1149",
         "100",
         "0",
         "0",
         "0",
         "2",
         "semanticweb"
        ],
        [
         "4",
         "100",
         "Seyed",
         "Julia-Bosque",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "5",
         "4",
         "87",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "I reviewed a previous version of this manuscript, for which I recommended a major revision based on the need for a clearer motivation, scope and limitations of this effort, as well as on the structure and flow of the paper at that time. In this new version the authors have addressed all my highlighted concerns: - The motivation, scope and limitations are clearly defined - The interplay between the different sections is elaborated and illustrated with a workflow diagram that facilitates reading. There are numerous references to this workflow and interlinks between the sections, resulting in a cohesive document. - More context is provided in the introductory paragraphs of each section, and the project in which this effort is carried out is clearly introduced. The relation of each section/topic with respect to the overall topic of the survey is now explicit. - The authors have improved the categorization of tools and approaches. - The tables in the appendix summarize the main approaches, tools and resources surveyed according to the proposed classification.  Taking into account these modifications, I maintain the reasons upon which I based the recommendation for acceptance in terms of the criteria for surveys: - The topic of the paper, at the intersection of humanities and the Semantic Web, is interesting and relevant for the advancement in a line of research which poses numerous challenges. - The quality of writing is good and the survey is well balanced, with a broad coverage encompassing theoretical standpoints and approaches, tools, repositories and datasets. - The granularity and length are also appropriate for the text to serve as an introductory text. Minor comments for improvement: - The authors have provided details on the methodology for the survey, indicating the different stages in the generation and keywords used in literature search. There is no explicit reference to a filtering process after those keyword-based search results, was there any filtering step? If so, which criteria were applied? - In table 3, the included resources diverge in their nature, so the current list groups together LLOD Cloud, Lila Etymological Lexicon, LingHub, and Diachronic semantic lexicon of Dutch, etc. for example. I suggest including a mark here to distinguish which resources are particularly relevant for diachronic analysis, in contrast to general LLOD resources (e.g. Lila Etymological Lexicon vs. LLOD cloud and LingHub). - The authors of [12], referenced on p. 5, mention Lemon (Lexicon Model For Ontologies), and in their diagrams (in Github)  they seem to be using OntoLex-Lemon, not its ancestor. Throughout this survey \"OntoLex-Lemon\" is the term used to refer to the 2016 Specification as the outcome of the W3C Ontology-Lexica Community Group, so for that bib. reference I would recommend to replace the mention of \"Lemon\" with \"OntoLex-Lemon\" for consistency in the whole document. *Typos*: l.19, .p. 19, right column, \"A combined resource like this, allows...\" → remove comma p. 20, l. 1, right column → remove \"(linguistic)\", already covered by the first L in LLOD Appendix tables, Table 4. → word embeddings (add pl. \"s\")",
         null,
         "04/Oct/2021",
         null,
         null,
         null,
         null,
         null,
         "503",
         "1",
         "5",
         "0.7741",
         "0.1697330447",
         "0.8522429466",
         "73",
         "34.66",
         "13.3",
         "14.3",
         "15.2",
         "14.0",
         "0.2025",
         "108",
         "0",
         "0",
         "0",
         "0",
         "semanticweb"
        ],
        [
         "5",
         "100",
         "Seyed",
         "Thierry-Declerck",
         "3",
         "1",
         "partially factual",
         "positive",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "4",
         "3",
         "4",
         "60",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "Not really a lot to add. I see that the revised version of the submission was taking good care of former comments and suggestions. Just a minor point: 1) Ensure that footnotes are always placed after the punctuation signs (for consistency across the paper, se fn 2 and 3 which are not placed consistently). So, very few corrections to do.",
         null,
         "05/Nov/2021",
         null,
         null,
         null,
         null,
         null,
         "60",
         "0",
         "0",
         "0.81",
         "0.058",
         "0.6966200471",
         "105",
         "64.71",
         "8.0",
         "10.0",
         "10.1",
         "8.0",
         "0.0548",
         "60",
         "0",
         "0",
         "0",
         "0",
         "semanticweb"
        ],
        [
         "6",
         "74",
         "Sonny",
         "Reviewer-HZXU",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "3",
         "80",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies how to train NeRF with the optimal training set under limited view inputs for novel view synthesis. It proposes a theoretical framework for view sampling strategies from a causal perspective, finally decomposing the objective into three components: a fitting term similar to traditional NeRF training loss, a consistency term requiring consistency between visible and invisible views, and a uniformity term demanding the sampling to be diverse. The proposed sampling strategy induces higher-quality NeRFs and can be used as regularization term for general NeRF training. 1. Framing the novel view synthesis problem via a causal perspective is novel. \n2. The deduced supervision objective with three terms is intuitive and well-explained. \n3. Experiments demonstrate that based on the proposed sampling strategy better performance could be achieved with the same number of training views, using the principles as a regularization term to the training of general term could also improve performance. 1. Although the derived supervision objective is intuitive, the framing of novel view synthesis problem with causal framework is a bit obscure with mistakes: e.g. page 5 the authors mentioned \"we defer the details to the Appendix\" which do not exist, Eq. 4 in page 6 is also falsely rendered. \n2. Two variants of the model are proposed (prioritizing consistency and uniformity term differently) without a consistency in which one would perform better which may limit the usability. 1. in Appendix Tab. 1, ActiveNeRF acquires better results 3/8 on ficus, materials and ship, are there any explainations for this? \n2. Could some qualitative comparisions with DietNerF (which would show the effects of uniformity loss only) be povided ?",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108591",
         "5.0",
         "3.0",
         "2.0",
         "2.0",
         "2.0",
         "269",
         "0",
         "7",
         "0.7805000000000001",
         "0.0904761905",
         "0.8525229096",
         "52",
         "32.8096",
         "13.8045",
         "16.7536",
         "15.402",
         "14.7564",
         "0.1303",
         "94",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "7",
         "74",
         "Sonny",
         "Reviewer-itVg",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "4",
         "85",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "The authors introduced a view sampling strategy for novel view synthesis, grounded in the perspective of causal representation learning. They identified three key metrics to assess sampling performance: the fitting term, the consistency term, and the uniformity term. Additionally, they presented a novel theoretical framework addressing the sampling challenge within NeRF. 1. The introduction of the causal perspective in the view sampling algorithm holds significant potential and could serve as a foundational approach for future research in this domain.\n2. The authors meticulously lay out a comprehensive mathematical framework that not only elucidates the underlying problem but also leads to the derivation of the three pivotal terms central to their methodology.\n3. The paper stands out for its clarity and coherence, ensuring that readers, regardless of their expertise level, can grasp the concepts and findings presented.\" 1. The rationale behind the view-sampling task raises questions. In certain scenarios, acquiring additional view images can be challenging. However, when a substantial number of dense views are already available, the motivation to devise a sampling strategy for training the neural rendering model with sparse views appears insufficient. Specifically, the activeNeRF model's primary objective is to identify the most optimal camera view for capturing the training image, rather than selecting from a plethora of pre-existing images.\n2. The paper's primary contribution seems to be the introduction of a metric or loss function to evaluate the selected views. However, the absence of an ablation study that separately assesses the impact of each of these three terms is a missed opportunity for deeper understanding. As a result, the contribution feels somewhat lacking in depth.\n3. The proposed loss function presents challenges in differentiability with respect to 't'. The sampling proposal, derived from the farthest sampling strategy, may not be the most efficient approach. It appears to demand significant training resources, resulting in elevated training costs. The potential enhancements in model performance might not justify the trade-off in terms of the increased training time and resource allocation. Please see the weakness above.",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108511",
         "5.0",
         "2.0",
         "3.0",
         "3.0",
         "1.0",
         "335",
         "0",
         "6",
         "0.7966000000000001",
         "0.1848602484",
         "0.9041278958000001",
         "52",
         "29.0988",
         "13.8242",
         "17.2355",
         "15.5433",
         "15.2217",
         "0.1431",
         "101",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "8",
         "74",
         "Sonny",
         "Reviewer-bNPg",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "3",
         "4",
         "4",
         "3",
         "90",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies the view sampling strategies of Nerf reconstruction from a causal perspective. The authors try to solve the problem using a small subset of photos from a total of K potential views, to achieve the best reconstruction. To solve this, the authors propose to use causal represntation learning using loss by Identification Treatment Effect. They propose three terms, a normal fitting term as reconstruction loss, a consistency term to ensure consistency between visible views and invisible views and a uniformity term requires the samples to be distributed evenly. The results show the proposed strategy can provide slightly better reconstruction compared to alternative baselines in the proposed setting. * The paper proposes a novel perspective to study the view sampling problem in volumetric reconstruction using NeRF as an example. This take-away can potentially also generalize other multiview reconstruction algorithms. \n* Given its current setting, the hypothesis is validated on nerf reconstruction datasets, with small improvement compared to its baselines. * The presentation of this paper could be greatly improved. I may not have understand a lot of details correctly given its current presentation. \n  * It is very hard to read without being very familiar with ActiveNeRF and casual representation learning. Have to trace to original papers for more details. This could be added to the preliminary parts. \n  * Too many notations which makes things more complicated than needed. I don't think I found how exactly the loss of consistency term and uniformity term were calculated in (8) at runtime. As I understand, the method should be as simple as calculating the reconstruction loss using different groups of input samples. Provide an algorithm chart of how of how P^{F}, P^{hat}^{CF} and P^{CF} will greatly help. \n  * There are some notations introduced in 4.1 (e.g. P(Y|do(d))) are not explained until 4.2. \n* Overall I am not sure I understand the real-world impact of this paper using the proposed strategy. Maybe I had some misunderstanding in the details given my concern on its presentation. Please correct me if I am wrong here. The goal of this paper to find \"optimal sampling strategy for training set\", \"K_s corresponding photos as sparse sample inputs among K_d total potential views\" is hardly a real problem statement for its real-world use case, which is my biggest concern for this proposed application of causal representation learning. From sampling perspective, we can use all the K_d potential views as long as they are available. As I understand, the evaluation of the counter factual distribution will require using the non-selected but captured images as supervision, which is not how active learning is executed in real-world case. Given this setting, it makes the results also less appealing in contrast to alternative baselines (which learns to predict next-best unknown view) given the fact all images from that particular datasets are used in evaluating the sampling strategy. 1. My major question is around how the clarity of the sampling process in training time. Confirm any places I misunderstood about this paper, as I highlighted in the weakness part. \n2. I am also curious how the views are sampled finally for different groups in the final results. Provide some visualization and discussions about them can be very helpful to guide the view-sampling process in real world applications. I wonder how that indicate the connection of uniformity term and consistency term are correlated to the camera FoV and ray distributions.",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108442",
         "3.0",
         "3.0",
         "2.0",
         "1.0",
         "2.0",
         "566",
         "0",
         "2",
         "0.8138000000000001",
         "0.1125",
         "0.8472209573",
         "52",
         "40.8228",
         "12.0451",
         "14.3685",
         "13.7425",
         "12.6507",
         "0.33",
         "107",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "9",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-GDNX",
         "3",
         "5",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "80",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         ">**Rebuttal:** The provided details satisfy my concerns. I think this paper should be accepted after applying the agreed changes.\n\n>**TL;DR:** **Good paper.** The proposed WTA-CRS algorithm is based on the existing CRS algorithm and is used to reduce activation memory during training. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size. However, WTA-CRS comes with computational overhead, which is discussed and explore. Addressing my concerns and questions would improve my score.\n\nThe paper proposes the WTA-CRS algorithm to reduce the neural networks training activation memory, where the paper claims that activation memory is primary memory bottleneck during training. The WTA-CRS algorithm is an unbiased estimators for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size.\n\nThe WTA-CRS algorithm works by sampling columns and rows to create an unbiased estimation of the original GEMM for the backpropagation. The WTA-CRS algorithm does not alter the neural architecture, and therefore the inference speed is left in tact. The experimental section shows that WTA-CRS outperforms existing prior work and is compatible with existing PEFT techniques. WTA-CRS adds a computational overhead due to sampling, however, WTA-CRS enables training on much larger batch sizes, which results in a 1.2× higher training throughput.\n * **S.1.** The proposed WTA-CRS algorithm tackles an important problem in existing PEFT techniques, which makes LLM PEFT training more accessible to researchers with low resources.\n* **S.2.** The paper provides a theoretical analysis on WTA-CRS.\n* **S.3.** The proposed WTA-CRS algorithm outperform existing algorithms.\n* **S.4.** An anonymized code repository is provided as part of the submission for reproduction .\n  * **W.1.** Popular existing memory efficient training techniques such as tensor rematerialization (gradient checkpointing) \\[2\\]\\[3\\] and ZeRO \\[1\\] are not compared to, although some are partially discussed in Appendix A.\n* **W.2.** The experiments are conducted on single neural network architecture (T5), although the proposed technique does not seem to be confined solely to that setting.\n* **W.3.** It is common practice today to train neural networks at a lower precision (quantization), however, it is not clear whether quantization (16bit) was used. Therefore, there is insufficient proof that the combined noise of WTA-CRS and quantization would be compatible.\n\n\n**Typos.**\n* Line #62: \"Thus\" → \"Thus,\"\n* Line #240: \"mAccording\" → \"According\"\n* Line #297: \"Thus\" → \"Thus,\"\n\n\\[1\\] Ren, J., Rajbhandari, S., Aminabadi, R.Y., Ruwase, O., Yang, S., Zhang, M., Li, D. and He, Y., 2021, July. ZeRO-Offload: Democratizing Billion-Scale Model Training. In USENIX Annual Technical Conference (pp. 551-564).\n\n\\[2\\] Jain, P., Jain, A., Nrusimha, A., Gholami, A., Abbeel, P., Gonzalez, J., Keutzer, K. and Stoica, I., 2020. Checkmate: Breaking the memory wall with optimal tensor rematerialization. Proceedings of Machine Learning and Systems, 2, pp.497-511.\n\n\\[3\\] Beaumont, O., Eyraud-Dubois, L. and Shilova, A., 2021. Efficient combination of rematerialization and offloading for training dnns. Advances in Neural Information Processing Systems, 34, pp.23844-23857. * **Q.1.** In line #43 and Figure 2 it is noted that \"storing activations (or feature maps) is the main memory bottleneck during training\". Does this hold true for all model architectures? What about LLM training where the fine-tuning batch size is usually very small?\n* **Q.2.** Why was the WTA-CRS algorithm compared to the Deterministic top-k from \\[1\\] but not to the Bernoulli-CRS from \\[1\\]? What are the key differences between WTA-CRS and Bernoulli-CRS?\n* **Q.3.** The paper proposes WTA-CRS which sacrifices computation speed at the cost of lower peak memory. There are several existing common approaches (such as gradient checkpointing and DeepSpeed) for general memory efficient training which are compatible with PEFT techniques. Why are these comparisons not explored or detailed in the main paper?\n\n\\[1\\] Adelman, Menachem, Kfir Levy, Ido Hakimi, and Mark Silberstein. \"Faster neural network training with approximate tensor operations.\" Advances in Neural Information Processing Systems 34 (2021): 27877-27889. The limitations are discussed in Appendix A.",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411175092",
         "7.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "669",
         "10",
         "14",
         "0.753",
         "0.09034013610000001",
         "0.8664653897",
         "215",
         "42.5651",
         "10.4983",
         "14.0094",
         "12.9915",
         "12.0464",
         "0.1507",
         "77",
         "1",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "10",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-j1mL",
         "4",
         "4",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "3",
         "70",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "In this paper, we propose a new method called WTA-CRS (Winner-Take-All Column Row Sampling) to address the main memory bottleneck issue during training, which arises from storing feature maps. To reduce memory usage during training, we sample the most likely column indices during backpropagation.\n\nFurthermore, \bthey proposed method demonstrates the ability to significantly reduce peak memory usage, by approximately up to 2.7 times, when fine-tuning downstream tasks. It also showcases the potential for higher throughput, enabling more efficient training. 1. The work clearly states its motivation and its solution and is easy to follow.\n2. The authors show that their method reaches comparable performance with backpropagation using the full activation when combined with LoRA.\n3. They also empirically measure throughput gains obtained by increasing batch size, which demonstrates the practical applicability of their method. 1. The paper needs a comparative analysis of other researchs, such as gradient checkpoint/recalculation and CRS, aimed at reducing activation memory during the training phase, as shown in Fig. 6 and Fig. 9.\n2. The paper should include an analysis of the overhead associated with the proposed WTS-CRS method, which involves sampling rows and columns. It is crucial to consider factors such as the computational cost of Equation 3 and any potential effects of lowering on the overall performance. Providing this analysis would enhance the clarity and completeness of the research.\n3. There is a need of analysis on the effectiveness of the proposed approach, WTS-CRS, in distributed training environments such as tensor parallelism or pipeline parallelism.\n4. It seems necessary to conduct performance evaluations on various LLMs of the GPT family, such as LLaMA and OPT. * In Figure 9, it can be observed that the throughput of WTS-CRS is lower than that of full when the batch size is small. Is this due to the overhead caused by lowering?\n* When comparing the training throughput, how does CRS differ from full in terms of throughput?\n* Could the authors include statistics for GPU utilization in their experiments? It would be helpful to analyze the causes of improved performance more thoroughly.\n* Considering that most large models are trained using multiple levels of parallelism, would it be possible to verify results for pipeline parallel, tensor parallel, etc.? Also, it is unclear from the paper whether the data parallelism used was distributed data parallelism or naïve data parallelism. * As previously mentioned, it would be valuable to include additional experimental results for models that are more challenging to quantify, such as GPT-series (OPT, LLaMA). This would enhance the validity and applicability of the proposed method across a broader range of models.\n* Considering that most large-scale models are trained using multiple levels of parallelism, it is important to assess how much the proposed methods, such as pipeline parallelism and tensor parallelism, can increase throughput while taking into account overhead (such as GPU-to-GPU or node-to-node communication), memory reduction, and computational cost. Furthermore, it is not clear from the paper whether the data parallel processing used is distributed data parallelism or naive data parallelism.",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174921",
         "5.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "506",
         "0",
         "8",
         "0.8129000000000001",
         "0.11685380590000001",
         "0.8539184332",
         "215",
         "31.6518",
         "13.622",
         "15.7723",
         "14.7722",
         "14.3231",
         "0.1355",
         "89",
         "0",
         "1",
         "0",
         "0",
         "neurips"
        ],
        [
         "11",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-cMiu",
         "4",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "80",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The authors studied fine-tuning LLMs with limited memory. As the increased scale of current LLMs, the memory cost during fine-tuning is of great importance when adapting the pretrained LLMs to down-streaming tasks. In contrast to the existing work that mainly focus on the number of updated weights, this paper proposed to reduce the number of stored activations, also the inputs to each layer. Given the widely used stochastic gradient descent optimization pipeline, the authors proposed to store a subset of activations that can generate an unbiased gradient estimation. This way, the training memory and the training time decreased significantly. The authors provide both theoretical and experimental analysis on their CRS methods.  - This paper studied an important problem in LLM fine-tuning, i.e., how to fine-tuning LLMs with less memory consumption without increasing the computation cost. The authors provided solid quantitative results to show that the main memory consumption is from storing the intermediate activations. \n- The authors provided a general solution for fine-tuning LLMs under memory constraints. The solution can be applied in most transformer-based network architectures.  \n- The authors provided solid mathematical proof on the unbiased gradient estimation, which is especially encouraged. \n- The extensive experiments on different network architectures showed the efficacy of the methods.\n- The released code can benefit the following researchers studying efficient LLM fine-tuning.  - I am not fully convinced by the comment made in Line241-244, i.e., the methods in the paper is orthogonal to the activation quantization. When activation is quantized into a lower bit width, it is very possible that the number of less important activations will decrease. This way, the selection on the top-k columns in activation matrices with the proposed methods may hurt the training accuracy or convergence. It would be great if the authors can provide some theoretical analysis or experimental results on this combination. Otherwise, it would be necessary to provide some comparison results w.r.t. the activation quantization.\n- It would be great if the authors can discuss the main difference of their paper w.r.t. \\[Randomized Automatic Differentiation, ICLR2021\\].\t  Overall, I think this paper has a relatively high quality in both writing and scientific contribution. Yes",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174804",
         "6.0",
         "4.0",
         "2.0",
         "3.0",
         "3.0",
         "358",
         "0",
         "2",
         "0.7825000000000001",
         "0.1275074405",
         "0.8477004170000001",
         "215",
         "33.3958",
         "12.2345",
         "15.5366",
         "14.3747",
         "12.6032",
         "0.1262",
         "97",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "12",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-ky3t",
         "2",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "70",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The paper's contribution is in proposing a practical, intuitive yet not trivial unbiased approximation to gradient training of matrix multiplication. It shows that even though totally deterministic sampling is biased, somewhat deterministic sampling is unbiased, and a judicious allocation of sampling to those pairs favored by deterministic thinking can lead to the use of a larger batch size with empirically negligible performance loss. This reviewer must declare that he does not check the derivation very carefully. The proposed idea is practical and can be readily combined with virtually all first-order gradient-based training methods.\nThe paper also derived why deterministic sampling is a biased estimator and empirically shown the associated bad performance, thus proving that the additional complexity of stochastic sampling over deterministic sampling is not only sufficiently better but also necessary. It's just a few empirical comparisons, but the performance gap between CRS and WTA-CRS seems modest. This reviewer does not have a question. N/A",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174720",
         "7.0",
         "3.0",
         "4.0",
         "3.0",
         "3.0",
         "155",
         "0",
         "1",
         "0.8418",
         "0.062142857100000004",
         "0.7829982042",
         "215",
         "17.3432",
         "16.3412",
         "19.4378",
         "17.1224",
         "17.2025",
         "0.1041",
         "90",
         "0",
         "1",
         "0",
         "0",
         "neurips"
        ],
        [
         "13",
         "38",
         "Seyed",
         "Reviewer-vqBu",
         "3",
         "2",
         "unfactual",
         "neutral",
         "polite",
         "low",
         "2",
         "2",
         "3",
         "2",
         "3",
         "4",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way. The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea. The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso. - in the frequentist case, how does the proposed framework compares against more classical techniques to obtain the solution paths, e.g., iterative reweighted l1-norm?  The authors adequately addressed the limitations of their proposed framework. ",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411519040",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "170",
         "0",
         "0",
         "0.799",
         "0.32",
         "0.9384971857000001",
         "215",
         "30.7103",
         "14.2239",
         "17.6808",
         "16.0619",
         "16.5336",
         "0.1149",
         "88",
         "1",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "14",
         "38",
         "Seyed",
         "Reviewer-3sWQ",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "2",
         "1",
         "3",
         "3",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution. - Well written paper.\n\n        - Illustrative toy experiments. - The proposed method is a combination of already known techniques.\n\n        - The experimental section is weak as only a single real problem is considered.\n\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\n\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\n\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros. None The authors have not commented on the limitations of their approach.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518947",
         "5.0",
         "3.0",
         "2.0",
         "3.0",
         "2.0",
         "279",
         "0",
         "2",
         "0.7414000000000001",
         "-0.007047619000000001",
         "0.9233116508",
         "215",
         "36.096",
         "12.2287",
         "15.0602",
         "13.9505",
         "11.6138",
         "0.0989",
         "92",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "15",
         "38",
         "Seyed",
         "Reviewer-pTVu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "3",
         "4",
         "4",
         "4",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\geq1}$ is used). 1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\n3. Using sub-l1 norm is suitable for structure learning. \n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \n5. The paper is well-written, and the relevant work is sufficiently discussed.    \n6. Due to its flexibility, the proposed method has the potential of having a large impact. Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \n\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \n\nMinor suggestion: \n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \n2. Fix minor typos e.g. the end sentence period in line 214. * In line 141, what do you mean by \"contradiction\"? The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \n\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518854",
         "6.0",
         "3.0",
         "3.0",
         "4.0",
         "2.0",
         "330",
         "0",
         "9",
         "0.7934",
         "0.1236940837",
         "0.8818445206000001",
         "215",
         "45.1097",
         "11.0541",
         "13.9964",
         "13.4279",
         "11.8722",
         "0.19690000000000002",
         "83",
         "0",
         "0",
         "0",
         "1",
         "neurips"
        ],
        [
         "16",
         "38",
         "Seyed",
         "Reviewer-CnQu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "moderate",
         "2",
         "2",
         "1",
         "1",
         "3",
         "4",
         "50",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets. Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \n\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated. Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost. In synthetic data example, why did you choose to have more samples than dimensions ( $n>d$ )? Since in that case GGM can be obtained with matrix inverse, and no need for penalized objective. Limitations were not discussed.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518763",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "205",
         "0",
         "2",
         "0.787",
         "0.1207251082",
         "0.8797656298000001",
         "215",
         "36.2535",
         "11.8049",
         "15.4552",
         "13.8167",
         "11.6905",
         "0.25730000000000003",
         "82",
         "0",
         "1",
         "0",
         "0",
         "neurips"
        ],
        [
         "17",
         "13",
         "Mana",
         "Joseph-philipraj",
         "5",
         "5",
         "factual",
         "positive",
         "polite",
         "low",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "95",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This systematic review is appropriate for the journal with a global problem of Mets and Urolithiasis. The introduction part clearly explains the motivation. The manuscript is clear and balanced. The manuscript stays focused on the subject. Authors have gone through the process of searching relevant articles from all websites and of sufficient duration. The inclusion and exclusion criteria in the analysis have been clearly stated. The impact of the analysis is clearly stated. The statistical analysis supports the paper well. The interpretation of the results, visualisation are well presented. The tables and figures are clear, relevant and correct. The authors demonstrate the knowledge of basic composition skills, including word choice, sentence structure, paragraph development and grammar. Limitations:  The studies included in the meta-analysis have cross-sectional nature and hence ascertainment of temporal association is not possible which also dictates need for further prospective studies. The specific type of stone formation is not correlated with studies. Despite these limitations all studies included in the meta-analysis showed the same directionality in the association between urolithiasis and Mets.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         null,
         "22 Mar 2021",
         null,
         null,
         null,
         null,
         null,
         "292",
         "0",
         "1",
         "0.7415",
         "0.1145833333",
         "0.8487246633000001",
         "39",
         "30.46",
         "12.8",
         "13.83",
         "14.6",
         "14.3",
         "0.0999",
         "99",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "18",
         "13",
         "Mana",
         "Muhammad-Faruk",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "93",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study assessed the association between metabolic syndrome and its components with the risk of developing nephrolithiasis by conducting systematic review, Bayesian random-effects meta-analysis, meta-regression and dose-response analysis. This study was done appropriately based on PRISMA flowchart. Risk of bias was also conducted of the included studies. This study has successfully presented the proper meta-analysis for this design. However, to complete this study for indexing, I personally recommended several revisions: 1. Abstract: Introduction section: It is better to address meta-regression as the analysis to assess the correlation of association along with dose-response analysis  Conclusion section: In reporting the association between predictors and nephrolithiasis, state only the predictors in which its coefficient was statistically significant 2. R language was not considered as a statistical software for data analysis. The software for data analysis should be written as \"R\" (Please refer to methods section in statistical analysis subsection). 3. Please update the PRISMA flowchart (refer to PRISMA guideline 2009). 4. Give the numbering of each Forrest plot in Figure 3 and numbering of each meta-regression plot in Figure 4. Design these figures so that it could be well presented. 5. Uniformly decide the word choice of \"traits\" or \"components\", choose whether to use traits or components in the whole text, use one of these words consistently to avoid any misunderstanding. 6. It is better to provide the meta-regression of hypertension in systolic blood pressure and diastolic blood pressure as it is important to explain the relationship to nephrolithiasis in differentiation for these two types of blood pressure. 7. Meta-regression of body mass index  was sufficient in this study thus waist circumference meta-regression was not necessary to be included. 8. Provide the value of coefficient and confidence interval of each meta-regression analysis in the result section so that better understanding of predictors-outcome relationship could be reached clearly.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         null,
         "08 Nov 2021",
         null,
         null,
         null,
         null,
         null,
         "422",
         "0",
         "7",
         "0.7554000000000001",
         "0.1982758621",
         "0.9299524426",
         "270",
         "24.68",
         "15.1",
         "14.79",
         "16.3",
         "16.8",
         "0.23020000000000002",
         "91",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "19",
         "181",
         "Hideaki-Joko",
         "Reviewer-sna7",
         "2",
         "2",
         "factual",
         "positive",
         "neutral",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This paper presents ULTRA, a single model that can be directly used/finetuned for link prediction over different knowledge graphs. The key is to model the transferrable relationships between different relations across knowledge graphs. Specifically, a NBFNet is used to learn relative relation representations and generate relation embeddings, which is then fed into another NBFNet to perform link predictions. Extensive experiments are performed over many knowledge graph to demonstrate the performance of this model. - This paper is well written and easy to follow\n- The core method around the relative relationships between relations is clever and interesting.\n- The experiments demonstrate the gains of the method. It is especially impressive to see the competitive zero-shot performance of ULTRA over different knowledge graphs. - The proposed method relies entirely on knowledge graph structure and does not consider using node embedding such as textual features of the knowledge graphs. In reality, text embedding of nodes and edges could be a better transferrable embedding. Such transferability has already been demonstrated by PRODIGY (https://arxiv.org/abs/2305.12600) and should be addressed.\n- The model does not scale well as the authors already pointed out.\n- The zero shot and fine-tuning performances are worse or on-par with the per dataset model performance, rendering pretraining not effective performance-wise. \n- Some notations are a bit hard to understand. See questions. - What are u and v in h_{u|v} in section 4.2?\n- Why are supervised SOTA baselines only reported for some datasets in Figure 4?",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636399067",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "245",
         "1",
         "1",
         "0.7559",
         "0.0971320346",
         "0.9083012938",
         "49",
         "38.7951",
         "11.5125",
         "14.374600000000001",
         "14.0058",
         "12.3979",
         "0.07200000000000001",
         "103",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "20",
         "181",
         "Hideaki-Joko",
         "Reviewer-HLbG",
         "3",
         "3",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This work aims to build a foundation model for knowledge graph reasoning tasks, where the authors explore the setting of generalization to any edges and nodes, including unseen, of any multi-relational knowledge graphs without using node and edge features. To this end, the authors first construct a view of a relation-centric graph from an original graph where edges become nodes of this new relation graph, and then, based on this view, the authors represent the relation (node) relative to and conditioned on the query relation. Then, based on this relative relation representation, the authors use existing inductive link prediction methods to perform knowledge graph reasoning. The authors conduct link prediction experiments on various knowledge graphs considering both inductive and transductive settings, and show that the proposed method, namely ULTRA, outperforms other SOTA baselines sometimes without further fine-tuning on target knowledge graphs (i.e., zero-shot). * This work studies the very important, challenging, and practical setups of building a foundation model for knowledge graph reasoning, which aims to be generalizable to any other knowledge graphs involving unseen nodes and unseen edges, without leveraging features of nodes and edges. \n* The proposed method works well with different knowledge graphs, on zero-shot transfer learning setups without further fine-tuning on target knowledge graphs, and further shows the boosted performance with task-specific further fine-tuning on them, on most experiment setups.\n* This paper is very well-written and easy to follow. * I would like to note that I don't see any major weakness, and below is the minor.\n* In Section 4.2, the explanation about the indicator function with variables $u$ and $v$ is a bit unclear to me. Could you elaborate more on the process and result of the indicator function according to those two variables, perhaps with visuals?\n* Text-based methods (e.g., LM-based methods) can be generalizable to any knowledge graphs including unseen nodes and unseen edges, as long as their nodes and edges are represented with texts. In this vein, I think one potential direction for building a foundation model for knowledge graph-related tasks might be to use the LMs, and the authors may highlight this point more and potentially make comparisons between the proposed approach and text-based methods. I don't think this should be the critical weakness of this paper since text-based methods are limited to knowledge graphs with textual features; meanwhile, given the framing of this work (\"Towards Foundation Models for Knowledge Graph Reasoning\"), this point should be carefully explained. * I would like to suggest emphasizing the performance differences between inductive and transductive setups when explaining Table 1. The proposed method w/ 0-shot settings are strong on inductive graphs; meanwhile, previous methods are superior to it on transductive graphs, which are worthwhile to discuss.\n* It may be beneficial to show the results of the ULTRA fine-tuned on the knowledge graphs used for pre-training the ULTRA. I am wondering if there are further performance improvements when further fine-tuning the model on the data used for pre-training.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398956",
         "8.0",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "496",
         "0",
         "0",
         "0.7682",
         "0.1549267161",
         "0.9152074456",
         "49",
         "38.4364",
         "14.2789",
         "16.8311",
         "15.0692",
         "17.4975",
         "0.37610000000000005",
         "103",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "21",
         "181",
         "Hideaki-Joko",
         "Reviewer-c3Sg",
         "4",
         "3",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "4",
         "3",
         "3",
         "4",
         "70",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "Paper claims to propose a foundation model, named Ultra, for knowledge graph representation learning. The proposed model can handle full inductive graphs in which new entities and relations may appear in the test set. To do so, the authors propose to lift the graph to a one with relations as the nodes and design 4 different edge types (head2head, head2tail, tail2head, tail2tail). The relational representations are then learnt using message passing on this graph. The learnt relation embeddings are then used in the original graph to perform inductive link prediction. For the experiments, the authors pre-train their method on 3 KGs and further evaluate in a zero-shot setting and also by fine-tuning the downstream tasks. - The paper proposes a transductive model that works in settings of new relations and entity nodes.\n- The method obtains good zero-shot pretraining results. - The authors have not explicitly stated the computational complexity of the method. From the paper, it seems that the forward pass is run on the entire relational graph to obtain relation representations. This is then used to initialize the node embedding from the query triple and the process is repeated for every triple. Thus it seems that the entire graph is being used for link prediction every triple making the computational complexity O(E^2). This seems limiting for large graphs that have not been explored in the paper (such as wikidata-5m etc.).\n- From Table 2 we can see that finetuning over the pre-trained models helps the results significantly over the 0-shot setting. Also, the fine-tuning steps are too large to claim few shot results. This weakens the claim of the \"foundation model\" for KGs. A fair comparison would be to show the pretraining results for other inductive and transductive methods as well in addition to the SOTA comparison.\n- Another limitation is that of scale. Since the current model has fewer parameters, this would limit learning over larger pretraining datasets as can be seen in Figure 6 and also reported by the authors.\n- SoTA results for transductive models are better than the pre-trained Ultra model in many datasets. Thus the Ultra model seems to work well for the inductive setting rather than transductive. Thus the claim of the \"foundation model\" seems broader in scope.\n- We see that in the metafam dataset, the pretraining results are poor but on finetuning the results are improved drastically. This shows that the method works well in cases where the relational patterns of the downstream datasets are similar to the pre-trained one but when the data distribution changes the results suffer. Moreover, due to limited capacity, the model may not be able to handle such cases by increasing the pretraining datasets calling for downstream finetuning. Thus domain adaptation is not a problem which can be easily overcome by scaling the current model and this further weakens the claim of a \"foundation model\" for KGs. - For weakness point 2: Any reason why this was not done by the authors?\n- For weakness point 3: How would this be addressed in future works for the model?\n-  For weakness point 4: Could the authors comment on why this would be the case and how would the model be improved to handle the transductive setting?\n- For weakness point 5: Any reason why the results on this dataset are not good?\n- Considering KGs are a rich source of textual/semantic data along with graph/structured data and the current model does not use this rich source of context information, how can we extend Ultra to incorporate the KG ontology? \n- Considering weaknesses 2,4,5 the claim of the foundation model seems a bit broad as of now and at best the model could be said to be a good inductive learner.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398852",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "625",
         "0",
         "0",
         "0.7487",
         "0.1723163098",
         "0.9095818996",
         "49",
         "51.6761",
         "10.8027",
         "13.532399999999999",
         "12.9203",
         "11.5318",
         "0.1355",
         "95",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "22",
         "181",
         "Hideaki-Joko",
         "Reviewer-ebFz",
         "2",
         "2",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "65",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "The key limitation of designing the foundation models for dealing with the Knowledge Graphs (KGs) is that the KGs have different entities and relations that generally do not overlap. To address this issue, this paper proposes ULTRA, which positively transfers the information of source KG to unseen KG. It constructs relation representations based on the interactions between the relations by introducing the graph of relations. The proposed approach has shown good performance on various tasks. - From their experiments, the proposed methods have shown good performance on various tasks.\n- Research topics about the foundational models on graph-structured datasets is really interesting and important.\n- The paper is well written and easy to follow. - The authors first pretrain the ULTRA model with the mixture of 3 standard KGs and then fine the model for the downstream task. But, the other supervised SOTA model only uses dataset of the downstream tasks without employing the pre-training datasets. If the supervised SOTA models are designed to deal with transductive settings, they may show worse performance on the downstream tasks. However, if the SOTA models are the models for the inductive setting, I think they may be possible to be pretrained like the ULTRA. So, could you measure the performance of the \"pretrained\" SOTA models on the inductive if possible? Please refer to the weaknesses.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398789",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "222",
         "0",
         "0",
         "0.7001000000000001",
         "0.16196172250000002",
         "0.9080925584",
         "49",
         "47.3913",
         "10.8151",
         "13.3132",
         "13.3974",
         "12.0322",
         "0.18230000000000002",
         "101",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "23",
         "9",
         "Seyed",
         "Reviewer-KmBd",
         "4",
         "4",
         "factual",
         "neutral",
         "neutral",
         "none",
         "4",
         "3",
         "4",
         "4",
         "3",
         "3",
         "90",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699637128872",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "487",
         "0",
         "1",
         "0.732",
         "0.1304191468",
         "0.9185432792",
         "47",
         "29.0538",
         "13.6602",
         "16.2613",
         "15.0211",
         "14.0811",
         "0.1695",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "24",
         "9",
         "Seyed",
         "Reviewer-3zCE",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699637128739",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "1.0",
         "480",
         "0",
         "0",
         "0.8331000000000001",
         "0.09343537410000001",
         "0.9183989763",
         "47",
         "39.3732",
         "11.51",
         "13.8202",
         "13.2344",
         "11.9386",
         "0.1932",
         "87",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "25",
         "9",
         "Seyed",
         "Reviewer-y5kB",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699642867494",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "41.9389",
         "11.9311",
         "14.8075",
         "13.9683",
         "12.4911",
         "0.050100000000000006",
         "104",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "26",
         "9",
         "Seyed",
         "Reviewer-XNx6",
         "5",
         "4",
         "factual",
         "neutral",
         "neutral",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "88",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1700672717423",
         "6.0",
         "4.0",
         "2.0",
         "2.0",
         "3.0",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.9159082770000001",
         "59",
         "42.2021",
         "12.1002",
         "14.7586",
         "13.9683",
         "12.0852",
         "0.929",
         "90",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "27",
         "81",
         "Emperatoor",
         "Gatot-Soepriyanto",
         "3",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study investigate whether financial distress, earnings management and audit quality as determinants/moderating variable for financial statements fraud in Indonesian listed firms during 2015 to 2019 period. The authors focused on infrastructure, utility and transportation sectors. In general, the study has been designed adequately to tackle the research questions and issues posed by the authors. However, there are some elements need to be addressed to improve the paper: Whilst the study provide adequate research background and institutional setting, it did not mention on why the study focuses on infrastructure, utility and transportation sectors? Is there any specific issues on that sector that related to financial statements fraud? In addition to that, why the study chooses 2015-2019 period?  The study should also discuss the reason choosing F-Score as its main measure for financial statement fraud. Why, for example, the study did not use, Beneish M-Score? Or other accounting irregularities measures in the literature?  The study needs to provide descriptive statistics table, so the reader can gauge and understand the dataset better. This should be provided before the authors arrive with the hypothesis discussion;  Given the study uses panel data (multi years, across different firms), is there any attempt to mitigate the issues of panel data regression? For example, using year-fixed effects or even using panel data regression analysis?  The manuscript need to be checked in terms of the quality of English write up. The title for example, is a little bit confusing, as it did not really represent what the study want to achieve in general.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "30 Jun 2023",
         null,
         null,
         null,
         null,
         null,
         "400",
         "0",
         "1",
         "0.7771",
         "0.11745495500000001",
         "0.9143848419",
         "220",
         "26.81",
         "14.2",
         "14.1",
         "14.9",
         "14.6",
         "0.016800000000000002",
         "96",
         "0",
         "0",
         "2",
         "0",
         "f1000"
        ],
        [
         "28",
         "81",
         "Emperatoor",
         "Toni-Šušak",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "25 Mar 2024",
         null,
         null,
         null,
         null,
         null,
         "909",
         "0",
         "5",
         "0.6798000000000001",
         "0.12259259260000001",
         "0.8569852710000001",
         "489",
         "50.12",
         "9.4",
         "10.63",
         "12.4",
         "10.8",
         "0.07200000000000001",
         "98",
         "0",
         "0",
         "0",
         "0",
         "f1000"
        ],
        [
         "29",
         "24",
         "Sajad-Ebrahimi",
         "Silvio-Buscemi",
         "1",
         "1",
         "unfactual",
         "negative",
         "polite",
         "extreme",
         "1",
         "3",
         "1",
         "2",
         "3",
         "3",
         "48",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         null,
         "07 Jan 2025",
         null,
         null,
         null,
         null,
         null,
         "280",
         "0",
         "1",
         "0.7857000000000001",
         "0.1403645833",
         "0.7798862457",
         "34",
         "24.27",
         "15.2",
         "16.6",
         "16.6",
         "16.3",
         "0.3225",
         "94",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "30",
         "77",
         "Mohammad-Hossein-Saliminabi",
         "Houcemeddine-Turki",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "85",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "This manuscript presents a novel rule-based approach for fact checking in knowledge graphs based on mining textual resources. The work provides new evidences that rule-based approaches can provide more precise evaluation of the accuracy of statements in knowledge graphs and can enhance the efficiency of embedding-based methods when combined with them. The availability of source codes and datasets in GitHub is an advantage for this work as this will allow the reproducibility of the described experimental study. However, there are several matters within the paper that should be addressed to ameliorate its final output: (i) Introduction: The \"Introduction\" seems to be a summary of \"Related Studies in Fact Checking\" rather than a proper introduction and contextualization of the paper. I propose to expand the part about misinformation fighting in the introduction to give better context for the development of this research paper. The authors can benefit from previous research papers about fact checking in general to develop the introduction of the paper. Several points in the introduction should be moved to Related Studies in Fact Checking. (ii) The paper did not emphasize the advantages of rule-based approaches when compared to embedding-based methods beyond having a better precision. Effectively, there are many other advantages of rule-based approaches. For example, the results of rule-based approaches can be more explainable than the ones of embedding-based approaches. Such advantages should be expanded and highlighted in the research paper. (iii) The paper did not emphasize the importance of having the datasets and source codes available in a specific GitHub repository. The authors should specify that this practice allows reproducibility and further development of the work by peers, particularly in the conclusion. (iv) The paper did not discuss the concept of reification in knowledge graphs. Effectively, several knowledge graphs add qualifiers to triples to provide a characteristic of the statements (i.e. {(s,p,o), p, o}. The authors should discuss the usefulness of the method to verify the qualifiers of the statements in the Discussion or as a future direction for this work. (v) The paper should evocate the robustness of the rule-based approach they proposed to adversarial attacks. This can be an advantage of the approach. (vi) There are several typos in the research paper (e.g. \"UC Berkely\" should be \"UC Berkeley\"). The authors should proofreading the paper to eliminate such deficiencies. (vii) The authors can expand the Discussion of the work (Part 5) to explain the strengths of KStream, KLinker, COPPAL, RUDIK, and PredPath that contributed to their efficiency as reported in the Experimental Study according to previous research papers. This can explicate the reasons of why the method developed by the authors was more efficient. (viii) The authors should provide future directions for the development of this work in the conclusion. Given this, I propose to accept this paper for publication after these six major revisions are applied.",
         null,
         "18/Feb/2021",
         null,
         null,
         null,
         null,
         null,
         "473",
         "0",
         "1",
         "0.7464000000000001",
         "0.1097294372",
         "0.9120528102000001",
         "4",
         "36.08",
         "12.7",
         "12.27",
         "13.7",
         "13.7",
         "0.2025",
         "97",
         "0",
         "0",
         "0",
         "0",
         "semanticweb"
        ],
        [
         "31",
         "77",
         "Mohammad-Hossein-Saliminabi",
         "Anonymous",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "The paper presents a weighted logical positive and negative rules-based approach to check logical consistency of triples in a knowledge graph.  The paper has multiple flaws in terms of writing (please, consider English proofreading for a future submission), but also in terms of its structure and form (see remarks below). Comparing rule-based and statistical approaches for graph completion is very useful. However, I was disappointed by table 1, which contains only three very obvious comparison criteria. I don’t find that very informative (and is totally redundant with the text in the corresponding paragraphe) and would strongly encourage a more in-depth analysis of the differences (pros and cons) of the two types of methods. On a related note, I find the related work section difficult to follow. It probably can be improved by structuring better the different approaches, defining a clear basis for comparison between them. Also, and importantly, the section lacks a clear positioning of the proposed approach as compared to those reviewed in this section. I also fail to see the purpose of presenting embeddings-based approaches since they are not applied in this work, as far as i can see. I fail to see the originality of the presented approach, my impression is that it builds largely on existing techniques (e.g. generation of negative samples, rule mining and the like). The overall structure of the paper can be improved significantly. It currently contains multiple redundant parts (e.g. large parts of section 3 are repetitive wrt what has been said already in the introduction or elsewhere in the paper). While the overall approach is explained clearly, I think that relatively straightforward ideas are described in way too much details (like for example the negative examples sampling).  The results do not report anything about the computational complexity of the method, while an argument is made in the introduction about assisting human/manual fact-checking at scale. Also, the number of predicates in the datasets that are used in the studies appears very small for the approach to be able to account for a real-world scenario. More surprisingly, the evaluation results are reported only on a handful of predicates. Therefore I am doubtful about the applicability/generalizability of the proposed approach in a more realistic scenarios and at scale. Minor: across media, community, and —> across media, communities, and -  Misinformation in the Web —>  Misinformation on the Web -  in media and community makes -->  in media and communities makes -  This problem is common and getting worse in modern digital society - this statement somehow needs support -  which is logically contradict —>  which logically contradicts -  we did not contain those triples already contained in K-Box —>  we did not include those triples already contained in K-Box - there’s a screenshot issue with fig. 7",
         null,
         "18/Mar/2021",
         null,
         null,
         null,
         null,
         null,
         "463",
         "0",
         "1",
         "0.7582",
         "0.036034151",
         "0.894587338",
         "32",
         "31.62",
         "14.5",
         "15.34",
         "15.6",
         "15.3",
         "0.3415",
         "99",
         "0",
         "0",
         "0",
         "0",
         "semanticweb"
        ],
        [
         "32",
         "77",
         "Mohammad-Hossein-Saliminabi",
         "Anonymous",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "- originality This work proposes a new method to generate positive and negative rules from a knowledge graph. Positive rules can be learned from known facts which the KG already contains. The authors proposed a negative sampling strategy to generate negative rules that are used to assess whether a fact should be not part of the KG. It explores different assumptions namely local and extended local closed world assumption (LCWA and E-LCWA) to generate false facts and learns negative rules from generated false facts. The positive and negative rules are combined to assign a truthfulness score for a given fact. The authors extend RUDIK’s negative sampling approach to produce better false facts for non-functional properties (the properties that can have more than one value such as ‘relative’ relation) by making a distant local closed world assumption (D-LCWA) .  - The authors propose a new rule weighting and truth scoring method, which is a revised version of RUDIK method, and compared its fact checking accuracy to other rule based fact checking algorithms on three different knowledge graph datasets: i) a synthetic dataset ii) a real-world dataset and iii) their constructed dataset.  The facts in their constructed dataset were extracted from the Wikipedia articles using a BERT-based relation extraction method and then the facts were labeled as true or false after manual checking for supporting sentences in Wikipedia articles.  - significance of the results The authors achieved 5% of improvement over the-state-of-art fact checking methods on the benchmark datasets and performed an extensive experimental evaluation on three datasets, comparing with 5 different methods namely; (1) KStream, (2) KLinker, (3) COPPAL, (4) RUDIK, and (5) PredPath. However, I still have some concerns regarding the results: - The authors pointed out some issues related to existing benchmark datasets and constructed a new evaluation dataset. The authors claim their evaluation dataset is more challenging than existing datasets for fact checking. We don’t know if this dataset has any biases. Have they done quality assessments on their dataset? Do the annotators record the supporting statements/sentences when labeling facts?  - The authors corrected existing datasets (i.e. synthetic and real world) by removing mislabeled true facts. Interestingly, they did not mention the removal of the overlapping true-labeled facts between the training dataset (in this case DBPedia) and the test dataset. Please explain this decision and why this issue was not addressed. - When I checked their Github page, the documentation quality on how to use the library was not good. It is not clear how to run their rule generation algorithm on a sample KG dataset. The documentation should show a sample run of the algorithm, preferably on a small KG. - quality of writing In general, the paper is well written. The introduction was divided into multiple subsections, which disrupts the flow. In the introduction, a comparison of embedding-based to the rule-based approaches is given, and a performance table from their previous paper was included. However, this work focuses on solely rule-based fact checking and I think that the embedding part is not that relevant. I would suggest removing or simplifying these parts.   -> The result section includes many subjective statements (e.g., Line 25 in page 15 ). I would also suggest that the authors create a separate discussion section for these statements.   -> The section of  3.5 (Rule Weighting by Logical Validity) in the methodology starts by explaining W2-measure without explaining W1. It would be useful to add a description for W1 used in the evaluation. What is an unbounded rule?  Please define it formally.",
         null,
         "08/Apr/2021",
         null,
         null,
         null,
         null,
         null,
         "589",
         "0",
         "0",
         "0.7586",
         "0.038220439700000004",
         "0.9288258553000001",
         "53",
         "45.76",
         "11.1",
         "12.2",
         "14.6",
         "12.8",
         "0.2561",
         "103",
         "0",
         "0",
         "1",
         "0",
         "semanticweb"
        ],
        [
         "33",
         "67",
         "Emperatoor",
         "Reviewer-um1j",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "4",
         "5",
         "3",
         "4",
         "4",
         "70",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "The paper introduces a new method for molecular modeling, QuinNet, which incorporates five-body interactions using only dihedral angles. The authors first introduce relevant concepts related to machine learning force fields and related work in the field related to a variety of equivariant models. Next, the paper describes pertinent definitions of force fields, group equivariance, and methods for calculating empirical force fields. In the methods section, the authors describe their approach for integrating five-body terms into the architecture of QuiNet using only dihedral angles and incorporating model designs from prior work (PaiNN for 3-body interactions, ViSNet for 4-body interactions) and new definitions for different topologies of 5-body interactions. In addition to the architectural description, the authors provide relevant mathematical formulations and a complexity analysis. In their results, the authors showcase QuiNets performance on a low (MD17) and high complexity (MD-22) dataset in terms of energy and force modeling, including an ablation for different body terms in Figure 5. The paper has the following strengths:\n* Originality: The proposed architecture incorporates relevant terms for molecular modeling that are physically relevant, but have not been incorporated before.\n* Quality: The method and experimental design showcase relevant cases for applying GNN models for molecular modeling with the idea behind the architecture being well-motivated.\n* Clarity: The paper presents a cohesive formulation of their method, both in figures and mathematics, and experiment descriptions with relevant takeaways.\n* Significance: The proposed architecture shows improved modeling performance, especially in forces, and provides a potential framework for incorporating physical interactions into GNNs. The paper could be improved by the following:\n* Providing a clear and concise discussion of limitations. \\[Quality, Significance\\]\n* Adding more context for the results in Figure 4. The MD simulations are only briefly described in Section 5.1, which is on a different page then the figure and easy to miss. \\[Clarity\\]\n* A description of the case in which a greater set of many-body interactions is beneficial. This is briefly mentioned in the discussion between MD17 and MD22, but it would be good to put in greater context in terms of the experimental results and could serve as part of the conclusion. \\[Clarity\\] * Could you provide additional details on the limitations of QuinNet? E.g. Is it limited to modeling mainly molecular systems? What sizes of molecules do you think QuinNet can be effective in and why?\n* Do you have data that supports your compute complexity analysis compared to other methods? If so, what kind of speedup do you generally find, if any? The authors do not provide a discussion on limitations, which I raised as a weakness. I would like to see a discussion of limitations in future versions and/or during the discussion period.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337960",
         "7.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "452",
         "0",
         "1",
         "0.7681",
         "0.1465895563",
         "0.867398262",
         "215",
         "29.1615",
         "13.9768",
         "17.1852",
         "15.6791",
         "14.5327",
         "0.464",
         "93",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "34",
         "67",
         "Emperatoor",
         "Reviewer-YmDt",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "5",
         "4",
         "5",
         "5",
         "80",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "In this work, the authors propose to incorporate features from five-body interaction into machine-learning force field models and develop QuinNet. To efficiently incorporate such high-order information, the authors are motivated by the topology of many-body interactions and design sophisticated components. Experiments on several benchmarks are conducted to demonstrate the performance of QuinNet. 1. The target problem of this paper, the development of machine learning force field models, is of great significance. 1. **The motivation for the designed components of many-body interaction is puzzling**. As introduced in Section 4, the development of four-body interaction (improper torsions) and five-body interactions are based on the topology. First, such analysis is purely qualitative. The authors did not provide further completeness proof or quantitative evidence about these interaction schemes in real-world data. Second, the reasons for deriving Eq (4)-(9) are not well explained. It is suggested to clarify how these components are motivated according to the topology analysis.\n\n\n2. **On the experimental evaluation**. Additionally, there are several aspects of the experiments that are concerned:\n    - The empirical performance is not consistently better than other baselines. Among the evaluated benchmarks, the proposed QuinNet cannot outperform the baselines significantly. For example, in MD17, the newly developed five-body interaction modules do not significantly improve performance. In rMD17, the best performance is diversely distributed among the compared models. Overall, the experimental evaluation does not well demonstrate the power of newly developed modules.\n    - The computation efficiency evaluation is missing. Although the authors provide complexity analysis, it is better to further show the time/memory cost comparison between the proposed QuinNet and baselines. Besides, the model parameters should also be provided for all compared models.\n    - The scale of the chosen benchmarks is rather small. Both the dataset size and sample size (number of atoms) are limited. It is suggested to further evaluate the proposed QuinNet on large-scale benchmarks, e.g., Open Catalyst Project \\[1\\].\n    - The ablation study. First, as shown in Figure 5, the inclusion of Five-body@I even induces further errors, which would make readers curious about whether such a phenomenon generally exists. Second, as introduced in VisNet, the improper angle was also considered. The authors should add further discussions and empirical comparisons between it and the newly proposed four-body interaction (improper torsion).\n\n\n3. **The writing does not meet the requirement of an acceptable paper in this conference**. First, Section 3.2 can be thoroughly extended (e.g., in the appendix) to introduce the background of force fields and highlight the importance of torsion potential, improper torsions, and higher-order many-body interactions. Second, there lack of formal descriptions of QuinNet. Figure 3 can hardly be understood by readers that are not familiar with the related works in this area. \n\n\\[1\\] Chanussot L, Das A, Goyal S, et al. Open catalyst 2020 (OC20) dataset and community challenges\\[J\\]. Acs Catalysis, 2021, 11(10): 6059-6072.\n    -  Please refer to the Weakness section to address the concerns. The authors did not discuss the limitations of this work.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337859",
         "4.0",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "489",
         "2",
         "6",
         "0.7931",
         "0.0741489571",
         "0.8583066463000001",
         "215",
         "34.6703",
         "11.5877",
         "14.5989",
         "13.0672",
         "12.5916",
         "0.19390000000000002",
         "92",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "35",
         "67",
         "Emperatoor",
         "Reviewer-8RW7",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper aims to incorporate 5-body interactions into geometric deep learning models. They first analyze the topology of 5-body interactions and identify three 5-body angles. Then they propose an efficient way to incorporate these 5-body information into models. The complexity of the proposed QuinNet is still O(|N|), the same as many previous 2-body methods like PaiNN. The results are comparable to previous SOTA methods. This paper is well-written and easy to follow.\n\nThe experimental results show that the proposed method can perform well on most tasks. The ablation study in Section 5.4 and Figure 5 show that the proposed 5-body information indeed helps to model. See details in the Question part. 1. About the motivation:   \n this paper aims to incorporate 5-body interactions into geometric deep learning models. However, based on my understanding, using up to 4-body (torsions) interaction is already complete \\[1\\]\\[2\\] in terms of capturing the geometric structures. If this is correct, then why do we need these 5-body angles? In addition, if we can incorporate 5-body interactions, do we also need to incorporate 6-body interactions?\n\n2. About the complexity:   \nin Section 4.3, the authors claim that the complexity is O(|N|), as efficient as many 2-body methods like SchNet and PaiNN. But I think this complexity is not well explained. Using pseudocode/algorithm may be better to analyze the complexity. In addition to the analysis, I suggest the authors use some results to empirically verify the great efficiency compared to other baseline methods, e.g. the inference time, used memory, etc.\n\n3. About the tasks:   \nthis paper focuses on MLFFs, how about other molecular property prediction tasks, such as QM9 and OC20? I am wondering if this method is specially designed for MLFFs, or can be used on all 3D molecule tasks. In other words, why do the authors emphasize MLFFs? Is there any significant difference between MLFFs and other molecule property prediction tasks?\n\n4. Other related papers: many-body \\[3\\], MLFFs \\[4\\]\n\n5. The j, k in Figure 2 are confusing to me. For example, in (f), why not be i, j1, j2, j3, and k1?\n\n\\[1\\] ComENet: Towards Complete and Efficient Message Passing for 3D Molecular Graphs.  \n\\[2\\] GemNet: Universal Directional Graph Neural Networks for Molecules.  \n\\[3\\] On the Expressive Power of Geometric Graph Neural Networks.  \n\\[4\\] Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations. None",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337767",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "394",
         "8",
         "6",
         "0.77",
         "0.13857142860000002",
         "0.8948391676",
         "215",
         "48.9981",
         "9.5825",
         "12.3935",
         "12.0149",
         "9.7898",
         "0.1429",
         "92",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "36",
         "67",
         "Emperatoor",
         "Reviewer-YYfR",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "70",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper introduces a machine learning force field that is a neural network with explicit interactions for up to 5-body terms.  The authors evaluate the model on a couple of public datasets and show demonstrate the competence or superiority of this new model compared to the state of the art in this field. The paper provides an important addition to a series of ever-improving machine learning potentials.  The contribution is clear and simple to understand at the high level, though the details are often unclear.  The benchmarks were compared against a set of reasonably strong published methods in this area.  In my opinion, if this work was presented in an unambiguously clear fashion and accompanied by code, it could be a strong contribution to this conference.  \n\n\\[The paper improved significantly following the first round of feedback from reviewers, so I'm raising my rating to a 7.\\] The complexity analysis is very limited.  How many total interactions did the typical molecule have as a function of their atoms, and how did the practical experimental complexity scale for the evaluation of these molecules.  One of the main reasons that 5-body terms were not used in traditional MD simulations was the poor scaling of the number of interactions one would need to calculate.\n\nThe MD simulation mentioned in section 5.1 and Fig 4 are not described anywhere.  The following sentences suggest that there would be some explanations in the supplement, but I couldn't find them: \"Additionally, we perform MD simulations using trained QuinNets as force fields and plot the distribution of interatomic distances h(r) for these 7 molecules in Fig. 4. Further details regarding additional settings can be found in the Supplementary Materials.\" \n\nThese sentences in the supplement, page2, are confusing or wrong: \"Similarly, five-body@III interaction (Fig. S1 (c)) is a special case of six-body interaction when nodes i and k4 in Fig. S1 (d) superpose each other. Thus, the QuinNet model captures all five-body interactions and a portion of six-body interactions, making it a versatile and comprehensive tool for modeling complex molecular systems.\"  There is no six-body interaction if two of the bodies are the same, and there is no physically acceptable case where two different atoms could superpose each other.\n\nThe code is not provided, so it is not possible for me to assess the reproducibility of this method.  The diagram in Figure 3 seems reasonable at the very high level, but it lacks the definitions of most of the terms annotated in the figure, thus rendering it confusing.  (What is $Y_l$? is it the set of all spherical harmonics $Y_{lm}$ for a given angular momentum $l$? What is $n_j$? What is $s_j$?  $W$?...) Could the authors add the presentation of the QM9 quantities estimated in the recent publication for Allegro?  (https://www.nature.com/articles/s41467-023-36329-y Table 3)\n\nHow long and how stable were the actual MD simulations?  What were the exact codes/protocols used?\n\nWhat is the practical performance of the model during evaluation? No potential negative societal impacts from this work.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337653",
         "7.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "497",
         "1",
         "2",
         "0.764",
         "0.0333794423",
         "0.8763324022000001",
         "215",
         "43.7997",
         "11.2658",
         "14.4335",
         "13.7657",
         "11.55",
         "0.1199",
         "109",
         "0",
         "1",
         "0",
         "1",
         "neurips"
        ],
        [
         "37",
         "171",
         "Sajad-Ebrahimi",
         "Magdalena-Czlapka-Matyasik",
         "1",
         "1",
         "unfactual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "35",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I commend the authors to contribute to this body of literature regarding the socio-demographic and lifestyle factors associated with understanding fast food consumption in Cambodia adults. The paper brings quantified information about the factors influenced by understanding fast food consumption. The authors revealed that poor and fair knowledge, insufficient exercise levels, and not getting enough sleep were predictors of inadequate understanding of the impact of fast food on health. Such conclusions do not bring entirely new knowledge to the literature, on this matter. Across the whole world population, the problems related to fast food consumption have been discussed. Nevertheless, I consider the work to be original, well designed and contribute knowledge to this field of public health research. My suggestions concern: In the introduction, the authors indicate the system of fast-food restaurants; it would be more attractive to explain, how it was developed in Cambodia directly?  What would be very interesting is information concerning the real take away or fast food intake in those groups. It must or might be in direct relation to this matter?  My main concern about the validation of the \"Level of knowledge of fast food consumption\": Could the authors explain the procedure? How were the questions selected and validated?  I regret that the authors discussed the interesting results in such a concise way.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         null,
         "12 Feb 2021",
         null,
         null,
         null,
         null,
         null,
         "361",
         "0",
         "1",
         "0.7773",
         "0.2011784512",
         "0.89415133",
         "137",
         "35.27",
         "13.1",
         "15.13",
         "15.1",
         "14.5",
         "0.1507",
         "99",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "38",
         "171",
         "Sajad-Ebrahimi",
         "Wanshui-Yang",
         "1",
         "0",
         "unfactual",
         "negative",
         "impolite",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "40",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript investigated the level of understanding of fast-food consumption among adults in Cambodia. The authors found that unsatisfactory levels of knowledge around fast food consumption were significantly associated with not taking regular exercise and sleeping less than eight hours per night. The results are interesting, but I have several comments. The authors should introduce the recent development of fast-food sector in Cambodia in the introduction part.  Is there an analysis of fast-food intake among these participants?  Interestingly, the authors found that not taking regular exercise and sleeping less than eight hours per night were associated with unsatisfactory levels of knowledge around fast food consumption. However, they were not well explained in the discussion part. In other words, the discussion part is a little too concise.  In addition, the education levels were not associated with the knowledge of fast-food consumption in the present study. I would like authors to discuss it and, at least, mention its possible causes.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "02 Mar 2022",
         null,
         null,
         null,
         null,
         null,
         "303",
         "0",
         "1",
         "0.7774000000000001",
         "0.1265046296",
         "0.9193514585",
         "520",
         "28.03",
         "13.8",
         "13.98",
         "14.7",
         "14.5",
         "0.1953",
         "97",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "39",
         "187",
         "Emperatoor",
         "Reviewer-2CBB",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "4",
         "4",
         "4",
         "4",
         "4",
         "70",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "This paper introduce a novel unsupervised feature selection methods called GRSSLFS, which combine matrix factorization with self-representation subspace learning and apply graph regularization to preserve the geometric structure of the feature vectors. This method is proved to be effective in both theory and experiments. In this paper, the author introduce the problem of the redundant data in traditional self-representation, and then apply matrix factorization self-representation problem to achieve the goal to reduce the dimension of basis matrix. Here are some strengths of this article:\n\n1. This paper introduce a novel problem of redundant data in self-representation problems and then propose a method to solve this problem.\n\n2. Plenty of theoretical proof are given in the paper and appendix, the convergence analysis indeed increase the persuasiveness of the article.\n\n3. The proposed method was compared with a variety of comparison algorithms on multiple data sets, demonstrating the effectiveness of the method. However, there are still some weaknesses in this paper.\n\n1. In the end of Introduction section, the second and third contribution points is not sufficient, as these constraints of regularization are not proposed in this article. \n\n2. In the methodology section, some formula calculations are confusing and not very convincing. Such as the multiplication in formula (6) and the optimization target in the optimization goal (formula 7). These issues will be described in detail in subsequent questions 1 and 2.\n\n3. In the methodology section, the description of the algorithm is not complete enough. The specific process of selecting features according to the matrix U in Algorithm 1 has not been described in detail. 1. In the section of methodology, the equation (6) is confusing and not so clear. It seems impossible to subtract the matrix XUV of shape m*m from the matrix X with the shape m*n? \n\n2. As the feature matrix B is fixed by the VBE method proposed in section 3.3, it is unclear why the basis coefficient matrix G in equation (7) is a parameter to be optimized. Why the matrix G can not be determined by equation (4) directly and reduce the number of parameters.\n\n3. In section 3.1, subspace learning that introduces graph regularization seems to be existing methods. Should this part of the content be moved to related work?",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636201193",
         "6.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "376",
         "0",
         "8",
         "0.679",
         "-0.048046398000000004",
         "0.9640573859",
         "51",
         "40.0877",
         "11.9138",
         "14.3896",
         "13.5354",
         "11.9056",
         "0.0751",
         "99",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "40",
         "187",
         "Emperatoor",
         "Reviewer-yUvs",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "5",
         "3",
         "4",
         "3",
         "4",
         "75",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Authors of this paper propose graph regularized self-representation and sparse subspace learning (GRSSLFS) for unsupervised feature selection. The basis extension method is modified to select bases with highest variance score. These bases are used to build graph regularized self-representation learning and subspace learning. The graph regularized self-presentation learning and subspace learning are combined in terms of a set of selected bases from input space with the highest variance score. Experiments on various datasets demonstrate the advantage of the proposed method comparing with baselines. The ablation study also shows the necessity of each component. The subspace learning module is the key component, but its derivation from selected bases highly relies on the assumption that XU=B. This might not be hold if B is selected according to the proposed variance basis extension method. Moreover, the selection based on subspace learning module lacks of convincing explanation since G does not exactly represent X based on B as a fixed set of feature vectors. It is confusing to explain (4) as the self-representation problem if B is arbitrary basis matrix since they may not come from the input data matrix X.  Taking PCA for example, the columns of B are orthogonal, but they are not from the input feature space. Moreover, B defined as a square matrix of size m is inconsistent with the sleeted r bases in section 3.3.\n\nIn section 3.1, authors mentioned that two features have a similar structure in the feature space, and it is expected Bg_l and Bg_r have similar structure. What does the similar structure mean? How is the similarity measured? In other words, it is unclear how the matrix A is constructed. \n\nThe derivation in section 3.2 depends on the assumption that XU=B. As B is a set of feature vectors selected from input data, it is unclear whether the assumption still holds or not. Similarly for Theorem 3.1, it is trivial to have if the assumption holds. \n\nThe variance basis extension is to simply change the selection order of feature vectors in terms of variance score of feature vectors. It is possible that for each individual feature, the variance is high, but is it similar to say the largest amount of data dispersion? \n\nFor completeness, authors should describe the derivation process on how equations (9)-(11) are obtained. Since all three equations are fractional, is it possible that any of the denominators can be zero? How is it handled?\n\nIn Algorithm 1, the selected features are derived from U. However, U is not directly related to the input X instead to B and G, unless BG=X. However, B is selected feature vectors from input space. It is unclear why the assumption can hold. So why is the selection rule proper?\n\nThe computation complexity is quite high since it is quadratic to both the number of samples and the number of features comparing with most of baseline methods.\nThe application to the PneumoniaMNIST dataset is quite interesting. However, the way of presenting the outcomes can be improved significantly.  For example, what is the interested region? how many selected features are in the interested region? How do other compared methods perform? The validation is not quantified. How many radiologists are involved in the evaluation?  What is the performance measured? These plots shown in Fig. 2 delivers less useful information except that more red points are accumulated in the center when the number of selected features increases.",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636201025",
         "5.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "567",
         "0",
         "0",
         "0.7308",
         "0.0892117117",
         "0.9616214633000001",
         "51",
         "50.3623",
         "9.5106",
         "12.188",
         "12.0985",
         "9.3859",
         "0.0364",
         "93",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "41",
         "187",
         "Emperatoor",
         "Reviewer-PMap",
         "1",
         "3",
         "partially factual",
         "negative",
         "polite",
         "moderate",
         "2",
         "2",
         "2",
         "3",
         "3",
         "4",
         "30",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Considering there exists a major gap in the mathematical principles that underlie the self-representation based unsupervised feature selection approaches and their capacity to represent the feature space, this paper proposes Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), for the unsupervised feature selection, which expresses the self-representation problem based on the concept of “a basis of feature space” to represent the original feature space as a low-dimensional space made of linearly independent features. Experiments on widely-used datasets are conducted to validate the efficacy of the proposed method. 1. The computational complexity of the proposed GRSSLFS method is low, which is efficient for large-scale and high-dimensional data;\n2. The results of the proposed method seem better than other ones. 1. Most of the compared methods are out-of-date, only one method used for comparison was publised in 2023, other methods are before 2020;\n2. The motivation of the proposed method is not clear. In Eq.(8), the first three terms have been well explained, but the final regularization term has not been explained. See weakness.",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636200941",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "2.0",
         "172",
         "0",
         "4",
         "0.6699",
         "0.1067307692",
         "0.9783408642",
         "51",
         "26.959",
         "15.6033",
         "17.9681",
         "15.9032",
         "18.2121",
         "0.0945",
         "85",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "42",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-NRqK",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "5",
         "5",
         "5",
         "4",
         "5",
         "94",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes an algorithm for learning MDP state abstractions that preserve information needed for planning (namely, the values of states). A major differentiator from symbolic approaches is the idea that these state abstractions should be continuous rather than discrete. The key assumption is that you are given a set of options and a dataset obtained by rolling them out. Experiments are conducted in a few simple domains: pinball and antmaze, and demonstrate that the learned abstractions are sensible. The paper addresses an important topic (abstraction learning) and I appreciate the theoretically motivated algorithms. This line of work is of great interest to many attendees of ICLR. I also appreciate that the authors were clear about wanting continuous representations right off-the-bat. The math is also correct as far as I was able to tell, though I didn't check the proofs in the appendix in careful detail. Unfortunately, I recommend rejection for this paper due to 4 major reasons: 1) unconvincing experiments, 2) missing key citations to related work, 3) issues in technical details, and 4) unclear motivation.\n\n1) unconvincing experiments\n\nThe experiments in this paper are very basic and only serve as a simple proof-of-concept that the learned abstractions are somewhat useful. To really scale up the experiments to the level expected for a conference paper, I would expect to see evidence that the learned abstractions are useful in more hierarchical domains (e.g., classic domains from the options literature like keys and doors). In such domains, we could test whether the value-preserving property holds empirically, by comparing the values from planning under the abstract model to the (ground truth) values from planning under the true model.\n\nAdditionally, I would like to see comparisons to many more RL algorithms, especially hierarchical ones like HIRO (https://arxiv.org/abs/1805.08296), HVF (https://arxiv.org/abs/1909.05829), and Director (https://arxiv.org/abs/2206.04114). This is because at the end of the day, the authors are proposing to learn a state encoder $\\phi$, and despite all the theory that has gone into their algorithm, the question that must be answered is whether this $\\phi$ outperforms the encoders learned by all these other SOTA hierarchical RL algorithms.\n\n2) missing key citations to related work\n\nThe authors are missing several key citations, the most important of which is the line of work by David Abel, such as \"Near optimal behavior via approximate state abstraction\" (https://proceedings.mlr.press/v48/abel16.html) and \"Value preserving state-action abstractions\" (https://proceedings.mlr.press/v108/abel20a/abel20a.pdf). Those papers have very similar theory to what appears in this one, and so the novelty of the proposed approach is unclear. There are also less-famous but still important-to-cite papers from other authors, like \"Abstract value iteration for hierarchical reinforcement learning\" (https://proceedings.mlr.press/v130/jothimurugan21a/jothimurugan21a.pdf) and \"Deciding what to model: Value-equivalent sampling for reinforcement learning\" (https://proceedings.neurips.cc/paper_files/paper/2022/hash/3b18d368150474ac6fc9bb665d3eb3da-Abstract-Conference.html). It is important for the authors to contextualize the contributions of this paper against all these related works.\n\n3) issues in technical details\n\nThe authors say in Section 3.2 that when B = \\bar{B}, \"then simulating a trajectory in the abstract model is the same as in the ground model\". But I don't think this is true, because we need the rewards to match between the two trajectories too, and $B_t$ says nothing about rewards, only dynamics. The authors go on to say: \"Therefore, planning in the abstract model is accurate, in the sense, that the value of an abstract state z computed in the abstract model is the same as the one would get from trajectories from the ground MDP for the abstraction operator G.\" Again, I think this is wrong because it ignores the abstract reward function, which could be arbitrarily different from the ground one. In fact, in the proof of corollary 3.8, the authors assume $E_{s \\sim G(\\cdot \\mid z)}\\[R(s, o)\\] = \\bar{R}(z, o)$, and it's only _under this assumption_ that the claims hold. But combining this assumption on reward function with Definition 3.6 ends us back up at the bisimulation conditions, and then it's not clear what the contributions of this paper are.\n \nAs a separate point, the second term in the mutual information expression of Section 4.2, $MI(S'; Z, A)$, seems very extreme! It is saying that you have to be able to predict the entire ground next state from the current abstract state and action. Doesn't this means the abstraction can't lose any information? This seems like an important technical limitation of the approach.\n\n4) unclear motivation\n\nThe authors often state that a discrete abstract state space is bad, when pointing to work on symbolic abstraction learning (e.g., PDDL). But it's not clear why this is really bad. The authors say discrete abstract states are \"not applicable when planning with the available high-level actions requires a continuous state representation\", but this doesn't make sense to me, as the options have to act in the ground environment states, not in the abstract state space, and so the options could be defined with respect to either a discrete or a continuous abstract state space. Furthermore, it can be much easier to plan in a discrete abstraction (e.g., using powerful symbolic planners).\n\nI believe a fruitful research direction would be to compare the abstractions learned by a symbolic approach against the abstractions learned by a continuous approach (like the authors'). Questions:\n* Not much is said about the dataset $\\mathcal{D}$, but intuitively, it has to be \"good\" in order for the learned state abstraction to be reasonable. In particular, the agent must see all the options being executed in a variety of settings, and obtain good coverage over the state-action space. Are there any concrete statements we can make about what properties we need this dataset to have?\n* \"we must build a model of its effect\" Do you mean to say \"of the effect of each option\"?\n* \"with mean value equal to that by planning with the original MDP\" What is the mean over?\n* Why did we switch from using O (denoting the option set) everywhere to using A throughout Section 4? Shouldn't we continue to use O, unless I am misunderstanding something?\n* Section 4.3: Why should there be any cost/reward associated with executing skills? Shouldn't a sparse reward for reaching the goal be enough?\n* Eq 2: What are the \"I\" random variables inside the mutual information expression referring to?\n\nMinor edits:\n* \"make the same decision\" To clarify, we just need that the policy maps all states in z to the same action distribution. A stochastic policy isn't really committing to a \"decision\" about what action to take.\n* \"Abstractions alleviate this tension: action abstractions enable agents to plan at larger temporal scales and state abstractions reduce the complexity of learning and planning\" I would say that both of them do both of these. Action abstractions certainly reduce the complexity of planning, which is typically exponential in the branching factor.\n* \"learns a further abstraction\" --> \"learn a further abstraction\"\n* \"otherwise it is referred as learning\" I would say \"policy learning\" to distinguish from other things you might learn\n* \"when it is the given position\" --> \"when it is in the given position\"\n* \"referred as learning\" --> \"referred to as learning\"\n* \"results a bounded value loss\" --> \"results in a bounded value loss\"\n* In definition 3.5, the authors use $s_o$ in a few places where they mean $s_0$.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1699636621573",
         "3.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "1210",
         "7",
         "0",
         "0.7753",
         "0.0567315252",
         "0.9024221301",
         "49",
         "44.7468",
         "12.0287",
         "14.3535",
         "13.6208",
         "14.151",
         "0.6075",
         "100",
         "2",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "43",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-36E8",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "3",
         "3",
         "4",
         "4",
         "80",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper presents an approach for learning dynamics preventing abstractions for sensorimotor observation space. Given a set of high-level skills and the learned dynamics preserving abstractions, the paper claims to develop an approach for planning for a solution. \n\nThe approach is evaluated in two test domains where the paper shows the visualization of the learned abstractions. - For the most part of the paper, it is extremely well written. Given the wide use of embodied AI systems and robots, an approach that generates plannable abstractions for high-dimensional sensor input is extremely important. \n\n- The paper nicely motivates the problem. While the paper in general is nicely written, it has a few limitations: \n\n- The paper advocates learning a continuous abstract  representation instead of a symbolic abstractions. However, it does not provide any reasons to that. Why are continuous abstractions more desirable than symbolic abstractions? \n\n- Sec 4.1 is unclear. The notation for MI is a bit unclear. It needs to be made more clear. Sec 4.1 requires a re-writing including more explanation for the equation. I have two important questions: \n\n- How is the dynamics preserving abstraction defined in Def. 3.6 different from the Markovian abstractions defined in \\[Srivastava et al. 2016\\]? \n\n- Can you discuss the differences between the presented approach and \\[Allen et al. 2021\\] \n\nReference \n\nAllen, Cameron, et al. \"Learning markov state abstractions for deep reinforcement learning.\" Advances in Neural Information Processing Systems 34 (2021): 8229-8241.\n\nSrivastava, Siddharth, Stuart Russell, and Alessandro Pinto. \"Metaphysics of planning domain descriptions.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1699636621454",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "264",
         "1",
         "6",
         "0.7512000000000001",
         "0.1625",
         "0.8653070927000001",
         "49",
         "41.1434",
         "10.434",
         "14.1483",
         "13.0239",
         "10.9274",
         "0.2429",
         "100",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "44",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-dCJp",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "83",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper introduces a method for enabling general-purpose agents to efficiently handle complex tasks by constructing abstract models based on temporally-extended actions. These models facilitate more efficient planning and learning and are characterized using principled conditions. The approach provides empirical evidence of improved sample efficiency in goal-based navigation tasks and offers theoretical support for information maximization strategies in abstract state representation learning.\nThe authors claim that they introduced a method for creating abstract world models that empower agents to plan effectively for goal-oriented tasks. The key idea is to allow agents to construct reusable abstract models for planning with specific skills. This is achieved by characterizing the state abstraction that ensures planning without any loss in simulation, meaning that planning with the learned abstract model can generate policies for the real world. The paper also provides theoretical support for the use of information maximization as a reliable strategy for learning abstract state representations. - Good overview of the related work.\n- Good description of motivations and intuitions. \n- proper choice of environment settings. Major:\n- Some measures are used without definition, \n- It seems that there exists a lot of inaccuracies and impreciseness in the theories and definitions. See all questions!\n\nminor:\n- typos: \nlast paragraph of the introduction \"the *agents* needs\", definition 3.5 \"$s_{o}$\" must be \"$s_0$\"\n- writing: \nDefine the abbreviations before using them, e.g. \"PDDL\", \"VAE\"\n\nThere is a chance that I have not fully understood what this paper is trying to present. 1- What is $P(s'|s,o)$ used in the paragraph right after definition 3.1?\n\n2- An option $o$ is defined, and then you mention $T(s'|s,o)$ to define the transition probability of taking option $o$ in $s$? $T$ earlier was defined on action space $A$. How is it applied on options without showing the relationship of $I_o$ and $\\beta_o$ with $s$ and $s'$ under option policy $\\pi_o$?\n\n3-the paper has defined \"$\\bar {\\gamma} = \\gamma ^{\\tau (s,o)}$ is the abstract discount factor, $\\tau: Z \\times O \\rightarrow \\[0,\\infty)$, which consists of contradictory phrases. How is ${\\tau (s,o)}$ but defined as a function of abstract variables $Z$ instead of $S$? Not clear what $\\tau$ is. If based on definition 3.1, it is the option's execution time starting from $s$ taking option $o$, it is not clear how in definition 3.2 it becomes a map from $Z$ and $O$ to a non-negative real.\n\n4- What does definition 3.4 mean? $ \\Pi = {\\pi \\in \\Pi : \\pi(·|s) = \\pi (·|z) \\forall s \\in z}$ says the probability of taking actions/options in $s$ should be equivalent to the probability of taking actions/options in abstract states. Transitions of taking actions in states might take you to another state $s'$ inside the similar abstract state $z$. How can the policies used for both abstract states and states be equivalent? Unless you are just discretizing the continuous state spaces based on the optimal policies that are already given. Lots of interchangeable usage of symbols here. Not precise and is hard to follow.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1700688515580",
         "3.0",
         "4.0",
         "2.0",
         "3.0",
         "2.0",
         "499",
         "0",
         "1",
         "0.7308",
         "0.0796438834",
         "0.93872118",
         "61",
         "45.6397",
         "10.6743",
         "12.7405",
         "12.3848",
         "11.5416",
         "0.1463",
         "105",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "45",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-gKE9",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "none",
         "5",
         "4",
         "4",
         "4",
         "4",
         "5",
         "89",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes a grounded abstract model formulation with a dynamic preserving abstraction. This abstract state representation (and model) guarantees not only accurate future predictions but also the bounded values in the abstracted rollouts. This paper then provides its implementation using contrastive learning to maximize mutual information between the future state, and the current abstract state and option. The results show that training DDQN in imagination using the abstract model improves the sample efficiency. * The paper proposes a solid foundation of the abstract model that preserves dynamics and values.\n\n* The paper is well written.\n\n* The visualization in Figure 3 clearly shows that the abstract state representations focus on important features in the original observation space. * The main focus of the paper is to show the efficiency of planning and learning when using the proposed abstract MDP. The experiments in the paper are a bit simple to showcase the benefits of the abstract model for planning. It would be stronger if the experiment was done in more complex environments with much longer-horizon tasks, such as AntMaze experiments (Hafner 2022) or robotic manipulation tasks \\[a\\].\n\n* Similarly, the comparisons in Figure 5 are essentially between model-free RL (ground) and model-based RL (abstract), which does not seem fair. It might be fair to compare the proposed method with other model-based RL approaches, such as Dreamer and TD-MPC.\n\n* Exhaustive comparisons to the alternatives to the dynamics preserving abstraction would be interesting, such as bisimulation.\n\n* Some highly relevant works on temporally-extended models \\[a,b\\] are missing in the paper. Proper comparisons to these approaches are necessary.\n\n\\[a\\] Shi et al. Skill-based Model-based Reinforcement Learning. CoRL 2022\n\n\\[b\\] Zhang et al. Leveraging Jumpy Models for Planning and Fast Learning in Robotic Domains. 2023 Please address the weaknesses mentioned above.\n\n\n### Minor questions and suggestions\n\n* Figure 1 may want to explain why abstract state representations and options are helpful for planning and learning. However, Figure 1 does not seem to help understand the paper. To understand this figure, we first need to know about options and abstract state representations, and how they simplify planning.\n\n* In Section 4.2, it is unclear whether $\\mathcal{L}^T_{\\theta, \\phi}$ is used to update $f_\\phi$ or not.\n\n* For multi-goal experiments in the paper, using the same amount of environment steps for the abstract planning and the ground baseline would make it easier to understand how better or worse a method is.\n\n* The appendix could be included in the main paper for easier navigation.\n\n* What is the difference between Figure 7 and 8?\n\n* Training the abstract planning method longer in Figure 7 and 8 would be helpful to see how it learns. Using different x-scales for two methods is okay but it would be better to have the same scale.\n\n* Many minor typos in the paper.\n\n\n---\n\nThank you for author responses. I would love to see comparisons to Dreamer-like baselines, but couldn't find the results by the end of the rebuttal period. Thus, I keep my rating, borderline reject.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1701585748243",
         "5.0",
         "3.0",
         "2.0",
         "3.0",
         "3.0",
         "507",
         "0",
         "3",
         "0.7684000000000001",
         "0.1385185185",
         "0.9183520675",
         "71",
         "48.6501",
         "10.0612",
         "11.805",
         "12.0009",
         "10.6133",
         "0.8246",
         "107",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "46",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-xxEb",
         "2",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "50",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper introduces a novel model, PatchSynth, in the Patch-Text Pre-training (PTP) domain, aiming to improve software patch representation and description generation. Through a blend of patch understanding and generation, PatchSynth\t addresses the limitations of prior models. Empirical evaluations reveal its superior performance in patch description generation, with an ablation study further underscoring the importance of generating task training. Novelty and Importance: The work is first to propose a unimodel for patch-text understanding and related tasks. And the topic is very important in this domain.\n\n\tMelds patch understanding and generation, addressing prior models' specialization limitations.\n\n\tThe work provides a good representation and good results Unclear adaptability across diverse programming languages or coding standards. What are the considerations for deploying PatchSynth in real-world software development environments, and what infrastructure would be required for efficient and secure operation?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319846",
         "8.0",
         "5.0",
         "4.0",
         "3.0",
         "4.0",
         "136",
         "0",
         "0",
         "0.7967000000000001",
         "0.30636363640000003",
         "0.944865346",
         "50",
         "11.6712",
         "15.8547",
         "19.1529",
         "16.3736",
         "17.8235",
         "0.0364",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "47",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-4kdr",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "65",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper discusses a new model, PatchSynth, in the domain of Patch-Text Pre-training (PTP) which aids in accurate patch representation for software evolution tasks like bug fixing and feature enhancement. PatchSynth is designed to balance patch understanding and generation, overcoming limitations of previous models. It outperforms existing models in patch description generation, as shown in experiments using standard evaluation metrics. An ablation study further reveals the importance of generating task training in improving PatchSynth performance. Novelty:\nThe novelty of PatchSynth lies in its harmonious synthesis of patch understanding and generation, coupled with an advanced synthetic description generator. This innovative approach addresses the historical challenges of accurate patch representation and description generation, marking a significant stride in the PTP paradigm.\nImportance:\nThe topic is of paramount importance as it addresses a critical need in software engineering for accurate patch representation and description, which are pivotal for collaborative development, systematic documentation, and rapid code review processes. By advancing the PTP paradigm, PatchSynth not only contributes to the academic discourse but also holds promise for practical applications in software development workflows.\nThe work achieves promising results. The paper doesn't elucidate how PatchSynth adapts to varying programming languages or codebases with differing coding standards and structures. This lack of demonstrated adaptability could limit its applicability across diverse software projects, potentially requiring additional tuning or re-training to maintain accuracy and effectiveness in different environments. 1. Given the advancements in PatchSynth for patch-text understanding and generation, how well does the model perform in a transfer learning scenario? Can PatchSynth be fine-tuned or adapted effectively to related tasks in software engineering or different programming languages?\n2. Are there considerations or plans for deploying PatchSynth in real-world software development environments? How would the integration look like, and what kind of support or infrastructure would be required to ensure the model operates efficiently and securely in a production setting?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319768",
         "10.0",
         "5.0",
         "4.0",
         "4.0",
         "4.0",
         "310",
         "0",
         "2",
         "0.8356",
         "0.18839531680000002",
         "0.9401642680000001",
         "50",
         "9.2899",
         "17.0977",
         "21.428",
         "18.1715",
         "19.1841",
         "0.068",
         "90",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "48",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-H6rR",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "2",
         "80",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "This paper tackles the problem of code patch representation learning -- how to represent edits on code to support downstream tasks like commit message generation, patch correctness assessment, etc. \n\nThis paper proposes a pretraining framework, with triplet losses on text-code contrastive loss, text-code matching loss and text generation loss based on code patch. The pretraining data includes 90K pairs of code change and synthesized commit messages. \n\nOn downstream task of commit message generation upon FIRA\\[1\\] dataset, PatchSynth showed performance gains over public & self-ablation baselines.\n\n\\[1\\] Jinhao Dong, Yiling Lou, Qihao Zhu, Zeyu Sun, Zhilin Li, Wenjie Zhang, and Dan Hao. Fira: Fine-grained graph-based code change representation for automated commit message generation. 2022. 1. Unlike from previous approaches(CCRep\\[1\\], Cache\\[2\\]) where code change is encoded with two streams (code-before-change, code-after-change), this work encodes code change(patch) with a standard transformer on a single patch file (like git commit diff). This is inline with the general trend in LLMs community that ultimately LLMs should be able to understand and capture internal structure without explicitly modelling it.\n2. This paper applies representation pretraining with triplet losses -- which is quite known in multimodal pretraining domain (BLIP\\[3\\], BLIP-2\\[4\\], etc) -- to code patch representation. It empirically showed that such pretraining is helpful for downstream task of commit message generation.\n\n\n\\[1\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[2\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022.\n\n\\[3\\] Junnan Li, Dongxu Li, Caiming Xiong, & Steven C. H. Hoi (2022). BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. In ICML (pp. 12888–12900). PMLR.\n\n\\[4\\] Junnan Li, Dongxu Li, Silvio Savarese, & Steven C. H. Hoi (2023). BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models. In ICML (pp. 19730–19742). PMLR. I have multiple major concerns on the paper based on its current form. The most concerning issues are:\n\n1. The paper claims \"The core part of PATCHSYNTH lies a state-of-the-art synthetic description generator\" in multiple places (3rd paragraph of Introduction, 2nd contribution in last part of Introduction, Section 2.3). However, there is no details on this synthetic description generator. The only mention is Section 4.4 with just one line \"Capitalizing on benchmarks from seminal works\\[1,2\\], our dataset, primarily focused on Java samples includes 90,661 patches with their **attendant** descriptions\"\n\n    i. Are these **attendant** descriptions generated by the author but simply taken from \\[1,2\\]? If the latter, then claiming such synthetic description generation as a key feature in this paper is highly problematic.\n\n2. The task of representation learning of code patch, defaultly assigns 1 vector for a code patch (w/ 1 or more edits), which is the case for all previous works including CC2Vec\\[3\\], CCRep\\[4\\], Cache\\[5\\]. However, PATCHSYNTH seems to encode the code patch to a sequence of vectors (Figure 1). \n\n    i. Such change needs explicit explanation and justification which authors have failed to deliver.\n\n3. Missing LLM baselines: with code patch being encoded with a sequence of vectors, the authors should compare with code-aware LLMs like Code-llama, or WizardCoder, as they also encode code patch to a sequence of vectors. \n    \n    i. As the recent code-aware LLMs have shown great abilities in general instruction following in coding-related tasks, a very timely baseline would be applying code-aware LLMs to the downstream task of commit message generation, with few-shot prompting or finetuning. \n\n    ii. A comparison of PATCHSYNTH vs code-aware LLMs would very helpful for the community to understand the edge and relevance of the proposed method in LLM era, which the authors have failed to deliver.\n\n4. Only 1 downstream task evaluated: The authors claimed that the method is designed both for generative and discriminative tasks. However, the empirical experiments were only conducted on commit message generation. As the encoding changed from one vector to a sequence of vectors, it's important to show how can such encoding can be adapted to tackle retrieval or classification tasks. Also, to claim it as a pretrain model, the authors need to evaluate on multiple downstream datasets.\n\n5. Fairness in comparison: \n\n    i. Is PATCHSYNTH firstly pretrained on 90K and then finetuned on 75K data of FIRA? If so, it's not so fair to compare PATCHSYNTH with CCRep and FIRA methods, as they are not trained on 90K pretraining data. For example, Is it possible to also pretrain CCRep with 90K data?\n\n    ii. As mentioned in point 2, CCRep has a more compact encoding of 1 vector while PATCHSYNTH encodes to a sequence of vectors. It is thus not fair to compare without explicitly mentioning such differences.\n\n6. Concerns on Pretraining:\n\n    i. details of creating negative pairs: one common technique in contrastive training is hard-negative-mining. However, the authors didn't disclose how they create negative pairs\n\n    ii. For vision-language representation learning, a large batch size (>= 512) and a large pool to select negative examples have been shown to be necessary. This paper mentions the batch size of 32, which seems pretty small. I will need more verification on ablation of 1) batch size, 2) negative example selection and 3) pretraining metrics to be convinced that such setting is adequate for code-text representation pretraining. \n\n7. Writing & formatting issues\n\n    i. On page 8, the chart of Figure 2 is partially blocked by its top legend\n\n    ii. On page 8, the paragraph for \\[Performance cross different patch attention\\] is repetitive: it repeats twice in introducing the numerical performance. Besides, I don't think it's a good idea to verbosely list down all numbers when they are clearly seen in Figure 2.\n\n    iii. In Section 2.1, there's no mention on recent code aware LLMs like Code-LLaMA. \n\n    iv. In Section 2.3, there's no citation to any work. Besides, CCRep\\[4\\] doesn't have the gap mentioned in Section 2.3 as it can both do discriminative and generative tasks and it doesn't reply on AST information. So an explicit comparison to CCRep in Related Work should be present.\n\n\\[1\\] Robert Dyer, Hoan Anh Nguyen, Hridesh Rajan, and Tien N Nguyen. Boa: A language and infras\u0002tructure for analyzing ultra-large-scale software repositories. In 2013 35th International Confer\u0002ence on Software Engineering (ICSE), pp. 422–431. IEEE, 2013.\n\n\\[2\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[3\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[4\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[5\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022. 1. Why did you use CodeBERT to initiate both text encoder and decoder? For example, did you consider encoder-decoder model like Code-T5?\n\n2. In Experiment Setup, you mentioned \"Model dimensions are meticulously calibrated\". May I know how are the hyper-parameters searched? Are you using the downstream task performance or some pretraining metrics?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319680",
         "3.0",
         "4.0",
         "1.0",
         "1.0",
         "2.0",
         "1254",
         "27",
         "37",
         "0.7999",
         "0.069050849",
         "0.8986387253",
         "50",
         "47.6556",
         "10.3417",
         "13.0995",
         "12.7417",
         "12.905",
         "0.1651",
         "86",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "49",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-639w",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "90",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "Programs are frequently modified in commits, with the changes represented as program patches and often described with natural language text. This work proposes to finetune a pair of BERT encoders on the combination of such patches and their descriptions, introducing a three-fold loss. The resulting model is evaluated on a patch description generation task, where it outperforms recent baselines. This work focuses on an established and reasonably important task in software engineering, patch representation and description (or, commit message) generation. It uses a fairly conventional encoder-decoder architecture with additional loss terms for this. Its main contribution lies in the combination of these components, which evidently yields improved performance compared to prior work.\n\nThe results show improvements in the order of 5-10% (relative) compared to baselines, which, while still yielding relative low BLEU scores (~21%), might benefit the commit message generation work and tools with a stronger baseline. The methodology, including the architecture and loss terms, was relatively easy to follow. The technical contribution is very limited. The work connects two pretrained encoders (one for text and one for code) with cross-attention. Its main aim is to generate patch descriptions from the patch. It introduces two additional (but not novel) loss terms that provide a form of embedding alignment, both based on a contrastive loss. One of these appears to provide no significant benefit (DPC, Tab. 2). The setup is evaluated on a fairly small batch of mainly Java samples that appear to consist of a single patch with their associated commit message. These type of Github-scraped datasets tend to suffer from many low-quality descriptions that make it hard to meaningfully train and evaluate models and the set used in this work is no exception: the highest reported BLEU score is just 21.82%. The results corresponding to Fig. 2 show that precision/recall is about even across use-cases. As such, the work offers a useful, fairly off-the-shelf baseline for further experiments in this domain, but does not provide significant new insights or theoretical contributions.\n\nThis aside, the writing suffers from a range of problems. A number of claims about prior work are poorly motivated and several methodological details are poorly described. I list these below. More generally, the paper was quite hard to read. Many sentences include an unusual adjective or phrase that often feels overly subjective and out of place. Some examples from the first few pages: \"a profusion of research endeavors\", \"pronounced specification\", \"exhibit prowess\", \"offering an all-encompassing understanding\", \"not merely theoretical postulates\", \"Our approach transcends conventional methods\", \"avant-garde graph intention embedding\". It would greatly benefit the work to normalize the language, both reducing the use of highly subjective statements and replacing rare words with more commonly used synonyms.\n\nA number of issues:\n\n- P1: \"will lead to the emergence of..\" seems wrong. As noted shortly afterwards, Patch-Text (pre)training is already the subject of multiple studies. If the intent is to forecast that this particular paper will produce a new paradigm, I would strongly recommend removing this sentence.\n- P2: \"seldom both\" -- does this imply that it is sometimes studied jointly? If so, please provide citations.\n- P2: \"fraught with inconsistencies, particularly those integrated with Abstract Syntax Trees\" -- it is not at all clear what this means. Why are ASTs more likely to be/lead to inconsistencies? The mapping of code to ASTs is unambiguous.\n- Sec 3.1: the reference to a \"previous section\" seems wrong; these terms were not introduced before this point.\n- Sec 4.1: wrong notation in \"e - 4\". As written, this subtracts 4 from e.\n- Sec 4.1: how exactly where the dimensions \"meticulously calibrated\"? The two hyper-parameters mentioned next are standard. Were hyper-parameter sweeps conducted? Please share the results of those if so.\n- Sec 4.4: does this mean you combined the dataset of two prior papers, or used the same as theirs? If so, \"our dataset\" is wrong. If not, please elaborate on the process by which the dataset was constructed.\n- Sec. 5.1: the text under \"Outcomes\" says that FIRA outperforms PatchSynth on ROUGE-L (Tab. 1), which it does not.\n- P8: the example here seems wrong on several counts. The patch should delete the previous if-statement. The newly added line is missing \"&&\". The word \"SINGLE\" appears a few times in places where it doesn't seem to be grammatically correct for it to do so. Perhaps this is due to the odd line wrapping and indentation?\n- Fig. 2: the count values should not be connected with a line; this data is not sequentially related. Please discuss whether this work offers a concrete novel technical contribution or whether it should be mainly read as setting a new baseline for patch description based on existing methods. Consider the limitations noted above: one of the loss terms does not seem to have much impact, none of the loss terms are not novel, nor is tuning a cross-attention layer between pretrained models.\n\nPlease clarify some of the methodogical questions raised above, including where the dataset came from, whether any further processing was done, and if/how the hyper-parameters were tuned.",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319601",
         "3.0",
         "5.0",
         "2.0",
         "1.0",
         "1.0",
         "846",
         "0",
         "5",
         "0.8399000000000001",
         "0.027047884100000003",
         "0.9130145311000001",
         "50",
         "49.8575",
         "10.1328",
         "13.1341",
         "12.5867",
         "11.5162",
         "0.5586",
         "95",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ]
       ],
       "shape": {
        "columns": 45,
        "rows": 505
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>assessor</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>Comprehensiveness</th>\n",
       "      <th>Usage_of_Technical_Terms</th>\n",
       "      <th>Factuality</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Politeness</th>\n",
       "      <th>Vagueness</th>\n",
       "      <th>Objectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-7mFW</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>16.1503</td>\n",
       "      <td>14.3268</td>\n",
       "      <td>14.1695</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-FAWm</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4394</td>\n",
       "      <td>13.7425</td>\n",
       "      <td>12.4851</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-kjkr</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4014</td>\n",
       "      <td>13.2462</td>\n",
       "      <td>12.1773</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Enrico-Daga</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>17.4100</td>\n",
       "      <td>16.6000</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Julia-Bosque</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>15.2000</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-s437</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16.7770</td>\n",
       "      <td>15.2830</td>\n",
       "      <td>14.4355</td>\n",
       "      <td>0.1585</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-mMGf</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>negative</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2389</td>\n",
       "      <td>13.9012</td>\n",
       "      <td>12.9422</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-AtQ2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5281</td>\n",
       "      <td>13.2950</td>\n",
       "      <td>12.5392</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-v6cq</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13.6019</td>\n",
       "      <td>12.7451</td>\n",
       "      <td>10.7297</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>5</td>\n",
       "      <td>Sonny</td>\n",
       "      <td>Alison-Kutywayo</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3900</td>\n",
       "      <td>15.2000</td>\n",
       "      <td>15.1000</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id         assessor         reviewer  Comprehensiveness  \\\n",
       "0         166   Sajad-Ebrahimi    Reviewer-7mFW                  2   \n",
       "1         166   Sajad-Ebrahimi    Reviewer-FAWm                  4   \n",
       "2         166   Sajad-Ebrahimi    Reviewer-kjkr                  3   \n",
       "3         100            Seyed      Enrico-Daga                  3   \n",
       "4         100            Seyed     Julia-Bosque                  5   \n",
       "..        ...              ...              ...                ...   \n",
       "500        75  Ali-Ghorbanpour    Reviewer-s437                  3   \n",
       "501        75  Ali-Ghorbanpour    Reviewer-mMGf                  4   \n",
       "502        75  Ali-Ghorbanpour    Reviewer-AtQ2                  5   \n",
       "503        75  Ali-Ghorbanpour    Reviewer-v6cq                  2   \n",
       "504         5            Sonny  Alison-Kutywayo                  3   \n",
       "\n",
       "     Usage_of_Technical_Terms         Factuality Sentiment_Polarity  \\\n",
       "0                           4            factual            neutral   \n",
       "1                           4            factual            neutral   \n",
       "2                           4            factual            neutral   \n",
       "3                           2            factual           positive   \n",
       "4                           4            factual           positive   \n",
       "..                        ...                ...                ...   \n",
       "500                         3  partially factual            neutral   \n",
       "501                         4            factual           negative   \n",
       "502                         4            factual           positive   \n",
       "503                         3  partially factual           positive   \n",
       "504                         4            factual            neutral   \n",
       "\n",
       "    Politeness Vagueness  Objectivity  ...  gunning_fog  smog_index  \\\n",
       "0       polite      high            4  ...      16.1503     14.3268   \n",
       "1       polite      none            4  ...      15.4394     13.7425   \n",
       "2       polite       low            4  ...      14.4014     13.2462   \n",
       "3       polite      none            4  ...      17.4100     16.6000   \n",
       "4       polite       low            4  ...      14.3000     15.2000   \n",
       "..         ...       ...          ...  ...          ...         ...   \n",
       "500     polite       low            2  ...      16.7770     15.2830   \n",
       "501     polite      none            4  ...      14.2389     13.9012   \n",
       "502     polite      none            4  ...      13.5281     13.2950   \n",
       "503     polite  moderate            3  ...      13.6019     12.7451   \n",
       "504     polite  moderate            4  ...      15.3900     15.2000   \n",
       "\n",
       "     automated_readability_index  politeness_score  hedge_C  hedge_D hedge_E  \\\n",
       "0                        14.1695            0.0999       88        0       0   \n",
       "1                        12.4851            0.1565       89        0       0   \n",
       "2                        12.1773            0.1507       93        0       0   \n",
       "3                        15.5000            0.1149      100        0       0   \n",
       "4                        14.0000            0.2025      108        0       0   \n",
       "..                           ...               ...      ...      ...     ...   \n",
       "500                      14.4355            0.1585       82        0       1   \n",
       "501                      12.9422            0.1100       88        0       1   \n",
       "502                      12.5392            0.9014       83        0       0   \n",
       "503                      10.7297            0.1108       97        0       0   \n",
       "504                      15.1000            0.9417      102        0       0   \n",
       "\n",
       "    hedge_I hedge_N        venue  \n",
       "0         0       0         iclr  \n",
       "1         0       0         iclr  \n",
       "2         0       0         iclr  \n",
       "3         0       2  semanticweb  \n",
       "4         0       0  semanticweb  \n",
       "..      ...     ...          ...  \n",
       "500       0       0      neurips  \n",
       "501       0       0      neurips  \n",
       "502       0       0      neurips  \n",
       "503       0       0      neurips  \n",
       "504       0       0        f1000  \n",
       "\n",
       "[505 rows x 45 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human['reviewer'] = df_human['reviewer'].str.replace('_', '-', regex=False)\n",
    "df_human['reviewer'] = df_human['reviewer'].str.replace(' ', '-', regex=False)\n",
    "df_reviews['reviewer'] = df_reviews['reviewer'].str.replace('_', '-', regex=False)\n",
    "df_reviews['reviewer'] = df_reviews['reviewer'].str.replace(' ', '-', regex=False)\n",
    "\n",
    "\n",
    "# merge two df_reviews on df_human based on paper_id and reviewer\n",
    "df_human['paper_id'] = df_human['paper_id'].astype(int)\n",
    "df_reviews['paper_id'] = df_reviews['paper_id'].astype(int)\n",
    "\n",
    "# transform paper_id column in all dfs to int\n",
    "df_human['reviewer'] = df_human['reviewer'].astype(str)\n",
    "df_reviews['reviewer'] = df_reviews['reviewer'].astype(str)\n",
    "\n",
    "df_human_vs_metric = (\n",
    "    df_human\n",
    "    .merge(df_reviews, on=['paper_id', 'reviewer'], how='inner')\n",
    ")\n",
    "\n",
    "# filter the df_human_vs_metric up to first 16 columns\n",
    "# df_human_vs_metric = df_human_vs_metric.iloc[:, :16]\n",
    "df_human_vs_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "assessor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_soundness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_presentation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_contribution",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "030e70b1-5779-4251-bbb7-84ca7038066b",
       "rows": [
        [
         "0",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-7mFW",
         "2",
         "4",
         "factual",
         "neutral",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "67",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This work focuses on the Q-function value overestimation issue. Observing that the overestimation issue will latter becomes underestimation during the learning process. Thus motivated, this work proposes the Blended Exploitation and Exploration (BEE) operator to take advantage of the historical best-perforation actions. The proposed operator is then used in both model-free and model-based settings and show better performance than previous methods. 1. The proposed BEE operator utilizes the Bellman exploitation operator and exploration operator to address the under-exploitation issue. The proposed operator can be easily incorporated into the RL algorithms.\n2. The experiments show that the proposed operator can effectively reduce the estimation error and achieve better performance comparing with other RL algorithms. 1. The terminology can be misleading. The overestimation issue in the Q-value approximation generally is due to the changing order of expectation and $\\max$. It is incorrect to say that  the $Q$-function will have \"underestimation when encountering successes\" in Fig 1 (a). The authors need to clarify the context and difference of the statement in order to avoid confusion.\n2. In order to investigate on the under-exploitation, the metric $\\Delta(\\cdot,\\cdot)$ is defined on the current Q-function approximation. Intuitively,   $\\Delta(\\cdot,\\cdot)$ shows that the current Q-function approximation can be either overestimate or underestimate given different policy, i.e., $\\mu_k$ and $\\pi_k$. It is unclear what is the meaning of this metric. Considering most of the algorithm will update the policy and Q-function approximation at the same time, e.g., Actor-Critic, the Q-function should be evaluated under the current policy instead of the policy obtained earlier. The authors need to clarify why the definition here makes sense for the under-exploitation investigation. See the weakness above.",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1699636492844",
         "6.0",
         "3.0",
         "3.0",
         "2.0",
         "2.0",
         "273",
         "0",
         "5",
         "0.7173",
         "0.12450980390000001",
         "0.8775630593",
         "49",
         "22.7412",
         "13.6569",
         "16.1503",
         "14.3268",
         "14.1695",
         "0.0999",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "1",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-FAWm",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "5",
         "5",
         "5",
         "4",
         "86",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This paper presents the Blended Exploitation and Exploration (BEE) operator, which addresses the issue of value underestimation during the exploitation phase in off-policy actor-critic methods. The paper highlights the importance of incorporating past successes to improve Q-value estimation and policy learning. The proposed BAC and MB-BAC algorithms outperform existing methods in various continuous control tasks and demonstrate strong performance in real-world robot tasks. - The paper addresses an important issue in off-policy actor-critic methods and proposes a novel approach to improve Q-value estimation and policy learning. \n- The BEE operator is simple yet effective and can be easily integrated into existing off-policy actor-critic frameworks.\n- The experimental results demonstrate the superiority of the proposed algorithms in various continuous control tasks and real-world robot tasks. 1. The novelty of the proposed approach is limited. \n2. The choice of $\\lambda$ is largely empirical and requires extra manipulation in new tasks.\n3. The paper only provides basic theoretical analysis, such as the accurate policy evaluation and the guarantee of policy improvement. The benefit of linearly combining two Q-value functions is not discussed theoretically.\n4. The experiments are conducted in continuous control tasks with dense rewards. The exploration ability can be better evaluated in environments with sparse rewards.\n5. There is a lack of discussions with related papers (See Question 3). 1. Emprically, the BAC algoithm will only be more efficient in exploiting the replay buffer. The exploration still rely on the maximum-extropy formulation in SAC. Then why can BAC perform significantly better than SAC in failure-prone scenarios such as HumanoidStandup, as if BAC can better explore the unknown regions?\n2. Can you discuss or exhibit the performance of BAC in some tasks with sparse rewards? This can demonstrate the generalizability of the proposed approach.\n3. What are the advantages of BAC compared with prioritized replay methods \\[1,2\\] or advantage-based methods \\[3\\]? These methods are related to BAC in that they also exploit the replay buffer with inductive bias, so they should be mentioned in the paper.\n\n\\[1\\] Sinha, S., Song, J., Garg, A. &amp; Ermon, S.. (2022). Experience Replay with Likelihood-free Importance Weights. Proceedings of The 4th Annual Learning for Dynamics and Control Conference.\n\n\\[2\\] Liu, X. H., Xue, Z., Pang, J., Jiang, S., Xu, F., & Yu, Y. (2021). Regret minimization experience replay in off-policy reinforcement learning. Advances in Neural Information Processing Systems, 34, 17604-17615.\n\n\\[3\\] Nair, A., Gupta, A., Dalal, M., & Levine, S. (2020). Awac: Accelerating online reinforcement learning with offline datasets. arXiv preprint arXiv:2006.09359.\n\n\nI am willing to raise my score if my concerns for weaknesses and questions are adequately discussed.",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1700565416102",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "432",
         "8",
         "14",
         "0.7996000000000001",
         "0.1588311688",
         "0.8829935789000001",
         "60",
         "31.9755",
         "12.2213",
         "15.4394",
         "13.7425",
         "12.4851",
         "0.1565",
         "89",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "2",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-kjkr",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "5",
         "5",
         "4",
         "5",
         "75",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "Motivated by the problem of underestimating values in the training of SAC, this paper introduces the Blended Exploitation and Exploration (BEE) operator, which calculates the TD target based on a combination of the standard TD target and a high expectile of the return distribution. The authors integrate this operator in both model-free and model-based scenarios, followed by a comprehensive experimental evaluation. 1. The paper contains extensive experiment results on both simulation and real-world environments.\n2. The paper is written clearly and easy to follow. Figure 1 provides a decent visualization of the underestimation issue. 1. The BAC method tunes its $\\lambda$ and $\\tau$ differently for tasks in MuJoCo and DMC (Table 1 & 5). It's questionable to claim superiority over other state-of-the-art (SOTA) methods like SAC and TD3, which use consistent hyperparameters (HP) across tasks. Adjusting HP for each task can inflate results as seen in Figure 5, which can be misleading. Why not showcase the automatic $\\lambda$ tuning methods from Appendix B.3.3 in the main text if they're effective?\n\n2. Figure 23 reveals that SAC, without the double-Q-trick, still underestimates in the Humanoid task. It's unclear if this is universally true. More convincing results would come from testing this across multiple tasks and providing absolute Q value estimates. I still suspect that Q underestimation largely stems from the double Q techniques, as suggested by the RL community \\[1\\]. For instance, OAC \\[1\\] introduces $\\beta_{\\text{LB}}$ to manage value estimation issues.\n\n3. Presuming the Q value underestimation problem is widely recognized (which I invite the authors to contest), the paper seems to lack innovation. The BEE operator, at its core, appears to be a fusion of existing Bellman operators.\n\n4. The statement \"BEE exhibits no extra overestimation\" seems conditional on specific $\\lambda$ and $\\tau$ values. For instance, using $\\lambda = 1$ and $\\tau = 1$ could induce overestimation.\n\n\\[1\\] Ciosek, Kamil, et al. \"Better exploration with optimistic actor critic.\" Advances in Neural Information Processing Systems 32 (2019). See Weakness",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1700668216355",
         "6.0",
         "5.0",
         "3.0",
         "4.0",
         "2.0",
         "328",
         "4",
         "8",
         "0.8027000000000001",
         "0.1464980159",
         "0.8531657457",
         "61",
         "35.3958",
         "11.9923",
         "14.4014",
         "13.2462",
         "12.1773",
         "0.1507",
         "93",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "3",
         "100",
         "Seyed",
         "Enrico-Daga",
         "3",
         "2",
         "factual",
         "positive",
         "polite",
         "none",
         "4",
         "5",
         "4",
         "4",
         "4",
         "4",
         "80",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "The authors have performed significant changes to the content, which significantly improve the article with respect to the previous submission. Following the four SWJ criteria for survey articles, the current version is indeed a good (1) introductory text, targeted at researchers, PhD students, or practitioners, to get started on the covered topic.  The addition of a methodology section gives reasonable justification for (2) how comprehensive and how balanced are the presentation and coverage. However, a few more details about the sources of the survey would be useful, especially if mentioning keywords and phrases used in the search (Scopus? Google Scholar? Microsoft Academia? …). In addition, it is still a bit opaque what is intended with \"refining and balancing the structure of the covered areas\" - end of Section 2. However, I consider these minor issues that can be fixed during the preparation of the camera-ready. Finally, the article is readable and clear (3) and the content is relevant to the community (4).",
         null,
         "21/Sep/2021",
         null,
         null,
         null,
         null,
         null,
         "162",
         "0",
         "1",
         "0.8103",
         "0.1645833333",
         "0.6678649187",
         "60",
         "31.31",
         "14.6",
         "17.41",
         "16.6",
         "15.5",
         "0.1149",
         "100",
         "0",
         "0",
         "0",
         "2",
         "semanticweb"
        ],
        [
         "4",
         "100",
         "Seyed",
         "Julia-Bosque",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "5",
         "4",
         "87",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "I reviewed a previous version of this manuscript, for which I recommended a major revision based on the need for a clearer motivation, scope and limitations of this effort, as well as on the structure and flow of the paper at that time. In this new version the authors have addressed all my highlighted concerns: - The motivation, scope and limitations are clearly defined - The interplay between the different sections is elaborated and illustrated with a workflow diagram that facilitates reading. There are numerous references to this workflow and interlinks between the sections, resulting in a cohesive document. - More context is provided in the introductory paragraphs of each section, and the project in which this effort is carried out is clearly introduced. The relation of each section/topic with respect to the overall topic of the survey is now explicit. - The authors have improved the categorization of tools and approaches. - The tables in the appendix summarize the main approaches, tools and resources surveyed according to the proposed classification.  Taking into account these modifications, I maintain the reasons upon which I based the recommendation for acceptance in terms of the criteria for surveys: - The topic of the paper, at the intersection of humanities and the Semantic Web, is interesting and relevant for the advancement in a line of research which poses numerous challenges. - The quality of writing is good and the survey is well balanced, with a broad coverage encompassing theoretical standpoints and approaches, tools, repositories and datasets. - The granularity and length are also appropriate for the text to serve as an introductory text. Minor comments for improvement: - The authors have provided details on the methodology for the survey, indicating the different stages in the generation and keywords used in literature search. There is no explicit reference to a filtering process after those keyword-based search results, was there any filtering step? If so, which criteria were applied? - In table 3, the included resources diverge in their nature, so the current list groups together LLOD Cloud, Lila Etymological Lexicon, LingHub, and Diachronic semantic lexicon of Dutch, etc. for example. I suggest including a mark here to distinguish which resources are particularly relevant for diachronic analysis, in contrast to general LLOD resources (e.g. Lila Etymological Lexicon vs. LLOD cloud and LingHub). - The authors of [12], referenced on p. 5, mention Lemon (Lexicon Model For Ontologies), and in their diagrams (in Github)  they seem to be using OntoLex-Lemon, not its ancestor. Throughout this survey \"OntoLex-Lemon\" is the term used to refer to the 2016 Specification as the outcome of the W3C Ontology-Lexica Community Group, so for that bib. reference I would recommend to replace the mention of \"Lemon\" with \"OntoLex-Lemon\" for consistency in the whole document. *Typos*: l.19, .p. 19, right column, \"A combined resource like this, allows...\" → remove comma p. 20, l. 1, right column → remove \"(linguistic)\", already covered by the first L in LLOD Appendix tables, Table 4. → word embeddings (add pl. \"s\")",
         null,
         "04/Oct/2021",
         null,
         null,
         null,
         null,
         null,
         "503",
         "1",
         "5",
         "0.7741",
         "0.1697330447",
         "0.8522429466",
         "73",
         "34.66",
         "13.3",
         "14.3",
         "15.2",
         "14.0",
         "0.2025",
         "108",
         "0",
         "0",
         "0",
         "0",
         "semanticweb"
        ],
        [
         "5",
         "100",
         "Seyed",
         "Thierry-Declerck",
         "3",
         "1",
         "partially factual",
         "positive",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "4",
         "3",
         "4",
         "60",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "Not really a lot to add. I see that the revised version of the submission was taking good care of former comments and suggestions. Just a minor point: 1) Ensure that footnotes are always placed after the punctuation signs (for consistency across the paper, se fn 2 and 3 which are not placed consistently). So, very few corrections to do.",
         null,
         "05/Nov/2021",
         null,
         null,
         null,
         null,
         null,
         "60",
         "0",
         "0",
         "0.81",
         "0.058",
         "0.6966200471",
         "105",
         "64.71",
         "8.0",
         "10.0",
         "10.1",
         "8.0",
         "0.0548",
         "60",
         "0",
         "0",
         "0",
         "0",
         "semanticweb"
        ],
        [
         "6",
         "74",
         "Sonny",
         "Reviewer-HZXU",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "3",
         "80",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies how to train NeRF with the optimal training set under limited view inputs for novel view synthesis. It proposes a theoretical framework for view sampling strategies from a causal perspective, finally decomposing the objective into three components: a fitting term similar to traditional NeRF training loss, a consistency term requiring consistency between visible and invisible views, and a uniformity term demanding the sampling to be diverse. The proposed sampling strategy induces higher-quality NeRFs and can be used as regularization term for general NeRF training. 1. Framing the novel view synthesis problem via a causal perspective is novel. \n2. The deduced supervision objective with three terms is intuitive and well-explained. \n3. Experiments demonstrate that based on the proposed sampling strategy better performance could be achieved with the same number of training views, using the principles as a regularization term to the training of general term could also improve performance. 1. Although the derived supervision objective is intuitive, the framing of novel view synthesis problem with causal framework is a bit obscure with mistakes: e.g. page 5 the authors mentioned \"we defer the details to the Appendix\" which do not exist, Eq. 4 in page 6 is also falsely rendered. \n2. Two variants of the model are proposed (prioritizing consistency and uniformity term differently) without a consistency in which one would perform better which may limit the usability. 1. in Appendix Tab. 1, ActiveNeRF acquires better results 3/8 on ficus, materials and ship, are there any explainations for this? \n2. Could some qualitative comparisions with DietNerF (which would show the effects of uniformity loss only) be povided ?",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108591",
         "5.0",
         "3.0",
         "2.0",
         "2.0",
         "2.0",
         "269",
         "0",
         "7",
         "0.7805000000000001",
         "0.0904761905",
         "0.8525229096",
         "52",
         "32.8096",
         "13.8045",
         "16.7536",
         "15.402",
         "14.7564",
         "0.1303",
         "94",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "7",
         "74",
         "Sonny",
         "Reviewer-itVg",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "4",
         "85",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "The authors introduced a view sampling strategy for novel view synthesis, grounded in the perspective of causal representation learning. They identified three key metrics to assess sampling performance: the fitting term, the consistency term, and the uniformity term. Additionally, they presented a novel theoretical framework addressing the sampling challenge within NeRF. 1. The introduction of the causal perspective in the view sampling algorithm holds significant potential and could serve as a foundational approach for future research in this domain.\n2. The authors meticulously lay out a comprehensive mathematical framework that not only elucidates the underlying problem but also leads to the derivation of the three pivotal terms central to their methodology.\n3. The paper stands out for its clarity and coherence, ensuring that readers, regardless of their expertise level, can grasp the concepts and findings presented.\" 1. The rationale behind the view-sampling task raises questions. In certain scenarios, acquiring additional view images can be challenging. However, when a substantial number of dense views are already available, the motivation to devise a sampling strategy for training the neural rendering model with sparse views appears insufficient. Specifically, the activeNeRF model's primary objective is to identify the most optimal camera view for capturing the training image, rather than selecting from a plethora of pre-existing images.\n2. The paper's primary contribution seems to be the introduction of a metric or loss function to evaluate the selected views. However, the absence of an ablation study that separately assesses the impact of each of these three terms is a missed opportunity for deeper understanding. As a result, the contribution feels somewhat lacking in depth.\n3. The proposed loss function presents challenges in differentiability with respect to 't'. The sampling proposal, derived from the farthest sampling strategy, may not be the most efficient approach. It appears to demand significant training resources, resulting in elevated training costs. The potential enhancements in model performance might not justify the trade-off in terms of the increased training time and resource allocation. Please see the weakness above.",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108511",
         "5.0",
         "2.0",
         "3.0",
         "3.0",
         "1.0",
         "335",
         "0",
         "6",
         "0.7966000000000001",
         "0.1848602484",
         "0.9041278958000001",
         "52",
         "29.0988",
         "13.8242",
         "17.2355",
         "15.5433",
         "15.2217",
         "0.1431",
         "101",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "8",
         "74",
         "Sonny",
         "Reviewer-bNPg",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "3",
         "4",
         "4",
         "3",
         "90",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies the view sampling strategies of Nerf reconstruction from a causal perspective. The authors try to solve the problem using a small subset of photos from a total of K potential views, to achieve the best reconstruction. To solve this, the authors propose to use causal represntation learning using loss by Identification Treatment Effect. They propose three terms, a normal fitting term as reconstruction loss, a consistency term to ensure consistency between visible views and invisible views and a uniformity term requires the samples to be distributed evenly. The results show the proposed strategy can provide slightly better reconstruction compared to alternative baselines in the proposed setting. * The paper proposes a novel perspective to study the view sampling problem in volumetric reconstruction using NeRF as an example. This take-away can potentially also generalize other multiview reconstruction algorithms. \n* Given its current setting, the hypothesis is validated on nerf reconstruction datasets, with small improvement compared to its baselines. * The presentation of this paper could be greatly improved. I may not have understand a lot of details correctly given its current presentation. \n  * It is very hard to read without being very familiar with ActiveNeRF and casual representation learning. Have to trace to original papers for more details. This could be added to the preliminary parts. \n  * Too many notations which makes things more complicated than needed. I don't think I found how exactly the loss of consistency term and uniformity term were calculated in (8) at runtime. As I understand, the method should be as simple as calculating the reconstruction loss using different groups of input samples. Provide an algorithm chart of how of how P^{F}, P^{hat}^{CF} and P^{CF} will greatly help. \n  * There are some notations introduced in 4.1 (e.g. P(Y|do(d))) are not explained until 4.2. \n* Overall I am not sure I understand the real-world impact of this paper using the proposed strategy. Maybe I had some misunderstanding in the details given my concern on its presentation. Please correct me if I am wrong here. The goal of this paper to find \"optimal sampling strategy for training set\", \"K_s corresponding photos as sparse sample inputs among K_d total potential views\" is hardly a real problem statement for its real-world use case, which is my biggest concern for this proposed application of causal representation learning. From sampling perspective, we can use all the K_d potential views as long as they are available. As I understand, the evaluation of the counter factual distribution will require using the non-selected but captured images as supervision, which is not how active learning is executed in real-world case. Given this setting, it makes the results also less appealing in contrast to alternative baselines (which learns to predict next-best unknown view) given the fact all images from that particular datasets are used in evaluating the sampling strategy. 1. My major question is around how the clarity of the sampling process in training time. Confirm any places I misunderstood about this paper, as I highlighted in the weakness part. \n2. I am also curious how the views are sampled finally for different groups in the final results. Provide some visualization and discussions about them can be very helpful to guide the view-sampling process in real world applications. I wonder how that indicate the connection of uniformity term and consistency term are correlated to the camera FoV and ray distributions.",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108442",
         "3.0",
         "3.0",
         "2.0",
         "1.0",
         "2.0",
         "566",
         "0",
         "2",
         "0.8138000000000001",
         "0.1125",
         "0.8472209573",
         "52",
         "40.8228",
         "12.0451",
         "14.3685",
         "13.7425",
         "12.6507",
         "0.33",
         "107",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "9",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-GDNX",
         "3",
         "5",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "80",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         ">**Rebuttal:** The provided details satisfy my concerns. I think this paper should be accepted after applying the agreed changes.\n\n>**TL;DR:** **Good paper.** The proposed WTA-CRS algorithm is based on the existing CRS algorithm and is used to reduce activation memory during training. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size. However, WTA-CRS comes with computational overhead, which is discussed and explore. Addressing my concerns and questions would improve my score.\n\nThe paper proposes the WTA-CRS algorithm to reduce the neural networks training activation memory, where the paper claims that activation memory is primary memory bottleneck during training. The WTA-CRS algorithm is an unbiased estimators for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size.\n\nThe WTA-CRS algorithm works by sampling columns and rows to create an unbiased estimation of the original GEMM for the backpropagation. The WTA-CRS algorithm does not alter the neural architecture, and therefore the inference speed is left in tact. The experimental section shows that WTA-CRS outperforms existing prior work and is compatible with existing PEFT techniques. WTA-CRS adds a computational overhead due to sampling, however, WTA-CRS enables training on much larger batch sizes, which results in a 1.2× higher training throughput.\n * **S.1.** The proposed WTA-CRS algorithm tackles an important problem in existing PEFT techniques, which makes LLM PEFT training more accessible to researchers with low resources.\n* **S.2.** The paper provides a theoretical analysis on WTA-CRS.\n* **S.3.** The proposed WTA-CRS algorithm outperform existing algorithms.\n* **S.4.** An anonymized code repository is provided as part of the submission for reproduction .\n  * **W.1.** Popular existing memory efficient training techniques such as tensor rematerialization (gradient checkpointing) \\[2\\]\\[3\\] and ZeRO \\[1\\] are not compared to, although some are partially discussed in Appendix A.\n* **W.2.** The experiments are conducted on single neural network architecture (T5), although the proposed technique does not seem to be confined solely to that setting.\n* **W.3.** It is common practice today to train neural networks at a lower precision (quantization), however, it is not clear whether quantization (16bit) was used. Therefore, there is insufficient proof that the combined noise of WTA-CRS and quantization would be compatible.\n\n\n**Typos.**\n* Line #62: \"Thus\" → \"Thus,\"\n* Line #240: \"mAccording\" → \"According\"\n* Line #297: \"Thus\" → \"Thus,\"\n\n\\[1\\] Ren, J., Rajbhandari, S., Aminabadi, R.Y., Ruwase, O., Yang, S., Zhang, M., Li, D. and He, Y., 2021, July. ZeRO-Offload: Democratizing Billion-Scale Model Training. In USENIX Annual Technical Conference (pp. 551-564).\n\n\\[2\\] Jain, P., Jain, A., Nrusimha, A., Gholami, A., Abbeel, P., Gonzalez, J., Keutzer, K. and Stoica, I., 2020. Checkmate: Breaking the memory wall with optimal tensor rematerialization. Proceedings of Machine Learning and Systems, 2, pp.497-511.\n\n\\[3\\] Beaumont, O., Eyraud-Dubois, L. and Shilova, A., 2021. Efficient combination of rematerialization and offloading for training dnns. Advances in Neural Information Processing Systems, 34, pp.23844-23857. * **Q.1.** In line #43 and Figure 2 it is noted that \"storing activations (or feature maps) is the main memory bottleneck during training\". Does this hold true for all model architectures? What about LLM training where the fine-tuning batch size is usually very small?\n* **Q.2.** Why was the WTA-CRS algorithm compared to the Deterministic top-k from \\[1\\] but not to the Bernoulli-CRS from \\[1\\]? What are the key differences between WTA-CRS and Bernoulli-CRS?\n* **Q.3.** The paper proposes WTA-CRS which sacrifices computation speed at the cost of lower peak memory. There are several existing common approaches (such as gradient checkpointing and DeepSpeed) for general memory efficient training which are compatible with PEFT techniques. Why are these comparisons not explored or detailed in the main paper?\n\n\\[1\\] Adelman, Menachem, Kfir Levy, Ido Hakimi, and Mark Silberstein. \"Faster neural network training with approximate tensor operations.\" Advances in Neural Information Processing Systems 34 (2021): 27877-27889. The limitations are discussed in Appendix A.",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411175092",
         "7.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "669",
         "10",
         "14",
         "0.753",
         "0.09034013610000001",
         "0.8664653897",
         "215",
         "42.5651",
         "10.4983",
         "14.0094",
         "12.9915",
         "12.0464",
         "0.1507",
         "77",
         "1",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "10",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-j1mL",
         "4",
         "4",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "3",
         "70",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "In this paper, we propose a new method called WTA-CRS (Winner-Take-All Column Row Sampling) to address the main memory bottleneck issue during training, which arises from storing feature maps. To reduce memory usage during training, we sample the most likely column indices during backpropagation.\n\nFurthermore, \bthey proposed method demonstrates the ability to significantly reduce peak memory usage, by approximately up to 2.7 times, when fine-tuning downstream tasks. It also showcases the potential for higher throughput, enabling more efficient training. 1. The work clearly states its motivation and its solution and is easy to follow.\n2. The authors show that their method reaches comparable performance with backpropagation using the full activation when combined with LoRA.\n3. They also empirically measure throughput gains obtained by increasing batch size, which demonstrates the practical applicability of their method. 1. The paper needs a comparative analysis of other researchs, such as gradient checkpoint/recalculation and CRS, aimed at reducing activation memory during the training phase, as shown in Fig. 6 and Fig. 9.\n2. The paper should include an analysis of the overhead associated with the proposed WTS-CRS method, which involves sampling rows and columns. It is crucial to consider factors such as the computational cost of Equation 3 and any potential effects of lowering on the overall performance. Providing this analysis would enhance the clarity and completeness of the research.\n3. There is a need of analysis on the effectiveness of the proposed approach, WTS-CRS, in distributed training environments such as tensor parallelism or pipeline parallelism.\n4. It seems necessary to conduct performance evaluations on various LLMs of the GPT family, such as LLaMA and OPT. * In Figure 9, it can be observed that the throughput of WTS-CRS is lower than that of full when the batch size is small. Is this due to the overhead caused by lowering?\n* When comparing the training throughput, how does CRS differ from full in terms of throughput?\n* Could the authors include statistics for GPU utilization in their experiments? It would be helpful to analyze the causes of improved performance more thoroughly.\n* Considering that most large models are trained using multiple levels of parallelism, would it be possible to verify results for pipeline parallel, tensor parallel, etc.? Also, it is unclear from the paper whether the data parallelism used was distributed data parallelism or naïve data parallelism. * As previously mentioned, it would be valuable to include additional experimental results for models that are more challenging to quantify, such as GPT-series (OPT, LLaMA). This would enhance the validity and applicability of the proposed method across a broader range of models.\n* Considering that most large-scale models are trained using multiple levels of parallelism, it is important to assess how much the proposed methods, such as pipeline parallelism and tensor parallelism, can increase throughput while taking into account overhead (such as GPU-to-GPU or node-to-node communication), memory reduction, and computational cost. Furthermore, it is not clear from the paper whether the data parallel processing used is distributed data parallelism or naive data parallelism.",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174921",
         "5.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "506",
         "0",
         "8",
         "0.8129000000000001",
         "0.11685380590000001",
         "0.8539184332",
         "215",
         "31.6518",
         "13.622",
         "15.7723",
         "14.7722",
         "14.3231",
         "0.1355",
         "89",
         "0",
         "1",
         "0",
         "0",
         "neurips"
        ],
        [
         "11",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-cMiu",
         "4",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "80",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The authors studied fine-tuning LLMs with limited memory. As the increased scale of current LLMs, the memory cost during fine-tuning is of great importance when adapting the pretrained LLMs to down-streaming tasks. In contrast to the existing work that mainly focus on the number of updated weights, this paper proposed to reduce the number of stored activations, also the inputs to each layer. Given the widely used stochastic gradient descent optimization pipeline, the authors proposed to store a subset of activations that can generate an unbiased gradient estimation. This way, the training memory and the training time decreased significantly. The authors provide both theoretical and experimental analysis on their CRS methods.  - This paper studied an important problem in LLM fine-tuning, i.e., how to fine-tuning LLMs with less memory consumption without increasing the computation cost. The authors provided solid quantitative results to show that the main memory consumption is from storing the intermediate activations. \n- The authors provided a general solution for fine-tuning LLMs under memory constraints. The solution can be applied in most transformer-based network architectures.  \n- The authors provided solid mathematical proof on the unbiased gradient estimation, which is especially encouraged. \n- The extensive experiments on different network architectures showed the efficacy of the methods.\n- The released code can benefit the following researchers studying efficient LLM fine-tuning.  - I am not fully convinced by the comment made in Line241-244, i.e., the methods in the paper is orthogonal to the activation quantization. When activation is quantized into a lower bit width, it is very possible that the number of less important activations will decrease. This way, the selection on the top-k columns in activation matrices with the proposed methods may hurt the training accuracy or convergence. It would be great if the authors can provide some theoretical analysis or experimental results on this combination. Otherwise, it would be necessary to provide some comparison results w.r.t. the activation quantization.\n- It would be great if the authors can discuss the main difference of their paper w.r.t. \\[Randomized Automatic Differentiation, ICLR2021\\].\t  Overall, I think this paper has a relatively high quality in both writing and scientific contribution. Yes",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174804",
         "6.0",
         "4.0",
         "2.0",
         "3.0",
         "3.0",
         "358",
         "0",
         "2",
         "0.7825000000000001",
         "0.1275074405",
         "0.8477004170000001",
         "215",
         "33.3958",
         "12.2345",
         "15.5366",
         "14.3747",
         "12.6032",
         "0.1262",
         "97",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "12",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-ky3t",
         "2",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "70",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The paper's contribution is in proposing a practical, intuitive yet not trivial unbiased approximation to gradient training of matrix multiplication. It shows that even though totally deterministic sampling is biased, somewhat deterministic sampling is unbiased, and a judicious allocation of sampling to those pairs favored by deterministic thinking can lead to the use of a larger batch size with empirically negligible performance loss. This reviewer must declare that he does not check the derivation very carefully. The proposed idea is practical and can be readily combined with virtually all first-order gradient-based training methods.\nThe paper also derived why deterministic sampling is a biased estimator and empirically shown the associated bad performance, thus proving that the additional complexity of stochastic sampling over deterministic sampling is not only sufficiently better but also necessary. It's just a few empirical comparisons, but the performance gap between CRS and WTA-CRS seems modest. This reviewer does not have a question. N/A",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174720",
         "7.0",
         "3.0",
         "4.0",
         "3.0",
         "3.0",
         "155",
         "0",
         "1",
         "0.8418",
         "0.062142857100000004",
         "0.7829982042",
         "215",
         "17.3432",
         "16.3412",
         "19.4378",
         "17.1224",
         "17.2025",
         "0.1041",
         "90",
         "0",
         "1",
         "0",
         "0",
         "neurips"
        ],
        [
         "13",
         "38",
         "Seyed",
         "Reviewer-vqBu",
         "3",
         "2",
         "unfactual",
         "neutral",
         "polite",
         "low",
         "2",
         "2",
         "3",
         "2",
         "3",
         "4",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way. The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea. The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso. - in the frequentist case, how does the proposed framework compares against more classical techniques to obtain the solution paths, e.g., iterative reweighted l1-norm?  The authors adequately addressed the limitations of their proposed framework. ",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411519040",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "170",
         "0",
         "0",
         "0.799",
         "0.32",
         "0.9384971857000001",
         "215",
         "30.7103",
         "14.2239",
         "17.6808",
         "16.0619",
         "16.5336",
         "0.1149",
         "88",
         "1",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "14",
         "38",
         "Seyed",
         "Reviewer-3sWQ",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "2",
         "1",
         "3",
         "3",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution. - Well written paper.\n\n        - Illustrative toy experiments. - The proposed method is a combination of already known techniques.\n\n        - The experimental section is weak as only a single real problem is considered.\n\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\n\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\n\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros. None The authors have not commented on the limitations of their approach.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518947",
         "5.0",
         "3.0",
         "2.0",
         "3.0",
         "2.0",
         "279",
         "0",
         "2",
         "0.7414000000000001",
         "-0.007047619000000001",
         "0.9233116508",
         "215",
         "36.096",
         "12.2287",
         "15.0602",
         "13.9505",
         "11.6138",
         "0.0989",
         "92",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "15",
         "38",
         "Seyed",
         "Reviewer-pTVu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "3",
         "4",
         "4",
         "4",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\geq1}$ is used). 1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\n3. Using sub-l1 norm is suitable for structure learning. \n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \n5. The paper is well-written, and the relevant work is sufficiently discussed.    \n6. Due to its flexibility, the proposed method has the potential of having a large impact. Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \n\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \n\nMinor suggestion: \n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \n2. Fix minor typos e.g. the end sentence period in line 214. * In line 141, what do you mean by \"contradiction\"? The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \n\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518854",
         "6.0",
         "3.0",
         "3.0",
         "4.0",
         "2.0",
         "330",
         "0",
         "9",
         "0.7934",
         "0.1236940837",
         "0.8818445206000001",
         "215",
         "45.1097",
         "11.0541",
         "13.9964",
         "13.4279",
         "11.8722",
         "0.19690000000000002",
         "83",
         "0",
         "0",
         "0",
         "1",
         "neurips"
        ],
        [
         "16",
         "38",
         "Seyed",
         "Reviewer-CnQu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "moderate",
         "2",
         "2",
         "1",
         "1",
         "3",
         "4",
         "50",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets. Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \n\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated. Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost. In synthetic data example, why did you choose to have more samples than dimensions ( $n>d$ )? Since in that case GGM can be obtained with matrix inverse, and no need for penalized objective. Limitations were not discussed.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518763",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "205",
         "0",
         "2",
         "0.787",
         "0.1207251082",
         "0.8797656298000001",
         "215",
         "36.2535",
         "11.8049",
         "15.4552",
         "13.8167",
         "11.6905",
         "0.25730000000000003",
         "82",
         "0",
         "1",
         "0",
         "0",
         "neurips"
        ],
        [
         "17",
         "13",
         "Mana",
         "Joseph-philipraj",
         "5",
         "5",
         "factual",
         "positive",
         "polite",
         "low",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "95",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This systematic review is appropriate for the journal with a global problem of Mets and Urolithiasis. The introduction part clearly explains the motivation. The manuscript is clear and balanced. The manuscript stays focused on the subject. Authors have gone through the process of searching relevant articles from all websites and of sufficient duration. The inclusion and exclusion criteria in the analysis have been clearly stated. The impact of the analysis is clearly stated. The statistical analysis supports the paper well. The interpretation of the results, visualisation are well presented. The tables and figures are clear, relevant and correct. The authors demonstrate the knowledge of basic composition skills, including word choice, sentence structure, paragraph development and grammar. Limitations:  The studies included in the meta-analysis have cross-sectional nature and hence ascertainment of temporal association is not possible which also dictates need for further prospective studies. The specific type of stone formation is not correlated with studies. Despite these limitations all studies included in the meta-analysis showed the same directionality in the association between urolithiasis and Mets.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         null,
         "22 Mar 2021",
         null,
         null,
         null,
         null,
         null,
         "292",
         "0",
         "1",
         "0.7415",
         "0.1145833333",
         "0.8487246633000001",
         "39",
         "30.46",
         "12.8",
         "13.83",
         "14.6",
         "14.3",
         "0.0999",
         "99",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "18",
         "13",
         "Mana",
         "Muhammad-Faruk",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "93",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study assessed the association between metabolic syndrome and its components with the risk of developing nephrolithiasis by conducting systematic review, Bayesian random-effects meta-analysis, meta-regression and dose-response analysis. This study was done appropriately based on PRISMA flowchart. Risk of bias was also conducted of the included studies. This study has successfully presented the proper meta-analysis for this design. However, to complete this study for indexing, I personally recommended several revisions: 1. Abstract: Introduction section: It is better to address meta-regression as the analysis to assess the correlation of association along with dose-response analysis  Conclusion section: In reporting the association between predictors and nephrolithiasis, state only the predictors in which its coefficient was statistically significant 2. R language was not considered as a statistical software for data analysis. The software for data analysis should be written as \"R\" (Please refer to methods section in statistical analysis subsection). 3. Please update the PRISMA flowchart (refer to PRISMA guideline 2009). 4. Give the numbering of each Forrest plot in Figure 3 and numbering of each meta-regression plot in Figure 4. Design these figures so that it could be well presented. 5. Uniformly decide the word choice of \"traits\" or \"components\", choose whether to use traits or components in the whole text, use one of these words consistently to avoid any misunderstanding. 6. It is better to provide the meta-regression of hypertension in systolic blood pressure and diastolic blood pressure as it is important to explain the relationship to nephrolithiasis in differentiation for these two types of blood pressure. 7. Meta-regression of body mass index  was sufficient in this study thus waist circumference meta-regression was not necessary to be included. 8. Provide the value of coefficient and confidence interval of each meta-regression analysis in the result section so that better understanding of predictors-outcome relationship could be reached clearly.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         null,
         "08 Nov 2021",
         null,
         null,
         null,
         null,
         null,
         "422",
         "0",
         "7",
         "0.7554000000000001",
         "0.1982758621",
         "0.9299524426",
         "270",
         "24.68",
         "15.1",
         "14.79",
         "16.3",
         "16.8",
         "0.23020000000000002",
         "91",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "19",
         "181",
         "Hideaki-Joko",
         "Reviewer-sna7",
         "2",
         "2",
         "factual",
         "positive",
         "neutral",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This paper presents ULTRA, a single model that can be directly used/finetuned for link prediction over different knowledge graphs. The key is to model the transferrable relationships between different relations across knowledge graphs. Specifically, a NBFNet is used to learn relative relation representations and generate relation embeddings, which is then fed into another NBFNet to perform link predictions. Extensive experiments are performed over many knowledge graph to demonstrate the performance of this model. - This paper is well written and easy to follow\n- The core method around the relative relationships between relations is clever and interesting.\n- The experiments demonstrate the gains of the method. It is especially impressive to see the competitive zero-shot performance of ULTRA over different knowledge graphs. - The proposed method relies entirely on knowledge graph structure and does not consider using node embedding such as textual features of the knowledge graphs. In reality, text embedding of nodes and edges could be a better transferrable embedding. Such transferability has already been demonstrated by PRODIGY (https://arxiv.org/abs/2305.12600) and should be addressed.\n- The model does not scale well as the authors already pointed out.\n- The zero shot and fine-tuning performances are worse or on-par with the per dataset model performance, rendering pretraining not effective performance-wise. \n- Some notations are a bit hard to understand. See questions. - What are u and v in h_{u|v} in section 4.2?\n- Why are supervised SOTA baselines only reported for some datasets in Figure 4?",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636399067",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "245",
         "1",
         "1",
         "0.7559",
         "0.0971320346",
         "0.9083012938",
         "49",
         "38.7951",
         "11.5125",
         "14.374600000000001",
         "14.0058",
         "12.3979",
         "0.07200000000000001",
         "103",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "20",
         "181",
         "Hideaki-Joko",
         "Reviewer-HLbG",
         "3",
         "3",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This work aims to build a foundation model for knowledge graph reasoning tasks, where the authors explore the setting of generalization to any edges and nodes, including unseen, of any multi-relational knowledge graphs without using node and edge features. To this end, the authors first construct a view of a relation-centric graph from an original graph where edges become nodes of this new relation graph, and then, based on this view, the authors represent the relation (node) relative to and conditioned on the query relation. Then, based on this relative relation representation, the authors use existing inductive link prediction methods to perform knowledge graph reasoning. The authors conduct link prediction experiments on various knowledge graphs considering both inductive and transductive settings, and show that the proposed method, namely ULTRA, outperforms other SOTA baselines sometimes without further fine-tuning on target knowledge graphs (i.e., zero-shot). * This work studies the very important, challenging, and practical setups of building a foundation model for knowledge graph reasoning, which aims to be generalizable to any other knowledge graphs involving unseen nodes and unseen edges, without leveraging features of nodes and edges. \n* The proposed method works well with different knowledge graphs, on zero-shot transfer learning setups without further fine-tuning on target knowledge graphs, and further shows the boosted performance with task-specific further fine-tuning on them, on most experiment setups.\n* This paper is very well-written and easy to follow. * I would like to note that I don't see any major weakness, and below is the minor.\n* In Section 4.2, the explanation about the indicator function with variables $u$ and $v$ is a bit unclear to me. Could you elaborate more on the process and result of the indicator function according to those two variables, perhaps with visuals?\n* Text-based methods (e.g., LM-based methods) can be generalizable to any knowledge graphs including unseen nodes and unseen edges, as long as their nodes and edges are represented with texts. In this vein, I think one potential direction for building a foundation model for knowledge graph-related tasks might be to use the LMs, and the authors may highlight this point more and potentially make comparisons between the proposed approach and text-based methods. I don't think this should be the critical weakness of this paper since text-based methods are limited to knowledge graphs with textual features; meanwhile, given the framing of this work (\"Towards Foundation Models for Knowledge Graph Reasoning\"), this point should be carefully explained. * I would like to suggest emphasizing the performance differences between inductive and transductive setups when explaining Table 1. The proposed method w/ 0-shot settings are strong on inductive graphs; meanwhile, previous methods are superior to it on transductive graphs, which are worthwhile to discuss.\n* It may be beneficial to show the results of the ULTRA fine-tuned on the knowledge graphs used for pre-training the ULTRA. I am wondering if there are further performance improvements when further fine-tuning the model on the data used for pre-training.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398956",
         "8.0",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "496",
         "0",
         "0",
         "0.7682",
         "0.1549267161",
         "0.9152074456",
         "49",
         "38.4364",
         "14.2789",
         "16.8311",
         "15.0692",
         "17.4975",
         "0.37610000000000005",
         "103",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "21",
         "181",
         "Hideaki-Joko",
         "Reviewer-c3Sg",
         "4",
         "3",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "4",
         "3",
         "3",
         "4",
         "70",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "Paper claims to propose a foundation model, named Ultra, for knowledge graph representation learning. The proposed model can handle full inductive graphs in which new entities and relations may appear in the test set. To do so, the authors propose to lift the graph to a one with relations as the nodes and design 4 different edge types (head2head, head2tail, tail2head, tail2tail). The relational representations are then learnt using message passing on this graph. The learnt relation embeddings are then used in the original graph to perform inductive link prediction. For the experiments, the authors pre-train their method on 3 KGs and further evaluate in a zero-shot setting and also by fine-tuning the downstream tasks. - The paper proposes a transductive model that works in settings of new relations and entity nodes.\n- The method obtains good zero-shot pretraining results. - The authors have not explicitly stated the computational complexity of the method. From the paper, it seems that the forward pass is run on the entire relational graph to obtain relation representations. This is then used to initialize the node embedding from the query triple and the process is repeated for every triple. Thus it seems that the entire graph is being used for link prediction every triple making the computational complexity O(E^2). This seems limiting for large graphs that have not been explored in the paper (such as wikidata-5m etc.).\n- From Table 2 we can see that finetuning over the pre-trained models helps the results significantly over the 0-shot setting. Also, the fine-tuning steps are too large to claim few shot results. This weakens the claim of the \"foundation model\" for KGs. A fair comparison would be to show the pretraining results for other inductive and transductive methods as well in addition to the SOTA comparison.\n- Another limitation is that of scale. Since the current model has fewer parameters, this would limit learning over larger pretraining datasets as can be seen in Figure 6 and also reported by the authors.\n- SoTA results for transductive models are better than the pre-trained Ultra model in many datasets. Thus the Ultra model seems to work well for the inductive setting rather than transductive. Thus the claim of the \"foundation model\" seems broader in scope.\n- We see that in the metafam dataset, the pretraining results are poor but on finetuning the results are improved drastically. This shows that the method works well in cases where the relational patterns of the downstream datasets are similar to the pre-trained one but when the data distribution changes the results suffer. Moreover, due to limited capacity, the model may not be able to handle such cases by increasing the pretraining datasets calling for downstream finetuning. Thus domain adaptation is not a problem which can be easily overcome by scaling the current model and this further weakens the claim of a \"foundation model\" for KGs. - For weakness point 2: Any reason why this was not done by the authors?\n- For weakness point 3: How would this be addressed in future works for the model?\n-  For weakness point 4: Could the authors comment on why this would be the case and how would the model be improved to handle the transductive setting?\n- For weakness point 5: Any reason why the results on this dataset are not good?\n- Considering KGs are a rich source of textual/semantic data along with graph/structured data and the current model does not use this rich source of context information, how can we extend Ultra to incorporate the KG ontology? \n- Considering weaknesses 2,4,5 the claim of the foundation model seems a bit broad as of now and at best the model could be said to be a good inductive learner.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398852",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "625",
         "0",
         "0",
         "0.7487",
         "0.1723163098",
         "0.9095818996",
         "49",
         "51.6761",
         "10.8027",
         "13.532399999999999",
         "12.9203",
         "11.5318",
         "0.1355",
         "95",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "22",
         "181",
         "Hideaki-Joko",
         "Reviewer-ebFz",
         "2",
         "2",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "65",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "The key limitation of designing the foundation models for dealing with the Knowledge Graphs (KGs) is that the KGs have different entities and relations that generally do not overlap. To address this issue, this paper proposes ULTRA, which positively transfers the information of source KG to unseen KG. It constructs relation representations based on the interactions between the relations by introducing the graph of relations. The proposed approach has shown good performance on various tasks. - From their experiments, the proposed methods have shown good performance on various tasks.\n- Research topics about the foundational models on graph-structured datasets is really interesting and important.\n- The paper is well written and easy to follow. - The authors first pretrain the ULTRA model with the mixture of 3 standard KGs and then fine the model for the downstream task. But, the other supervised SOTA model only uses dataset of the downstream tasks without employing the pre-training datasets. If the supervised SOTA models are designed to deal with transductive settings, they may show worse performance on the downstream tasks. However, if the SOTA models are the models for the inductive setting, I think they may be possible to be pretrained like the ULTRA. So, could you measure the performance of the \"pretrained\" SOTA models on the inductive if possible? Please refer to the weaknesses.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398789",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "222",
         "0",
         "0",
         "0.7001000000000001",
         "0.16196172250000002",
         "0.9080925584",
         "49",
         "47.3913",
         "10.8151",
         "13.3132",
         "13.3974",
         "12.0322",
         "0.18230000000000002",
         "101",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "23",
         "9",
         "Seyed",
         "Reviewer-KmBd",
         "4",
         "4",
         "factual",
         "neutral",
         "neutral",
         "none",
         "4",
         "3",
         "4",
         "4",
         "3",
         "3",
         "90",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699637128872",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "487",
         "0",
         "1",
         "0.732",
         "0.1304191468",
         "0.9185432792",
         "47",
         "29.0538",
         "13.6602",
         "16.2613",
         "15.0211",
         "14.0811",
         "0.1695",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "24",
         "9",
         "Seyed",
         "Reviewer-3zCE",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699637128739",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "1.0",
         "480",
         "0",
         "0",
         "0.8331000000000001",
         "0.09343537410000001",
         "0.9183989763",
         "47",
         "39.3732",
         "11.51",
         "13.8202",
         "13.2344",
         "11.9386",
         "0.1932",
         "87",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "25",
         "9",
         "Seyed",
         "Reviewer-y5kB",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699642867494",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "41.9389",
         "11.9311",
         "14.8075",
         "13.9683",
         "12.4911",
         "0.050100000000000006",
         "104",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "26",
         "9",
         "Seyed",
         "Reviewer-XNx6",
         "5",
         "4",
         "factual",
         "neutral",
         "neutral",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "88",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1700672717423",
         "6.0",
         "4.0",
         "2.0",
         "2.0",
         "3.0",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.9159082770000001",
         "59",
         "42.2021",
         "12.1002",
         "14.7586",
         "13.9683",
         "12.0852",
         "0.929",
         "90",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "27",
         "81",
         "Emperatoor",
         "Gatot-Soepriyanto",
         "3",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study investigate whether financial distress, earnings management and audit quality as determinants/moderating variable for financial statements fraud in Indonesian listed firms during 2015 to 2019 period. The authors focused on infrastructure, utility and transportation sectors. In general, the study has been designed adequately to tackle the research questions and issues posed by the authors. However, there are some elements need to be addressed to improve the paper: Whilst the study provide adequate research background and institutional setting, it did not mention on why the study focuses on infrastructure, utility and transportation sectors? Is there any specific issues on that sector that related to financial statements fraud? In addition to that, why the study chooses 2015-2019 period?  The study should also discuss the reason choosing F-Score as its main measure for financial statement fraud. Why, for example, the study did not use, Beneish M-Score? Or other accounting irregularities measures in the literature?  The study needs to provide descriptive statistics table, so the reader can gauge and understand the dataset better. This should be provided before the authors arrive with the hypothesis discussion;  Given the study uses panel data (multi years, across different firms), is there any attempt to mitigate the issues of panel data regression? For example, using year-fixed effects or even using panel data regression analysis?  The manuscript need to be checked in terms of the quality of English write up. The title for example, is a little bit confusing, as it did not really represent what the study want to achieve in general.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "30 Jun 2023",
         null,
         null,
         null,
         null,
         null,
         "400",
         "0",
         "1",
         "0.7771",
         "0.11745495500000001",
         "0.9143848419",
         "220",
         "26.81",
         "14.2",
         "14.1",
         "14.9",
         "14.6",
         "0.016800000000000002",
         "96",
         "0",
         "0",
         "2",
         "0",
         "f1000"
        ],
        [
         "28",
         "81",
         "Emperatoor",
         "Toni-Šušak",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "25 Mar 2024",
         null,
         null,
         null,
         null,
         null,
         "909",
         "0",
         "5",
         "0.6798000000000001",
         "0.12259259260000001",
         "0.8569852710000001",
         "489",
         "50.12",
         "9.4",
         "10.63",
         "12.4",
         "10.8",
         "0.07200000000000001",
         "98",
         "0",
         "0",
         "0",
         "0",
         "f1000"
        ],
        [
         "29",
         "24",
         "Sajad-Ebrahimi",
         "Silvio-Buscemi",
         "1",
         "1",
         "unfactual",
         "negative",
         "polite",
         "extreme",
         "1",
         "3",
         "1",
         "2",
         "3",
         "3",
         "48",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         null,
         "07 Jan 2025",
         null,
         null,
         null,
         null,
         null,
         "280",
         "0",
         "1",
         "0.7857000000000001",
         "0.1403645833",
         "0.7798862457",
         "34",
         "24.27",
         "15.2",
         "16.6",
         "16.6",
         "16.3",
         "0.3225",
         "94",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "30",
         "77",
         "Mohammad-Hossein-Saliminabi",
         "Houcemeddine-Turki",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "85",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "This manuscript presents a novel rule-based approach for fact checking in knowledge graphs based on mining textual resources. The work provides new evidences that rule-based approaches can provide more precise evaluation of the accuracy of statements in knowledge graphs and can enhance the efficiency of embedding-based methods when combined with them. The availability of source codes and datasets in GitHub is an advantage for this work as this will allow the reproducibility of the described experimental study. However, there are several matters within the paper that should be addressed to ameliorate its final output: (i) Introduction: The \"Introduction\" seems to be a summary of \"Related Studies in Fact Checking\" rather than a proper introduction and contextualization of the paper. I propose to expand the part about misinformation fighting in the introduction to give better context for the development of this research paper. The authors can benefit from previous research papers about fact checking in general to develop the introduction of the paper. Several points in the introduction should be moved to Related Studies in Fact Checking. (ii) The paper did not emphasize the advantages of rule-based approaches when compared to embedding-based methods beyond having a better precision. Effectively, there are many other advantages of rule-based approaches. For example, the results of rule-based approaches can be more explainable than the ones of embedding-based approaches. Such advantages should be expanded and highlighted in the research paper. (iii) The paper did not emphasize the importance of having the datasets and source codes available in a specific GitHub repository. The authors should specify that this practice allows reproducibility and further development of the work by peers, particularly in the conclusion. (iv) The paper did not discuss the concept of reification in knowledge graphs. Effectively, several knowledge graphs add qualifiers to triples to provide a characteristic of the statements (i.e. {(s,p,o), p, o}. The authors should discuss the usefulness of the method to verify the qualifiers of the statements in the Discussion or as a future direction for this work. (v) The paper should evocate the robustness of the rule-based approach they proposed to adversarial attacks. This can be an advantage of the approach. (vi) There are several typos in the research paper (e.g. \"UC Berkely\" should be \"UC Berkeley\"). The authors should proofreading the paper to eliminate such deficiencies. (vii) The authors can expand the Discussion of the work (Part 5) to explain the strengths of KStream, KLinker, COPPAL, RUDIK, and PredPath that contributed to their efficiency as reported in the Experimental Study according to previous research papers. This can explicate the reasons of why the method developed by the authors was more efficient. (viii) The authors should provide future directions for the development of this work in the conclusion. Given this, I propose to accept this paper for publication after these six major revisions are applied.",
         null,
         "18/Feb/2021",
         null,
         null,
         null,
         null,
         null,
         "473",
         "0",
         "1",
         "0.7464000000000001",
         "0.1097294372",
         "0.9120528102000001",
         "4",
         "36.08",
         "12.7",
         "12.27",
         "13.7",
         "13.7",
         "0.2025",
         "97",
         "0",
         "0",
         "0",
         "0",
         "semanticweb"
        ],
        [
         "33",
         "67",
         "Emperatoor",
         "Reviewer-um1j",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "4",
         "5",
         "3",
         "4",
         "4",
         "70",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "The paper introduces a new method for molecular modeling, QuinNet, which incorporates five-body interactions using only dihedral angles. The authors first introduce relevant concepts related to machine learning force fields and related work in the field related to a variety of equivariant models. Next, the paper describes pertinent definitions of force fields, group equivariance, and methods for calculating empirical force fields. In the methods section, the authors describe their approach for integrating five-body terms into the architecture of QuiNet using only dihedral angles and incorporating model designs from prior work (PaiNN for 3-body interactions, ViSNet for 4-body interactions) and new definitions for different topologies of 5-body interactions. In addition to the architectural description, the authors provide relevant mathematical formulations and a complexity analysis. In their results, the authors showcase QuiNets performance on a low (MD17) and high complexity (MD-22) dataset in terms of energy and force modeling, including an ablation for different body terms in Figure 5. The paper has the following strengths:\n* Originality: The proposed architecture incorporates relevant terms for molecular modeling that are physically relevant, but have not been incorporated before.\n* Quality: The method and experimental design showcase relevant cases for applying GNN models for molecular modeling with the idea behind the architecture being well-motivated.\n* Clarity: The paper presents a cohesive formulation of their method, both in figures and mathematics, and experiment descriptions with relevant takeaways.\n* Significance: The proposed architecture shows improved modeling performance, especially in forces, and provides a potential framework for incorporating physical interactions into GNNs. The paper could be improved by the following:\n* Providing a clear and concise discussion of limitations. \\[Quality, Significance\\]\n* Adding more context for the results in Figure 4. The MD simulations are only briefly described in Section 5.1, which is on a different page then the figure and easy to miss. \\[Clarity\\]\n* A description of the case in which a greater set of many-body interactions is beneficial. This is briefly mentioned in the discussion between MD17 and MD22, but it would be good to put in greater context in terms of the experimental results and could serve as part of the conclusion. \\[Clarity\\] * Could you provide additional details on the limitations of QuinNet? E.g. Is it limited to modeling mainly molecular systems? What sizes of molecules do you think QuinNet can be effective in and why?\n* Do you have data that supports your compute complexity analysis compared to other methods? If so, what kind of speedup do you generally find, if any? The authors do not provide a discussion on limitations, which I raised as a weakness. I would like to see a discussion of limitations in future versions and/or during the discussion period.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337960",
         "7.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "452",
         "0",
         "1",
         "0.7681",
         "0.1465895563",
         "0.867398262",
         "215",
         "29.1615",
         "13.9768",
         "17.1852",
         "15.6791",
         "14.5327",
         "0.464",
         "93",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "34",
         "67",
         "Emperatoor",
         "Reviewer-YmDt",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "5",
         "4",
         "5",
         "5",
         "80",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "In this work, the authors propose to incorporate features from five-body interaction into machine-learning force field models and develop QuinNet. To efficiently incorporate such high-order information, the authors are motivated by the topology of many-body interactions and design sophisticated components. Experiments on several benchmarks are conducted to demonstrate the performance of QuinNet. 1. The target problem of this paper, the development of machine learning force field models, is of great significance. 1. **The motivation for the designed components of many-body interaction is puzzling**. As introduced in Section 4, the development of four-body interaction (improper torsions) and five-body interactions are based on the topology. First, such analysis is purely qualitative. The authors did not provide further completeness proof or quantitative evidence about these interaction schemes in real-world data. Second, the reasons for deriving Eq (4)-(9) are not well explained. It is suggested to clarify how these components are motivated according to the topology analysis.\n\n\n2. **On the experimental evaluation**. Additionally, there are several aspects of the experiments that are concerned:\n    - The empirical performance is not consistently better than other baselines. Among the evaluated benchmarks, the proposed QuinNet cannot outperform the baselines significantly. For example, in MD17, the newly developed five-body interaction modules do not significantly improve performance. In rMD17, the best performance is diversely distributed among the compared models. Overall, the experimental evaluation does not well demonstrate the power of newly developed modules.\n    - The computation efficiency evaluation is missing. Although the authors provide complexity analysis, it is better to further show the time/memory cost comparison between the proposed QuinNet and baselines. Besides, the model parameters should also be provided for all compared models.\n    - The scale of the chosen benchmarks is rather small. Both the dataset size and sample size (number of atoms) are limited. It is suggested to further evaluate the proposed QuinNet on large-scale benchmarks, e.g., Open Catalyst Project \\[1\\].\n    - The ablation study. First, as shown in Figure 5, the inclusion of Five-body@I even induces further errors, which would make readers curious about whether such a phenomenon generally exists. Second, as introduced in VisNet, the improper angle was also considered. The authors should add further discussions and empirical comparisons between it and the newly proposed four-body interaction (improper torsion).\n\n\n3. **The writing does not meet the requirement of an acceptable paper in this conference**. First, Section 3.2 can be thoroughly extended (e.g., in the appendix) to introduce the background of force fields and highlight the importance of torsion potential, improper torsions, and higher-order many-body interactions. Second, there lack of formal descriptions of QuinNet. Figure 3 can hardly be understood by readers that are not familiar with the related works in this area. \n\n\\[1\\] Chanussot L, Das A, Goyal S, et al. Open catalyst 2020 (OC20) dataset and community challenges\\[J\\]. Acs Catalysis, 2021, 11(10): 6059-6072.\n    -  Please refer to the Weakness section to address the concerns. The authors did not discuss the limitations of this work.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337859",
         "4.0",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "489",
         "2",
         "6",
         "0.7931",
         "0.0741489571",
         "0.8583066463000001",
         "215",
         "34.6703",
         "11.5877",
         "14.5989",
         "13.0672",
         "12.5916",
         "0.19390000000000002",
         "92",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "35",
         "67",
         "Emperatoor",
         "Reviewer-8RW7",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper aims to incorporate 5-body interactions into geometric deep learning models. They first analyze the topology of 5-body interactions and identify three 5-body angles. Then they propose an efficient way to incorporate these 5-body information into models. The complexity of the proposed QuinNet is still O(|N|), the same as many previous 2-body methods like PaiNN. The results are comparable to previous SOTA methods. This paper is well-written and easy to follow.\n\nThe experimental results show that the proposed method can perform well on most tasks. The ablation study in Section 5.4 and Figure 5 show that the proposed 5-body information indeed helps to model. See details in the Question part. 1. About the motivation:   \n this paper aims to incorporate 5-body interactions into geometric deep learning models. However, based on my understanding, using up to 4-body (torsions) interaction is already complete \\[1\\]\\[2\\] in terms of capturing the geometric structures. If this is correct, then why do we need these 5-body angles? In addition, if we can incorporate 5-body interactions, do we also need to incorporate 6-body interactions?\n\n2. About the complexity:   \nin Section 4.3, the authors claim that the complexity is O(|N|), as efficient as many 2-body methods like SchNet and PaiNN. But I think this complexity is not well explained. Using pseudocode/algorithm may be better to analyze the complexity. In addition to the analysis, I suggest the authors use some results to empirically verify the great efficiency compared to other baseline methods, e.g. the inference time, used memory, etc.\n\n3. About the tasks:   \nthis paper focuses on MLFFs, how about other molecular property prediction tasks, such as QM9 and OC20? I am wondering if this method is specially designed for MLFFs, or can be used on all 3D molecule tasks. In other words, why do the authors emphasize MLFFs? Is there any significant difference between MLFFs and other molecule property prediction tasks?\n\n4. Other related papers: many-body \\[3\\], MLFFs \\[4\\]\n\n5. The j, k in Figure 2 are confusing to me. For example, in (f), why not be i, j1, j2, j3, and k1?\n\n\\[1\\] ComENet: Towards Complete and Efficient Message Passing for 3D Molecular Graphs.  \n\\[2\\] GemNet: Universal Directional Graph Neural Networks for Molecules.  \n\\[3\\] On the Expressive Power of Geometric Graph Neural Networks.  \n\\[4\\] Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations. None",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337767",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "394",
         "8",
         "6",
         "0.77",
         "0.13857142860000002",
         "0.8948391676",
         "215",
         "48.9981",
         "9.5825",
         "12.3935",
         "12.0149",
         "9.7898",
         "0.1429",
         "92",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ],
        [
         "36",
         "67",
         "Emperatoor",
         "Reviewer-YYfR",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "70",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper introduces a machine learning force field that is a neural network with explicit interactions for up to 5-body terms.  The authors evaluate the model on a couple of public datasets and show demonstrate the competence or superiority of this new model compared to the state of the art in this field. The paper provides an important addition to a series of ever-improving machine learning potentials.  The contribution is clear and simple to understand at the high level, though the details are often unclear.  The benchmarks were compared against a set of reasonably strong published methods in this area.  In my opinion, if this work was presented in an unambiguously clear fashion and accompanied by code, it could be a strong contribution to this conference.  \n\n\\[The paper improved significantly following the first round of feedback from reviewers, so I'm raising my rating to a 7.\\] The complexity analysis is very limited.  How many total interactions did the typical molecule have as a function of their atoms, and how did the practical experimental complexity scale for the evaluation of these molecules.  One of the main reasons that 5-body terms were not used in traditional MD simulations was the poor scaling of the number of interactions one would need to calculate.\n\nThe MD simulation mentioned in section 5.1 and Fig 4 are not described anywhere.  The following sentences suggest that there would be some explanations in the supplement, but I couldn't find them: \"Additionally, we perform MD simulations using trained QuinNets as force fields and plot the distribution of interatomic distances h(r) for these 7 molecules in Fig. 4. Further details regarding additional settings can be found in the Supplementary Materials.\" \n\nThese sentences in the supplement, page2, are confusing or wrong: \"Similarly, five-body@III interaction (Fig. S1 (c)) is a special case of six-body interaction when nodes i and k4 in Fig. S1 (d) superpose each other. Thus, the QuinNet model captures all five-body interactions and a portion of six-body interactions, making it a versatile and comprehensive tool for modeling complex molecular systems.\"  There is no six-body interaction if two of the bodies are the same, and there is no physically acceptable case where two different atoms could superpose each other.\n\nThe code is not provided, so it is not possible for me to assess the reproducibility of this method.  The diagram in Figure 3 seems reasonable at the very high level, but it lacks the definitions of most of the terms annotated in the figure, thus rendering it confusing.  (What is $Y_l$? is it the set of all spherical harmonics $Y_{lm}$ for a given angular momentum $l$? What is $n_j$? What is $s_j$?  $W$?...) Could the authors add the presentation of the QM9 quantities estimated in the recent publication for Allegro?  (https://www.nature.com/articles/s41467-023-36329-y Table 3)\n\nHow long and how stable were the actual MD simulations?  What were the exact codes/protocols used?\n\nWhat is the practical performance of the model during evaluation? No potential negative societal impacts from this work.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337653",
         "7.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "497",
         "1",
         "2",
         "0.764",
         "0.0333794423",
         "0.8763324022000001",
         "215",
         "43.7997",
         "11.2658",
         "14.4335",
         "13.7657",
         "11.55",
         "0.1199",
         "109",
         "0",
         "1",
         "0",
         "1",
         "neurips"
        ],
        [
         "37",
         "171",
         "Sajad-Ebrahimi",
         "Magdalena-Czlapka-Matyasik",
         "1",
         "1",
         "unfactual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "35",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I commend the authors to contribute to this body of literature regarding the socio-demographic and lifestyle factors associated with understanding fast food consumption in Cambodia adults. The paper brings quantified information about the factors influenced by understanding fast food consumption. The authors revealed that poor and fair knowledge, insufficient exercise levels, and not getting enough sleep were predictors of inadequate understanding of the impact of fast food on health. Such conclusions do not bring entirely new knowledge to the literature, on this matter. Across the whole world population, the problems related to fast food consumption have been discussed. Nevertheless, I consider the work to be original, well designed and contribute knowledge to this field of public health research. My suggestions concern: In the introduction, the authors indicate the system of fast-food restaurants; it would be more attractive to explain, how it was developed in Cambodia directly?  What would be very interesting is information concerning the real take away or fast food intake in those groups. It must or might be in direct relation to this matter?  My main concern about the validation of the \"Level of knowledge of fast food consumption\": Could the authors explain the procedure? How were the questions selected and validated?  I regret that the authors discussed the interesting results in such a concise way.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         null,
         "12 Feb 2021",
         null,
         null,
         null,
         null,
         null,
         "361",
         "0",
         "1",
         "0.7773",
         "0.2011784512",
         "0.89415133",
         "137",
         "35.27",
         "13.1",
         "15.13",
         "15.1",
         "14.5",
         "0.1507",
         "99",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "38",
         "171",
         "Sajad-Ebrahimi",
         "Wanshui-Yang",
         "1",
         "0",
         "unfactual",
         "negative",
         "impolite",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "40",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript investigated the level of understanding of fast-food consumption among adults in Cambodia. The authors found that unsatisfactory levels of knowledge around fast food consumption were significantly associated with not taking regular exercise and sleeping less than eight hours per night. The results are interesting, but I have several comments. The authors should introduce the recent development of fast-food sector in Cambodia in the introduction part.  Is there an analysis of fast-food intake among these participants?  Interestingly, the authors found that not taking regular exercise and sleeping less than eight hours per night were associated with unsatisfactory levels of knowledge around fast food consumption. However, they were not well explained in the discussion part. In other words, the discussion part is a little too concise.  In addition, the education levels were not associated with the knowledge of fast-food consumption in the present study. I would like authors to discuss it and, at least, mention its possible causes.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "02 Mar 2022",
         null,
         null,
         null,
         null,
         null,
         "303",
         "0",
         "1",
         "0.7774000000000001",
         "0.1265046296",
         "0.9193514585",
         "520",
         "28.03",
         "13.8",
         "13.98",
         "14.7",
         "14.5",
         "0.1953",
         "97",
         "0",
         "1",
         "0",
         "0",
         "f1000"
        ],
        [
         "39",
         "187",
         "Emperatoor",
         "Reviewer-2CBB",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "4",
         "4",
         "4",
         "4",
         "4",
         "70",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "This paper introduce a novel unsupervised feature selection methods called GRSSLFS, which combine matrix factorization with self-representation subspace learning and apply graph regularization to preserve the geometric structure of the feature vectors. This method is proved to be effective in both theory and experiments. In this paper, the author introduce the problem of the redundant data in traditional self-representation, and then apply matrix factorization self-representation problem to achieve the goal to reduce the dimension of basis matrix. Here are some strengths of this article:\n\n1. This paper introduce a novel problem of redundant data in self-representation problems and then propose a method to solve this problem.\n\n2. Plenty of theoretical proof are given in the paper and appendix, the convergence analysis indeed increase the persuasiveness of the article.\n\n3. The proposed method was compared with a variety of comparison algorithms on multiple data sets, demonstrating the effectiveness of the method. However, there are still some weaknesses in this paper.\n\n1. In the end of Introduction section, the second and third contribution points is not sufficient, as these constraints of regularization are not proposed in this article. \n\n2. In the methodology section, some formula calculations are confusing and not very convincing. Such as the multiplication in formula (6) and the optimization target in the optimization goal (formula 7). These issues will be described in detail in subsequent questions 1 and 2.\n\n3. In the methodology section, the description of the algorithm is not complete enough. The specific process of selecting features according to the matrix U in Algorithm 1 has not been described in detail. 1. In the section of methodology, the equation (6) is confusing and not so clear. It seems impossible to subtract the matrix XUV of shape m*m from the matrix X with the shape m*n? \n\n2. As the feature matrix B is fixed by the VBE method proposed in section 3.3, it is unclear why the basis coefficient matrix G in equation (7) is a parameter to be optimized. Why the matrix G can not be determined by equation (4) directly and reduce the number of parameters.\n\n3. In section 3.1, subspace learning that introduces graph regularization seems to be existing methods. Should this part of the content be moved to related work?",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636201193",
         "6.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "376",
         "0",
         "8",
         "0.679",
         "-0.048046398000000004",
         "0.9640573859",
         "51",
         "40.0877",
         "11.9138",
         "14.3896",
         "13.5354",
         "11.9056",
         "0.0751",
         "99",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "40",
         "187",
         "Emperatoor",
         "Reviewer-yUvs",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "5",
         "3",
         "4",
         "3",
         "4",
         "75",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Authors of this paper propose graph regularized self-representation and sparse subspace learning (GRSSLFS) for unsupervised feature selection. The basis extension method is modified to select bases with highest variance score. These bases are used to build graph regularized self-representation learning and subspace learning. The graph regularized self-presentation learning and subspace learning are combined in terms of a set of selected bases from input space with the highest variance score. Experiments on various datasets demonstrate the advantage of the proposed method comparing with baselines. The ablation study also shows the necessity of each component. The subspace learning module is the key component, but its derivation from selected bases highly relies on the assumption that XU=B. This might not be hold if B is selected according to the proposed variance basis extension method. Moreover, the selection based on subspace learning module lacks of convincing explanation since G does not exactly represent X based on B as a fixed set of feature vectors. It is confusing to explain (4) as the self-representation problem if B is arbitrary basis matrix since they may not come from the input data matrix X.  Taking PCA for example, the columns of B are orthogonal, but they are not from the input feature space. Moreover, B defined as a square matrix of size m is inconsistent with the sleeted r bases in section 3.3.\n\nIn section 3.1, authors mentioned that two features have a similar structure in the feature space, and it is expected Bg_l and Bg_r have similar structure. What does the similar structure mean? How is the similarity measured? In other words, it is unclear how the matrix A is constructed. \n\nThe derivation in section 3.2 depends on the assumption that XU=B. As B is a set of feature vectors selected from input data, it is unclear whether the assumption still holds or not. Similarly for Theorem 3.1, it is trivial to have if the assumption holds. \n\nThe variance basis extension is to simply change the selection order of feature vectors in terms of variance score of feature vectors. It is possible that for each individual feature, the variance is high, but is it similar to say the largest amount of data dispersion? \n\nFor completeness, authors should describe the derivation process on how equations (9)-(11) are obtained. Since all three equations are fractional, is it possible that any of the denominators can be zero? How is it handled?\n\nIn Algorithm 1, the selected features are derived from U. However, U is not directly related to the input X instead to B and G, unless BG=X. However, B is selected feature vectors from input space. It is unclear why the assumption can hold. So why is the selection rule proper?\n\nThe computation complexity is quite high since it is quadratic to both the number of samples and the number of features comparing with most of baseline methods.\nThe application to the PneumoniaMNIST dataset is quite interesting. However, the way of presenting the outcomes can be improved significantly.  For example, what is the interested region? how many selected features are in the interested region? How do other compared methods perform? The validation is not quantified. How many radiologists are involved in the evaluation?  What is the performance measured? These plots shown in Fig. 2 delivers less useful information except that more red points are accumulated in the center when the number of selected features increases.",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636201025",
         "5.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "567",
         "0",
         "0",
         "0.7308",
         "0.0892117117",
         "0.9616214633000001",
         "51",
         "50.3623",
         "9.5106",
         "12.188",
         "12.0985",
         "9.3859",
         "0.0364",
         "93",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "41",
         "187",
         "Emperatoor",
         "Reviewer-PMap",
         "1",
         "3",
         "partially factual",
         "negative",
         "polite",
         "moderate",
         "2",
         "2",
         "2",
         "3",
         "3",
         "4",
         "30",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Considering there exists a major gap in the mathematical principles that underlie the self-representation based unsupervised feature selection approaches and their capacity to represent the feature space, this paper proposes Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), for the unsupervised feature selection, which expresses the self-representation problem based on the concept of “a basis of feature space” to represent the original feature space as a low-dimensional space made of linearly independent features. Experiments on widely-used datasets are conducted to validate the efficacy of the proposed method. 1. The computational complexity of the proposed GRSSLFS method is low, which is efficient for large-scale and high-dimensional data;\n2. The results of the proposed method seem better than other ones. 1. Most of the compared methods are out-of-date, only one method used for comparison was publised in 2023, other methods are before 2020;\n2. The motivation of the proposed method is not clear. In Eq.(8), the first three terms have been well explained, but the final regularization term has not been explained. See weakness.",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636200941",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "2.0",
         "172",
         "0",
         "4",
         "0.6699",
         "0.1067307692",
         "0.9783408642",
         "51",
         "26.959",
         "15.6033",
         "17.9681",
         "15.9032",
         "18.2121",
         "0.0945",
         "85",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "42",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-NRqK",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "5",
         "5",
         "5",
         "4",
         "5",
         "94",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes an algorithm for learning MDP state abstractions that preserve information needed for planning (namely, the values of states). A major differentiator from symbolic approaches is the idea that these state abstractions should be continuous rather than discrete. The key assumption is that you are given a set of options and a dataset obtained by rolling them out. Experiments are conducted in a few simple domains: pinball and antmaze, and demonstrate that the learned abstractions are sensible. The paper addresses an important topic (abstraction learning) and I appreciate the theoretically motivated algorithms. This line of work is of great interest to many attendees of ICLR. I also appreciate that the authors were clear about wanting continuous representations right off-the-bat. The math is also correct as far as I was able to tell, though I didn't check the proofs in the appendix in careful detail. Unfortunately, I recommend rejection for this paper due to 4 major reasons: 1) unconvincing experiments, 2) missing key citations to related work, 3) issues in technical details, and 4) unclear motivation.\n\n1) unconvincing experiments\n\nThe experiments in this paper are very basic and only serve as a simple proof-of-concept that the learned abstractions are somewhat useful. To really scale up the experiments to the level expected for a conference paper, I would expect to see evidence that the learned abstractions are useful in more hierarchical domains (e.g., classic domains from the options literature like keys and doors). In such domains, we could test whether the value-preserving property holds empirically, by comparing the values from planning under the abstract model to the (ground truth) values from planning under the true model.\n\nAdditionally, I would like to see comparisons to many more RL algorithms, especially hierarchical ones like HIRO (https://arxiv.org/abs/1805.08296), HVF (https://arxiv.org/abs/1909.05829), and Director (https://arxiv.org/abs/2206.04114). This is because at the end of the day, the authors are proposing to learn a state encoder $\\phi$, and despite all the theory that has gone into their algorithm, the question that must be answered is whether this $\\phi$ outperforms the encoders learned by all these other SOTA hierarchical RL algorithms.\n\n2) missing key citations to related work\n\nThe authors are missing several key citations, the most important of which is the line of work by David Abel, such as \"Near optimal behavior via approximate state abstraction\" (https://proceedings.mlr.press/v48/abel16.html) and \"Value preserving state-action abstractions\" (https://proceedings.mlr.press/v108/abel20a/abel20a.pdf). Those papers have very similar theory to what appears in this one, and so the novelty of the proposed approach is unclear. There are also less-famous but still important-to-cite papers from other authors, like \"Abstract value iteration for hierarchical reinforcement learning\" (https://proceedings.mlr.press/v130/jothimurugan21a/jothimurugan21a.pdf) and \"Deciding what to model: Value-equivalent sampling for reinforcement learning\" (https://proceedings.neurips.cc/paper_files/paper/2022/hash/3b18d368150474ac6fc9bb665d3eb3da-Abstract-Conference.html). It is important for the authors to contextualize the contributions of this paper against all these related works.\n\n3) issues in technical details\n\nThe authors say in Section 3.2 that when B = \\bar{B}, \"then simulating a trajectory in the abstract model is the same as in the ground model\". But I don't think this is true, because we need the rewards to match between the two trajectories too, and $B_t$ says nothing about rewards, only dynamics. The authors go on to say: \"Therefore, planning in the abstract model is accurate, in the sense, that the value of an abstract state z computed in the abstract model is the same as the one would get from trajectories from the ground MDP for the abstraction operator G.\" Again, I think this is wrong because it ignores the abstract reward function, which could be arbitrarily different from the ground one. In fact, in the proof of corollary 3.8, the authors assume $E_{s \\sim G(\\cdot \\mid z)}\\[R(s, o)\\] = \\bar{R}(z, o)$, and it's only _under this assumption_ that the claims hold. But combining this assumption on reward function with Definition 3.6 ends us back up at the bisimulation conditions, and then it's not clear what the contributions of this paper are.\n \nAs a separate point, the second term in the mutual information expression of Section 4.2, $MI(S'; Z, A)$, seems very extreme! It is saying that you have to be able to predict the entire ground next state from the current abstract state and action. Doesn't this means the abstraction can't lose any information? This seems like an important technical limitation of the approach.\n\n4) unclear motivation\n\nThe authors often state that a discrete abstract state space is bad, when pointing to work on symbolic abstraction learning (e.g., PDDL). But it's not clear why this is really bad. The authors say discrete abstract states are \"not applicable when planning with the available high-level actions requires a continuous state representation\", but this doesn't make sense to me, as the options have to act in the ground environment states, not in the abstract state space, and so the options could be defined with respect to either a discrete or a continuous abstract state space. Furthermore, it can be much easier to plan in a discrete abstraction (e.g., using powerful symbolic planners).\n\nI believe a fruitful research direction would be to compare the abstractions learned by a symbolic approach against the abstractions learned by a continuous approach (like the authors'). Questions:\n* Not much is said about the dataset $\\mathcal{D}$, but intuitively, it has to be \"good\" in order for the learned state abstraction to be reasonable. In particular, the agent must see all the options being executed in a variety of settings, and obtain good coverage over the state-action space. Are there any concrete statements we can make about what properties we need this dataset to have?\n* \"we must build a model of its effect\" Do you mean to say \"of the effect of each option\"?\n* \"with mean value equal to that by planning with the original MDP\" What is the mean over?\n* Why did we switch from using O (denoting the option set) everywhere to using A throughout Section 4? Shouldn't we continue to use O, unless I am misunderstanding something?\n* Section 4.3: Why should there be any cost/reward associated with executing skills? Shouldn't a sparse reward for reaching the goal be enough?\n* Eq 2: What are the \"I\" random variables inside the mutual information expression referring to?\n\nMinor edits:\n* \"make the same decision\" To clarify, we just need that the policy maps all states in z to the same action distribution. A stochastic policy isn't really committing to a \"decision\" about what action to take.\n* \"Abstractions alleviate this tension: action abstractions enable agents to plan at larger temporal scales and state abstractions reduce the complexity of learning and planning\" I would say that both of them do both of these. Action abstractions certainly reduce the complexity of planning, which is typically exponential in the branching factor.\n* \"learns a further abstraction\" --> \"learn a further abstraction\"\n* \"otherwise it is referred as learning\" I would say \"policy learning\" to distinguish from other things you might learn\n* \"when it is the given position\" --> \"when it is in the given position\"\n* \"referred as learning\" --> \"referred to as learning\"\n* \"results a bounded value loss\" --> \"results in a bounded value loss\"\n* In definition 3.5, the authors use $s_o$ in a few places where they mean $s_0$.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1699636621573",
         "3.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "1210",
         "7",
         "0",
         "0.7753",
         "0.0567315252",
         "0.9024221301",
         "49",
         "44.7468",
         "12.0287",
         "14.3535",
         "13.6208",
         "14.151",
         "0.6075",
         "100",
         "2",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "43",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-36E8",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "3",
         "3",
         "4",
         "4",
         "80",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper presents an approach for learning dynamics preventing abstractions for sensorimotor observation space. Given a set of high-level skills and the learned dynamics preserving abstractions, the paper claims to develop an approach for planning for a solution. \n\nThe approach is evaluated in two test domains where the paper shows the visualization of the learned abstractions. - For the most part of the paper, it is extremely well written. Given the wide use of embodied AI systems and robots, an approach that generates plannable abstractions for high-dimensional sensor input is extremely important. \n\n- The paper nicely motivates the problem. While the paper in general is nicely written, it has a few limitations: \n\n- The paper advocates learning a continuous abstract  representation instead of a symbolic abstractions. However, it does not provide any reasons to that. Why are continuous abstractions more desirable than symbolic abstractions? \n\n- Sec 4.1 is unclear. The notation for MI is a bit unclear. It needs to be made more clear. Sec 4.1 requires a re-writing including more explanation for the equation. I have two important questions: \n\n- How is the dynamics preserving abstraction defined in Def. 3.6 different from the Markovian abstractions defined in \\[Srivastava et al. 2016\\]? \n\n- Can you discuss the differences between the presented approach and \\[Allen et al. 2021\\] \n\nReference \n\nAllen, Cameron, et al. \"Learning markov state abstractions for deep reinforcement learning.\" Advances in Neural Information Processing Systems 34 (2021): 8229-8241.\n\nSrivastava, Siddharth, Stuart Russell, and Alessandro Pinto. \"Metaphysics of planning domain descriptions.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1699636621454",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "264",
         "1",
         "6",
         "0.7512000000000001",
         "0.1625",
         "0.8653070927000001",
         "49",
         "41.1434",
         "10.434",
         "14.1483",
         "13.0239",
         "10.9274",
         "0.2429",
         "100",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "44",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-dCJp",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "83",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper introduces a method for enabling general-purpose agents to efficiently handle complex tasks by constructing abstract models based on temporally-extended actions. These models facilitate more efficient planning and learning and are characterized using principled conditions. The approach provides empirical evidence of improved sample efficiency in goal-based navigation tasks and offers theoretical support for information maximization strategies in abstract state representation learning.\nThe authors claim that they introduced a method for creating abstract world models that empower agents to plan effectively for goal-oriented tasks. The key idea is to allow agents to construct reusable abstract models for planning with specific skills. This is achieved by characterizing the state abstraction that ensures planning without any loss in simulation, meaning that planning with the learned abstract model can generate policies for the real world. The paper also provides theoretical support for the use of information maximization as a reliable strategy for learning abstract state representations. - Good overview of the related work.\n- Good description of motivations and intuitions. \n- proper choice of environment settings. Major:\n- Some measures are used without definition, \n- It seems that there exists a lot of inaccuracies and impreciseness in the theories and definitions. See all questions!\n\nminor:\n- typos: \nlast paragraph of the introduction \"the *agents* needs\", definition 3.5 \"$s_{o}$\" must be \"$s_0$\"\n- writing: \nDefine the abbreviations before using them, e.g. \"PDDL\", \"VAE\"\n\nThere is a chance that I have not fully understood what this paper is trying to present. 1- What is $P(s'|s,o)$ used in the paragraph right after definition 3.1?\n\n2- An option $o$ is defined, and then you mention $T(s'|s,o)$ to define the transition probability of taking option $o$ in $s$? $T$ earlier was defined on action space $A$. How is it applied on options without showing the relationship of $I_o$ and $\\beta_o$ with $s$ and $s'$ under option policy $\\pi_o$?\n\n3-the paper has defined \"$\\bar {\\gamma} = \\gamma ^{\\tau (s,o)}$ is the abstract discount factor, $\\tau: Z \\times O \\rightarrow \\[0,\\infty)$, which consists of contradictory phrases. How is ${\\tau (s,o)}$ but defined as a function of abstract variables $Z$ instead of $S$? Not clear what $\\tau$ is. If based on definition 3.1, it is the option's execution time starting from $s$ taking option $o$, it is not clear how in definition 3.2 it becomes a map from $Z$ and $O$ to a non-negative real.\n\n4- What does definition 3.4 mean? $ \\Pi = {\\pi \\in \\Pi : \\pi(·|s) = \\pi (·|z) \\forall s \\in z}$ says the probability of taking actions/options in $s$ should be equivalent to the probability of taking actions/options in abstract states. Transitions of taking actions in states might take you to another state $s'$ inside the similar abstract state $z$. How can the policies used for both abstract states and states be equivalent? Unless you are just discretizing the continuous state spaces based on the optimal policies that are already given. Lots of interchangeable usage of symbols here. Not precise and is hard to follow.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1700688515580",
         "3.0",
         "4.0",
         "2.0",
         "3.0",
         "2.0",
         "499",
         "0",
         "1",
         "0.7308",
         "0.0796438834",
         "0.93872118",
         "61",
         "45.6397",
         "10.6743",
         "12.7405",
         "12.3848",
         "11.5416",
         "0.1463",
         "105",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "45",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-gKE9",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "none",
         "5",
         "4",
         "4",
         "4",
         "4",
         "5",
         "89",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes a grounded abstract model formulation with a dynamic preserving abstraction. This abstract state representation (and model) guarantees not only accurate future predictions but also the bounded values in the abstracted rollouts. This paper then provides its implementation using contrastive learning to maximize mutual information between the future state, and the current abstract state and option. The results show that training DDQN in imagination using the abstract model improves the sample efficiency. * The paper proposes a solid foundation of the abstract model that preserves dynamics and values.\n\n* The paper is well written.\n\n* The visualization in Figure 3 clearly shows that the abstract state representations focus on important features in the original observation space. * The main focus of the paper is to show the efficiency of planning and learning when using the proposed abstract MDP. The experiments in the paper are a bit simple to showcase the benefits of the abstract model for planning. It would be stronger if the experiment was done in more complex environments with much longer-horizon tasks, such as AntMaze experiments (Hafner 2022) or robotic manipulation tasks \\[a\\].\n\n* Similarly, the comparisons in Figure 5 are essentially between model-free RL (ground) and model-based RL (abstract), which does not seem fair. It might be fair to compare the proposed method with other model-based RL approaches, such as Dreamer and TD-MPC.\n\n* Exhaustive comparisons to the alternatives to the dynamics preserving abstraction would be interesting, such as bisimulation.\n\n* Some highly relevant works on temporally-extended models \\[a,b\\] are missing in the paper. Proper comparisons to these approaches are necessary.\n\n\\[a\\] Shi et al. Skill-based Model-based Reinforcement Learning. CoRL 2022\n\n\\[b\\] Zhang et al. Leveraging Jumpy Models for Planning and Fast Learning in Robotic Domains. 2023 Please address the weaknesses mentioned above.\n\n\n### Minor questions and suggestions\n\n* Figure 1 may want to explain why abstract state representations and options are helpful for planning and learning. However, Figure 1 does not seem to help understand the paper. To understand this figure, we first need to know about options and abstract state representations, and how they simplify planning.\n\n* In Section 4.2, it is unclear whether $\\mathcal{L}^T_{\\theta, \\phi}$ is used to update $f_\\phi$ or not.\n\n* For multi-goal experiments in the paper, using the same amount of environment steps for the abstract planning and the ground baseline would make it easier to understand how better or worse a method is.\n\n* The appendix could be included in the main paper for easier navigation.\n\n* What is the difference between Figure 7 and 8?\n\n* Training the abstract planning method longer in Figure 7 and 8 would be helpful to see how it learns. Using different x-scales for two methods is okay but it would be better to have the same scale.\n\n* Many minor typos in the paper.\n\n\n---\n\nThank you for author responses. I would love to see comparisons to Dreamer-like baselines, but couldn't find the results by the end of the rebuttal period. Thus, I keep my rating, borderline reject.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1701585748243",
         "5.0",
         "3.0",
         "2.0",
         "3.0",
         "3.0",
         "507",
         "0",
         "3",
         "0.7684000000000001",
         "0.1385185185",
         "0.9183520675",
         "71",
         "48.6501",
         "10.0612",
         "11.805",
         "12.0009",
         "10.6133",
         "0.8246",
         "107",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "46",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-xxEb",
         "2",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "50",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper introduces a novel model, PatchSynth, in the Patch-Text Pre-training (PTP) domain, aiming to improve software patch representation and description generation. Through a blend of patch understanding and generation, PatchSynth\t addresses the limitations of prior models. Empirical evaluations reveal its superior performance in patch description generation, with an ablation study further underscoring the importance of generating task training. Novelty and Importance: The work is first to propose a unimodel for patch-text understanding and related tasks. And the topic is very important in this domain.\n\n\tMelds patch understanding and generation, addressing prior models' specialization limitations.\n\n\tThe work provides a good representation and good results Unclear adaptability across diverse programming languages or coding standards. What are the considerations for deploying PatchSynth in real-world software development environments, and what infrastructure would be required for efficient and secure operation?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319846",
         "8.0",
         "5.0",
         "4.0",
         "3.0",
         "4.0",
         "136",
         "0",
         "0",
         "0.7967000000000001",
         "0.30636363640000003",
         "0.944865346",
         "50",
         "11.6712",
         "15.8547",
         "19.1529",
         "16.3736",
         "17.8235",
         "0.0364",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "47",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-4kdr",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "65",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper discusses a new model, PatchSynth, in the domain of Patch-Text Pre-training (PTP) which aids in accurate patch representation for software evolution tasks like bug fixing and feature enhancement. PatchSynth is designed to balance patch understanding and generation, overcoming limitations of previous models. It outperforms existing models in patch description generation, as shown in experiments using standard evaluation metrics. An ablation study further reveals the importance of generating task training in improving PatchSynth performance. Novelty:\nThe novelty of PatchSynth lies in its harmonious synthesis of patch understanding and generation, coupled with an advanced synthetic description generator. This innovative approach addresses the historical challenges of accurate patch representation and description generation, marking a significant stride in the PTP paradigm.\nImportance:\nThe topic is of paramount importance as it addresses a critical need in software engineering for accurate patch representation and description, which are pivotal for collaborative development, systematic documentation, and rapid code review processes. By advancing the PTP paradigm, PatchSynth not only contributes to the academic discourse but also holds promise for practical applications in software development workflows.\nThe work achieves promising results. The paper doesn't elucidate how PatchSynth adapts to varying programming languages or codebases with differing coding standards and structures. This lack of demonstrated adaptability could limit its applicability across diverse software projects, potentially requiring additional tuning or re-training to maintain accuracy and effectiveness in different environments. 1. Given the advancements in PatchSynth for patch-text understanding and generation, how well does the model perform in a transfer learning scenario? Can PatchSynth be fine-tuned or adapted effectively to related tasks in software engineering or different programming languages?\n2. Are there considerations or plans for deploying PatchSynth in real-world software development environments? How would the integration look like, and what kind of support or infrastructure would be required to ensure the model operates efficiently and securely in a production setting?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319768",
         "10.0",
         "5.0",
         "4.0",
         "4.0",
         "4.0",
         "310",
         "0",
         "2",
         "0.8356",
         "0.18839531680000002",
         "0.9401642680000001",
         "50",
         "9.2899",
         "17.0977",
         "21.428",
         "18.1715",
         "19.1841",
         "0.068",
         "90",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "48",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-H6rR",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "2",
         "80",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "This paper tackles the problem of code patch representation learning -- how to represent edits on code to support downstream tasks like commit message generation, patch correctness assessment, etc. \n\nThis paper proposes a pretraining framework, with triplet losses on text-code contrastive loss, text-code matching loss and text generation loss based on code patch. The pretraining data includes 90K pairs of code change and synthesized commit messages. \n\nOn downstream task of commit message generation upon FIRA\\[1\\] dataset, PatchSynth showed performance gains over public & self-ablation baselines.\n\n\\[1\\] Jinhao Dong, Yiling Lou, Qihao Zhu, Zeyu Sun, Zhilin Li, Wenjie Zhang, and Dan Hao. Fira: Fine-grained graph-based code change representation for automated commit message generation. 2022. 1. Unlike from previous approaches(CCRep\\[1\\], Cache\\[2\\]) where code change is encoded with two streams (code-before-change, code-after-change), this work encodes code change(patch) with a standard transformer on a single patch file (like git commit diff). This is inline with the general trend in LLMs community that ultimately LLMs should be able to understand and capture internal structure without explicitly modelling it.\n2. This paper applies representation pretraining with triplet losses -- which is quite known in multimodal pretraining domain (BLIP\\[3\\], BLIP-2\\[4\\], etc) -- to code patch representation. It empirically showed that such pretraining is helpful for downstream task of commit message generation.\n\n\n\\[1\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[2\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022.\n\n\\[3\\] Junnan Li, Dongxu Li, Caiming Xiong, & Steven C. H. Hoi (2022). BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. In ICML (pp. 12888–12900). PMLR.\n\n\\[4\\] Junnan Li, Dongxu Li, Silvio Savarese, & Steven C. H. Hoi (2023). BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models. In ICML (pp. 19730–19742). PMLR. I have multiple major concerns on the paper based on its current form. The most concerning issues are:\n\n1. The paper claims \"The core part of PATCHSYNTH lies a state-of-the-art synthetic description generator\" in multiple places (3rd paragraph of Introduction, 2nd contribution in last part of Introduction, Section 2.3). However, there is no details on this synthetic description generator. The only mention is Section 4.4 with just one line \"Capitalizing on benchmarks from seminal works\\[1,2\\], our dataset, primarily focused on Java samples includes 90,661 patches with their **attendant** descriptions\"\n\n    i. Are these **attendant** descriptions generated by the author but simply taken from \\[1,2\\]? If the latter, then claiming such synthetic description generation as a key feature in this paper is highly problematic.\n\n2. The task of representation learning of code patch, defaultly assigns 1 vector for a code patch (w/ 1 or more edits), which is the case for all previous works including CC2Vec\\[3\\], CCRep\\[4\\], Cache\\[5\\]. However, PATCHSYNTH seems to encode the code patch to a sequence of vectors (Figure 1). \n\n    i. Such change needs explicit explanation and justification which authors have failed to deliver.\n\n3. Missing LLM baselines: with code patch being encoded with a sequence of vectors, the authors should compare with code-aware LLMs like Code-llama, or WizardCoder, as they also encode code patch to a sequence of vectors. \n    \n    i. As the recent code-aware LLMs have shown great abilities in general instruction following in coding-related tasks, a very timely baseline would be applying code-aware LLMs to the downstream task of commit message generation, with few-shot prompting or finetuning. \n\n    ii. A comparison of PATCHSYNTH vs code-aware LLMs would very helpful for the community to understand the edge and relevance of the proposed method in LLM era, which the authors have failed to deliver.\n\n4. Only 1 downstream task evaluated: The authors claimed that the method is designed both for generative and discriminative tasks. However, the empirical experiments were only conducted on commit message generation. As the encoding changed from one vector to a sequence of vectors, it's important to show how can such encoding can be adapted to tackle retrieval or classification tasks. Also, to claim it as a pretrain model, the authors need to evaluate on multiple downstream datasets.\n\n5. Fairness in comparison: \n\n    i. Is PATCHSYNTH firstly pretrained on 90K and then finetuned on 75K data of FIRA? If so, it's not so fair to compare PATCHSYNTH with CCRep and FIRA methods, as they are not trained on 90K pretraining data. For example, Is it possible to also pretrain CCRep with 90K data?\n\n    ii. As mentioned in point 2, CCRep has a more compact encoding of 1 vector while PATCHSYNTH encodes to a sequence of vectors. It is thus not fair to compare without explicitly mentioning such differences.\n\n6. Concerns on Pretraining:\n\n    i. details of creating negative pairs: one common technique in contrastive training is hard-negative-mining. However, the authors didn't disclose how they create negative pairs\n\n    ii. For vision-language representation learning, a large batch size (>= 512) and a large pool to select negative examples have been shown to be necessary. This paper mentions the batch size of 32, which seems pretty small. I will need more verification on ablation of 1) batch size, 2) negative example selection and 3) pretraining metrics to be convinced that such setting is adequate for code-text representation pretraining. \n\n7. Writing & formatting issues\n\n    i. On page 8, the chart of Figure 2 is partially blocked by its top legend\n\n    ii. On page 8, the paragraph for \\[Performance cross different patch attention\\] is repetitive: it repeats twice in introducing the numerical performance. Besides, I don't think it's a good idea to verbosely list down all numbers when they are clearly seen in Figure 2.\n\n    iii. In Section 2.1, there's no mention on recent code aware LLMs like Code-LLaMA. \n\n    iv. In Section 2.3, there's no citation to any work. Besides, CCRep\\[4\\] doesn't have the gap mentioned in Section 2.3 as it can both do discriminative and generative tasks and it doesn't reply on AST information. So an explicit comparison to CCRep in Related Work should be present.\n\n\\[1\\] Robert Dyer, Hoan Anh Nguyen, Hridesh Rajan, and Tien N Nguyen. Boa: A language and infras\u0002tructure for analyzing ultra-large-scale software repositories. In 2013 35th International Confer\u0002ence on Software Engineering (ICSE), pp. 422–431. IEEE, 2013.\n\n\\[2\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[3\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[4\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[5\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022. 1. Why did you use CodeBERT to initiate both text encoder and decoder? For example, did you consider encoder-decoder model like Code-T5?\n\n2. In Experiment Setup, you mentioned \"Model dimensions are meticulously calibrated\". May I know how are the hyper-parameters searched? Are you using the downstream task performance or some pretraining metrics?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319680",
         "3.0",
         "4.0",
         "1.0",
         "1.0",
         "2.0",
         "1254",
         "27",
         "37",
         "0.7999",
         "0.069050849",
         "0.8986387253",
         "50",
         "47.6556",
         "10.3417",
         "13.0995",
         "12.7417",
         "12.905",
         "0.1651",
         "86",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "49",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-639w",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "90",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "Programs are frequently modified in commits, with the changes represented as program patches and often described with natural language text. This work proposes to finetune a pair of BERT encoders on the combination of such patches and their descriptions, introducing a three-fold loss. The resulting model is evaluated on a patch description generation task, where it outperforms recent baselines. This work focuses on an established and reasonably important task in software engineering, patch representation and description (or, commit message) generation. It uses a fairly conventional encoder-decoder architecture with additional loss terms for this. Its main contribution lies in the combination of these components, which evidently yields improved performance compared to prior work.\n\nThe results show improvements in the order of 5-10% (relative) compared to baselines, which, while still yielding relative low BLEU scores (~21%), might benefit the commit message generation work and tools with a stronger baseline. The methodology, including the architecture and loss terms, was relatively easy to follow. The technical contribution is very limited. The work connects two pretrained encoders (one for text and one for code) with cross-attention. Its main aim is to generate patch descriptions from the patch. It introduces two additional (but not novel) loss terms that provide a form of embedding alignment, both based on a contrastive loss. One of these appears to provide no significant benefit (DPC, Tab. 2). The setup is evaluated on a fairly small batch of mainly Java samples that appear to consist of a single patch with their associated commit message. These type of Github-scraped datasets tend to suffer from many low-quality descriptions that make it hard to meaningfully train and evaluate models and the set used in this work is no exception: the highest reported BLEU score is just 21.82%. The results corresponding to Fig. 2 show that precision/recall is about even across use-cases. As such, the work offers a useful, fairly off-the-shelf baseline for further experiments in this domain, but does not provide significant new insights or theoretical contributions.\n\nThis aside, the writing suffers from a range of problems. A number of claims about prior work are poorly motivated and several methodological details are poorly described. I list these below. More generally, the paper was quite hard to read. Many sentences include an unusual adjective or phrase that often feels overly subjective and out of place. Some examples from the first few pages: \"a profusion of research endeavors\", \"pronounced specification\", \"exhibit prowess\", \"offering an all-encompassing understanding\", \"not merely theoretical postulates\", \"Our approach transcends conventional methods\", \"avant-garde graph intention embedding\". It would greatly benefit the work to normalize the language, both reducing the use of highly subjective statements and replacing rare words with more commonly used synonyms.\n\nA number of issues:\n\n- P1: \"will lead to the emergence of..\" seems wrong. As noted shortly afterwards, Patch-Text (pre)training is already the subject of multiple studies. If the intent is to forecast that this particular paper will produce a new paradigm, I would strongly recommend removing this sentence.\n- P2: \"seldom both\" -- does this imply that it is sometimes studied jointly? If so, please provide citations.\n- P2: \"fraught with inconsistencies, particularly those integrated with Abstract Syntax Trees\" -- it is not at all clear what this means. Why are ASTs more likely to be/lead to inconsistencies? The mapping of code to ASTs is unambiguous.\n- Sec 3.1: the reference to a \"previous section\" seems wrong; these terms were not introduced before this point.\n- Sec 4.1: wrong notation in \"e - 4\". As written, this subtracts 4 from e.\n- Sec 4.1: how exactly where the dimensions \"meticulously calibrated\"? The two hyper-parameters mentioned next are standard. Were hyper-parameter sweeps conducted? Please share the results of those if so.\n- Sec 4.4: does this mean you combined the dataset of two prior papers, or used the same as theirs? If so, \"our dataset\" is wrong. If not, please elaborate on the process by which the dataset was constructed.\n- Sec. 5.1: the text under \"Outcomes\" says that FIRA outperforms PatchSynth on ROUGE-L (Tab. 1), which it does not.\n- P8: the example here seems wrong on several counts. The patch should delete the previous if-statement. The newly added line is missing \"&&\". The word \"SINGLE\" appears a few times in places where it doesn't seem to be grammatically correct for it to do so. Perhaps this is due to the odd line wrapping and indentation?\n- Fig. 2: the count values should not be connected with a line; this data is not sequentially related. Please discuss whether this work offers a concrete novel technical contribution or whether it should be mainly read as setting a new baseline for patch description based on existing methods. Consider the limitations noted above: one of the loss terms does not seem to have much impact, none of the loss terms are not novel, nor is tuning a cross-attention layer between pretrained models.\n\nPlease clarify some of the methodogical questions raised above, including where the dataset came from, whether any further processing was done, and if/how the hyper-parameters were tuned.",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319601",
         "3.0",
         "5.0",
         "2.0",
         "1.0",
         "1.0",
         "846",
         "0",
         "5",
         "0.8399000000000001",
         "0.027047884100000003",
         "0.9130145311000001",
         "50",
         "49.8575",
         "10.1328",
         "13.1341",
         "12.5867",
         "11.5162",
         "0.5586",
         "95",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "50",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-9sGD",
         "4",
         "4",
         "factual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "85",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "Main contributions of the paper are:\n\n- Proposes PATCHSYNTH, a novel pre-training framework for jointly learning patch and text representations. This allows the model to perform well on both patch understanding and generation tasks.\n- Implements an innovative synthetic description generator to capture semantics within patches. This aims to mitigate issues with inconsistent data sources like error-prone ASTs.\n- Uses a triple loss training strategy with losses for contrastive learning, matching, and generation. The joint training aims to harmonize the losses.\n- Sets new state-of-the-art results on patch description generation, outperforming existing methods on metrics like BLEU, ROUGE-L, and METEOR. This paper addresses the patch generation task, which is typically a difficult task in the software engineering domain. Adapting the triplet loss into the pretraining stage is somehow new. The first thing I notice is that the writing is very bad and uses unnatural words, such as \"Distinct from contemporary models, PATCHSYNTH is underpinned by a harmonious synthesis of patch understanding and generation. To steer clear of the pitfalls of excessive specialization, our model is designed to effortlessly switch between these two essential tasks\". This looks very similar to an AI assistant tool like ChatGPT generated. Can the authors confirm that the majority of the writing was generated by AI tools?\n\nThe related section lacks a lot of related work to patch generation tasks, such as commit message generation \\[1, 7\\], code summarization \\[4,5,6\\], and patch assessment \\[2,3\\]. It appears that the author did not conduct a thorough literature review before working on this topic.\n\nCan the authors highlight how the triplet loss contributes to the novelty of the paper?\n\nThe evaluation metrics are unclear; why are such metrics used for this task? Furthermore, the baselines used are weak and not carefully chosen. PatchSync should be compared to recent Code Large Language Models such as GPT 3.5, GPT-4, CodeGen \\[9\\], StarCoder \\[8\\], and others. I believe that simple prompting on these models can easily solve this task without using PATCHSYNTH. Finally, the benchmark datasets are old, and the purpose is not well explained due to poor writing.\n\nOverall, I believe that this paper is poorly written, lacks a novel contribution, and the literature is poorly performed. The experiments aren't much better. \n\n\n\\[1\\] Context-aware retrieval-based deep commit message generation, https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=7779&context=sis_research\n\n\\[2\\] Invalidator: Automated Patch Correctness Assessment Via Semantic and Syntactic Reasoning, https://ieeexplore.ieee.org/abstract/document/10066209\n\n\\[3\\] Zero-Shot Automatic Patch Correctness Assessment, https://arxiv.org/abs/2303.00202\n\n\\[4\\] Deep code comment generation, https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5295&context=sis_research\n\n\\[5\\] Just-in-time obsolete comment detection and update, https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=8772&context=sis_research\n\n\\[6\\] Retrieve and refine: exemplar-based neural comment generation, https://arxiv.org/pdf/2010.04459.pdf\n\n\\[7\\] Jointly Learning to Repair Code and Generate Commit Message, https://arxiv.org/abs/2109.12296\n\n\\[8\\] StarCoder: may the source be with you!, https://arxiv.org/abs/2305.06161\n\n\\[9\\] CodeGen2: Lessons for Training LLMs on Programming and Natural Languages, https://arxiv.org/abs/2305.02309 Why the evaluation metrics are used for this task?\n\nCan you provide comparison with Code Large Language Models?\n\nWhy the triplet loss is novel for this task?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319498",
         "1.0",
         "5.0",
         "2.0",
         "1.0",
         "1.0",
         "480",
         "23",
         "0",
         "0.8239000000000001",
         "0.0002152802",
         "0.9607024193",
         "50",
         "33.101",
         "11.9272",
         "13.5242",
         "12.6026",
         "15.7863",
         "0.43510000000000004",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "51",
         "28",
         "Muhan",
         "Reviewer-xyNq",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "4",
         "3",
         "3",
         "4",
         "5",
         "60",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper considers the problem of certifying individual fairness (IF), which is of great importance to reliable machine learning algorithms. To this end, the authors propose a novel convex relation of IF constraints that greatly reduces the computational cost. In addition, the authors propose to certify distributional individual fairness, ensuring that the neural network has guaranteed individually fair predictions for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball. 1. This paper is technically sound.\n2. The extensive experiments validate the effectiveness of the proposed methods. The paper studies individual fairness and distributional fairness. To my opinion, the two topics seem to be independent. However, it is possible that I misunderstand this paper. It would be better if the authors can present more relations between these topics. ## Miscellaneous\n1.\tLine 106: feed forward $\\to$ feedforward\n2.\tLine 168: $d$ is indeed a vector; however, the denotation $\\sqrt{d}$ should be defined more specifically.\n none",
         "['~Matthew_Robert_Wicker1', '~Vihari_Piratla1', '~Adrian_Weller1']",
         "1702411365184",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "2.0",
         "156",
         "0",
         "5",
         "0.8035",
         "0.28125",
         "0.9500498772",
         "215",
         "29.3366",
         "12.668",
         "14.9267",
         "13.8858",
         "13.1206",
         "0.1213",
         "96",
         "0",
         "0",
         "0",
         "0",
         "neurips"
        ]
       ],
       "shape": {
        "columns": 45,
        "rows": 454
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>assessor</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>Comprehensiveness</th>\n",
       "      <th>Usage_of_Technical_Terms</th>\n",
       "      <th>Factuality</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Politeness</th>\n",
       "      <th>Vagueness</th>\n",
       "      <th>Objectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-7mFW</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>16.1503</td>\n",
       "      <td>14.3268</td>\n",
       "      <td>14.1695</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-FAWm</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4394</td>\n",
       "      <td>13.7425</td>\n",
       "      <td>12.4851</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-kjkr</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4014</td>\n",
       "      <td>13.2462</td>\n",
       "      <td>12.1773</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Enrico-Daga</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>17.4100</td>\n",
       "      <td>16.6000</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Julia-Bosque</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>15.2000</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-s437</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16.7770</td>\n",
       "      <td>15.2830</td>\n",
       "      <td>14.4355</td>\n",
       "      <td>0.1585</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-mMGf</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>negative</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2389</td>\n",
       "      <td>13.9012</td>\n",
       "      <td>12.9422</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-AtQ2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5281</td>\n",
       "      <td>13.2950</td>\n",
       "      <td>12.5392</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-v6cq</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13.6019</td>\n",
       "      <td>12.7451</td>\n",
       "      <td>10.7297</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>5</td>\n",
       "      <td>Sonny</td>\n",
       "      <td>Alison-Kutywayo</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3900</td>\n",
       "      <td>15.2000</td>\n",
       "      <td>15.1000</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id         assessor         reviewer  Comprehensiveness  \\\n",
       "0         166   Sajad-Ebrahimi    Reviewer-7mFW                  2   \n",
       "1         166   Sajad-Ebrahimi    Reviewer-FAWm                  4   \n",
       "2         166   Sajad-Ebrahimi    Reviewer-kjkr                  3   \n",
       "3         100            Seyed      Enrico-Daga                  3   \n",
       "4         100            Seyed     Julia-Bosque                  5   \n",
       "..        ...              ...              ...                ...   \n",
       "500        75  Ali-Ghorbanpour    Reviewer-s437                  3   \n",
       "501        75  Ali-Ghorbanpour    Reviewer-mMGf                  4   \n",
       "502        75  Ali-Ghorbanpour    Reviewer-AtQ2                  5   \n",
       "503        75  Ali-Ghorbanpour    Reviewer-v6cq                  2   \n",
       "504         5            Sonny  Alison-Kutywayo                  3   \n",
       "\n",
       "     Usage_of_Technical_Terms         Factuality Sentiment_Polarity  \\\n",
       "0                           4            factual            neutral   \n",
       "1                           4            factual            neutral   \n",
       "2                           4            factual            neutral   \n",
       "3                           2            factual           positive   \n",
       "4                           4            factual           positive   \n",
       "..                        ...                ...                ...   \n",
       "500                         3  partially factual            neutral   \n",
       "501                         4            factual           negative   \n",
       "502                         4            factual           positive   \n",
       "503                         3  partially factual           positive   \n",
       "504                         4            factual            neutral   \n",
       "\n",
       "    Politeness Vagueness  Objectivity  ...  gunning_fog  smog_index  \\\n",
       "0       polite      high            4  ...      16.1503     14.3268   \n",
       "1       polite      none            4  ...      15.4394     13.7425   \n",
       "2       polite       low            4  ...      14.4014     13.2462   \n",
       "3       polite      none            4  ...      17.4100     16.6000   \n",
       "4       polite       low            4  ...      14.3000     15.2000   \n",
       "..         ...       ...          ...  ...          ...         ...   \n",
       "500     polite       low            2  ...      16.7770     15.2830   \n",
       "501     polite      none            4  ...      14.2389     13.9012   \n",
       "502     polite      none            4  ...      13.5281     13.2950   \n",
       "503     polite  moderate            3  ...      13.6019     12.7451   \n",
       "504     polite  moderate            4  ...      15.3900     15.2000   \n",
       "\n",
       "     automated_readability_index  politeness_score  hedge_C  hedge_D hedge_E  \\\n",
       "0                        14.1695            0.0999       88        0       0   \n",
       "1                        12.4851            0.1565       89        0       0   \n",
       "2                        12.1773            0.1507       93        0       0   \n",
       "3                        15.5000            0.1149      100        0       0   \n",
       "4                        14.0000            0.2025      108        0       0   \n",
       "..                           ...               ...      ...      ...     ...   \n",
       "500                      14.4355            0.1585       82        0       1   \n",
       "501                      12.9422            0.1100       88        0       1   \n",
       "502                      12.5392            0.9014       83        0       0   \n",
       "503                      10.7297            0.1108       97        0       0   \n",
       "504                      15.1000            0.9417      102        0       0   \n",
       "\n",
       "    hedge_I hedge_N        venue  \n",
       "0         0       0         iclr  \n",
       "1         0       0         iclr  \n",
       "2         0       0         iclr  \n",
       "3         0       2  semanticweb  \n",
       "4         0       0  semanticweb  \n",
       "..      ...     ...          ...  \n",
       "500       0       0      neurips  \n",
       "501       0       0      neurips  \n",
       "502       0       0      neurips  \n",
       "503       0       0      neurips  \n",
       "504       0       0        f1000  \n",
       "\n",
       "[454 rows x 45 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with Anonymous reviewers\n",
    "df_human_vs_metric = df_human_vs_metric[~df_human_vs_metric['reviewer'].str.contains('Anonymous')]\n",
    "df_human_vs_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3880991/3083477036.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_human_vs_metric['hedging'] = 1 - (df_human_vs_metric['hedge_C'] / (df_human_vs_metric['hedge_C'] + df_human_vs_metric['hedge_D'] + df_human_vs_metric['hedge_E'] + df_human_vs_metric['hedge_I'] + df_human_vs_metric['hedge_N']))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "assessor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_soundness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_presentation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_contribution",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hedging",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b03d0bdf-c6c2-445d-96c4-b5eafb480e46",
       "rows": [
        [
         "0",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-7mFW",
         "2",
         "4",
         "factual",
         "neutral",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "67",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This work focuses on the Q-function value overestimation issue. Observing that the overestimation issue will latter becomes underestimation during the learning process. Thus motivated, this work proposes the Blended Exploitation and Exploration (BEE) operator to take advantage of the historical best-perforation actions. The proposed operator is then used in both model-free and model-based settings and show better performance than previous methods. 1. The proposed BEE operator utilizes the Bellman exploitation operator and exploration operator to address the under-exploitation issue. The proposed operator can be easily incorporated into the RL algorithms.\n2. The experiments show that the proposed operator can effectively reduce the estimation error and achieve better performance comparing with other RL algorithms. 1. The terminology can be misleading. The overestimation issue in the Q-value approximation generally is due to the changing order of expectation and $\\max$. It is incorrect to say that  the $Q$-function will have \"underestimation when encountering successes\" in Fig 1 (a). The authors need to clarify the context and difference of the statement in order to avoid confusion.\n2. In order to investigate on the under-exploitation, the metric $\\Delta(\\cdot,\\cdot)$ is defined on the current Q-function approximation. Intuitively,   $\\Delta(\\cdot,\\cdot)$ shows that the current Q-function approximation can be either overestimate or underestimate given different policy, i.e., $\\mu_k$ and $\\pi_k$. It is unclear what is the meaning of this metric. Considering most of the algorithm will update the policy and Q-function approximation at the same time, e.g., Actor-Critic, the Q-function should be evaluated under the current policy instead of the policy obtained earlier. The authors need to clarify why the definition here makes sense for the under-exploitation investigation. See the weakness above.",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1699636492844",
         "6.0",
         "3.0",
         "3.0",
         "2.0",
         "2.0",
         "273",
         "0",
         "5",
         "0.7173",
         "0.12450980390000001",
         "0.8775630593",
         "49",
         "22.7412",
         "0.0999",
         "iclr",
         "0.0"
        ],
        [
         "1",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-FAWm",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "5",
         "5",
         "5",
         "4",
         "86",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This paper presents the Blended Exploitation and Exploration (BEE) operator, which addresses the issue of value underestimation during the exploitation phase in off-policy actor-critic methods. The paper highlights the importance of incorporating past successes to improve Q-value estimation and policy learning. The proposed BAC and MB-BAC algorithms outperform existing methods in various continuous control tasks and demonstrate strong performance in real-world robot tasks. - The paper addresses an important issue in off-policy actor-critic methods and proposes a novel approach to improve Q-value estimation and policy learning. \n- The BEE operator is simple yet effective and can be easily integrated into existing off-policy actor-critic frameworks.\n- The experimental results demonstrate the superiority of the proposed algorithms in various continuous control tasks and real-world robot tasks. 1. The novelty of the proposed approach is limited. \n2. The choice of $\\lambda$ is largely empirical and requires extra manipulation in new tasks.\n3. The paper only provides basic theoretical analysis, such as the accurate policy evaluation and the guarantee of policy improvement. The benefit of linearly combining two Q-value functions is not discussed theoretically.\n4. The experiments are conducted in continuous control tasks with dense rewards. The exploration ability can be better evaluated in environments with sparse rewards.\n5. There is a lack of discussions with related papers (See Question 3). 1. Emprically, the BAC algoithm will only be more efficient in exploiting the replay buffer. The exploration still rely on the maximum-extropy formulation in SAC. Then why can BAC perform significantly better than SAC in failure-prone scenarios such as HumanoidStandup, as if BAC can better explore the unknown regions?\n2. Can you discuss or exhibit the performance of BAC in some tasks with sparse rewards? This can demonstrate the generalizability of the proposed approach.\n3. What are the advantages of BAC compared with prioritized replay methods \\[1,2\\] or advantage-based methods \\[3\\]? These methods are related to BAC in that they also exploit the replay buffer with inductive bias, so they should be mentioned in the paper.\n\n\\[1\\] Sinha, S., Song, J., Garg, A. &amp; Ermon, S.. (2022). Experience Replay with Likelihood-free Importance Weights. Proceedings of The 4th Annual Learning for Dynamics and Control Conference.\n\n\\[2\\] Liu, X. H., Xue, Z., Pang, J., Jiang, S., Xu, F., & Yu, Y. (2021). Regret minimization experience replay in off-policy reinforcement learning. Advances in Neural Information Processing Systems, 34, 17604-17615.\n\n\\[3\\] Nair, A., Gupta, A., Dalal, M., & Levine, S. (2020). Awac: Accelerating online reinforcement learning with offline datasets. arXiv preprint arXiv:2006.09359.\n\n\nI am willing to raise my score if my concerns for weaknesses and questions are adequately discussed.",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1700565416102",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "432",
         "8",
         "14",
         "0.7996000000000001",
         "0.1588311688",
         "0.8829935789000001",
         "60",
         "31.9755",
         "0.1565",
         "iclr",
         "0.0"
        ],
        [
         "2",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-kjkr",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "5",
         "5",
         "4",
         "5",
         "75",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "Motivated by the problem of underestimating values in the training of SAC, this paper introduces the Blended Exploitation and Exploration (BEE) operator, which calculates the TD target based on a combination of the standard TD target and a high expectile of the return distribution. The authors integrate this operator in both model-free and model-based scenarios, followed by a comprehensive experimental evaluation. 1. The paper contains extensive experiment results on both simulation and real-world environments.\n2. The paper is written clearly and easy to follow. Figure 1 provides a decent visualization of the underestimation issue. 1. The BAC method tunes its $\\lambda$ and $\\tau$ differently for tasks in MuJoCo and DMC (Table 1 & 5). It's questionable to claim superiority over other state-of-the-art (SOTA) methods like SAC and TD3, which use consistent hyperparameters (HP) across tasks. Adjusting HP for each task can inflate results as seen in Figure 5, which can be misleading. Why not showcase the automatic $\\lambda$ tuning methods from Appendix B.3.3 in the main text if they're effective?\n\n2. Figure 23 reveals that SAC, without the double-Q-trick, still underestimates in the Humanoid task. It's unclear if this is universally true. More convincing results would come from testing this across multiple tasks and providing absolute Q value estimates. I still suspect that Q underestimation largely stems from the double Q techniques, as suggested by the RL community \\[1\\]. For instance, OAC \\[1\\] introduces $\\beta_{\\text{LB}}$ to manage value estimation issues.\n\n3. Presuming the Q value underestimation problem is widely recognized (which I invite the authors to contest), the paper seems to lack innovation. The BEE operator, at its core, appears to be a fusion of existing Bellman operators.\n\n4. The statement \"BEE exhibits no extra overestimation\" seems conditional on specific $\\lambda$ and $\\tau$ values. For instance, using $\\lambda = 1$ and $\\tau = 1$ could induce overestimation.\n\n\\[1\\] Ciosek, Kamil, et al. \"Better exploration with optimistic actor critic.\" Advances in Neural Information Processing Systems 32 (2019). See Weakness",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1700668216355",
         "6.0",
         "5.0",
         "3.0",
         "4.0",
         "2.0",
         "328",
         "4",
         "8",
         "0.8027000000000001",
         "0.1464980159",
         "0.8531657457",
         "61",
         "35.3958",
         "0.1507",
         "iclr",
         "0.0"
        ],
        [
         "3",
         "100",
         "Seyed",
         "Enrico-Daga",
         "3",
         "2",
         "factual",
         "positive",
         "polite",
         "none",
         "4",
         "5",
         "4",
         "4",
         "4",
         "4",
         "80",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "The authors have performed significant changes to the content, which significantly improve the article with respect to the previous submission. Following the four SWJ criteria for survey articles, the current version is indeed a good (1) introductory text, targeted at researchers, PhD students, or practitioners, to get started on the covered topic.  The addition of a methodology section gives reasonable justification for (2) how comprehensive and how balanced are the presentation and coverage. However, a few more details about the sources of the survey would be useful, especially if mentioning keywords and phrases used in the search (Scopus? Google Scholar? Microsoft Academia? …). In addition, it is still a bit opaque what is intended with \"refining and balancing the structure of the covered areas\" - end of Section 2. However, I consider these minor issues that can be fixed during the preparation of the camera-ready. Finally, the article is readable and clear (3) and the content is relevant to the community (4).",
         null,
         "21/Sep/2021",
         null,
         null,
         null,
         null,
         null,
         "162",
         "0",
         "1",
         "0.8103",
         "0.1645833333",
         "0.6678649187",
         "60",
         "31.31",
         "0.1149",
         "semanticweb",
         "0.019607843137254943"
        ],
        [
         "4",
         "100",
         "Seyed",
         "Julia-Bosque",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "5",
         "4",
         "87",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "I reviewed a previous version of this manuscript, for which I recommended a major revision based on the need for a clearer motivation, scope and limitations of this effort, as well as on the structure and flow of the paper at that time. In this new version the authors have addressed all my highlighted concerns: - The motivation, scope and limitations are clearly defined - The interplay between the different sections is elaborated and illustrated with a workflow diagram that facilitates reading. There are numerous references to this workflow and interlinks between the sections, resulting in a cohesive document. - More context is provided in the introductory paragraphs of each section, and the project in which this effort is carried out is clearly introduced. The relation of each section/topic with respect to the overall topic of the survey is now explicit. - The authors have improved the categorization of tools and approaches. - The tables in the appendix summarize the main approaches, tools and resources surveyed according to the proposed classification.  Taking into account these modifications, I maintain the reasons upon which I based the recommendation for acceptance in terms of the criteria for surveys: - The topic of the paper, at the intersection of humanities and the Semantic Web, is interesting and relevant for the advancement in a line of research which poses numerous challenges. - The quality of writing is good and the survey is well balanced, with a broad coverage encompassing theoretical standpoints and approaches, tools, repositories and datasets. - The granularity and length are also appropriate for the text to serve as an introductory text. Minor comments for improvement: - The authors have provided details on the methodology for the survey, indicating the different stages in the generation and keywords used in literature search. There is no explicit reference to a filtering process after those keyword-based search results, was there any filtering step? If so, which criteria were applied? - In table 3, the included resources diverge in their nature, so the current list groups together LLOD Cloud, Lila Etymological Lexicon, LingHub, and Diachronic semantic lexicon of Dutch, etc. for example. I suggest including a mark here to distinguish which resources are particularly relevant for diachronic analysis, in contrast to general LLOD resources (e.g. Lila Etymological Lexicon vs. LLOD cloud and LingHub). - The authors of [12], referenced on p. 5, mention Lemon (Lexicon Model For Ontologies), and in their diagrams (in Github)  they seem to be using OntoLex-Lemon, not its ancestor. Throughout this survey \"OntoLex-Lemon\" is the term used to refer to the 2016 Specification as the outcome of the W3C Ontology-Lexica Community Group, so for that bib. reference I would recommend to replace the mention of \"Lemon\" with \"OntoLex-Lemon\" for consistency in the whole document. *Typos*: l.19, .p. 19, right column, \"A combined resource like this, allows...\" → remove comma p. 20, l. 1, right column → remove \"(linguistic)\", already covered by the first L in LLOD Appendix tables, Table 4. → word embeddings (add pl. \"s\")",
         null,
         "04/Oct/2021",
         null,
         null,
         null,
         null,
         null,
         "503",
         "1",
         "5",
         "0.7741",
         "0.1697330447",
         "0.8522429466",
         "73",
         "34.66",
         "0.2025",
         "semanticweb",
         "0.0"
        ],
        [
         "5",
         "100",
         "Seyed",
         "Thierry-Declerck",
         "3",
         "1",
         "partially factual",
         "positive",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "4",
         "3",
         "4",
         "60",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "Not really a lot to add. I see that the revised version of the submission was taking good care of former comments and suggestions. Just a minor point: 1) Ensure that footnotes are always placed after the punctuation signs (for consistency across the paper, se fn 2 and 3 which are not placed consistently). So, very few corrections to do.",
         null,
         "05/Nov/2021",
         null,
         null,
         null,
         null,
         null,
         "60",
         "0",
         "0",
         "0.81",
         "0.058",
         "0.6966200471",
         "105",
         "64.71",
         "0.0548",
         "semanticweb",
         "0.0"
        ],
        [
         "6",
         "74",
         "Sonny",
         "Reviewer-HZXU",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "3",
         "80",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies how to train NeRF with the optimal training set under limited view inputs for novel view synthesis. It proposes a theoretical framework for view sampling strategies from a causal perspective, finally decomposing the objective into three components: a fitting term similar to traditional NeRF training loss, a consistency term requiring consistency between visible and invisible views, and a uniformity term demanding the sampling to be diverse. The proposed sampling strategy induces higher-quality NeRFs and can be used as regularization term for general NeRF training. 1. Framing the novel view synthesis problem via a causal perspective is novel. \n2. The deduced supervision objective with three terms is intuitive and well-explained. \n3. Experiments demonstrate that based on the proposed sampling strategy better performance could be achieved with the same number of training views, using the principles as a regularization term to the training of general term could also improve performance. 1. Although the derived supervision objective is intuitive, the framing of novel view synthesis problem with causal framework is a bit obscure with mistakes: e.g. page 5 the authors mentioned \"we defer the details to the Appendix\" which do not exist, Eq. 4 in page 6 is also falsely rendered. \n2. Two variants of the model are proposed (prioritizing consistency and uniformity term differently) without a consistency in which one would perform better which may limit the usability. 1. in Appendix Tab. 1, ActiveNeRF acquires better results 3/8 on ficus, materials and ship, are there any explainations for this? \n2. Could some qualitative comparisions with DietNerF (which would show the effects of uniformity loss only) be povided ?",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108591",
         "5.0",
         "3.0",
         "2.0",
         "2.0",
         "2.0",
         "269",
         "0",
         "7",
         "0.7805000000000001",
         "0.0904761905",
         "0.8525229096",
         "52",
         "32.8096",
         "0.1303",
         "iclr",
         "0.0"
        ],
        [
         "7",
         "74",
         "Sonny",
         "Reviewer-itVg",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "4",
         "85",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "The authors introduced a view sampling strategy for novel view synthesis, grounded in the perspective of causal representation learning. They identified three key metrics to assess sampling performance: the fitting term, the consistency term, and the uniformity term. Additionally, they presented a novel theoretical framework addressing the sampling challenge within NeRF. 1. The introduction of the causal perspective in the view sampling algorithm holds significant potential and could serve as a foundational approach for future research in this domain.\n2. The authors meticulously lay out a comprehensive mathematical framework that not only elucidates the underlying problem but also leads to the derivation of the three pivotal terms central to their methodology.\n3. The paper stands out for its clarity and coherence, ensuring that readers, regardless of their expertise level, can grasp the concepts and findings presented.\" 1. The rationale behind the view-sampling task raises questions. In certain scenarios, acquiring additional view images can be challenging. However, when a substantial number of dense views are already available, the motivation to devise a sampling strategy for training the neural rendering model with sparse views appears insufficient. Specifically, the activeNeRF model's primary objective is to identify the most optimal camera view for capturing the training image, rather than selecting from a plethora of pre-existing images.\n2. The paper's primary contribution seems to be the introduction of a metric or loss function to evaluate the selected views. However, the absence of an ablation study that separately assesses the impact of each of these three terms is a missed opportunity for deeper understanding. As a result, the contribution feels somewhat lacking in depth.\n3. The proposed loss function presents challenges in differentiability with respect to 't'. The sampling proposal, derived from the farthest sampling strategy, may not be the most efficient approach. It appears to demand significant training resources, resulting in elevated training costs. The potential enhancements in model performance might not justify the trade-off in terms of the increased training time and resource allocation. Please see the weakness above.",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108511",
         "5.0",
         "2.0",
         "3.0",
         "3.0",
         "1.0",
         "335",
         "0",
         "6",
         "0.7966000000000001",
         "0.1848602484",
         "0.9041278958000001",
         "52",
         "29.0988",
         "0.1431",
         "iclr",
         "0.009803921568627416"
        ],
        [
         "8",
         "74",
         "Sonny",
         "Reviewer-bNPg",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "3",
         "4",
         "4",
         "3",
         "90",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies the view sampling strategies of Nerf reconstruction from a causal perspective. The authors try to solve the problem using a small subset of photos from a total of K potential views, to achieve the best reconstruction. To solve this, the authors propose to use causal represntation learning using loss by Identification Treatment Effect. They propose three terms, a normal fitting term as reconstruction loss, a consistency term to ensure consistency between visible views and invisible views and a uniformity term requires the samples to be distributed evenly. The results show the proposed strategy can provide slightly better reconstruction compared to alternative baselines in the proposed setting. * The paper proposes a novel perspective to study the view sampling problem in volumetric reconstruction using NeRF as an example. This take-away can potentially also generalize other multiview reconstruction algorithms. \n* Given its current setting, the hypothesis is validated on nerf reconstruction datasets, with small improvement compared to its baselines. * The presentation of this paper could be greatly improved. I may not have understand a lot of details correctly given its current presentation. \n  * It is very hard to read without being very familiar with ActiveNeRF and casual representation learning. Have to trace to original papers for more details. This could be added to the preliminary parts. \n  * Too many notations which makes things more complicated than needed. I don't think I found how exactly the loss of consistency term and uniformity term were calculated in (8) at runtime. As I understand, the method should be as simple as calculating the reconstruction loss using different groups of input samples. Provide an algorithm chart of how of how P^{F}, P^{hat}^{CF} and P^{CF} will greatly help. \n  * There are some notations introduced in 4.1 (e.g. P(Y|do(d))) are not explained until 4.2. \n* Overall I am not sure I understand the real-world impact of this paper using the proposed strategy. Maybe I had some misunderstanding in the details given my concern on its presentation. Please correct me if I am wrong here. The goal of this paper to find \"optimal sampling strategy for training set\", \"K_s corresponding photos as sparse sample inputs among K_d total potential views\" is hardly a real problem statement for its real-world use case, which is my biggest concern for this proposed application of causal representation learning. From sampling perspective, we can use all the K_d potential views as long as they are available. As I understand, the evaluation of the counter factual distribution will require using the non-selected but captured images as supervision, which is not how active learning is executed in real-world case. Given this setting, it makes the results also less appealing in contrast to alternative baselines (which learns to predict next-best unknown view) given the fact all images from that particular datasets are used in evaluating the sampling strategy. 1. My major question is around how the clarity of the sampling process in training time. Confirm any places I misunderstood about this paper, as I highlighted in the weakness part. \n2. I am also curious how the views are sampled finally for different groups in the final results. Provide some visualization and discussions about them can be very helpful to guide the view-sampling process in real world applications. I wonder how that indicate the connection of uniformity term and consistency term are correlated to the camera FoV and ray distributions.",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108442",
         "3.0",
         "3.0",
         "2.0",
         "1.0",
         "2.0",
         "566",
         "0",
         "2",
         "0.8138000000000001",
         "0.1125",
         "0.8472209573",
         "52",
         "40.8228",
         "0.33",
         "iclr",
         "0.0"
        ],
        [
         "9",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-GDNX",
         "3",
         "5",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "80",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         ">**Rebuttal:** The provided details satisfy my concerns. I think this paper should be accepted after applying the agreed changes.\n\n>**TL;DR:** **Good paper.** The proposed WTA-CRS algorithm is based on the existing CRS algorithm and is used to reduce activation memory during training. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size. However, WTA-CRS comes with computational overhead, which is discussed and explore. Addressing my concerns and questions would improve my score.\n\nThe paper proposes the WTA-CRS algorithm to reduce the neural networks training activation memory, where the paper claims that activation memory is primary memory bottleneck during training. The WTA-CRS algorithm is an unbiased estimators for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size.\n\nThe WTA-CRS algorithm works by sampling columns and rows to create an unbiased estimation of the original GEMM for the backpropagation. The WTA-CRS algorithm does not alter the neural architecture, and therefore the inference speed is left in tact. The experimental section shows that WTA-CRS outperforms existing prior work and is compatible with existing PEFT techniques. WTA-CRS adds a computational overhead due to sampling, however, WTA-CRS enables training on much larger batch sizes, which results in a 1.2× higher training throughput.\n * **S.1.** The proposed WTA-CRS algorithm tackles an important problem in existing PEFT techniques, which makes LLM PEFT training more accessible to researchers with low resources.\n* **S.2.** The paper provides a theoretical analysis on WTA-CRS.\n* **S.3.** The proposed WTA-CRS algorithm outperform existing algorithms.\n* **S.4.** An anonymized code repository is provided as part of the submission for reproduction .\n  * **W.1.** Popular existing memory efficient training techniques such as tensor rematerialization (gradient checkpointing) \\[2\\]\\[3\\] and ZeRO \\[1\\] are not compared to, although some are partially discussed in Appendix A.\n* **W.2.** The experiments are conducted on single neural network architecture (T5), although the proposed technique does not seem to be confined solely to that setting.\n* **W.3.** It is common practice today to train neural networks at a lower precision (quantization), however, it is not clear whether quantization (16bit) was used. Therefore, there is insufficient proof that the combined noise of WTA-CRS and quantization would be compatible.\n\n\n**Typos.**\n* Line #62: \"Thus\" → \"Thus,\"\n* Line #240: \"mAccording\" → \"According\"\n* Line #297: \"Thus\" → \"Thus,\"\n\n\\[1\\] Ren, J., Rajbhandari, S., Aminabadi, R.Y., Ruwase, O., Yang, S., Zhang, M., Li, D. and He, Y., 2021, July. ZeRO-Offload: Democratizing Billion-Scale Model Training. In USENIX Annual Technical Conference (pp. 551-564).\n\n\\[2\\] Jain, P., Jain, A., Nrusimha, A., Gholami, A., Abbeel, P., Gonzalez, J., Keutzer, K. and Stoica, I., 2020. Checkmate: Breaking the memory wall with optimal tensor rematerialization. Proceedings of Machine Learning and Systems, 2, pp.497-511.\n\n\\[3\\] Beaumont, O., Eyraud-Dubois, L. and Shilova, A., 2021. Efficient combination of rematerialization and offloading for training dnns. Advances in Neural Information Processing Systems, 34, pp.23844-23857. * **Q.1.** In line #43 and Figure 2 it is noted that \"storing activations (or feature maps) is the main memory bottleneck during training\". Does this hold true for all model architectures? What about LLM training where the fine-tuning batch size is usually very small?\n* **Q.2.** Why was the WTA-CRS algorithm compared to the Deterministic top-k from \\[1\\] but not to the Bernoulli-CRS from \\[1\\]? What are the key differences between WTA-CRS and Bernoulli-CRS?\n* **Q.3.** The paper proposes WTA-CRS which sacrifices computation speed at the cost of lower peak memory. There are several existing common approaches (such as gradient checkpointing and DeepSpeed) for general memory efficient training which are compatible with PEFT techniques. Why are these comparisons not explored or detailed in the main paper?\n\n\\[1\\] Adelman, Menachem, Kfir Levy, Ido Hakimi, and Mark Silberstein. \"Faster neural network training with approximate tensor operations.\" Advances in Neural Information Processing Systems 34 (2021): 27877-27889. The limitations are discussed in Appendix A.",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411175092",
         "7.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "669",
         "10",
         "14",
         "0.753",
         "0.09034013610000001",
         "0.8664653897",
         "215",
         "42.5651",
         "0.1507",
         "neurips",
         "0.012820512820512775"
        ],
        [
         "10",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-j1mL",
         "4",
         "4",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "3",
         "70",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "In this paper, we propose a new method called WTA-CRS (Winner-Take-All Column Row Sampling) to address the main memory bottleneck issue during training, which arises from storing feature maps. To reduce memory usage during training, we sample the most likely column indices during backpropagation.\n\nFurthermore, \bthey proposed method demonstrates the ability to significantly reduce peak memory usage, by approximately up to 2.7 times, when fine-tuning downstream tasks. It also showcases the potential for higher throughput, enabling more efficient training. 1. The work clearly states its motivation and its solution and is easy to follow.\n2. The authors show that their method reaches comparable performance with backpropagation using the full activation when combined with LoRA.\n3. They also empirically measure throughput gains obtained by increasing batch size, which demonstrates the practical applicability of their method. 1. The paper needs a comparative analysis of other researchs, such as gradient checkpoint/recalculation and CRS, aimed at reducing activation memory during the training phase, as shown in Fig. 6 and Fig. 9.\n2. The paper should include an analysis of the overhead associated with the proposed WTS-CRS method, which involves sampling rows and columns. It is crucial to consider factors such as the computational cost of Equation 3 and any potential effects of lowering on the overall performance. Providing this analysis would enhance the clarity and completeness of the research.\n3. There is a need of analysis on the effectiveness of the proposed approach, WTS-CRS, in distributed training environments such as tensor parallelism or pipeline parallelism.\n4. It seems necessary to conduct performance evaluations on various LLMs of the GPT family, such as LLaMA and OPT. * In Figure 9, it can be observed that the throughput of WTS-CRS is lower than that of full when the batch size is small. Is this due to the overhead caused by lowering?\n* When comparing the training throughput, how does CRS differ from full in terms of throughput?\n* Could the authors include statistics for GPU utilization in their experiments? It would be helpful to analyze the causes of improved performance more thoroughly.\n* Considering that most large models are trained using multiple levels of parallelism, would it be possible to verify results for pipeline parallel, tensor parallel, etc.? Also, it is unclear from the paper whether the data parallelism used was distributed data parallelism or naïve data parallelism. * As previously mentioned, it would be valuable to include additional experimental results for models that are more challenging to quantify, such as GPT-series (OPT, LLaMA). This would enhance the validity and applicability of the proposed method across a broader range of models.\n* Considering that most large-scale models are trained using multiple levels of parallelism, it is important to assess how much the proposed methods, such as pipeline parallelism and tensor parallelism, can increase throughput while taking into account overhead (such as GPU-to-GPU or node-to-node communication), memory reduction, and computational cost. Furthermore, it is not clear from the paper whether the data parallel processing used is distributed data parallelism or naive data parallelism.",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174921",
         "5.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "506",
         "0",
         "8",
         "0.8129000000000001",
         "0.11685380590000001",
         "0.8539184332",
         "215",
         "31.6518",
         "0.1355",
         "neurips",
         "0.011111111111111072"
        ],
        [
         "11",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-cMiu",
         "4",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "80",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The authors studied fine-tuning LLMs with limited memory. As the increased scale of current LLMs, the memory cost during fine-tuning is of great importance when adapting the pretrained LLMs to down-streaming tasks. In contrast to the existing work that mainly focus on the number of updated weights, this paper proposed to reduce the number of stored activations, also the inputs to each layer. Given the widely used stochastic gradient descent optimization pipeline, the authors proposed to store a subset of activations that can generate an unbiased gradient estimation. This way, the training memory and the training time decreased significantly. The authors provide both theoretical and experimental analysis on their CRS methods.  - This paper studied an important problem in LLM fine-tuning, i.e., how to fine-tuning LLMs with less memory consumption without increasing the computation cost. The authors provided solid quantitative results to show that the main memory consumption is from storing the intermediate activations. \n- The authors provided a general solution for fine-tuning LLMs under memory constraints. The solution can be applied in most transformer-based network architectures.  \n- The authors provided solid mathematical proof on the unbiased gradient estimation, which is especially encouraged. \n- The extensive experiments on different network architectures showed the efficacy of the methods.\n- The released code can benefit the following researchers studying efficient LLM fine-tuning.  - I am not fully convinced by the comment made in Line241-244, i.e., the methods in the paper is orthogonal to the activation quantization. When activation is quantized into a lower bit width, it is very possible that the number of less important activations will decrease. This way, the selection on the top-k columns in activation matrices with the proposed methods may hurt the training accuracy or convergence. It would be great if the authors can provide some theoretical analysis or experimental results on this combination. Otherwise, it would be necessary to provide some comparison results w.r.t. the activation quantization.\n- It would be great if the authors can discuss the main difference of their paper w.r.t. \\[Randomized Automatic Differentiation, ICLR2021\\].\t  Overall, I think this paper has a relatively high quality in both writing and scientific contribution. Yes",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174804",
         "6.0",
         "4.0",
         "2.0",
         "3.0",
         "3.0",
         "358",
         "0",
         "2",
         "0.7825000000000001",
         "0.1275074405",
         "0.8477004170000001",
         "215",
         "33.3958",
         "0.1262",
         "neurips",
         "0.0"
        ],
        [
         "12",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-ky3t",
         "2",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "70",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The paper's contribution is in proposing a practical, intuitive yet not trivial unbiased approximation to gradient training of matrix multiplication. It shows that even though totally deterministic sampling is biased, somewhat deterministic sampling is unbiased, and a judicious allocation of sampling to those pairs favored by deterministic thinking can lead to the use of a larger batch size with empirically negligible performance loss. This reviewer must declare that he does not check the derivation very carefully. The proposed idea is practical and can be readily combined with virtually all first-order gradient-based training methods.\nThe paper also derived why deterministic sampling is a biased estimator and empirically shown the associated bad performance, thus proving that the additional complexity of stochastic sampling over deterministic sampling is not only sufficiently better but also necessary. It's just a few empirical comparisons, but the performance gap between CRS and WTA-CRS seems modest. This reviewer does not have a question. N/A",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174720",
         "7.0",
         "3.0",
         "4.0",
         "3.0",
         "3.0",
         "155",
         "0",
         "1",
         "0.8418",
         "0.062142857100000004",
         "0.7829982042",
         "215",
         "17.3432",
         "0.1041",
         "neurips",
         "0.01098901098901095"
        ],
        [
         "13",
         "38",
         "Seyed",
         "Reviewer-vqBu",
         "3",
         "2",
         "unfactual",
         "neutral",
         "polite",
         "low",
         "2",
         "2",
         "3",
         "2",
         "3",
         "4",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way. The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea. The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso. - in the frequentist case, how does the proposed framework compares against more classical techniques to obtain the solution paths, e.g., iterative reweighted l1-norm?  The authors adequately addressed the limitations of their proposed framework. ",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411519040",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "170",
         "0",
         "0",
         "0.799",
         "0.32",
         "0.9384971857000001",
         "215",
         "30.7103",
         "0.1149",
         "neurips",
         "0.011235955056179803"
        ],
        [
         "14",
         "38",
         "Seyed",
         "Reviewer-3sWQ",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "2",
         "1",
         "3",
         "3",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution. - Well written paper.\n\n        - Illustrative toy experiments. - The proposed method is a combination of already known techniques.\n\n        - The experimental section is weak as only a single real problem is considered.\n\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\n\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\n\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros. None The authors have not commented on the limitations of their approach.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518947",
         "5.0",
         "3.0",
         "2.0",
         "3.0",
         "2.0",
         "279",
         "0",
         "2",
         "0.7414000000000001",
         "-0.007047619000000001",
         "0.9233116508",
         "215",
         "36.096",
         "0.0989",
         "neurips",
         "0.0"
        ],
        [
         "15",
         "38",
         "Seyed",
         "Reviewer-pTVu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "3",
         "4",
         "4",
         "4",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\geq1}$ is used). 1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\n3. Using sub-l1 norm is suitable for structure learning. \n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \n5. The paper is well-written, and the relevant work is sufficiently discussed.    \n6. Due to its flexibility, the proposed method has the potential of having a large impact. Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \n\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \n\nMinor suggestion: \n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \n2. Fix minor typos e.g. the end sentence period in line 214. * In line 141, what do you mean by \"contradiction\"? The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \n\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518854",
         "6.0",
         "3.0",
         "3.0",
         "4.0",
         "2.0",
         "330",
         "0",
         "9",
         "0.7934",
         "0.1236940837",
         "0.8818445206000001",
         "215",
         "45.1097",
         "0.19690000000000002",
         "neurips",
         "0.011904761904761862"
        ],
        [
         "16",
         "38",
         "Seyed",
         "Reviewer-CnQu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "moderate",
         "2",
         "2",
         "1",
         "1",
         "3",
         "4",
         "50",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets. Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \n\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated. Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost. In synthetic data example, why did you choose to have more samples than dimensions ( $n>d$ )? Since in that case GGM can be obtained with matrix inverse, and no need for penalized objective. Limitations were not discussed.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518763",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "205",
         "0",
         "2",
         "0.787",
         "0.1207251082",
         "0.8797656298000001",
         "215",
         "36.2535",
         "0.25730000000000003",
         "neurips",
         "0.012048192771084376"
        ],
        [
         "17",
         "13",
         "Mana",
         "Joseph-philipraj",
         "5",
         "5",
         "factual",
         "positive",
         "polite",
         "low",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "95",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This systematic review is appropriate for the journal with a global problem of Mets and Urolithiasis. The introduction part clearly explains the motivation. The manuscript is clear and balanced. The manuscript stays focused on the subject. Authors have gone through the process of searching relevant articles from all websites and of sufficient duration. The inclusion and exclusion criteria in the analysis have been clearly stated. The impact of the analysis is clearly stated. The statistical analysis supports the paper well. The interpretation of the results, visualisation are well presented. The tables and figures are clear, relevant and correct. The authors demonstrate the knowledge of basic composition skills, including word choice, sentence structure, paragraph development and grammar. Limitations:  The studies included in the meta-analysis have cross-sectional nature and hence ascertainment of temporal association is not possible which also dictates need for further prospective studies. The specific type of stone formation is not correlated with studies. Despite these limitations all studies included in the meta-analysis showed the same directionality in the association between urolithiasis and Mets.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         null,
         "22 Mar 2021",
         null,
         null,
         null,
         null,
         null,
         "292",
         "0",
         "1",
         "0.7415",
         "0.1145833333",
         "0.8487246633000001",
         "39",
         "30.46",
         "0.0999",
         "f1000",
         "0.010000000000000009"
        ],
        [
         "18",
         "13",
         "Mana",
         "Muhammad-Faruk",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "93",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study assessed the association between metabolic syndrome and its components with the risk of developing nephrolithiasis by conducting systematic review, Bayesian random-effects meta-analysis, meta-regression and dose-response analysis. This study was done appropriately based on PRISMA flowchart. Risk of bias was also conducted of the included studies. This study has successfully presented the proper meta-analysis for this design. However, to complete this study for indexing, I personally recommended several revisions: 1. Abstract: Introduction section: It is better to address meta-regression as the analysis to assess the correlation of association along with dose-response analysis  Conclusion section: In reporting the association between predictors and nephrolithiasis, state only the predictors in which its coefficient was statistically significant 2. R language was not considered as a statistical software for data analysis. The software for data analysis should be written as \"R\" (Please refer to methods section in statistical analysis subsection). 3. Please update the PRISMA flowchart (refer to PRISMA guideline 2009). 4. Give the numbering of each Forrest plot in Figure 3 and numbering of each meta-regression plot in Figure 4. Design these figures so that it could be well presented. 5. Uniformly decide the word choice of \"traits\" or \"components\", choose whether to use traits or components in the whole text, use one of these words consistently to avoid any misunderstanding. 6. It is better to provide the meta-regression of hypertension in systolic blood pressure and diastolic blood pressure as it is important to explain the relationship to nephrolithiasis in differentiation for these two types of blood pressure. 7. Meta-regression of body mass index  was sufficient in this study thus waist circumference meta-regression was not necessary to be included. 8. Provide the value of coefficient and confidence interval of each meta-regression analysis in the result section so that better understanding of predictors-outcome relationship could be reached clearly.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         null,
         "08 Nov 2021",
         null,
         null,
         null,
         null,
         null,
         "422",
         "0",
         "7",
         "0.7554000000000001",
         "0.1982758621",
         "0.9299524426",
         "270",
         "24.68",
         "0.23020000000000002",
         "f1000",
         "0.010869565217391353"
        ],
        [
         "19",
         "181",
         "Hideaki-Joko",
         "Reviewer-sna7",
         "2",
         "2",
         "factual",
         "positive",
         "neutral",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This paper presents ULTRA, a single model that can be directly used/finetuned for link prediction over different knowledge graphs. The key is to model the transferrable relationships between different relations across knowledge graphs. Specifically, a NBFNet is used to learn relative relation representations and generate relation embeddings, which is then fed into another NBFNet to perform link predictions. Extensive experiments are performed over many knowledge graph to demonstrate the performance of this model. - This paper is well written and easy to follow\n- The core method around the relative relationships between relations is clever and interesting.\n- The experiments demonstrate the gains of the method. It is especially impressive to see the competitive zero-shot performance of ULTRA over different knowledge graphs. - The proposed method relies entirely on knowledge graph structure and does not consider using node embedding such as textual features of the knowledge graphs. In reality, text embedding of nodes and edges could be a better transferrable embedding. Such transferability has already been demonstrated by PRODIGY (https://arxiv.org/abs/2305.12600) and should be addressed.\n- The model does not scale well as the authors already pointed out.\n- The zero shot and fine-tuning performances are worse or on-par with the per dataset model performance, rendering pretraining not effective performance-wise. \n- Some notations are a bit hard to understand. See questions. - What are u and v in h_{u|v} in section 4.2?\n- Why are supervised SOTA baselines only reported for some datasets in Figure 4?",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636399067",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "245",
         "1",
         "1",
         "0.7559",
         "0.0971320346",
         "0.9083012938",
         "49",
         "38.7951",
         "0.07200000000000001",
         "iclr",
         "0.0"
        ],
        [
         "20",
         "181",
         "Hideaki-Joko",
         "Reviewer-HLbG",
         "3",
         "3",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This work aims to build a foundation model for knowledge graph reasoning tasks, where the authors explore the setting of generalization to any edges and nodes, including unseen, of any multi-relational knowledge graphs without using node and edge features. To this end, the authors first construct a view of a relation-centric graph from an original graph where edges become nodes of this new relation graph, and then, based on this view, the authors represent the relation (node) relative to and conditioned on the query relation. Then, based on this relative relation representation, the authors use existing inductive link prediction methods to perform knowledge graph reasoning. The authors conduct link prediction experiments on various knowledge graphs considering both inductive and transductive settings, and show that the proposed method, namely ULTRA, outperforms other SOTA baselines sometimes without further fine-tuning on target knowledge graphs (i.e., zero-shot). * This work studies the very important, challenging, and practical setups of building a foundation model for knowledge graph reasoning, which aims to be generalizable to any other knowledge graphs involving unseen nodes and unseen edges, without leveraging features of nodes and edges. \n* The proposed method works well with different knowledge graphs, on zero-shot transfer learning setups without further fine-tuning on target knowledge graphs, and further shows the boosted performance with task-specific further fine-tuning on them, on most experiment setups.\n* This paper is very well-written and easy to follow. * I would like to note that I don't see any major weakness, and below is the minor.\n* In Section 4.2, the explanation about the indicator function with variables $u$ and $v$ is a bit unclear to me. Could you elaborate more on the process and result of the indicator function according to those two variables, perhaps with visuals?\n* Text-based methods (e.g., LM-based methods) can be generalizable to any knowledge graphs including unseen nodes and unseen edges, as long as their nodes and edges are represented with texts. In this vein, I think one potential direction for building a foundation model for knowledge graph-related tasks might be to use the LMs, and the authors may highlight this point more and potentially make comparisons between the proposed approach and text-based methods. I don't think this should be the critical weakness of this paper since text-based methods are limited to knowledge graphs with textual features; meanwhile, given the framing of this work (\"Towards Foundation Models for Knowledge Graph Reasoning\"), this point should be carefully explained. * I would like to suggest emphasizing the performance differences between inductive and transductive setups when explaining Table 1. The proposed method w/ 0-shot settings are strong on inductive graphs; meanwhile, previous methods are superior to it on transductive graphs, which are worthwhile to discuss.\n* It may be beneficial to show the results of the ULTRA fine-tuned on the knowledge graphs used for pre-training the ULTRA. I am wondering if there are further performance improvements when further fine-tuning the model on the data used for pre-training.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398956",
         "8.0",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "496",
         "0",
         "0",
         "0.7682",
         "0.1549267161",
         "0.9152074456",
         "49",
         "38.4364",
         "0.37610000000000005",
         "iclr",
         "0.0"
        ],
        [
         "21",
         "181",
         "Hideaki-Joko",
         "Reviewer-c3Sg",
         "4",
         "3",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "4",
         "3",
         "3",
         "4",
         "70",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "Paper claims to propose a foundation model, named Ultra, for knowledge graph representation learning. The proposed model can handle full inductive graphs in which new entities and relations may appear in the test set. To do so, the authors propose to lift the graph to a one with relations as the nodes and design 4 different edge types (head2head, head2tail, tail2head, tail2tail). The relational representations are then learnt using message passing on this graph. The learnt relation embeddings are then used in the original graph to perform inductive link prediction. For the experiments, the authors pre-train their method on 3 KGs and further evaluate in a zero-shot setting and also by fine-tuning the downstream tasks. - The paper proposes a transductive model that works in settings of new relations and entity nodes.\n- The method obtains good zero-shot pretraining results. - The authors have not explicitly stated the computational complexity of the method. From the paper, it seems that the forward pass is run on the entire relational graph to obtain relation representations. This is then used to initialize the node embedding from the query triple and the process is repeated for every triple. Thus it seems that the entire graph is being used for link prediction every triple making the computational complexity O(E^2). This seems limiting for large graphs that have not been explored in the paper (such as wikidata-5m etc.).\n- From Table 2 we can see that finetuning over the pre-trained models helps the results significantly over the 0-shot setting. Also, the fine-tuning steps are too large to claim few shot results. This weakens the claim of the \"foundation model\" for KGs. A fair comparison would be to show the pretraining results for other inductive and transductive methods as well in addition to the SOTA comparison.\n- Another limitation is that of scale. Since the current model has fewer parameters, this would limit learning over larger pretraining datasets as can be seen in Figure 6 and also reported by the authors.\n- SoTA results for transductive models are better than the pre-trained Ultra model in many datasets. Thus the Ultra model seems to work well for the inductive setting rather than transductive. Thus the claim of the \"foundation model\" seems broader in scope.\n- We see that in the metafam dataset, the pretraining results are poor but on finetuning the results are improved drastically. This shows that the method works well in cases where the relational patterns of the downstream datasets are similar to the pre-trained one but when the data distribution changes the results suffer. Moreover, due to limited capacity, the model may not be able to handle such cases by increasing the pretraining datasets calling for downstream finetuning. Thus domain adaptation is not a problem which can be easily overcome by scaling the current model and this further weakens the claim of a \"foundation model\" for KGs. - For weakness point 2: Any reason why this was not done by the authors?\n- For weakness point 3: How would this be addressed in future works for the model?\n-  For weakness point 4: Could the authors comment on why this would be the case and how would the model be improved to handle the transductive setting?\n- For weakness point 5: Any reason why the results on this dataset are not good?\n- Considering KGs are a rich source of textual/semantic data along with graph/structured data and the current model does not use this rich source of context information, how can we extend Ultra to incorporate the KG ontology? \n- Considering weaknesses 2,4,5 the claim of the foundation model seems a bit broad as of now and at best the model could be said to be a good inductive learner.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398852",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "625",
         "0",
         "0",
         "0.7487",
         "0.1723163098",
         "0.9095818996",
         "49",
         "51.6761",
         "0.1355",
         "iclr",
         "0.01041666666666663"
        ],
        [
         "22",
         "181",
         "Hideaki-Joko",
         "Reviewer-ebFz",
         "2",
         "2",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "65",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "The key limitation of designing the foundation models for dealing with the Knowledge Graphs (KGs) is that the KGs have different entities and relations that generally do not overlap. To address this issue, this paper proposes ULTRA, which positively transfers the information of source KG to unseen KG. It constructs relation representations based on the interactions between the relations by introducing the graph of relations. The proposed approach has shown good performance on various tasks. - From their experiments, the proposed methods have shown good performance on various tasks.\n- Research topics about the foundational models on graph-structured datasets is really interesting and important.\n- The paper is well written and easy to follow. - The authors first pretrain the ULTRA model with the mixture of 3 standard KGs and then fine the model for the downstream task. But, the other supervised SOTA model only uses dataset of the downstream tasks without employing the pre-training datasets. If the supervised SOTA models are designed to deal with transductive settings, they may show worse performance on the downstream tasks. However, if the SOTA models are the models for the inductive setting, I think they may be possible to be pretrained like the ULTRA. So, could you measure the performance of the \"pretrained\" SOTA models on the inductive if possible? Please refer to the weaknesses.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398789",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "222",
         "0",
         "0",
         "0.7001000000000001",
         "0.16196172250000002",
         "0.9080925584",
         "49",
         "47.3913",
         "0.18230000000000002",
         "iclr",
         "0.0"
        ],
        [
         "23",
         "9",
         "Seyed",
         "Reviewer-KmBd",
         "4",
         "4",
         "factual",
         "neutral",
         "neutral",
         "none",
         "4",
         "3",
         "4",
         "4",
         "3",
         "3",
         "90",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699637128872",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "487",
         "0",
         "1",
         "0.732",
         "0.1304191468",
         "0.9185432792",
         "47",
         "29.0538",
         "0.1695",
         "iclr",
         "0.0"
        ],
        [
         "24",
         "9",
         "Seyed",
         "Reviewer-3zCE",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699637128739",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "1.0",
         "480",
         "0",
         "0",
         "0.8331000000000001",
         "0.09343537410000001",
         "0.9183989763",
         "47",
         "39.3732",
         "0.1932",
         "iclr",
         "0.0"
        ],
        [
         "25",
         "9",
         "Seyed",
         "Reviewer-y5kB",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699642867494",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "41.9389",
         "0.050100000000000006",
         "iclr",
         "0.0"
        ],
        [
         "26",
         "9",
         "Seyed",
         "Reviewer-XNx6",
         "5",
         "4",
         "factual",
         "neutral",
         "neutral",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "88",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1700672717423",
         "6.0",
         "4.0",
         "2.0",
         "2.0",
         "3.0",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.9159082770000001",
         "59",
         "42.2021",
         "0.929",
         "iclr",
         "0.0"
        ],
        [
         "27",
         "81",
         "Emperatoor",
         "Gatot-Soepriyanto",
         "3",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study investigate whether financial distress, earnings management and audit quality as determinants/moderating variable for financial statements fraud in Indonesian listed firms during 2015 to 2019 period. The authors focused on infrastructure, utility and transportation sectors. In general, the study has been designed adequately to tackle the research questions and issues posed by the authors. However, there are some elements need to be addressed to improve the paper: Whilst the study provide adequate research background and institutional setting, it did not mention on why the study focuses on infrastructure, utility and transportation sectors? Is there any specific issues on that sector that related to financial statements fraud? In addition to that, why the study chooses 2015-2019 period?  The study should also discuss the reason choosing F-Score as its main measure for financial statement fraud. Why, for example, the study did not use, Beneish M-Score? Or other accounting irregularities measures in the literature?  The study needs to provide descriptive statistics table, so the reader can gauge and understand the dataset better. This should be provided before the authors arrive with the hypothesis discussion;  Given the study uses panel data (multi years, across different firms), is there any attempt to mitigate the issues of panel data regression? For example, using year-fixed effects or even using panel data regression analysis?  The manuscript need to be checked in terms of the quality of English write up. The title for example, is a little bit confusing, as it did not really represent what the study want to achieve in general.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "30 Jun 2023",
         null,
         null,
         null,
         null,
         null,
         "400",
         "0",
         "1",
         "0.7771",
         "0.11745495500000001",
         "0.9143848419",
         "220",
         "26.81",
         "0.016800000000000002",
         "f1000",
         "0.020408163265306145"
        ],
        [
         "28",
         "81",
         "Emperatoor",
         "Toni-Šušak",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "25 Mar 2024",
         null,
         null,
         null,
         null,
         null,
         "909",
         "0",
         "5",
         "0.6798000000000001",
         "0.12259259260000001",
         "0.8569852710000001",
         "489",
         "50.12",
         "0.07200000000000001",
         "f1000",
         "0.0"
        ],
        [
         "29",
         "24",
         "Sajad-Ebrahimi",
         "Silvio-Buscemi",
         "1",
         "1",
         "unfactual",
         "negative",
         "polite",
         "extreme",
         "1",
         "3",
         "1",
         "2",
         "3",
         "3",
         "48",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         null,
         "07 Jan 2025",
         null,
         null,
         null,
         null,
         null,
         "280",
         "0",
         "1",
         "0.7857000000000001",
         "0.1403645833",
         "0.7798862457",
         "34",
         "24.27",
         "0.3225",
         "f1000",
         "0.010526315789473717"
        ],
        [
         "30",
         "77",
         "Mohammad-Hossein-Saliminabi",
         "Houcemeddine-Turki",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "85",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "This manuscript presents a novel rule-based approach for fact checking in knowledge graphs based on mining textual resources. The work provides new evidences that rule-based approaches can provide more precise evaluation of the accuracy of statements in knowledge graphs and can enhance the efficiency of embedding-based methods when combined with them. The availability of source codes and datasets in GitHub is an advantage for this work as this will allow the reproducibility of the described experimental study. However, there are several matters within the paper that should be addressed to ameliorate its final output: (i) Introduction: The \"Introduction\" seems to be a summary of \"Related Studies in Fact Checking\" rather than a proper introduction and contextualization of the paper. I propose to expand the part about misinformation fighting in the introduction to give better context for the development of this research paper. The authors can benefit from previous research papers about fact checking in general to develop the introduction of the paper. Several points in the introduction should be moved to Related Studies in Fact Checking. (ii) The paper did not emphasize the advantages of rule-based approaches when compared to embedding-based methods beyond having a better precision. Effectively, there are many other advantages of rule-based approaches. For example, the results of rule-based approaches can be more explainable than the ones of embedding-based approaches. Such advantages should be expanded and highlighted in the research paper. (iii) The paper did not emphasize the importance of having the datasets and source codes available in a specific GitHub repository. The authors should specify that this practice allows reproducibility and further development of the work by peers, particularly in the conclusion. (iv) The paper did not discuss the concept of reification in knowledge graphs. Effectively, several knowledge graphs add qualifiers to triples to provide a characteristic of the statements (i.e. {(s,p,o), p, o}. The authors should discuss the usefulness of the method to verify the qualifiers of the statements in the Discussion or as a future direction for this work. (v) The paper should evocate the robustness of the rule-based approach they proposed to adversarial attacks. This can be an advantage of the approach. (vi) There are several typos in the research paper (e.g. \"UC Berkely\" should be \"UC Berkeley\"). The authors should proofreading the paper to eliminate such deficiencies. (vii) The authors can expand the Discussion of the work (Part 5) to explain the strengths of KStream, KLinker, COPPAL, RUDIK, and PredPath that contributed to their efficiency as reported in the Experimental Study according to previous research papers. This can explicate the reasons of why the method developed by the authors was more efficient. (viii) The authors should provide future directions for the development of this work in the conclusion. Given this, I propose to accept this paper for publication after these six major revisions are applied.",
         null,
         "18/Feb/2021",
         null,
         null,
         null,
         null,
         null,
         "473",
         "0",
         "1",
         "0.7464000000000001",
         "0.1097294372",
         "0.9120528102000001",
         "4",
         "36.08",
         "0.2025",
         "semanticweb",
         "0.0"
        ],
        [
         "33",
         "67",
         "Emperatoor",
         "Reviewer-um1j",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "4",
         "5",
         "3",
         "4",
         "4",
         "70",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "The paper introduces a new method for molecular modeling, QuinNet, which incorporates five-body interactions using only dihedral angles. The authors first introduce relevant concepts related to machine learning force fields and related work in the field related to a variety of equivariant models. Next, the paper describes pertinent definitions of force fields, group equivariance, and methods for calculating empirical force fields. In the methods section, the authors describe their approach for integrating five-body terms into the architecture of QuiNet using only dihedral angles and incorporating model designs from prior work (PaiNN for 3-body interactions, ViSNet for 4-body interactions) and new definitions for different topologies of 5-body interactions. In addition to the architectural description, the authors provide relevant mathematical formulations and a complexity analysis. In their results, the authors showcase QuiNets performance on a low (MD17) and high complexity (MD-22) dataset in terms of energy and force modeling, including an ablation for different body terms in Figure 5. The paper has the following strengths:\n* Originality: The proposed architecture incorporates relevant terms for molecular modeling that are physically relevant, but have not been incorporated before.\n* Quality: The method and experimental design showcase relevant cases for applying GNN models for molecular modeling with the idea behind the architecture being well-motivated.\n* Clarity: The paper presents a cohesive formulation of their method, both in figures and mathematics, and experiment descriptions with relevant takeaways.\n* Significance: The proposed architecture shows improved modeling performance, especially in forces, and provides a potential framework for incorporating physical interactions into GNNs. The paper could be improved by the following:\n* Providing a clear and concise discussion of limitations. \\[Quality, Significance\\]\n* Adding more context for the results in Figure 4. The MD simulations are only briefly described in Section 5.1, which is on a different page then the figure and easy to miss. \\[Clarity\\]\n* A description of the case in which a greater set of many-body interactions is beneficial. This is briefly mentioned in the discussion between MD17 and MD22, but it would be good to put in greater context in terms of the experimental results and could serve as part of the conclusion. \\[Clarity\\] * Could you provide additional details on the limitations of QuinNet? E.g. Is it limited to modeling mainly molecular systems? What sizes of molecules do you think QuinNet can be effective in and why?\n* Do you have data that supports your compute complexity analysis compared to other methods? If so, what kind of speedup do you generally find, if any? The authors do not provide a discussion on limitations, which I raised as a weakness. I would like to see a discussion of limitations in future versions and/or during the discussion period.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337960",
         "7.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "452",
         "0",
         "1",
         "0.7681",
         "0.1465895563",
         "0.867398262",
         "215",
         "29.1615",
         "0.464",
         "neurips",
         "0.0"
        ],
        [
         "34",
         "67",
         "Emperatoor",
         "Reviewer-YmDt",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "5",
         "4",
         "5",
         "5",
         "80",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "In this work, the authors propose to incorporate features from five-body interaction into machine-learning force field models and develop QuinNet. To efficiently incorporate such high-order information, the authors are motivated by the topology of many-body interactions and design sophisticated components. Experiments on several benchmarks are conducted to demonstrate the performance of QuinNet. 1. The target problem of this paper, the development of machine learning force field models, is of great significance. 1. **The motivation for the designed components of many-body interaction is puzzling**. As introduced in Section 4, the development of four-body interaction (improper torsions) and five-body interactions are based on the topology. First, such analysis is purely qualitative. The authors did not provide further completeness proof or quantitative evidence about these interaction schemes in real-world data. Second, the reasons for deriving Eq (4)-(9) are not well explained. It is suggested to clarify how these components are motivated according to the topology analysis.\n\n\n2. **On the experimental evaluation**. Additionally, there are several aspects of the experiments that are concerned:\n    - The empirical performance is not consistently better than other baselines. Among the evaluated benchmarks, the proposed QuinNet cannot outperform the baselines significantly. For example, in MD17, the newly developed five-body interaction modules do not significantly improve performance. In rMD17, the best performance is diversely distributed among the compared models. Overall, the experimental evaluation does not well demonstrate the power of newly developed modules.\n    - The computation efficiency evaluation is missing. Although the authors provide complexity analysis, it is better to further show the time/memory cost comparison between the proposed QuinNet and baselines. Besides, the model parameters should also be provided for all compared models.\n    - The scale of the chosen benchmarks is rather small. Both the dataset size and sample size (number of atoms) are limited. It is suggested to further evaluate the proposed QuinNet on large-scale benchmarks, e.g., Open Catalyst Project \\[1\\].\n    - The ablation study. First, as shown in Figure 5, the inclusion of Five-body@I even induces further errors, which would make readers curious about whether such a phenomenon generally exists. Second, as introduced in VisNet, the improper angle was also considered. The authors should add further discussions and empirical comparisons between it and the newly proposed four-body interaction (improper torsion).\n\n\n3. **The writing does not meet the requirement of an acceptable paper in this conference**. First, Section 3.2 can be thoroughly extended (e.g., in the appendix) to introduce the background of force fields and highlight the importance of torsion potential, improper torsions, and higher-order many-body interactions. Second, there lack of formal descriptions of QuinNet. Figure 3 can hardly be understood by readers that are not familiar with the related works in this area. \n\n\\[1\\] Chanussot L, Das A, Goyal S, et al. Open catalyst 2020 (OC20) dataset and community challenges\\[J\\]. Acs Catalysis, 2021, 11(10): 6059-6072.\n    -  Please refer to the Weakness section to address the concerns. The authors did not discuss the limitations of this work.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337859",
         "4.0",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "489",
         "2",
         "6",
         "0.7931",
         "0.0741489571",
         "0.8583066463000001",
         "215",
         "34.6703",
         "0.19390000000000002",
         "neurips",
         "0.0"
        ],
        [
         "35",
         "67",
         "Emperatoor",
         "Reviewer-8RW7",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper aims to incorporate 5-body interactions into geometric deep learning models. They first analyze the topology of 5-body interactions and identify three 5-body angles. Then they propose an efficient way to incorporate these 5-body information into models. The complexity of the proposed QuinNet is still O(|N|), the same as many previous 2-body methods like PaiNN. The results are comparable to previous SOTA methods. This paper is well-written and easy to follow.\n\nThe experimental results show that the proposed method can perform well on most tasks. The ablation study in Section 5.4 and Figure 5 show that the proposed 5-body information indeed helps to model. See details in the Question part. 1. About the motivation:   \n this paper aims to incorporate 5-body interactions into geometric deep learning models. However, based on my understanding, using up to 4-body (torsions) interaction is already complete \\[1\\]\\[2\\] in terms of capturing the geometric structures. If this is correct, then why do we need these 5-body angles? In addition, if we can incorporate 5-body interactions, do we also need to incorporate 6-body interactions?\n\n2. About the complexity:   \nin Section 4.3, the authors claim that the complexity is O(|N|), as efficient as many 2-body methods like SchNet and PaiNN. But I think this complexity is not well explained. Using pseudocode/algorithm may be better to analyze the complexity. In addition to the analysis, I suggest the authors use some results to empirically verify the great efficiency compared to other baseline methods, e.g. the inference time, used memory, etc.\n\n3. About the tasks:   \nthis paper focuses on MLFFs, how about other molecular property prediction tasks, such as QM9 and OC20? I am wondering if this method is specially designed for MLFFs, or can be used on all 3D molecule tasks. In other words, why do the authors emphasize MLFFs? Is there any significant difference between MLFFs and other molecule property prediction tasks?\n\n4. Other related papers: many-body \\[3\\], MLFFs \\[4\\]\n\n5. The j, k in Figure 2 are confusing to me. For example, in (f), why not be i, j1, j2, j3, and k1?\n\n\\[1\\] ComENet: Towards Complete and Efficient Message Passing for 3D Molecular Graphs.  \n\\[2\\] GemNet: Universal Directional Graph Neural Networks for Molecules.  \n\\[3\\] On the Expressive Power of Geometric Graph Neural Networks.  \n\\[4\\] Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations. None",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337767",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "394",
         "8",
         "6",
         "0.77",
         "0.13857142860000002",
         "0.8948391676",
         "215",
         "48.9981",
         "0.1429",
         "neurips",
         "0.0"
        ],
        [
         "36",
         "67",
         "Emperatoor",
         "Reviewer-YYfR",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "70",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper introduces a machine learning force field that is a neural network with explicit interactions for up to 5-body terms.  The authors evaluate the model on a couple of public datasets and show demonstrate the competence or superiority of this new model compared to the state of the art in this field. The paper provides an important addition to a series of ever-improving machine learning potentials.  The contribution is clear and simple to understand at the high level, though the details are often unclear.  The benchmarks were compared against a set of reasonably strong published methods in this area.  In my opinion, if this work was presented in an unambiguously clear fashion and accompanied by code, it could be a strong contribution to this conference.  \n\n\\[The paper improved significantly following the first round of feedback from reviewers, so I'm raising my rating to a 7.\\] The complexity analysis is very limited.  How many total interactions did the typical molecule have as a function of their atoms, and how did the practical experimental complexity scale for the evaluation of these molecules.  One of the main reasons that 5-body terms were not used in traditional MD simulations was the poor scaling of the number of interactions one would need to calculate.\n\nThe MD simulation mentioned in section 5.1 and Fig 4 are not described anywhere.  The following sentences suggest that there would be some explanations in the supplement, but I couldn't find them: \"Additionally, we perform MD simulations using trained QuinNets as force fields and plot the distribution of interatomic distances h(r) for these 7 molecules in Fig. 4. Further details regarding additional settings can be found in the Supplementary Materials.\" \n\nThese sentences in the supplement, page2, are confusing or wrong: \"Similarly, five-body@III interaction (Fig. S1 (c)) is a special case of six-body interaction when nodes i and k4 in Fig. S1 (d) superpose each other. Thus, the QuinNet model captures all five-body interactions and a portion of six-body interactions, making it a versatile and comprehensive tool for modeling complex molecular systems.\"  There is no six-body interaction if two of the bodies are the same, and there is no physically acceptable case where two different atoms could superpose each other.\n\nThe code is not provided, so it is not possible for me to assess the reproducibility of this method.  The diagram in Figure 3 seems reasonable at the very high level, but it lacks the definitions of most of the terms annotated in the figure, thus rendering it confusing.  (What is $Y_l$? is it the set of all spherical harmonics $Y_{lm}$ for a given angular momentum $l$? What is $n_j$? What is $s_j$?  $W$?...) Could the authors add the presentation of the QM9 quantities estimated in the recent publication for Allegro?  (https://www.nature.com/articles/s41467-023-36329-y Table 3)\n\nHow long and how stable were the actual MD simulations?  What were the exact codes/protocols used?\n\nWhat is the practical performance of the model during evaluation? No potential negative societal impacts from this work.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337653",
         "7.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "497",
         "1",
         "2",
         "0.764",
         "0.0333794423",
         "0.8763324022000001",
         "215",
         "43.7997",
         "0.1199",
         "neurips",
         "0.018018018018018056"
        ],
        [
         "37",
         "171",
         "Sajad-Ebrahimi",
         "Magdalena-Czlapka-Matyasik",
         "1",
         "1",
         "unfactual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "35",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I commend the authors to contribute to this body of literature regarding the socio-demographic and lifestyle factors associated with understanding fast food consumption in Cambodia adults. The paper brings quantified information about the factors influenced by understanding fast food consumption. The authors revealed that poor and fair knowledge, insufficient exercise levels, and not getting enough sleep were predictors of inadequate understanding of the impact of fast food on health. Such conclusions do not bring entirely new knowledge to the literature, on this matter. Across the whole world population, the problems related to fast food consumption have been discussed. Nevertheless, I consider the work to be original, well designed and contribute knowledge to this field of public health research. My suggestions concern: In the introduction, the authors indicate the system of fast-food restaurants; it would be more attractive to explain, how it was developed in Cambodia directly?  What would be very interesting is information concerning the real take away or fast food intake in those groups. It must or might be in direct relation to this matter?  My main concern about the validation of the \"Level of knowledge of fast food consumption\": Could the authors explain the procedure? How were the questions selected and validated?  I regret that the authors discussed the interesting results in such a concise way.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         null,
         "12 Feb 2021",
         null,
         null,
         null,
         null,
         null,
         "361",
         "0",
         "1",
         "0.7773",
         "0.2011784512",
         "0.89415133",
         "137",
         "35.27",
         "0.1507",
         "f1000",
         "0.010000000000000009"
        ],
        [
         "38",
         "171",
         "Sajad-Ebrahimi",
         "Wanshui-Yang",
         "1",
         "0",
         "unfactual",
         "negative",
         "impolite",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "40",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript investigated the level of understanding of fast-food consumption among adults in Cambodia. The authors found that unsatisfactory levels of knowledge around fast food consumption were significantly associated with not taking regular exercise and sleeping less than eight hours per night. The results are interesting, but I have several comments. The authors should introduce the recent development of fast-food sector in Cambodia in the introduction part.  Is there an analysis of fast-food intake among these participants?  Interestingly, the authors found that not taking regular exercise and sleeping less than eight hours per night were associated with unsatisfactory levels of knowledge around fast food consumption. However, they were not well explained in the discussion part. In other words, the discussion part is a little too concise.  In addition, the education levels were not associated with the knowledge of fast-food consumption in the present study. I would like authors to discuss it and, at least, mention its possible causes.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "02 Mar 2022",
         null,
         null,
         null,
         null,
         null,
         "303",
         "0",
         "1",
         "0.7774000000000001",
         "0.1265046296",
         "0.9193514585",
         "520",
         "28.03",
         "0.1953",
         "f1000",
         "0.010204081632653073"
        ],
        [
         "39",
         "187",
         "Emperatoor",
         "Reviewer-2CBB",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "4",
         "4",
         "4",
         "4",
         "4",
         "70",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "This paper introduce a novel unsupervised feature selection methods called GRSSLFS, which combine matrix factorization with self-representation subspace learning and apply graph regularization to preserve the geometric structure of the feature vectors. This method is proved to be effective in both theory and experiments. In this paper, the author introduce the problem of the redundant data in traditional self-representation, and then apply matrix factorization self-representation problem to achieve the goal to reduce the dimension of basis matrix. Here are some strengths of this article:\n\n1. This paper introduce a novel problem of redundant data in self-representation problems and then propose a method to solve this problem.\n\n2. Plenty of theoretical proof are given in the paper and appendix, the convergence analysis indeed increase the persuasiveness of the article.\n\n3. The proposed method was compared with a variety of comparison algorithms on multiple data sets, demonstrating the effectiveness of the method. However, there are still some weaknesses in this paper.\n\n1. In the end of Introduction section, the second and third contribution points is not sufficient, as these constraints of regularization are not proposed in this article. \n\n2. In the methodology section, some formula calculations are confusing and not very convincing. Such as the multiplication in formula (6) and the optimization target in the optimization goal (formula 7). These issues will be described in detail in subsequent questions 1 and 2.\n\n3. In the methodology section, the description of the algorithm is not complete enough. The specific process of selecting features according to the matrix U in Algorithm 1 has not been described in detail. 1. In the section of methodology, the equation (6) is confusing and not so clear. It seems impossible to subtract the matrix XUV of shape m*m from the matrix X with the shape m*n? \n\n2. As the feature matrix B is fixed by the VBE method proposed in section 3.3, it is unclear why the basis coefficient matrix G in equation (7) is a parameter to be optimized. Why the matrix G can not be determined by equation (4) directly and reduce the number of parameters.\n\n3. In section 3.1, subspace learning that introduces graph regularization seems to be existing methods. Should this part of the content be moved to related work?",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636201193",
         "6.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "376",
         "0",
         "8",
         "0.679",
         "-0.048046398000000004",
         "0.9640573859",
         "51",
         "40.0877",
         "0.0751",
         "iclr",
         "0.0"
        ],
        [
         "40",
         "187",
         "Emperatoor",
         "Reviewer-yUvs",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "5",
         "3",
         "4",
         "3",
         "4",
         "75",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Authors of this paper propose graph regularized self-representation and sparse subspace learning (GRSSLFS) for unsupervised feature selection. The basis extension method is modified to select bases with highest variance score. These bases are used to build graph regularized self-representation learning and subspace learning. The graph regularized self-presentation learning and subspace learning are combined in terms of a set of selected bases from input space with the highest variance score. Experiments on various datasets demonstrate the advantage of the proposed method comparing with baselines. The ablation study also shows the necessity of each component. The subspace learning module is the key component, but its derivation from selected bases highly relies on the assumption that XU=B. This might not be hold if B is selected according to the proposed variance basis extension method. Moreover, the selection based on subspace learning module lacks of convincing explanation since G does not exactly represent X based on B as a fixed set of feature vectors. It is confusing to explain (4) as the self-representation problem if B is arbitrary basis matrix since they may not come from the input data matrix X.  Taking PCA for example, the columns of B are orthogonal, but they are not from the input feature space. Moreover, B defined as a square matrix of size m is inconsistent with the sleeted r bases in section 3.3.\n\nIn section 3.1, authors mentioned that two features have a similar structure in the feature space, and it is expected Bg_l and Bg_r have similar structure. What does the similar structure mean? How is the similarity measured? In other words, it is unclear how the matrix A is constructed. \n\nThe derivation in section 3.2 depends on the assumption that XU=B. As B is a set of feature vectors selected from input data, it is unclear whether the assumption still holds or not. Similarly for Theorem 3.1, it is trivial to have if the assumption holds. \n\nThe variance basis extension is to simply change the selection order of feature vectors in terms of variance score of feature vectors. It is possible that for each individual feature, the variance is high, but is it similar to say the largest amount of data dispersion? \n\nFor completeness, authors should describe the derivation process on how equations (9)-(11) are obtained. Since all three equations are fractional, is it possible that any of the denominators can be zero? How is it handled?\n\nIn Algorithm 1, the selected features are derived from U. However, U is not directly related to the input X instead to B and G, unless BG=X. However, B is selected feature vectors from input space. It is unclear why the assumption can hold. So why is the selection rule proper?\n\nThe computation complexity is quite high since it is quadratic to both the number of samples and the number of features comparing with most of baseline methods.\nThe application to the PneumoniaMNIST dataset is quite interesting. However, the way of presenting the outcomes can be improved significantly.  For example, what is the interested region? how many selected features are in the interested region? How do other compared methods perform? The validation is not quantified. How many radiologists are involved in the evaluation?  What is the performance measured? These plots shown in Fig. 2 delivers less useful information except that more red points are accumulated in the center when the number of selected features increases.",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636201025",
         "5.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "567",
         "0",
         "0",
         "0.7308",
         "0.0892117117",
         "0.9616214633000001",
         "51",
         "50.3623",
         "0.0364",
         "iclr",
         "0.0"
        ],
        [
         "41",
         "187",
         "Emperatoor",
         "Reviewer-PMap",
         "1",
         "3",
         "partially factual",
         "negative",
         "polite",
         "moderate",
         "2",
         "2",
         "2",
         "3",
         "3",
         "4",
         "30",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Considering there exists a major gap in the mathematical principles that underlie the self-representation based unsupervised feature selection approaches and their capacity to represent the feature space, this paper proposes Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), for the unsupervised feature selection, which expresses the self-representation problem based on the concept of “a basis of feature space” to represent the original feature space as a low-dimensional space made of linearly independent features. Experiments on widely-used datasets are conducted to validate the efficacy of the proposed method. 1. The computational complexity of the proposed GRSSLFS method is low, which is efficient for large-scale and high-dimensional data;\n2. The results of the proposed method seem better than other ones. 1. Most of the compared methods are out-of-date, only one method used for comparison was publised in 2023, other methods are before 2020;\n2. The motivation of the proposed method is not clear. In Eq.(8), the first three terms have been well explained, but the final regularization term has not been explained. See weakness.",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636200941",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "2.0",
         "172",
         "0",
         "4",
         "0.6699",
         "0.1067307692",
         "0.9783408642",
         "51",
         "26.959",
         "0.0945",
         "iclr",
         "0.0"
        ],
        [
         "42",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-NRqK",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "5",
         "5",
         "5",
         "4",
         "5",
         "94",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes an algorithm for learning MDP state abstractions that preserve information needed for planning (namely, the values of states). A major differentiator from symbolic approaches is the idea that these state abstractions should be continuous rather than discrete. The key assumption is that you are given a set of options and a dataset obtained by rolling them out. Experiments are conducted in a few simple domains: pinball and antmaze, and demonstrate that the learned abstractions are sensible. The paper addresses an important topic (abstraction learning) and I appreciate the theoretically motivated algorithms. This line of work is of great interest to many attendees of ICLR. I also appreciate that the authors were clear about wanting continuous representations right off-the-bat. The math is also correct as far as I was able to tell, though I didn't check the proofs in the appendix in careful detail. Unfortunately, I recommend rejection for this paper due to 4 major reasons: 1) unconvincing experiments, 2) missing key citations to related work, 3) issues in technical details, and 4) unclear motivation.\n\n1) unconvincing experiments\n\nThe experiments in this paper are very basic and only serve as a simple proof-of-concept that the learned abstractions are somewhat useful. To really scale up the experiments to the level expected for a conference paper, I would expect to see evidence that the learned abstractions are useful in more hierarchical domains (e.g., classic domains from the options literature like keys and doors). In such domains, we could test whether the value-preserving property holds empirically, by comparing the values from planning under the abstract model to the (ground truth) values from planning under the true model.\n\nAdditionally, I would like to see comparisons to many more RL algorithms, especially hierarchical ones like HIRO (https://arxiv.org/abs/1805.08296), HVF (https://arxiv.org/abs/1909.05829), and Director (https://arxiv.org/abs/2206.04114). This is because at the end of the day, the authors are proposing to learn a state encoder $\\phi$, and despite all the theory that has gone into their algorithm, the question that must be answered is whether this $\\phi$ outperforms the encoders learned by all these other SOTA hierarchical RL algorithms.\n\n2) missing key citations to related work\n\nThe authors are missing several key citations, the most important of which is the line of work by David Abel, such as \"Near optimal behavior via approximate state abstraction\" (https://proceedings.mlr.press/v48/abel16.html) and \"Value preserving state-action abstractions\" (https://proceedings.mlr.press/v108/abel20a/abel20a.pdf). Those papers have very similar theory to what appears in this one, and so the novelty of the proposed approach is unclear. There are also less-famous but still important-to-cite papers from other authors, like \"Abstract value iteration for hierarchical reinforcement learning\" (https://proceedings.mlr.press/v130/jothimurugan21a/jothimurugan21a.pdf) and \"Deciding what to model: Value-equivalent sampling for reinforcement learning\" (https://proceedings.neurips.cc/paper_files/paper/2022/hash/3b18d368150474ac6fc9bb665d3eb3da-Abstract-Conference.html). It is important for the authors to contextualize the contributions of this paper against all these related works.\n\n3) issues in technical details\n\nThe authors say in Section 3.2 that when B = \\bar{B}, \"then simulating a trajectory in the abstract model is the same as in the ground model\". But I don't think this is true, because we need the rewards to match between the two trajectories too, and $B_t$ says nothing about rewards, only dynamics. The authors go on to say: \"Therefore, planning in the abstract model is accurate, in the sense, that the value of an abstract state z computed in the abstract model is the same as the one would get from trajectories from the ground MDP for the abstraction operator G.\" Again, I think this is wrong because it ignores the abstract reward function, which could be arbitrarily different from the ground one. In fact, in the proof of corollary 3.8, the authors assume $E_{s \\sim G(\\cdot \\mid z)}\\[R(s, o)\\] = \\bar{R}(z, o)$, and it's only _under this assumption_ that the claims hold. But combining this assumption on reward function with Definition 3.6 ends us back up at the bisimulation conditions, and then it's not clear what the contributions of this paper are.\n \nAs a separate point, the second term in the mutual information expression of Section 4.2, $MI(S'; Z, A)$, seems very extreme! It is saying that you have to be able to predict the entire ground next state from the current abstract state and action. Doesn't this means the abstraction can't lose any information? This seems like an important technical limitation of the approach.\n\n4) unclear motivation\n\nThe authors often state that a discrete abstract state space is bad, when pointing to work on symbolic abstraction learning (e.g., PDDL). But it's not clear why this is really bad. The authors say discrete abstract states are \"not applicable when planning with the available high-level actions requires a continuous state representation\", but this doesn't make sense to me, as the options have to act in the ground environment states, not in the abstract state space, and so the options could be defined with respect to either a discrete or a continuous abstract state space. Furthermore, it can be much easier to plan in a discrete abstraction (e.g., using powerful symbolic planners).\n\nI believe a fruitful research direction would be to compare the abstractions learned by a symbolic approach against the abstractions learned by a continuous approach (like the authors'). Questions:\n* Not much is said about the dataset $\\mathcal{D}$, but intuitively, it has to be \"good\" in order for the learned state abstraction to be reasonable. In particular, the agent must see all the options being executed in a variety of settings, and obtain good coverage over the state-action space. Are there any concrete statements we can make about what properties we need this dataset to have?\n* \"we must build a model of its effect\" Do you mean to say \"of the effect of each option\"?\n* \"with mean value equal to that by planning with the original MDP\" What is the mean over?\n* Why did we switch from using O (denoting the option set) everywhere to using A throughout Section 4? Shouldn't we continue to use O, unless I am misunderstanding something?\n* Section 4.3: Why should there be any cost/reward associated with executing skills? Shouldn't a sparse reward for reaching the goal be enough?\n* Eq 2: What are the \"I\" random variables inside the mutual information expression referring to?\n\nMinor edits:\n* \"make the same decision\" To clarify, we just need that the policy maps all states in z to the same action distribution. A stochastic policy isn't really committing to a \"decision\" about what action to take.\n* \"Abstractions alleviate this tension: action abstractions enable agents to plan at larger temporal scales and state abstractions reduce the complexity of learning and planning\" I would say that both of them do both of these. Action abstractions certainly reduce the complexity of planning, which is typically exponential in the branching factor.\n* \"learns a further abstraction\" --> \"learn a further abstraction\"\n* \"otherwise it is referred as learning\" I would say \"policy learning\" to distinguish from other things you might learn\n* \"when it is the given position\" --> \"when it is in the given position\"\n* \"referred as learning\" --> \"referred to as learning\"\n* \"results a bounded value loss\" --> \"results in a bounded value loss\"\n* In definition 3.5, the authors use $s_o$ in a few places where they mean $s_0$.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1699636621573",
         "3.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "1210",
         "7",
         "0",
         "0.7753",
         "0.0567315252",
         "0.9024221301",
         "49",
         "44.7468",
         "0.6075",
         "iclr",
         "0.019607843137254943"
        ],
        [
         "43",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-36E8",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "3",
         "3",
         "4",
         "4",
         "80",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper presents an approach for learning dynamics preventing abstractions for sensorimotor observation space. Given a set of high-level skills and the learned dynamics preserving abstractions, the paper claims to develop an approach for planning for a solution. \n\nThe approach is evaluated in two test domains where the paper shows the visualization of the learned abstractions. - For the most part of the paper, it is extremely well written. Given the wide use of embodied AI systems and robots, an approach that generates plannable abstractions for high-dimensional sensor input is extremely important. \n\n- The paper nicely motivates the problem. While the paper in general is nicely written, it has a few limitations: \n\n- The paper advocates learning a continuous abstract  representation instead of a symbolic abstractions. However, it does not provide any reasons to that. Why are continuous abstractions more desirable than symbolic abstractions? \n\n- Sec 4.1 is unclear. The notation for MI is a bit unclear. It needs to be made more clear. Sec 4.1 requires a re-writing including more explanation for the equation. I have two important questions: \n\n- How is the dynamics preserving abstraction defined in Def. 3.6 different from the Markovian abstractions defined in \\[Srivastava et al. 2016\\]? \n\n- Can you discuss the differences between the presented approach and \\[Allen et al. 2021\\] \n\nReference \n\nAllen, Cameron, et al. \"Learning markov state abstractions for deep reinforcement learning.\" Advances in Neural Information Processing Systems 34 (2021): 8229-8241.\n\nSrivastava, Siddharth, Stuart Russell, and Alessandro Pinto. \"Metaphysics of planning domain descriptions.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1699636621454",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "264",
         "1",
         "6",
         "0.7512000000000001",
         "0.1625",
         "0.8653070927000001",
         "49",
         "41.1434",
         "0.2429",
         "iclr",
         "0.0"
        ],
        [
         "44",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-dCJp",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "83",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper introduces a method for enabling general-purpose agents to efficiently handle complex tasks by constructing abstract models based on temporally-extended actions. These models facilitate more efficient planning and learning and are characterized using principled conditions. The approach provides empirical evidence of improved sample efficiency in goal-based navigation tasks and offers theoretical support for information maximization strategies in abstract state representation learning.\nThe authors claim that they introduced a method for creating abstract world models that empower agents to plan effectively for goal-oriented tasks. The key idea is to allow agents to construct reusable abstract models for planning with specific skills. This is achieved by characterizing the state abstraction that ensures planning without any loss in simulation, meaning that planning with the learned abstract model can generate policies for the real world. The paper also provides theoretical support for the use of information maximization as a reliable strategy for learning abstract state representations. - Good overview of the related work.\n- Good description of motivations and intuitions. \n- proper choice of environment settings. Major:\n- Some measures are used without definition, \n- It seems that there exists a lot of inaccuracies and impreciseness in the theories and definitions. See all questions!\n\nminor:\n- typos: \nlast paragraph of the introduction \"the *agents* needs\", definition 3.5 \"$s_{o}$\" must be \"$s_0$\"\n- writing: \nDefine the abbreviations before using them, e.g. \"PDDL\", \"VAE\"\n\nThere is a chance that I have not fully understood what this paper is trying to present. 1- What is $P(s'|s,o)$ used in the paragraph right after definition 3.1?\n\n2- An option $o$ is defined, and then you mention $T(s'|s,o)$ to define the transition probability of taking option $o$ in $s$? $T$ earlier was defined on action space $A$. How is it applied on options without showing the relationship of $I_o$ and $\\beta_o$ with $s$ and $s'$ under option policy $\\pi_o$?\n\n3-the paper has defined \"$\\bar {\\gamma} = \\gamma ^{\\tau (s,o)}$ is the abstract discount factor, $\\tau: Z \\times O \\rightarrow \\[0,\\infty)$, which consists of contradictory phrases. How is ${\\tau (s,o)}$ but defined as a function of abstract variables $Z$ instead of $S$? Not clear what $\\tau$ is. If based on definition 3.1, it is the option's execution time starting from $s$ taking option $o$, it is not clear how in definition 3.2 it becomes a map from $Z$ and $O$ to a non-negative real.\n\n4- What does definition 3.4 mean? $ \\Pi = {\\pi \\in \\Pi : \\pi(·|s) = \\pi (·|z) \\forall s \\in z}$ says the probability of taking actions/options in $s$ should be equivalent to the probability of taking actions/options in abstract states. Transitions of taking actions in states might take you to another state $s'$ inside the similar abstract state $z$. How can the policies used for both abstract states and states be equivalent? Unless you are just discretizing the continuous state spaces based on the optimal policies that are already given. Lots of interchangeable usage of symbols here. Not precise and is hard to follow.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1700688515580",
         "3.0",
         "4.0",
         "2.0",
         "3.0",
         "2.0",
         "499",
         "0",
         "1",
         "0.7308",
         "0.0796438834",
         "0.93872118",
         "61",
         "45.6397",
         "0.1463",
         "iclr",
         "0.0"
        ],
        [
         "45",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-gKE9",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "none",
         "5",
         "4",
         "4",
         "4",
         "4",
         "5",
         "89",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes a grounded abstract model formulation with a dynamic preserving abstraction. This abstract state representation (and model) guarantees not only accurate future predictions but also the bounded values in the abstracted rollouts. This paper then provides its implementation using contrastive learning to maximize mutual information between the future state, and the current abstract state and option. The results show that training DDQN in imagination using the abstract model improves the sample efficiency. * The paper proposes a solid foundation of the abstract model that preserves dynamics and values.\n\n* The paper is well written.\n\n* The visualization in Figure 3 clearly shows that the abstract state representations focus on important features in the original observation space. * The main focus of the paper is to show the efficiency of planning and learning when using the proposed abstract MDP. The experiments in the paper are a bit simple to showcase the benefits of the abstract model for planning. It would be stronger if the experiment was done in more complex environments with much longer-horizon tasks, such as AntMaze experiments (Hafner 2022) or robotic manipulation tasks \\[a\\].\n\n* Similarly, the comparisons in Figure 5 are essentially between model-free RL (ground) and model-based RL (abstract), which does not seem fair. It might be fair to compare the proposed method with other model-based RL approaches, such as Dreamer and TD-MPC.\n\n* Exhaustive comparisons to the alternatives to the dynamics preserving abstraction would be interesting, such as bisimulation.\n\n* Some highly relevant works on temporally-extended models \\[a,b\\] are missing in the paper. Proper comparisons to these approaches are necessary.\n\n\\[a\\] Shi et al. Skill-based Model-based Reinforcement Learning. CoRL 2022\n\n\\[b\\] Zhang et al. Leveraging Jumpy Models for Planning and Fast Learning in Robotic Domains. 2023 Please address the weaknesses mentioned above.\n\n\n### Minor questions and suggestions\n\n* Figure 1 may want to explain why abstract state representations and options are helpful for planning and learning. However, Figure 1 does not seem to help understand the paper. To understand this figure, we first need to know about options and abstract state representations, and how they simplify planning.\n\n* In Section 4.2, it is unclear whether $\\mathcal{L}^T_{\\theta, \\phi}$ is used to update $f_\\phi$ or not.\n\n* For multi-goal experiments in the paper, using the same amount of environment steps for the abstract planning and the ground baseline would make it easier to understand how better or worse a method is.\n\n* The appendix could be included in the main paper for easier navigation.\n\n* What is the difference between Figure 7 and 8?\n\n* Training the abstract planning method longer in Figure 7 and 8 would be helpful to see how it learns. Using different x-scales for two methods is okay but it would be better to have the same scale.\n\n* Many minor typos in the paper.\n\n\n---\n\nThank you for author responses. I would love to see comparisons to Dreamer-like baselines, but couldn't find the results by the end of the rebuttal period. Thus, I keep my rating, borderline reject.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1701585748243",
         "5.0",
         "3.0",
         "2.0",
         "3.0",
         "3.0",
         "507",
         "0",
         "3",
         "0.7684000000000001",
         "0.1385185185",
         "0.9183520675",
         "71",
         "48.6501",
         "0.8246",
         "iclr",
         "0.0"
        ],
        [
         "46",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-xxEb",
         "2",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "50",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper introduces a novel model, PatchSynth, in the Patch-Text Pre-training (PTP) domain, aiming to improve software patch representation and description generation. Through a blend of patch understanding and generation, PatchSynth\t addresses the limitations of prior models. Empirical evaluations reveal its superior performance in patch description generation, with an ablation study further underscoring the importance of generating task training. Novelty and Importance: The work is first to propose a unimodel for patch-text understanding and related tasks. And the topic is very important in this domain.\n\n\tMelds patch understanding and generation, addressing prior models' specialization limitations.\n\n\tThe work provides a good representation and good results Unclear adaptability across diverse programming languages or coding standards. What are the considerations for deploying PatchSynth in real-world software development environments, and what infrastructure would be required for efficient and secure operation?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319846",
         "8.0",
         "5.0",
         "4.0",
         "3.0",
         "4.0",
         "136",
         "0",
         "0",
         "0.7967000000000001",
         "0.30636363640000003",
         "0.944865346",
         "50",
         "11.6712",
         "0.0364",
         "iclr",
         "0.0"
        ],
        [
         "47",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-4kdr",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "65",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper discusses a new model, PatchSynth, in the domain of Patch-Text Pre-training (PTP) which aids in accurate patch representation for software evolution tasks like bug fixing and feature enhancement. PatchSynth is designed to balance patch understanding and generation, overcoming limitations of previous models. It outperforms existing models in patch description generation, as shown in experiments using standard evaluation metrics. An ablation study further reveals the importance of generating task training in improving PatchSynth performance. Novelty:\nThe novelty of PatchSynth lies in its harmonious synthesis of patch understanding and generation, coupled with an advanced synthetic description generator. This innovative approach addresses the historical challenges of accurate patch representation and description generation, marking a significant stride in the PTP paradigm.\nImportance:\nThe topic is of paramount importance as it addresses a critical need in software engineering for accurate patch representation and description, which are pivotal for collaborative development, systematic documentation, and rapid code review processes. By advancing the PTP paradigm, PatchSynth not only contributes to the academic discourse but also holds promise for practical applications in software development workflows.\nThe work achieves promising results. The paper doesn't elucidate how PatchSynth adapts to varying programming languages or codebases with differing coding standards and structures. This lack of demonstrated adaptability could limit its applicability across diverse software projects, potentially requiring additional tuning or re-training to maintain accuracy and effectiveness in different environments. 1. Given the advancements in PatchSynth for patch-text understanding and generation, how well does the model perform in a transfer learning scenario? Can PatchSynth be fine-tuned or adapted effectively to related tasks in software engineering or different programming languages?\n2. Are there considerations or plans for deploying PatchSynth in real-world software development environments? How would the integration look like, and what kind of support or infrastructure would be required to ensure the model operates efficiently and securely in a production setting?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319768",
         "10.0",
         "5.0",
         "4.0",
         "4.0",
         "4.0",
         "310",
         "0",
         "2",
         "0.8356",
         "0.18839531680000002",
         "0.9401642680000001",
         "50",
         "9.2899",
         "0.068",
         "iclr",
         "0.0"
        ],
        [
         "48",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-H6rR",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "2",
         "80",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "This paper tackles the problem of code patch representation learning -- how to represent edits on code to support downstream tasks like commit message generation, patch correctness assessment, etc. \n\nThis paper proposes a pretraining framework, with triplet losses on text-code contrastive loss, text-code matching loss and text generation loss based on code patch. The pretraining data includes 90K pairs of code change and synthesized commit messages. \n\nOn downstream task of commit message generation upon FIRA\\[1\\] dataset, PatchSynth showed performance gains over public & self-ablation baselines.\n\n\\[1\\] Jinhao Dong, Yiling Lou, Qihao Zhu, Zeyu Sun, Zhilin Li, Wenjie Zhang, and Dan Hao. Fira: Fine-grained graph-based code change representation for automated commit message generation. 2022. 1. Unlike from previous approaches(CCRep\\[1\\], Cache\\[2\\]) where code change is encoded with two streams (code-before-change, code-after-change), this work encodes code change(patch) with a standard transformer on a single patch file (like git commit diff). This is inline with the general trend in LLMs community that ultimately LLMs should be able to understand and capture internal structure without explicitly modelling it.\n2. This paper applies representation pretraining with triplet losses -- which is quite known in multimodal pretraining domain (BLIP\\[3\\], BLIP-2\\[4\\], etc) -- to code patch representation. It empirically showed that such pretraining is helpful for downstream task of commit message generation.\n\n\n\\[1\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[2\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022.\n\n\\[3\\] Junnan Li, Dongxu Li, Caiming Xiong, & Steven C. H. Hoi (2022). BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. In ICML (pp. 12888–12900). PMLR.\n\n\\[4\\] Junnan Li, Dongxu Li, Silvio Savarese, & Steven C. H. Hoi (2023). BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models. In ICML (pp. 19730–19742). PMLR. I have multiple major concerns on the paper based on its current form. The most concerning issues are:\n\n1. The paper claims \"The core part of PATCHSYNTH lies a state-of-the-art synthetic description generator\" in multiple places (3rd paragraph of Introduction, 2nd contribution in last part of Introduction, Section 2.3). However, there is no details on this synthetic description generator. The only mention is Section 4.4 with just one line \"Capitalizing on benchmarks from seminal works\\[1,2\\], our dataset, primarily focused on Java samples includes 90,661 patches with their **attendant** descriptions\"\n\n    i. Are these **attendant** descriptions generated by the author but simply taken from \\[1,2\\]? If the latter, then claiming such synthetic description generation as a key feature in this paper is highly problematic.\n\n2. The task of representation learning of code patch, defaultly assigns 1 vector for a code patch (w/ 1 or more edits), which is the case for all previous works including CC2Vec\\[3\\], CCRep\\[4\\], Cache\\[5\\]. However, PATCHSYNTH seems to encode the code patch to a sequence of vectors (Figure 1). \n\n    i. Such change needs explicit explanation and justification which authors have failed to deliver.\n\n3. Missing LLM baselines: with code patch being encoded with a sequence of vectors, the authors should compare with code-aware LLMs like Code-llama, or WizardCoder, as they also encode code patch to a sequence of vectors. \n    \n    i. As the recent code-aware LLMs have shown great abilities in general instruction following in coding-related tasks, a very timely baseline would be applying code-aware LLMs to the downstream task of commit message generation, with few-shot prompting or finetuning. \n\n    ii. A comparison of PATCHSYNTH vs code-aware LLMs would very helpful for the community to understand the edge and relevance of the proposed method in LLM era, which the authors have failed to deliver.\n\n4. Only 1 downstream task evaluated: The authors claimed that the method is designed both for generative and discriminative tasks. However, the empirical experiments were only conducted on commit message generation. As the encoding changed from one vector to a sequence of vectors, it's important to show how can such encoding can be adapted to tackle retrieval or classification tasks. Also, to claim it as a pretrain model, the authors need to evaluate on multiple downstream datasets.\n\n5. Fairness in comparison: \n\n    i. Is PATCHSYNTH firstly pretrained on 90K and then finetuned on 75K data of FIRA? If so, it's not so fair to compare PATCHSYNTH with CCRep and FIRA methods, as they are not trained on 90K pretraining data. For example, Is it possible to also pretrain CCRep with 90K data?\n\n    ii. As mentioned in point 2, CCRep has a more compact encoding of 1 vector while PATCHSYNTH encodes to a sequence of vectors. It is thus not fair to compare without explicitly mentioning such differences.\n\n6. Concerns on Pretraining:\n\n    i. details of creating negative pairs: one common technique in contrastive training is hard-negative-mining. However, the authors didn't disclose how they create negative pairs\n\n    ii. For vision-language representation learning, a large batch size (>= 512) and a large pool to select negative examples have been shown to be necessary. This paper mentions the batch size of 32, which seems pretty small. I will need more verification on ablation of 1) batch size, 2) negative example selection and 3) pretraining metrics to be convinced that such setting is adequate for code-text representation pretraining. \n\n7. Writing & formatting issues\n\n    i. On page 8, the chart of Figure 2 is partially blocked by its top legend\n\n    ii. On page 8, the paragraph for \\[Performance cross different patch attention\\] is repetitive: it repeats twice in introducing the numerical performance. Besides, I don't think it's a good idea to verbosely list down all numbers when they are clearly seen in Figure 2.\n\n    iii. In Section 2.1, there's no mention on recent code aware LLMs like Code-LLaMA. \n\n    iv. In Section 2.3, there's no citation to any work. Besides, CCRep\\[4\\] doesn't have the gap mentioned in Section 2.3 as it can both do discriminative and generative tasks and it doesn't reply on AST information. So an explicit comparison to CCRep in Related Work should be present.\n\n\\[1\\] Robert Dyer, Hoan Anh Nguyen, Hridesh Rajan, and Tien N Nguyen. Boa: A language and infras\u0002tructure for analyzing ultra-large-scale software repositories. In 2013 35th International Confer\u0002ence on Software Engineering (ICSE), pp. 422–431. IEEE, 2013.\n\n\\[2\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[3\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[4\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[5\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022. 1. Why did you use CodeBERT to initiate both text encoder and decoder? For example, did you consider encoder-decoder model like Code-T5?\n\n2. In Experiment Setup, you mentioned \"Model dimensions are meticulously calibrated\". May I know how are the hyper-parameters searched? Are you using the downstream task performance or some pretraining metrics?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319680",
         "3.0",
         "4.0",
         "1.0",
         "1.0",
         "2.0",
         "1254",
         "27",
         "37",
         "0.7999",
         "0.069050849",
         "0.8986387253",
         "50",
         "47.6556",
         "0.1651",
         "iclr",
         "0.0"
        ],
        [
         "49",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-639w",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "90",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "Programs are frequently modified in commits, with the changes represented as program patches and often described with natural language text. This work proposes to finetune a pair of BERT encoders on the combination of such patches and their descriptions, introducing a three-fold loss. The resulting model is evaluated on a patch description generation task, where it outperforms recent baselines. This work focuses on an established and reasonably important task in software engineering, patch representation and description (or, commit message) generation. It uses a fairly conventional encoder-decoder architecture with additional loss terms for this. Its main contribution lies in the combination of these components, which evidently yields improved performance compared to prior work.\n\nThe results show improvements in the order of 5-10% (relative) compared to baselines, which, while still yielding relative low BLEU scores (~21%), might benefit the commit message generation work and tools with a stronger baseline. The methodology, including the architecture and loss terms, was relatively easy to follow. The technical contribution is very limited. The work connects two pretrained encoders (one for text and one for code) with cross-attention. Its main aim is to generate patch descriptions from the patch. It introduces two additional (but not novel) loss terms that provide a form of embedding alignment, both based on a contrastive loss. One of these appears to provide no significant benefit (DPC, Tab. 2). The setup is evaluated on a fairly small batch of mainly Java samples that appear to consist of a single patch with their associated commit message. These type of Github-scraped datasets tend to suffer from many low-quality descriptions that make it hard to meaningfully train and evaluate models and the set used in this work is no exception: the highest reported BLEU score is just 21.82%. The results corresponding to Fig. 2 show that precision/recall is about even across use-cases. As such, the work offers a useful, fairly off-the-shelf baseline for further experiments in this domain, but does not provide significant new insights or theoretical contributions.\n\nThis aside, the writing suffers from a range of problems. A number of claims about prior work are poorly motivated and several methodological details are poorly described. I list these below. More generally, the paper was quite hard to read. Many sentences include an unusual adjective or phrase that often feels overly subjective and out of place. Some examples from the first few pages: \"a profusion of research endeavors\", \"pronounced specification\", \"exhibit prowess\", \"offering an all-encompassing understanding\", \"not merely theoretical postulates\", \"Our approach transcends conventional methods\", \"avant-garde graph intention embedding\". It would greatly benefit the work to normalize the language, both reducing the use of highly subjective statements and replacing rare words with more commonly used synonyms.\n\nA number of issues:\n\n- P1: \"will lead to the emergence of..\" seems wrong. As noted shortly afterwards, Patch-Text (pre)training is already the subject of multiple studies. If the intent is to forecast that this particular paper will produce a new paradigm, I would strongly recommend removing this sentence.\n- P2: \"seldom both\" -- does this imply that it is sometimes studied jointly? If so, please provide citations.\n- P2: \"fraught with inconsistencies, particularly those integrated with Abstract Syntax Trees\" -- it is not at all clear what this means. Why are ASTs more likely to be/lead to inconsistencies? The mapping of code to ASTs is unambiguous.\n- Sec 3.1: the reference to a \"previous section\" seems wrong; these terms were not introduced before this point.\n- Sec 4.1: wrong notation in \"e - 4\". As written, this subtracts 4 from e.\n- Sec 4.1: how exactly where the dimensions \"meticulously calibrated\"? The two hyper-parameters mentioned next are standard. Were hyper-parameter sweeps conducted? Please share the results of those if so.\n- Sec 4.4: does this mean you combined the dataset of two prior papers, or used the same as theirs? If so, \"our dataset\" is wrong. If not, please elaborate on the process by which the dataset was constructed.\n- Sec. 5.1: the text under \"Outcomes\" says that FIRA outperforms PatchSynth on ROUGE-L (Tab. 1), which it does not.\n- P8: the example here seems wrong on several counts. The patch should delete the previous if-statement. The newly added line is missing \"&&\". The word \"SINGLE\" appears a few times in places where it doesn't seem to be grammatically correct for it to do so. Perhaps this is due to the odd line wrapping and indentation?\n- Fig. 2: the count values should not be connected with a line; this data is not sequentially related. Please discuss whether this work offers a concrete novel technical contribution or whether it should be mainly read as setting a new baseline for patch description based on existing methods. Consider the limitations noted above: one of the loss terms does not seem to have much impact, none of the loss terms are not novel, nor is tuning a cross-attention layer between pretrained models.\n\nPlease clarify some of the methodogical questions raised above, including where the dataset came from, whether any further processing was done, and if/how the hyper-parameters were tuned.",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319601",
         "3.0",
         "5.0",
         "2.0",
         "1.0",
         "1.0",
         "846",
         "0",
         "5",
         "0.8399000000000001",
         "0.027047884100000003",
         "0.9130145311000001",
         "50",
         "49.8575",
         "0.5586",
         "iclr",
         "0.0"
        ],
        [
         "50",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-9sGD",
         "4",
         "4",
         "factual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "85",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "Main contributions of the paper are:\n\n- Proposes PATCHSYNTH, a novel pre-training framework for jointly learning patch and text representations. This allows the model to perform well on both patch understanding and generation tasks.\n- Implements an innovative synthetic description generator to capture semantics within patches. This aims to mitigate issues with inconsistent data sources like error-prone ASTs.\n- Uses a triple loss training strategy with losses for contrastive learning, matching, and generation. The joint training aims to harmonize the losses.\n- Sets new state-of-the-art results on patch description generation, outperforming existing methods on metrics like BLEU, ROUGE-L, and METEOR. This paper addresses the patch generation task, which is typically a difficult task in the software engineering domain. Adapting the triplet loss into the pretraining stage is somehow new. The first thing I notice is that the writing is very bad and uses unnatural words, such as \"Distinct from contemporary models, PATCHSYNTH is underpinned by a harmonious synthesis of patch understanding and generation. To steer clear of the pitfalls of excessive specialization, our model is designed to effortlessly switch between these two essential tasks\". This looks very similar to an AI assistant tool like ChatGPT generated. Can the authors confirm that the majority of the writing was generated by AI tools?\n\nThe related section lacks a lot of related work to patch generation tasks, such as commit message generation \\[1, 7\\], code summarization \\[4,5,6\\], and patch assessment \\[2,3\\]. It appears that the author did not conduct a thorough literature review before working on this topic.\n\nCan the authors highlight how the triplet loss contributes to the novelty of the paper?\n\nThe evaluation metrics are unclear; why are such metrics used for this task? Furthermore, the baselines used are weak and not carefully chosen. PatchSync should be compared to recent Code Large Language Models such as GPT 3.5, GPT-4, CodeGen \\[9\\], StarCoder \\[8\\], and others. I believe that simple prompting on these models can easily solve this task without using PATCHSYNTH. Finally, the benchmark datasets are old, and the purpose is not well explained due to poor writing.\n\nOverall, I believe that this paper is poorly written, lacks a novel contribution, and the literature is poorly performed. The experiments aren't much better. \n\n\n\\[1\\] Context-aware retrieval-based deep commit message generation, https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=7779&context=sis_research\n\n\\[2\\] Invalidator: Automated Patch Correctness Assessment Via Semantic and Syntactic Reasoning, https://ieeexplore.ieee.org/abstract/document/10066209\n\n\\[3\\] Zero-Shot Automatic Patch Correctness Assessment, https://arxiv.org/abs/2303.00202\n\n\\[4\\] Deep code comment generation, https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5295&context=sis_research\n\n\\[5\\] Just-in-time obsolete comment detection and update, https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=8772&context=sis_research\n\n\\[6\\] Retrieve and refine: exemplar-based neural comment generation, https://arxiv.org/pdf/2010.04459.pdf\n\n\\[7\\] Jointly Learning to Repair Code and Generate Commit Message, https://arxiv.org/abs/2109.12296\n\n\\[8\\] StarCoder: may the source be with you!, https://arxiv.org/abs/2305.06161\n\n\\[9\\] CodeGen2: Lessons for Training LLMs on Programming and Natural Languages, https://arxiv.org/abs/2305.02309 Why the evaluation metrics are used for this task?\n\nCan you provide comparison with Code Large Language Models?\n\nWhy the triplet loss is novel for this task?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319498",
         "1.0",
         "5.0",
         "2.0",
         "1.0",
         "1.0",
         "480",
         "23",
         "0",
         "0.8239000000000001",
         "0.0002152802",
         "0.9607024193",
         "50",
         "33.101",
         "0.43510000000000004",
         "iclr",
         "0.0"
        ],
        [
         "51",
         "28",
         "Muhan",
         "Reviewer-xyNq",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "4",
         "3",
         "3",
         "4",
         "5",
         "60",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper considers the problem of certifying individual fairness (IF), which is of great importance to reliable machine learning algorithms. To this end, the authors propose a novel convex relation of IF constraints that greatly reduces the computational cost. In addition, the authors propose to certify distributional individual fairness, ensuring that the neural network has guaranteed individually fair predictions for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball. 1. This paper is technically sound.\n2. The extensive experiments validate the effectiveness of the proposed methods. The paper studies individual fairness and distributional fairness. To my opinion, the two topics seem to be independent. However, it is possible that I misunderstand this paper. It would be better if the authors can present more relations between these topics. ## Miscellaneous\n1.\tLine 106: feed forward $\\to$ feedforward\n2.\tLine 168: $d$ is indeed a vector; however, the denotation $\\sqrt{d}$ should be defined more specifically.\n none",
         "['~Matthew_Robert_Wicker1', '~Vihari_Piratla1', '~Adrian_Weller1']",
         "1702411365184",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "2.0",
         "156",
         "0",
         "5",
         "0.8035",
         "0.28125",
         "0.9500498772",
         "215",
         "29.3366",
         "0.1213",
         "neurips",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 37,
        "rows": 454
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>assessor</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>Comprehensiveness</th>\n",
       "      <th>Usage_of_Technical_Terms</th>\n",
       "      <th>Factuality</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Politeness</th>\n",
       "      <th>Vagueness</th>\n",
       "      <th>Objectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>days_to_submit</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>venue</th>\n",
       "      <th>hedging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-7mFW</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.124510</td>\n",
       "      <td>0.877563</td>\n",
       "      <td>49</td>\n",
       "      <td>22.7412</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>iclr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-FAWm</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.158831</td>\n",
       "      <td>0.882994</td>\n",
       "      <td>60</td>\n",
       "      <td>31.9755</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>iclr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-kjkr</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.146498</td>\n",
       "      <td>0.853166</td>\n",
       "      <td>61</td>\n",
       "      <td>35.3958</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>iclr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Enrico-Daga</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.164583</td>\n",
       "      <td>0.667865</td>\n",
       "      <td>60</td>\n",
       "      <td>31.3100</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>semanticweb</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Julia-Bosque</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.169733</td>\n",
       "      <td>0.852243</td>\n",
       "      <td>73</td>\n",
       "      <td>34.6600</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>semanticweb</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-s437</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>0.942502</td>\n",
       "      <td>216</td>\n",
       "      <td>31.0628</td>\n",
       "      <td>0.1585</td>\n",
       "      <td>neurips</td>\n",
       "      <td>0.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-mMGf</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>negative</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.068210</td>\n",
       "      <td>0.909826</td>\n",
       "      <td>216</td>\n",
       "      <td>36.0945</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>neurips</td>\n",
       "      <td>0.011236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-AtQ2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.056486</td>\n",
       "      <td>0.936743</td>\n",
       "      <td>216</td>\n",
       "      <td>42.2587</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>neurips</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-v6cq</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.216739</td>\n",
       "      <td>0.921304</td>\n",
       "      <td>216</td>\n",
       "      <td>39.0844</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>neurips</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>5</td>\n",
       "      <td>Sonny</td>\n",
       "      <td>Alison-Kutywayo</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.126449</td>\n",
       "      <td>0.844406</td>\n",
       "      <td>604</td>\n",
       "      <td>34.7600</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>f1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id         assessor         reviewer  Comprehensiveness  \\\n",
       "0         166   Sajad-Ebrahimi    Reviewer-7mFW                  2   \n",
       "1         166   Sajad-Ebrahimi    Reviewer-FAWm                  4   \n",
       "2         166   Sajad-Ebrahimi    Reviewer-kjkr                  3   \n",
       "3         100            Seyed      Enrico-Daga                  3   \n",
       "4         100            Seyed     Julia-Bosque                  5   \n",
       "..        ...              ...              ...                ...   \n",
       "500        75  Ali-Ghorbanpour    Reviewer-s437                  3   \n",
       "501        75  Ali-Ghorbanpour    Reviewer-mMGf                  4   \n",
       "502        75  Ali-Ghorbanpour    Reviewer-AtQ2                  5   \n",
       "503        75  Ali-Ghorbanpour    Reviewer-v6cq                  2   \n",
       "504         5            Sonny  Alison-Kutywayo                  3   \n",
       "\n",
       "     Usage_of_Technical_Terms         Factuality Sentiment_Polarity  \\\n",
       "0                           4            factual            neutral   \n",
       "1                           4            factual            neutral   \n",
       "2                           4            factual            neutral   \n",
       "3                           2            factual           positive   \n",
       "4                           4            factual           positive   \n",
       "..                        ...                ...                ...   \n",
       "500                         3  partially factual            neutral   \n",
       "501                         4            factual           negative   \n",
       "502                         4            factual           positive   \n",
       "503                         3  partially factual           positive   \n",
       "504                         4            factual            neutral   \n",
       "\n",
       "    Politeness Vagueness  Objectivity  ...  citation_count  question_count  \\\n",
       "0       polite      high            4  ...               0               5   \n",
       "1       polite      none            4  ...               8              14   \n",
       "2       polite       low            4  ...               4               8   \n",
       "3       polite      none            4  ...               0               1   \n",
       "4       polite       low            4  ...               1               5   \n",
       "..         ...       ...          ...  ...             ...             ...   \n",
       "500     polite       low            2  ...               0               1   \n",
       "501     polite      none            4  ...               0               5   \n",
       "502     polite      none            4  ...               5               3   \n",
       "503     polite  moderate            3  ...               0               5   \n",
       "504     polite  moderate            4  ...               1               1   \n",
       "\n",
       "      mattr  sentiment_polarity  similarity_score  days_to_submit  \\\n",
       "0    0.7173            0.124510          0.877563              49   \n",
       "1    0.7996            0.158831          0.882994              60   \n",
       "2    0.8027            0.146498          0.853166              61   \n",
       "3    0.8103            0.164583          0.667865              60   \n",
       "4    0.7741            0.169733          0.852243              73   \n",
       "..      ...                 ...               ...             ...   \n",
       "500  0.8233            0.074735          0.942502             216   \n",
       "501  0.8096            0.068210          0.909826             216   \n",
       "502  0.8291            0.056486          0.936743             216   \n",
       "503  0.8219            0.216739          0.921304             216   \n",
       "504  0.7795            0.126449          0.844406             604   \n",
       "\n",
       "    flesch_reading_ease politeness_score        venue   hedging  \n",
       "0               22.7412           0.0999         iclr  0.000000  \n",
       "1               31.9755           0.1565         iclr  0.000000  \n",
       "2               35.3958           0.1507         iclr  0.000000  \n",
       "3               31.3100           0.1149  semanticweb  0.019608  \n",
       "4               34.6600           0.2025  semanticweb  0.000000  \n",
       "..                  ...              ...          ...       ...  \n",
       "500             31.0628           0.1585      neurips  0.012048  \n",
       "501             36.0945           0.1100      neurips  0.011236  \n",
       "502             42.2587           0.9014      neurips  0.000000  \n",
       "503             39.0844           0.1108      neurips  0.000000  \n",
       "504             34.7600           0.9417        f1000  0.000000  \n",
       "\n",
       "[454 rows x 37 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new column named hedging compute as follows: 1 - (hedge_C / (hedge_C + hedge_D + hedge_E + hedge_I + hedge_N))\n",
    "df_human_vs_metric['hedging'] = 1 - (df_human_vs_metric['hedge_C'] / (df_human_vs_metric['hedge_C'] + df_human_vs_metric['hedge_D'] + df_human_vs_metric['hedge_E'] + df_human_vs_metric['hedge_I'] + df_human_vs_metric['hedge_N']))\n",
    "# drop columns with 'hedge_' prefix\n",
    "df_human_vs_metric = df_human_vs_metric.drop(columns=[col for col in df_human_vs_metric.columns if col.startswith('hedge_')])\n",
    "# drop following columns: flesch_kincaid_grade, gunning_fog, smog_index, automated_readability_index\n",
    "df_human_vs_metric = df_human_vs_metric.drop(columns=['flesch_kincaid_grade', 'gunning_fog', 'smog_index', 'automated_readability_index'])\n",
    "df_human_vs_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Actionability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Clarity_and_Readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Comprehensiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Constructiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Fairness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Objectivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Overall_Quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Relevance_Alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Usage_of_Technical_Terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Vagueness",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "97d0e669-5e94-4ef3-9ed8-dfcb1ca29806",
       "rows": [
        [
         "0",
         "166",
         "Reviewer-7mFW",
         "4",
         "4",
         "2",
         "3",
         "factual",
         "4",
         "4",
         "67",
         "polite",
         "4",
         "neutral",
         "4",
         "high",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "partially factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "neutral",
         "4",
         "moderate",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "1",
         "166",
         "Reviewer-FAWm",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "86",
         "polite",
         "5",
         "neutral",
         "4",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "2",
         "166",
         "Reviewer-kjkr",
         "5",
         "5",
         "3",
         "5",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "80",
         "polite",
         "5",
         "negative",
         "5",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "partially factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "3",
         "100",
         "Enrico-Daga",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "5",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "2",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "4",
         "100",
         "Julia-Bosque",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "87",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "100",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "5",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "4",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "5",
         "100",
         "Thierry-Declerck",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "60",
         "polite",
         "3",
         "positive",
         "1",
         "high",
         "5",
         "5",
         "2",
         "5",
         "factual",
         "5",
         "5",
         "60",
         "polite",
         "5",
         "neutral",
         "2",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "4.0",
         "none",
         "2",
         "4",
         "2",
         "2",
         "factual",
         "4",
         "3",
         "3",
         "polite",
         "3",
         "positive",
         "1",
         "low",
         "1",
         "4",
         "1",
         "1",
         "factual",
         "3",
         "2",
         "35",
         "polite",
         "2",
         "positive",
         "0",
         "high"
        ],
        [
         "6",
         "74",
         "Reviewer-itVg",
         "2",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "3",
         "none",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "5",
         "5",
         "75",
         "5",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "7",
         "74",
         "Reviewer-bNPg",
         "3",
         "3",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "90",
         "polite",
         "4",
         "neutral",
         "3",
         "none",
         "5",
         "4",
         "4",
         "5",
         "partially factual",
         "4",
         "4",
         "65",
         "polite",
         "5",
         "negative",
         "5",
         "moderate",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "neutral",
         "5",
         "neutral",
         "4",
         "moderate",
         "2",
         "2",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "8",
         "194",
         "Reviewer-GDNX",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "neutral",
         "4",
         "neutral",
         "5",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "9",
         "194",
         "Reviewer-j1mL",
         "4",
         "3",
         "4",
         "4",
         "partially factual",
         "3",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "10",
         "194",
         "Reviewer-cMiu",
         "4",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "11",
         "194",
         "Reviewer-ky3t",
         "3",
         "4",
         "2",
         "3",
         "factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "2",
         "4",
         "3",
         "2",
         "5",
         "5",
         "4",
         "65",
         "neutral",
         "5",
         "positive",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "1",
         "3",
         "3",
         "1",
         "partially factual",
         "3",
         "3",
         "50",
         "polite",
         "4",
         "positive",
         "4",
         "moderate",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "12",
         "38",
         "Reviewer-vqBu",
         "3",
         "4",
         "3",
         "2",
         "unfactual",
         "2",
         "2",
         "60",
         "polite",
         "3",
         "neutral",
         "2",
         "low",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "4",
         "78",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "13",
         "38",
         "Reviewer-3sWQ",
         "2",
         "3",
         "3",
         "1",
         "unfactual",
         "3",
         "3",
         "60",
         "neutral",
         "3",
         "negative",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "3",
         "4",
         "65",
         "neutral",
         "5",
         "negative",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "2",
         "3",
         "3",
         "2",
         "factual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "14",
         "38",
         "Reviewer-pTVu",
         "3",
         "4",
         "3",
         "4",
         "unfactual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "negative",
         "3",
         "low",
         "5",
         "5",
         "4",
         "5",
         "5",
         "5",
         "5",
         "90",
         "5",
         "5",
         "5",
         "5",
         "1",
         "2.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "15",
         "38",
         "Reviewer-CnQu",
         "1",
         "4",
         "3",
         "1",
         "unfactual",
         "2",
         "2",
         "50",
         "neutral",
         "3",
         "negative",
         "3",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "16",
         "13",
         "Joseph-philipraj",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "5",
         "5",
         "3",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "85.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "2",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "92",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "17",
         "13",
         "Muhammad-Faruk",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "93",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "85.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "18",
         "181",
         "Reviewer-sna7",
         "4",
         "4",
         "2",
         "3",
         "factual",
         "4",
         "3",
         "70",
         "neutral",
         "4",
         "positive",
         "2",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "19",
         "181",
         "Reviewer-HLbG",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "3",
         "80",
         "neutral",
         "4",
         "neutral",
         "3",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "20",
         "181",
         "Reviewer-c3Sg",
         "4",
         "4",
         "4",
         "3",
         "factual",
         "3",
         "3",
         "70",
         "neutral",
         "3",
         "neutral",
         "3",
         "high",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "21",
         "181",
         "Reviewer-ebFz",
         "3",
         "4",
         "2",
         "3",
         "factual",
         "3",
         "3",
         "65",
         "neutral",
         "3",
         "neutral",
         "2",
         "high",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "2",
         "4",
         "3",
         "3",
         "factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "1",
         "4",
         "2",
         "2",
         "partially factual",
         "3",
         "2",
         "45",
         "polite",
         "4",
         "positive",
         "3",
         "low"
        ],
        [
         "22",
         "9",
         "Reviewer-KmBd",
         "4",
         "3",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "90",
         "neutral",
         "3",
         "neutral",
         "4",
         "none",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "23",
         "9",
         "Reviewer-3zCE",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "negative",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "75",
         "polite",
         "5",
         "negative",
         "5",
         "low",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "70",
         "neutral",
         "5",
         "negative",
         "4",
         "low"
        ],
        [
         "24",
         "9",
         "Reviewer-y5kB",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "25",
         "9",
         "Reviewer-XNx6",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "88",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "5",
         "4",
         "5",
         "5",
         "5",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "26",
         "81",
         "Gatot-Soepriyanto",
         "4",
         "4",
         "3",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "moderate",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "27",
         "81",
         "Toni-Šušak",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "5",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "5",
         "4",
         "5",
         "5",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "3",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "28",
         "24",
         "Silvio-Buscemi",
         "1",
         "3",
         "1",
         "2",
         "unfactual",
         "3",
         "1",
         "48",
         "polite",
         "3",
         "negative",
         "1",
         "extreme",
         "4",
         "5",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "29",
         "77",
         "Houcemeddine-Turki",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "88",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "30",
         "67",
         "Reviewer-um1j",
         "5",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "5",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "31",
         "67",
         "Reviewer-YmDt",
         "5",
         "5",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "80",
         "polite",
         "5",
         "negative",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "1.0",
         "3.0",
         "3.0",
         "2.0",
         "partially factual",
         "3.0",
         "2.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "4.0",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "32",
         "67",
         "Reviewer-8RW7",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "85",
         "polite",
         "5",
         "negative",
         "4",
         "low",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "33",
         "67",
         "Reviewer-YYfR",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "polite",
         "5",
         "positive",
         "4",
         "moderate",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "34",
         "171",
         "Magdalena-Czlapka-Matyasik",
         "0",
         "4",
         "1",
         "0",
         "unfactual",
         "3",
         "3",
         "35",
         "neutral",
         "3",
         "neutral",
         "1",
         "high",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "positive",
         "3",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "35",
         "171",
         "Wanshui-Yang",
         "0",
         "4",
         "1",
         "0",
         "unfactual",
         "3",
         "3",
         "40",
         "impolite",
         "3",
         "negative",
         "0",
         "high",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "36",
         "187",
         "Reviewer-2CBB",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "4",
         "4",
         "70",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "37",
         "187",
         "Reviewer-yUvs",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "75",
         "polite",
         "3",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "5",
         "4",
         "4",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "neutral",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "75",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "38",
         "187",
         "Reviewer-PMap",
         "2",
         "4",
         "1",
         "3",
         "partially factual",
         "2",
         "2",
         "30",
         "polite",
         "3",
         "negative",
         "3",
         "moderate",
         "3",
         "4",
         "3",
         "3",
         "partially factual",
         "4",
         "4",
         "65",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "3",
         "3",
         "factual",
         "3",
         "4",
         "65",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "39",
         "103",
         "Reviewer-NRqK",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "4",
         "94",
         "polite",
         "4",
         "negative",
         "5",
         "none",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "negative",
         "5",
         "none",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "3.0",
         "60.0",
         "neutral",
         "5.0",
         "negative",
         "5.0",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "negative",
         "5",
         "none",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "40",
         "103",
         "Reviewer-36E8",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "3",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "4",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "41",
         "103",
         "Reviewer-dCJp",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "3",
         "4",
         "83",
         "polite",
         "4",
         "negative",
         "5",
         "none",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "4",
         "4",
         "45",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "neutral",
         "4",
         "neutral",
         "4",
         "moderate",
         "2",
         "3",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate"
        ],
        [
         "42",
         "103",
         "Reviewer-gKE9",
         "4",
         "5",
         "5",
         "4",
         "factual",
         "4",
         "5",
         "89",
         "polite",
         "4",
         "positive",
         "4",
         "none",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "43",
         "141",
         "Reviewer-xxEb",
         "3",
         "4",
         "2",
         "3",
         "partially factual",
         "3",
         "3",
         "50",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "2",
         "3",
         "3",
         "2",
         "factual",
         "4",
         "3",
         "60",
         "polite",
         "4",
         "positive",
         "4",
         "moderate",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "44",
         "141",
         "Reviewer-4kdr",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "88",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "5",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "45",
         "141",
         "Reviewer-H6rR",
         "4",
         "2",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "1.0",
         "4.0",
         "3.0",
         "4.0",
         "partially factual",
         "2.0",
         "3.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "4.0",
         "moderate",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "4",
         "5",
         "90",
         "neutral",
         "5",
         "negative",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "85",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "46",
         "28",
         "Reviewer-xyNq",
         "3",
         "5",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "60",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "5",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "47",
         "28",
         "Reviewer-Lpfq",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "48",
         "28",
         "Reviewer-FRnw",
         "4",
         "4",
         "3",
         "3",
         "factual",
         "3",
         "4",
         "60",
         "neutral",
         "3",
         "negative",
         "4",
         "high",
         "4",
         "4",
         "4",
         "5",
         "5",
         "5",
         "5",
         "85",
         "5",
         "5",
         "neutral",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "49",
         "41",
         "Reviewer-viiH",
         "2",
         "4",
         "3",
         "2",
         "factual",
         "4",
         "3",
         "60",
         "polite",
         "3",
         "neutral",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "78",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ]
       ],
       "shape": {
        "columns": 67,
        "rows": 434
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>Human_Actionability</th>\n",
       "      <th>Human_Clarity_and_Readability</th>\n",
       "      <th>Human_Comprehensiveness</th>\n",
       "      <th>Human_Constructiveness</th>\n",
       "      <th>Human_Factuality</th>\n",
       "      <th>Human_Fairness</th>\n",
       "      <th>Human_Objectivity</th>\n",
       "      <th>Human_Overall_Quality</th>\n",
       "      <th>...</th>\n",
       "      <th>Phi_Constructiveness</th>\n",
       "      <th>Phi_Factuality</th>\n",
       "      <th>Phi_Fairness</th>\n",
       "      <th>Phi_Objectivity</th>\n",
       "      <th>Phi_Overall_Quality</th>\n",
       "      <th>Phi_Politeness</th>\n",
       "      <th>Phi_Relevance_Alignment</th>\n",
       "      <th>Phi_Sentiment_Polarity</th>\n",
       "      <th>Phi_Usage_of_Technical_Terms</th>\n",
       "      <th>Phi_Vagueness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-7mFW</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-FAWm</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-kjkr</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Enrico-Daga</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Julia-Bosque</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>factual</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-wEMM</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-s437</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-mMGf</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-v6cq</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>5</td>\n",
       "      <td>Alison-Kutywayo</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id         reviewer  Human_Actionability  \\\n",
       "0         166    Reviewer-7mFW                    4   \n",
       "1         166    Reviewer-FAWm                    5   \n",
       "2         166    Reviewer-kjkr                    5   \n",
       "3         100      Enrico-Daga                    4   \n",
       "4         100     Julia-Bosque                    4   \n",
       "..        ...              ...                  ...   \n",
       "429        75    Reviewer-wEMM                    3   \n",
       "430        75    Reviewer-s437                    2   \n",
       "431        75    Reviewer-mMGf                    4   \n",
       "432        75    Reviewer-v6cq                    2   \n",
       "433         5  Alison-Kutywayo                    2   \n",
       "\n",
       "     Human_Clarity_and_Readability  Human_Comprehensiveness  \\\n",
       "0                                4                        2   \n",
       "1                                4                        4   \n",
       "2                                5                        3   \n",
       "3                                4                        3   \n",
       "4                                4                        5   \n",
       "..                             ...                      ...   \n",
       "429                              4                        3   \n",
       "430                              3                        3   \n",
       "431                              4                        4   \n",
       "432                              3                        2   \n",
       "433                              3                        3   \n",
       "\n",
       "     Human_Constructiveness   Human_Factuality  Human_Fairness  \\\n",
       "0                         3            factual               4   \n",
       "1                         5            factual               4   \n",
       "2                         5            factual               4   \n",
       "3                         4            factual               5   \n",
       "4                         4            factual               4   \n",
       "..                      ...                ...             ...   \n",
       "429                       4            factual               3   \n",
       "430                       3  partially factual               3   \n",
       "431                       5            factual               4   \n",
       "432                       3  partially factual               3   \n",
       "433                       2            factual               4   \n",
       "\n",
       "     Human_Objectivity  Human_Overall_Quality  ... Phi_Constructiveness  \\\n",
       "0                    4                     67  ...                    4   \n",
       "1                    4                     86  ...                    4   \n",
       "2                    4                     75  ...                    4   \n",
       "3                    4                     80  ...                    4   \n",
       "4                    4                     87  ...                    5   \n",
       "..                 ...                    ...  ...                  ...   \n",
       "429                  3                     70  ...                    3   \n",
       "430                  2                     55  ...                    4   \n",
       "431                  4                     80  ...                    4   \n",
       "432                  3                     50  ...                    3   \n",
       "433                  4                     75  ...                    4   \n",
       "\n",
       "        Phi_Factuality Phi_Fairness  Phi_Objectivity Phi_Overall_Quality  \\\n",
       "0    partially factual            3                4                  75   \n",
       "1    partially factual            4                4                  85   \n",
       "2    partially factual            4                3                  78   \n",
       "3              factual            4                4                  85   \n",
       "4              factual            5                5                  95   \n",
       "..                 ...          ...              ...                 ...   \n",
       "429  partially factual            3                3                  65   \n",
       "430            factual            4                4                  85   \n",
       "431  partially factual            4                4                  85   \n",
       "432  partially factual            4                3                  75   \n",
       "433  partially factual            4                4                  85   \n",
       "\n",
       "     Phi_Politeness  Phi_Relevance_Alignment  Phi_Sentiment_Polarity  \\\n",
       "0            polite                        5                 neutral   \n",
       "1            polite                        5                 neutral   \n",
       "2           neutral                        5                negative   \n",
       "3            polite                        5                positive   \n",
       "4            polite                        5                positive   \n",
       "..              ...                      ...                     ...   \n",
       "429         neutral                        4                negative   \n",
       "430          polite                        5                 neutral   \n",
       "431          polite                        5                 neutral   \n",
       "432          polite                        4                positive   \n",
       "433          polite                        5                 neutral   \n",
       "\n",
       "     Phi_Usage_of_Technical_Terms Phi_Vagueness  \n",
       "0                               4           low  \n",
       "1                               3           low  \n",
       "2                               5           low  \n",
       "3                               3           low  \n",
       "4                               4           low  \n",
       "..                            ...           ...  \n",
       "429                             4           low  \n",
       "430                             5           low  \n",
       "431                             3           low  \n",
       "432                             4           low  \n",
       "433                             3           low  \n",
       "\n",
       "[434 rows x 67 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_vs_llm = pd.read_csv('human_vs_llm.csv')\n",
    "df_human_vs_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate paper_id and reviewer pairs from both DFs\n",
    "df_human_vs_metric = df_human_vs_metric.drop_duplicates(subset=['paper_id', 'reviewer'])\n",
    "df_human_vs_llm = df_human_vs_llm.drop_duplicates(subset=['paper_id', 'reviewer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "assessor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_soundness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_presentation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "review_contribution",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hedging",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Human_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Actionability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Clarity_and_Readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Comprehensiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Constructiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Fairness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Objectivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Overall_Quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Relevance_Alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Usage_of_Technical_Terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Vagueness",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a8458554-6d3c-4b7c-adde-7c816b4b929a",
       "rows": [
        [
         "0",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-7mFW",
         "2",
         "4",
         "factual",
         "neutral",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "67",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This work focuses on the Q-function value overestimation issue. Observing that the overestimation issue will latter becomes underestimation during the learning process. Thus motivated, this work proposes the Blended Exploitation and Exploration (BEE) operator to take advantage of the historical best-perforation actions. The proposed operator is then used in both model-free and model-based settings and show better performance than previous methods. 1. The proposed BEE operator utilizes the Bellman exploitation operator and exploration operator to address the under-exploitation issue. The proposed operator can be easily incorporated into the RL algorithms.\n2. The experiments show that the proposed operator can effectively reduce the estimation error and achieve better performance comparing with other RL algorithms. 1. The terminology can be misleading. The overestimation issue in the Q-value approximation generally is due to the changing order of expectation and $\\max$. It is incorrect to say that  the $Q$-function will have \"underestimation when encountering successes\" in Fig 1 (a). The authors need to clarify the context and difference of the statement in order to avoid confusion.\n2. In order to investigate on the under-exploitation, the metric $\\Delta(\\cdot,\\cdot)$ is defined on the current Q-function approximation. Intuitively,   $\\Delta(\\cdot,\\cdot)$ shows that the current Q-function approximation can be either overestimate or underestimate given different policy, i.e., $\\mu_k$ and $\\pi_k$. It is unclear what is the meaning of this metric. Considering most of the algorithm will update the policy and Q-function approximation at the same time, e.g., Actor-Critic, the Q-function should be evaluated under the current policy instead of the policy obtained earlier. The authors need to clarify why the definition here makes sense for the under-exploitation investigation. See the weakness above.",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1699636492844",
         "6.0",
         "3.0",
         "3.0",
         "2.0",
         "2.0",
         "273",
         "0",
         "5",
         "0.7173",
         "0.12450980390000001",
         "0.8775630593",
         "49",
         "22.7412",
         "0.0999",
         "iclr",
         "0.0",
         "4",
         "4",
         "2",
         "3",
         "factual",
         "4",
         "4",
         "67",
         "polite",
         "4",
         "neutral",
         "4",
         "high",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "partially factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "neutral",
         "4",
         "moderate",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "1",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-FAWm",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "5",
         "5",
         "5",
         "4",
         "86",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This paper presents the Blended Exploitation and Exploration (BEE) operator, which addresses the issue of value underestimation during the exploitation phase in off-policy actor-critic methods. The paper highlights the importance of incorporating past successes to improve Q-value estimation and policy learning. The proposed BAC and MB-BAC algorithms outperform existing methods in various continuous control tasks and demonstrate strong performance in real-world robot tasks. - The paper addresses an important issue in off-policy actor-critic methods and proposes a novel approach to improve Q-value estimation and policy learning. \n- The BEE operator is simple yet effective and can be easily integrated into existing off-policy actor-critic frameworks.\n- The experimental results demonstrate the superiority of the proposed algorithms in various continuous control tasks and real-world robot tasks. 1. The novelty of the proposed approach is limited. \n2. The choice of $\\lambda$ is largely empirical and requires extra manipulation in new tasks.\n3. The paper only provides basic theoretical analysis, such as the accurate policy evaluation and the guarantee of policy improvement. The benefit of linearly combining two Q-value functions is not discussed theoretically.\n4. The experiments are conducted in continuous control tasks with dense rewards. The exploration ability can be better evaluated in environments with sparse rewards.\n5. There is a lack of discussions with related papers (See Question 3). 1. Emprically, the BAC algoithm will only be more efficient in exploiting the replay buffer. The exploration still rely on the maximum-extropy formulation in SAC. Then why can BAC perform significantly better than SAC in failure-prone scenarios such as HumanoidStandup, as if BAC can better explore the unknown regions?\n2. Can you discuss or exhibit the performance of BAC in some tasks with sparse rewards? This can demonstrate the generalizability of the proposed approach.\n3. What are the advantages of BAC compared with prioritized replay methods \\[1,2\\] or advantage-based methods \\[3\\]? These methods are related to BAC in that they also exploit the replay buffer with inductive bias, so they should be mentioned in the paper.\n\n\\[1\\] Sinha, S., Song, J., Garg, A. &amp; Ermon, S.. (2022). Experience Replay with Likelihood-free Importance Weights. Proceedings of The 4th Annual Learning for Dynamics and Control Conference.\n\n\\[2\\] Liu, X. H., Xue, Z., Pang, J., Jiang, S., Xu, F., & Yu, Y. (2021). Regret minimization experience replay in off-policy reinforcement learning. Advances in Neural Information Processing Systems, 34, 17604-17615.\n\n\\[3\\] Nair, A., Gupta, A., Dalal, M., & Levine, S. (2020). Awac: Accelerating online reinforcement learning with offline datasets. arXiv preprint arXiv:2006.09359.\n\n\nI am willing to raise my score if my concerns for weaknesses and questions are adequately discussed.",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1700565416102",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "432",
         "8",
         "14",
         "0.7996000000000001",
         "0.1588311688",
         "0.8829935789000001",
         "60",
         "31.9755",
         "0.1565",
         "iclr",
         "0.0",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "86",
         "polite",
         "5",
         "neutral",
         "4",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "2",
         "166",
         "Sajad-Ebrahimi",
         "Reviewer-kjkr",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "5",
         "5",
         "4",
         "5",
         "75",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "Motivated by the problem of underestimating values in the training of SAC, this paper introduces the Blended Exploitation and Exploration (BEE) operator, which calculates the TD target based on a combination of the standard TD target and a high expectile of the return distribution. The authors integrate this operator in both model-free and model-based scenarios, followed by a comprehensive experimental evaluation. 1. The paper contains extensive experiment results on both simulation and real-world environments.\n2. The paper is written clearly and easy to follow. Figure 1 provides a decent visualization of the underestimation issue. 1. The BAC method tunes its $\\lambda$ and $\\tau$ differently for tasks in MuJoCo and DMC (Table 1 & 5). It's questionable to claim superiority over other state-of-the-art (SOTA) methods like SAC and TD3, which use consistent hyperparameters (HP) across tasks. Adjusting HP for each task can inflate results as seen in Figure 5, which can be misleading. Why not showcase the automatic $\\lambda$ tuning methods from Appendix B.3.3 in the main text if they're effective?\n\n2. Figure 23 reveals that SAC, without the double-Q-trick, still underestimates in the Humanoid task. It's unclear if this is universally true. More convincing results would come from testing this across multiple tasks and providing absolute Q value estimates. I still suspect that Q underestimation largely stems from the double Q techniques, as suggested by the RL community \\[1\\]. For instance, OAC \\[1\\] introduces $\\beta_{\\text{LB}}$ to manage value estimation issues.\n\n3. Presuming the Q value underestimation problem is widely recognized (which I invite the authors to contest), the paper seems to lack innovation. The BEE operator, at its core, appears to be a fusion of existing Bellman operators.\n\n4. The statement \"BEE exhibits no extra overestimation\" seems conditional on specific $\\lambda$ and $\\tau$ values. For instance, using $\\lambda = 1$ and $\\tau = 1$ could induce overestimation.\n\n\\[1\\] Ciosek, Kamil, et al. \"Better exploration with optimistic actor critic.\" Advances in Neural Information Processing Systems 32 (2019). See Weakness",
         "['~Tianying_Ji2', '~Yu_Luo5', '~Fuchun_Sun1', '~Xianyuan_Zhan1', '~Jianwei_Dr._Zhang1', '~Huazhe_Xu1']",
         "1700668216355",
         "6.0",
         "5.0",
         "3.0",
         "4.0",
         "2.0",
         "328",
         "4",
         "8",
         "0.8027000000000001",
         "0.1464980159",
         "0.8531657457",
         "61",
         "35.3958",
         "0.1507",
         "iclr",
         "0.0",
         "5",
         "5",
         "3",
         "5",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "80",
         "polite",
         "5",
         "negative",
         "5",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "partially factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "3",
         "100",
         "Seyed",
         "Enrico-Daga",
         "3",
         "2",
         "factual",
         "positive",
         "polite",
         "none",
         "4",
         "5",
         "4",
         "4",
         "4",
         "4",
         "80",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "The authors have performed significant changes to the content, which significantly improve the article with respect to the previous submission. Following the four SWJ criteria for survey articles, the current version is indeed a good (1) introductory text, targeted at researchers, PhD students, or practitioners, to get started on the covered topic.  The addition of a methodology section gives reasonable justification for (2) how comprehensive and how balanced are the presentation and coverage. However, a few more details about the sources of the survey would be useful, especially if mentioning keywords and phrases used in the search (Scopus? Google Scholar? Microsoft Academia? …). In addition, it is still a bit opaque what is intended with \"refining and balancing the structure of the covered areas\" - end of Section 2. However, I consider these minor issues that can be fixed during the preparation of the camera-ready. Finally, the article is readable and clear (3) and the content is relevant to the community (4).",
         null,
         "21/Sep/2021",
         null,
         null,
         null,
         null,
         null,
         "162",
         "0",
         "1",
         "0.8103",
         "0.1645833333",
         "0.6678649187",
         "60",
         "31.31",
         "0.1149",
         "semanticweb",
         "0.019607843137254943",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "5",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "2",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "4",
         "100",
         "Seyed",
         "Julia-Bosque",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "5",
         "4",
         "87",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "I reviewed a previous version of this manuscript, for which I recommended a major revision based on the need for a clearer motivation, scope and limitations of this effort, as well as on the structure and flow of the paper at that time. In this new version the authors have addressed all my highlighted concerns: - The motivation, scope and limitations are clearly defined - The interplay between the different sections is elaborated and illustrated with a workflow diagram that facilitates reading. There are numerous references to this workflow and interlinks between the sections, resulting in a cohesive document. - More context is provided in the introductory paragraphs of each section, and the project in which this effort is carried out is clearly introduced. The relation of each section/topic with respect to the overall topic of the survey is now explicit. - The authors have improved the categorization of tools and approaches. - The tables in the appendix summarize the main approaches, tools and resources surveyed according to the proposed classification.  Taking into account these modifications, I maintain the reasons upon which I based the recommendation for acceptance in terms of the criteria for surveys: - The topic of the paper, at the intersection of humanities and the Semantic Web, is interesting and relevant for the advancement in a line of research which poses numerous challenges. - The quality of writing is good and the survey is well balanced, with a broad coverage encompassing theoretical standpoints and approaches, tools, repositories and datasets. - The granularity and length are also appropriate for the text to serve as an introductory text. Minor comments for improvement: - The authors have provided details on the methodology for the survey, indicating the different stages in the generation and keywords used in literature search. There is no explicit reference to a filtering process after those keyword-based search results, was there any filtering step? If so, which criteria were applied? - In table 3, the included resources diverge in their nature, so the current list groups together LLOD Cloud, Lila Etymological Lexicon, LingHub, and Diachronic semantic lexicon of Dutch, etc. for example. I suggest including a mark here to distinguish which resources are particularly relevant for diachronic analysis, in contrast to general LLOD resources (e.g. Lila Etymological Lexicon vs. LLOD cloud and LingHub). - The authors of [12], referenced on p. 5, mention Lemon (Lexicon Model For Ontologies), and in their diagrams (in Github)  they seem to be using OntoLex-Lemon, not its ancestor. Throughout this survey \"OntoLex-Lemon\" is the term used to refer to the 2016 Specification as the outcome of the W3C Ontology-Lexica Community Group, so for that bib. reference I would recommend to replace the mention of \"Lemon\" with \"OntoLex-Lemon\" for consistency in the whole document. *Typos*: l.19, .p. 19, right column, \"A combined resource like this, allows...\" → remove comma p. 20, l. 1, right column → remove \"(linguistic)\", already covered by the first L in LLOD Appendix tables, Table 4. → word embeddings (add pl. \"s\")",
         null,
         "04/Oct/2021",
         null,
         null,
         null,
         null,
         null,
         "503",
         "1",
         "5",
         "0.7741",
         "0.1697330447",
         "0.8522429466",
         "73",
         "34.66",
         "0.2025",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "87",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "100",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "5",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "4",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "5",
         "100",
         "Seyed",
         "Thierry-Declerck",
         "3",
         "1",
         "partially factual",
         "positive",
         "polite",
         "high",
         "4",
         "4",
         "4",
         "4",
         "3",
         "4",
         "60",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "Not really a lot to add. I see that the revised version of the submission was taking good care of former comments and suggestions. Just a minor point: 1) Ensure that footnotes are always placed after the punctuation signs (for consistency across the paper, se fn 2 and 3 which are not placed consistently). So, very few corrections to do.",
         null,
         "05/Nov/2021",
         null,
         null,
         null,
         null,
         null,
         "60",
         "0",
         "0",
         "0.81",
         "0.058",
         "0.6966200471",
         "105",
         "64.71",
         "0.0548",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "60",
         "polite",
         "3",
         "positive",
         "1",
         "high",
         "5",
         "5",
         "2",
         "5",
         "factual",
         "5",
         "5",
         "60",
         "polite",
         "5",
         "neutral",
         "2",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "4.0",
         "none",
         "2",
         "4",
         "2",
         "2",
         "factual",
         "4",
         "3",
         "3",
         "polite",
         "3",
         "positive",
         "1",
         "low",
         "1",
         "4",
         "1",
         "1",
         "factual",
         "3",
         "2",
         "35",
         "polite",
         "2",
         "positive",
         "0",
         "high"
        ],
        [
         "6",
         "74",
         "Sonny",
         "Reviewer-itVg",
         "3",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "2",
         "4",
         "4",
         "4",
         "85",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "The authors introduced a view sampling strategy for novel view synthesis, grounded in the perspective of causal representation learning. They identified three key metrics to assess sampling performance: the fitting term, the consistency term, and the uniformity term. Additionally, they presented a novel theoretical framework addressing the sampling challenge within NeRF. 1. The introduction of the causal perspective in the view sampling algorithm holds significant potential and could serve as a foundational approach for future research in this domain.\n2. The authors meticulously lay out a comprehensive mathematical framework that not only elucidates the underlying problem but also leads to the derivation of the three pivotal terms central to their methodology.\n3. The paper stands out for its clarity and coherence, ensuring that readers, regardless of their expertise level, can grasp the concepts and findings presented.\" 1. The rationale behind the view-sampling task raises questions. In certain scenarios, acquiring additional view images can be challenging. However, when a substantial number of dense views are already available, the motivation to devise a sampling strategy for training the neural rendering model with sparse views appears insufficient. Specifically, the activeNeRF model's primary objective is to identify the most optimal camera view for capturing the training image, rather than selecting from a plethora of pre-existing images.\n2. The paper's primary contribution seems to be the introduction of a metric or loss function to evaluate the selected views. However, the absence of an ablation study that separately assesses the impact of each of these three terms is a missed opportunity for deeper understanding. As a result, the contribution feels somewhat lacking in depth.\n3. The proposed loss function presents challenges in differentiability with respect to 't'. The sampling proposal, derived from the farthest sampling strategy, may not be the most efficient approach. It appears to demand significant training resources, resulting in elevated training costs. The potential enhancements in model performance might not justify the trade-off in terms of the increased training time and resource allocation. Please see the weakness above.",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108511",
         "5.0",
         "2.0",
         "3.0",
         "3.0",
         "1.0",
         "335",
         "0",
         "6",
         "0.7966000000000001",
         "0.1848602484",
         "0.9041278958000001",
         "52",
         "29.0988",
         "0.1431",
         "iclr",
         "0.009803921568627416",
         "2",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "3",
         "none",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "5",
         "5",
         "75",
         "5",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "7",
         "74",
         "Sonny",
         "Reviewer-bNPg",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "none",
         "4",
         "4",
         "3",
         "4",
         "4",
         "3",
         "90",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies the view sampling strategies of Nerf reconstruction from a causal perspective. The authors try to solve the problem using a small subset of photos from a total of K potential views, to achieve the best reconstruction. To solve this, the authors propose to use causal represntation learning using loss by Identification Treatment Effect. They propose three terms, a normal fitting term as reconstruction loss, a consistency term to ensure consistency between visible views and invisible views and a uniformity term requires the samples to be distributed evenly. The results show the proposed strategy can provide slightly better reconstruction compared to alternative baselines in the proposed setting. * The paper proposes a novel perspective to study the view sampling problem in volumetric reconstruction using NeRF as an example. This take-away can potentially also generalize other multiview reconstruction algorithms. \n* Given its current setting, the hypothesis is validated on nerf reconstruction datasets, with small improvement compared to its baselines. * The presentation of this paper could be greatly improved. I may not have understand a lot of details correctly given its current presentation. \n  * It is very hard to read without being very familiar with ActiveNeRF and casual representation learning. Have to trace to original papers for more details. This could be added to the preliminary parts. \n  * Too many notations which makes things more complicated than needed. I don't think I found how exactly the loss of consistency term and uniformity term were calculated in (8) at runtime. As I understand, the method should be as simple as calculating the reconstruction loss using different groups of input samples. Provide an algorithm chart of how of how P^{F}, P^{hat}^{CF} and P^{CF} will greatly help. \n  * There are some notations introduced in 4.1 (e.g. P(Y|do(d))) are not explained until 4.2. \n* Overall I am not sure I understand the real-world impact of this paper using the proposed strategy. Maybe I had some misunderstanding in the details given my concern on its presentation. Please correct me if I am wrong here. The goal of this paper to find \"optimal sampling strategy for training set\", \"K_s corresponding photos as sparse sample inputs among K_d total potential views\" is hardly a real problem statement for its real-world use case, which is my biggest concern for this proposed application of causal representation learning. From sampling perspective, we can use all the K_d potential views as long as they are available. As I understand, the evaluation of the counter factual distribution will require using the non-selected but captured images as supervision, which is not how active learning is executed in real-world case. Given this setting, it makes the results also less appealing in contrast to alternative baselines (which learns to predict next-best unknown view) given the fact all images from that particular datasets are used in evaluating the sampling strategy. 1. My major question is around how the clarity of the sampling process in training time. Confirm any places I misunderstood about this paper, as I highlighted in the weakness part. \n2. I am also curious how the views are sampled finally for different groups in the final results. Provide some visualization and discussions about them can be very helpful to guide the view-sampling process in real world applications. I wonder how that indicate the connection of uniformity term and consistency term are correlated to the camera FoV and ray distributions.",
         "['~Yunze_Liu2', '~Zifan_Wang3', '~Zhiheng_Zhang1']",
         "1699636108442",
         "3.0",
         "3.0",
         "2.0",
         "1.0",
         "2.0",
         "566",
         "0",
         "2",
         "0.8138000000000001",
         "0.1125",
         "0.8472209573",
         "52",
         "40.8228",
         "0.33",
         "iclr",
         "0.0",
         "3",
         "3",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "90",
         "polite",
         "4",
         "neutral",
         "3",
         "none",
         "5",
         "4",
         "4",
         "5",
         "partially factual",
         "4",
         "4",
         "65",
         "polite",
         "5",
         "negative",
         "5",
         "moderate",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "neutral",
         "5",
         "neutral",
         "4",
         "moderate",
         "2",
         "2",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "8",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-GDNX",
         "3",
         "5",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "80",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         ">**Rebuttal:** The provided details satisfy my concerns. I think this paper should be accepted after applying the agreed changes.\n\n>**TL;DR:** **Good paper.** The proposed WTA-CRS algorithm is based on the existing CRS algorithm and is used to reduce activation memory during training. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size. However, WTA-CRS comes with computational overhead, which is discussed and explore. Addressing my concerns and questions would improve my score.\n\nThe paper proposes the WTA-CRS algorithm to reduce the neural networks training activation memory, where the paper claims that activation memory is primary memory bottleneck during training. The WTA-CRS algorithm is an unbiased estimators for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size.\n\nThe WTA-CRS algorithm works by sampling columns and rows to create an unbiased estimation of the original GEMM for the backpropagation. The WTA-CRS algorithm does not alter the neural architecture, and therefore the inference speed is left in tact. The experimental section shows that WTA-CRS outperforms existing prior work and is compatible with existing PEFT techniques. WTA-CRS adds a computational overhead due to sampling, however, WTA-CRS enables training on much larger batch sizes, which results in a 1.2× higher training throughput.\n * **S.1.** The proposed WTA-CRS algorithm tackles an important problem in existing PEFT techniques, which makes LLM PEFT training more accessible to researchers with low resources.\n* **S.2.** The paper provides a theoretical analysis on WTA-CRS.\n* **S.3.** The proposed WTA-CRS algorithm outperform existing algorithms.\n* **S.4.** An anonymized code repository is provided as part of the submission for reproduction .\n  * **W.1.** Popular existing memory efficient training techniques such as tensor rematerialization (gradient checkpointing) \\[2\\]\\[3\\] and ZeRO \\[1\\] are not compared to, although some are partially discussed in Appendix A.\n* **W.2.** The experiments are conducted on single neural network architecture (T5), although the proposed technique does not seem to be confined solely to that setting.\n* **W.3.** It is common practice today to train neural networks at a lower precision (quantization), however, it is not clear whether quantization (16bit) was used. Therefore, there is insufficient proof that the combined noise of WTA-CRS and quantization would be compatible.\n\n\n**Typos.**\n* Line #62: \"Thus\" → \"Thus,\"\n* Line #240: \"mAccording\" → \"According\"\n* Line #297: \"Thus\" → \"Thus,\"\n\n\\[1\\] Ren, J., Rajbhandari, S., Aminabadi, R.Y., Ruwase, O., Yang, S., Zhang, M., Li, D. and He, Y., 2021, July. ZeRO-Offload: Democratizing Billion-Scale Model Training. In USENIX Annual Technical Conference (pp. 551-564).\n\n\\[2\\] Jain, P., Jain, A., Nrusimha, A., Gholami, A., Abbeel, P., Gonzalez, J., Keutzer, K. and Stoica, I., 2020. Checkmate: Breaking the memory wall with optimal tensor rematerialization. Proceedings of Machine Learning and Systems, 2, pp.497-511.\n\n\\[3\\] Beaumont, O., Eyraud-Dubois, L. and Shilova, A., 2021. Efficient combination of rematerialization and offloading for training dnns. Advances in Neural Information Processing Systems, 34, pp.23844-23857. * **Q.1.** In line #43 and Figure 2 it is noted that \"storing activations (or feature maps) is the main memory bottleneck during training\". Does this hold true for all model architectures? What about LLM training where the fine-tuning batch size is usually very small?\n* **Q.2.** Why was the WTA-CRS algorithm compared to the Deterministic top-k from \\[1\\] but not to the Bernoulli-CRS from \\[1\\]? What are the key differences between WTA-CRS and Bernoulli-CRS?\n* **Q.3.** The paper proposes WTA-CRS which sacrifices computation speed at the cost of lower peak memory. There are several existing common approaches (such as gradient checkpointing and DeepSpeed) for general memory efficient training which are compatible with PEFT techniques. Why are these comparisons not explored or detailed in the main paper?\n\n\\[1\\] Adelman, Menachem, Kfir Levy, Ido Hakimi, and Mark Silberstein. \"Faster neural network training with approximate tensor operations.\" Advances in Neural Information Processing Systems 34 (2021): 27877-27889. The limitations are discussed in Appendix A.",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411175092",
         "7.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "669",
         "10",
         "14",
         "0.753",
         "0.09034013610000001",
         "0.8664653897",
         "215",
         "42.5651",
         "0.1507",
         "neurips",
         "0.012820512820512775",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "neutral",
         "4",
         "neutral",
         "5",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "9",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-j1mL",
         "4",
         "4",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "3",
         "70",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "In this paper, we propose a new method called WTA-CRS (Winner-Take-All Column Row Sampling) to address the main memory bottleneck issue during training, which arises from storing feature maps. To reduce memory usage during training, we sample the most likely column indices during backpropagation.\n\nFurthermore, \bthey proposed method demonstrates the ability to significantly reduce peak memory usage, by approximately up to 2.7 times, when fine-tuning downstream tasks. It also showcases the potential for higher throughput, enabling more efficient training. 1. The work clearly states its motivation and its solution and is easy to follow.\n2. The authors show that their method reaches comparable performance with backpropagation using the full activation when combined with LoRA.\n3. They also empirically measure throughput gains obtained by increasing batch size, which demonstrates the practical applicability of their method. 1. The paper needs a comparative analysis of other researchs, such as gradient checkpoint/recalculation and CRS, aimed at reducing activation memory during the training phase, as shown in Fig. 6 and Fig. 9.\n2. The paper should include an analysis of the overhead associated with the proposed WTS-CRS method, which involves sampling rows and columns. It is crucial to consider factors such as the computational cost of Equation 3 and any potential effects of lowering on the overall performance. Providing this analysis would enhance the clarity and completeness of the research.\n3. There is a need of analysis on the effectiveness of the proposed approach, WTS-CRS, in distributed training environments such as tensor parallelism or pipeline parallelism.\n4. It seems necessary to conduct performance evaluations on various LLMs of the GPT family, such as LLaMA and OPT. * In Figure 9, it can be observed that the throughput of WTS-CRS is lower than that of full when the batch size is small. Is this due to the overhead caused by lowering?\n* When comparing the training throughput, how does CRS differ from full in terms of throughput?\n* Could the authors include statistics for GPU utilization in their experiments? It would be helpful to analyze the causes of improved performance more thoroughly.\n* Considering that most large models are trained using multiple levels of parallelism, would it be possible to verify results for pipeline parallel, tensor parallel, etc.? Also, it is unclear from the paper whether the data parallelism used was distributed data parallelism or naïve data parallelism. * As previously mentioned, it would be valuable to include additional experimental results for models that are more challenging to quantify, such as GPT-series (OPT, LLaMA). This would enhance the validity and applicability of the proposed method across a broader range of models.\n* Considering that most large-scale models are trained using multiple levels of parallelism, it is important to assess how much the proposed methods, such as pipeline parallelism and tensor parallelism, can increase throughput while taking into account overhead (such as GPU-to-GPU or node-to-node communication), memory reduction, and computational cost. Furthermore, it is not clear from the paper whether the data parallel processing used is distributed data parallelism or naive data parallelism.",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174921",
         "5.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "506",
         "0",
         "8",
         "0.8129000000000001",
         "0.11685380590000001",
         "0.8539184332",
         "215",
         "31.6518",
         "0.1355",
         "neurips",
         "0.011111111111111072",
         "4",
         "3",
         "4",
         "4",
         "partially factual",
         "3",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "10",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-cMiu",
         "4",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "3",
         "4",
         "4",
         "80",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The authors studied fine-tuning LLMs with limited memory. As the increased scale of current LLMs, the memory cost during fine-tuning is of great importance when adapting the pretrained LLMs to down-streaming tasks. In contrast to the existing work that mainly focus on the number of updated weights, this paper proposed to reduce the number of stored activations, also the inputs to each layer. Given the widely used stochastic gradient descent optimization pipeline, the authors proposed to store a subset of activations that can generate an unbiased gradient estimation. This way, the training memory and the training time decreased significantly. The authors provide both theoretical and experimental analysis on their CRS methods.  - This paper studied an important problem in LLM fine-tuning, i.e., how to fine-tuning LLMs with less memory consumption without increasing the computation cost. The authors provided solid quantitative results to show that the main memory consumption is from storing the intermediate activations. \n- The authors provided a general solution for fine-tuning LLMs under memory constraints. The solution can be applied in most transformer-based network architectures.  \n- The authors provided solid mathematical proof on the unbiased gradient estimation, which is especially encouraged. \n- The extensive experiments on different network architectures showed the efficacy of the methods.\n- The released code can benefit the following researchers studying efficient LLM fine-tuning.  - I am not fully convinced by the comment made in Line241-244, i.e., the methods in the paper is orthogonal to the activation quantization. When activation is quantized into a lower bit width, it is very possible that the number of less important activations will decrease. This way, the selection on the top-k columns in activation matrices with the proposed methods may hurt the training accuracy or convergence. It would be great if the authors can provide some theoretical analysis or experimental results on this combination. Otherwise, it would be necessary to provide some comparison results w.r.t. the activation quantization.\n- It would be great if the authors can discuss the main difference of their paper w.r.t. \\[Randomized Automatic Differentiation, ICLR2021\\].\t  Overall, I think this paper has a relatively high quality in both writing and scientific contribution. Yes",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174804",
         "6.0",
         "4.0",
         "2.0",
         "3.0",
         "3.0",
         "358",
         "0",
         "2",
         "0.7825000000000001",
         "0.1275074405",
         "0.8477004170000001",
         "215",
         "33.3958",
         "0.1262",
         "neurips",
         "0.0",
         "4",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "11",
         "194",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-ky3t",
         "2",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "70",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The paper's contribution is in proposing a practical, intuitive yet not trivial unbiased approximation to gradient training of matrix multiplication. It shows that even though totally deterministic sampling is biased, somewhat deterministic sampling is unbiased, and a judicious allocation of sampling to those pairs favored by deterministic thinking can lead to the use of a larger batch size with empirically negligible performance loss. This reviewer must declare that he does not check the derivation very carefully. The proposed idea is practical and can be readily combined with virtually all first-order gradient-based training methods.\nThe paper also derived why deterministic sampling is a biased estimator and empirically shown the associated bad performance, thus proving that the additional complexity of stochastic sampling over deterministic sampling is not only sufficiently better but also necessary. It's just a few empirical comparisons, but the performance gap between CRS and WTA-CRS seems modest. This reviewer does not have a question. N/A",
         "['~Zirui_Liu1', '~Guanchu_Wang1', '~Shaochen_Zhong1', '~Zhaozhuo_Xu2', '~Daochen_Zha1', '~Ruixiang_Tang1', '~Zhimeng_Jiang1', '~Kaixiong_Zhou1', '~Vipin_Chaudhary2', '~Shuai_Xu2', '~Xia_Hu4']",
         "1702411174720",
         "7.0",
         "3.0",
         "4.0",
         "3.0",
         "3.0",
         "155",
         "0",
         "1",
         "0.8418",
         "0.062142857100000004",
         "0.7829982042",
         "215",
         "17.3432",
         "0.1041",
         "neurips",
         "0.01098901098901095",
         "3",
         "4",
         "2",
         "3",
         "factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "2",
         "4",
         "3",
         "2",
         "5",
         "5",
         "4",
         "65",
         "neutral",
         "5",
         "positive",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "1",
         "3",
         "3",
         "1",
         "partially factual",
         "3",
         "3",
         "50",
         "polite",
         "4",
         "positive",
         "4",
         "moderate",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "12",
         "38",
         "Seyed",
         "Reviewer-vqBu",
         "3",
         "2",
         "unfactual",
         "neutral",
         "polite",
         "low",
         "2",
         "2",
         "3",
         "2",
         "3",
         "4",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way. The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea. The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso. - in the frequentist case, how does the proposed framework compares against more classical techniques to obtain the solution paths, e.g., iterative reweighted l1-norm?  The authors adequately addressed the limitations of their proposed framework. ",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411519040",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "170",
         "0",
         "0",
         "0.799",
         "0.32",
         "0.9384971857000001",
         "215",
         "30.7103",
         "0.1149",
         "neurips",
         "0.011235955056179803",
         "3",
         "4",
         "3",
         "2",
         "unfactual",
         "2",
         "2",
         "60",
         "polite",
         "3",
         "neutral",
         "2",
         "low",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "4",
         "78",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "13",
         "38",
         "Seyed",
         "Reviewer-3sWQ",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "2",
         "1",
         "3",
         "3",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution. - Well written paper.\n\n        - Illustrative toy experiments. - The proposed method is a combination of already known techniques.\n\n        - The experimental section is weak as only a single real problem is considered.\n\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\n\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\n\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros. None The authors have not commented on the limitations of their approach.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518947",
         "5.0",
         "3.0",
         "2.0",
         "3.0",
         "2.0",
         "279",
         "0",
         "2",
         "0.7414000000000001",
         "-0.007047619000000001",
         "0.9233116508",
         "215",
         "36.096",
         "0.0989",
         "neurips",
         "0.0",
         "2",
         "3",
         "3",
         "1",
         "unfactual",
         "3",
         "3",
         "60",
         "neutral",
         "3",
         "negative",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "3",
         "4",
         "65",
         "neutral",
         "5",
         "negative",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "2",
         "3",
         "3",
         "2",
         "factual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "14",
         "38",
         "Seyed",
         "Reviewer-pTVu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "low",
         "3",
         "3",
         "3",
         "4",
         "4",
         "4",
         "60",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\geq1}$ is used). 1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\n3. Using sub-l1 norm is suitable for structure learning. \n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \n5. The paper is well-written, and the relevant work is sufficiently discussed.    \n6. Due to its flexibility, the proposed method has the potential of having a large impact. Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \n\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \n\nMinor suggestion: \n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \n2. Fix minor typos e.g. the end sentence period in line 214. * In line 141, what do you mean by \"contradiction\"? The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \n\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518854",
         "6.0",
         "3.0",
         "3.0",
         "4.0",
         "2.0",
         "330",
         "0",
         "9",
         "0.7934",
         "0.1236940837",
         "0.8818445206000001",
         "215",
         "45.1097",
         "0.19690000000000002",
         "neurips",
         "0.011904761904761862",
         "3",
         "4",
         "3",
         "4",
         "unfactual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "negative",
         "3",
         "low",
         "5",
         "5",
         "4",
         "5",
         "5",
         "5",
         "5",
         "90",
         "5",
         "5",
         "5",
         "5",
         "1",
         "2.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "15",
         "38",
         "Seyed",
         "Reviewer-CnQu",
         "3",
         "3",
         "unfactual",
         "negative",
         "neutral",
         "moderate",
         "2",
         "2",
         "1",
         "1",
         "3",
         "4",
         "50",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets. Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \n\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated. Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost. In synthetic data example, why did you choose to have more samples than dimensions ( $n>d$ )? Since in that case GGM can be obtained with matrix inverse, and no need for penalized objective. Limitations were not discussed.",
         "['~Marcello_Massimo_Negri1', '~Fabricio_Arend_Torres1', '~Volker_Roth1']",
         "1702411518763",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "205",
         "0",
         "2",
         "0.787",
         "0.1207251082",
         "0.8797656298000001",
         "215",
         "36.2535",
         "0.25730000000000003",
         "neurips",
         "0.012048192771084376",
         "1",
         "4",
         "3",
         "1",
         "unfactual",
         "2",
         "2",
         "50",
         "neutral",
         "3",
         "negative",
         "3",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "16",
         "13",
         "Mana",
         "Joseph-philipraj",
         "5",
         "5",
         "factual",
         "positive",
         "polite",
         "low",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "95",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This systematic review is appropriate for the journal with a global problem of Mets and Urolithiasis. The introduction part clearly explains the motivation. The manuscript is clear and balanced. The manuscript stays focused on the subject. Authors have gone through the process of searching relevant articles from all websites and of sufficient duration. The inclusion and exclusion criteria in the analysis have been clearly stated. The impact of the analysis is clearly stated. The statistical analysis supports the paper well. The interpretation of the results, visualisation are well presented. The tables and figures are clear, relevant and correct. The authors demonstrate the knowledge of basic composition skills, including word choice, sentence structure, paragraph development and grammar. Limitations:  The studies included in the meta-analysis have cross-sectional nature and hence ascertainment of temporal association is not possible which also dictates need for further prospective studies. The specific type of stone formation is not correlated with studies. Despite these limitations all studies included in the meta-analysis showed the same directionality in the association between urolithiasis and Mets.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         null,
         "22 Mar 2021",
         null,
         null,
         null,
         null,
         null,
         "292",
         "0",
         "1",
         "0.7415",
         "0.1145833333",
         "0.8487246633000001",
         "39",
         "30.46",
         "0.0999",
         "f1000",
         "0.010000000000000009",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "5",
         "5",
         "3",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "85.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "2",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "92",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "17",
         "13",
         "Mana",
         "Muhammad-Faruk",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "93",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study assessed the association between metabolic syndrome and its components with the risk of developing nephrolithiasis by conducting systematic review, Bayesian random-effects meta-analysis, meta-regression and dose-response analysis. This study was done appropriately based on PRISMA flowchart. Risk of bias was also conducted of the included studies. This study has successfully presented the proper meta-analysis for this design. However, to complete this study for indexing, I personally recommended several revisions: 1. Abstract: Introduction section: It is better to address meta-regression as the analysis to assess the correlation of association along with dose-response analysis  Conclusion section: In reporting the association between predictors and nephrolithiasis, state only the predictors in which its coefficient was statistically significant 2. R language was not considered as a statistical software for data analysis. The software for data analysis should be written as \"R\" (Please refer to methods section in statistical analysis subsection). 3. Please update the PRISMA flowchart (refer to PRISMA guideline 2009). 4. Give the numbering of each Forrest plot in Figure 3 and numbering of each meta-regression plot in Figure 4. Design these figures so that it could be well presented. 5. Uniformly decide the word choice of \"traits\" or \"components\", choose whether to use traits or components in the whole text, use one of these words consistently to avoid any misunderstanding. 6. It is better to provide the meta-regression of hypertension in systolic blood pressure and diastolic blood pressure as it is important to explain the relationship to nephrolithiasis in differentiation for these two types of blood pressure. 7. Meta-regression of body mass index  was sufficient in this study thus waist circumference meta-regression was not necessary to be included. 8. Provide the value of coefficient and confidence interval of each meta-regression analysis in the result section so that better understanding of predictors-outcome relationship could be reached clearly.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         null,
         "08 Nov 2021",
         null,
         null,
         null,
         null,
         null,
         "422",
         "0",
         "7",
         "0.7554000000000001",
         "0.1982758621",
         "0.9299524426",
         "270",
         "24.68",
         "0.23020000000000002",
         "f1000",
         "0.010869565217391353",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "93",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "85.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "18",
         "181",
         "Hideaki-Joko",
         "Reviewer-sna7",
         "2",
         "2",
         "factual",
         "positive",
         "neutral",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This paper presents ULTRA, a single model that can be directly used/finetuned for link prediction over different knowledge graphs. The key is to model the transferrable relationships between different relations across knowledge graphs. Specifically, a NBFNet is used to learn relative relation representations and generate relation embeddings, which is then fed into another NBFNet to perform link predictions. Extensive experiments are performed over many knowledge graph to demonstrate the performance of this model. - This paper is well written and easy to follow\n- The core method around the relative relationships between relations is clever and interesting.\n- The experiments demonstrate the gains of the method. It is especially impressive to see the competitive zero-shot performance of ULTRA over different knowledge graphs. - The proposed method relies entirely on knowledge graph structure and does not consider using node embedding such as textual features of the knowledge graphs. In reality, text embedding of nodes and edges could be a better transferrable embedding. Such transferability has already been demonstrated by PRODIGY (https://arxiv.org/abs/2305.12600) and should be addressed.\n- The model does not scale well as the authors already pointed out.\n- The zero shot and fine-tuning performances are worse or on-par with the per dataset model performance, rendering pretraining not effective performance-wise. \n- Some notations are a bit hard to understand. See questions. - What are u and v in h_{u|v} in section 4.2?\n- Why are supervised SOTA baselines only reported for some datasets in Figure 4?",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636399067",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "245",
         "1",
         "1",
         "0.7559",
         "0.0971320346",
         "0.9083012938",
         "49",
         "38.7951",
         "0.07200000000000001",
         "iclr",
         "0.0",
         "4",
         "4",
         "2",
         "3",
         "factual",
         "4",
         "3",
         "70",
         "neutral",
         "4",
         "positive",
         "2",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "19",
         "181",
         "Hideaki-Joko",
         "Reviewer-HLbG",
         "3",
         "3",
         "factual",
         "neutral",
         "neutral",
         "moderate",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This work aims to build a foundation model for knowledge graph reasoning tasks, where the authors explore the setting of generalization to any edges and nodes, including unseen, of any multi-relational knowledge graphs without using node and edge features. To this end, the authors first construct a view of a relation-centric graph from an original graph where edges become nodes of this new relation graph, and then, based on this view, the authors represent the relation (node) relative to and conditioned on the query relation. Then, based on this relative relation representation, the authors use existing inductive link prediction methods to perform knowledge graph reasoning. The authors conduct link prediction experiments on various knowledge graphs considering both inductive and transductive settings, and show that the proposed method, namely ULTRA, outperforms other SOTA baselines sometimes without further fine-tuning on target knowledge graphs (i.e., zero-shot). * This work studies the very important, challenging, and practical setups of building a foundation model for knowledge graph reasoning, which aims to be generalizable to any other knowledge graphs involving unseen nodes and unseen edges, without leveraging features of nodes and edges. \n* The proposed method works well with different knowledge graphs, on zero-shot transfer learning setups without further fine-tuning on target knowledge graphs, and further shows the boosted performance with task-specific further fine-tuning on them, on most experiment setups.\n* This paper is very well-written and easy to follow. * I would like to note that I don't see any major weakness, and below is the minor.\n* In Section 4.2, the explanation about the indicator function with variables $u$ and $v$ is a bit unclear to me. Could you elaborate more on the process and result of the indicator function according to those two variables, perhaps with visuals?\n* Text-based methods (e.g., LM-based methods) can be generalizable to any knowledge graphs including unseen nodes and unseen edges, as long as their nodes and edges are represented with texts. In this vein, I think one potential direction for building a foundation model for knowledge graph-related tasks might be to use the LMs, and the authors may highlight this point more and potentially make comparisons between the proposed approach and text-based methods. I don't think this should be the critical weakness of this paper since text-based methods are limited to knowledge graphs with textual features; meanwhile, given the framing of this work (\"Towards Foundation Models for Knowledge Graph Reasoning\"), this point should be carefully explained. * I would like to suggest emphasizing the performance differences between inductive and transductive setups when explaining Table 1. The proposed method w/ 0-shot settings are strong on inductive graphs; meanwhile, previous methods are superior to it on transductive graphs, which are worthwhile to discuss.\n* It may be beneficial to show the results of the ULTRA fine-tuned on the knowledge graphs used for pre-training the ULTRA. I am wondering if there are further performance improvements when further fine-tuning the model on the data used for pre-training.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398956",
         "8.0",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "496",
         "0",
         "0",
         "0.7682",
         "0.1549267161",
         "0.9152074456",
         "49",
         "38.4364",
         "0.37610000000000005",
         "iclr",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "3",
         "80",
         "neutral",
         "4",
         "neutral",
         "3",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "20",
         "181",
         "Hideaki-Joko",
         "Reviewer-c3Sg",
         "4",
         "3",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "4",
         "3",
         "3",
         "4",
         "70",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "Paper claims to propose a foundation model, named Ultra, for knowledge graph representation learning. The proposed model can handle full inductive graphs in which new entities and relations may appear in the test set. To do so, the authors propose to lift the graph to a one with relations as the nodes and design 4 different edge types (head2head, head2tail, tail2head, tail2tail). The relational representations are then learnt using message passing on this graph. The learnt relation embeddings are then used in the original graph to perform inductive link prediction. For the experiments, the authors pre-train their method on 3 KGs and further evaluate in a zero-shot setting and also by fine-tuning the downstream tasks. - The paper proposes a transductive model that works in settings of new relations and entity nodes.\n- The method obtains good zero-shot pretraining results. - The authors have not explicitly stated the computational complexity of the method. From the paper, it seems that the forward pass is run on the entire relational graph to obtain relation representations. This is then used to initialize the node embedding from the query triple and the process is repeated for every triple. Thus it seems that the entire graph is being used for link prediction every triple making the computational complexity O(E^2). This seems limiting for large graphs that have not been explored in the paper (such as wikidata-5m etc.).\n- From Table 2 we can see that finetuning over the pre-trained models helps the results significantly over the 0-shot setting. Also, the fine-tuning steps are too large to claim few shot results. This weakens the claim of the \"foundation model\" for KGs. A fair comparison would be to show the pretraining results for other inductive and transductive methods as well in addition to the SOTA comparison.\n- Another limitation is that of scale. Since the current model has fewer parameters, this would limit learning over larger pretraining datasets as can be seen in Figure 6 and also reported by the authors.\n- SoTA results for transductive models are better than the pre-trained Ultra model in many datasets. Thus the Ultra model seems to work well for the inductive setting rather than transductive. Thus the claim of the \"foundation model\" seems broader in scope.\n- We see that in the metafam dataset, the pretraining results are poor but on finetuning the results are improved drastically. This shows that the method works well in cases where the relational patterns of the downstream datasets are similar to the pre-trained one but when the data distribution changes the results suffer. Moreover, due to limited capacity, the model may not be able to handle such cases by increasing the pretraining datasets calling for downstream finetuning. Thus domain adaptation is not a problem which can be easily overcome by scaling the current model and this further weakens the claim of a \"foundation model\" for KGs. - For weakness point 2: Any reason why this was not done by the authors?\n- For weakness point 3: How would this be addressed in future works for the model?\n-  For weakness point 4: Could the authors comment on why this would be the case and how would the model be improved to handle the transductive setting?\n- For weakness point 5: Any reason why the results on this dataset are not good?\n- Considering KGs are a rich source of textual/semantic data along with graph/structured data and the current model does not use this rich source of context information, how can we extend Ultra to incorporate the KG ontology? \n- Considering weaknesses 2,4,5 the claim of the foundation model seems a bit broad as of now and at best the model could be said to be a good inductive learner.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398852",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "625",
         "0",
         "0",
         "0.7487",
         "0.1723163098",
         "0.9095818996",
         "49",
         "51.6761",
         "0.1355",
         "iclr",
         "0.01041666666666663",
         "4",
         "4",
         "4",
         "3",
         "factual",
         "3",
         "3",
         "70",
         "neutral",
         "3",
         "neutral",
         "3",
         "high",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "21",
         "181",
         "Hideaki-Joko",
         "Reviewer-ebFz",
         "2",
         "2",
         "factual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "3",
         "3",
         "3",
         "4",
         "65",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "The key limitation of designing the foundation models for dealing with the Knowledge Graphs (KGs) is that the KGs have different entities and relations that generally do not overlap. To address this issue, this paper proposes ULTRA, which positively transfers the information of source KG to unseen KG. It constructs relation representations based on the interactions between the relations by introducing the graph of relations. The proposed approach has shown good performance on various tasks. - From their experiments, the proposed methods have shown good performance on various tasks.\n- Research topics about the foundational models on graph-structured datasets is really interesting and important.\n- The paper is well written and easy to follow. - The authors first pretrain the ULTRA model with the mixture of 3 standard KGs and then fine the model for the downstream task. But, the other supervised SOTA model only uses dataset of the downstream tasks without employing the pre-training datasets. If the supervised SOTA models are designed to deal with transductive settings, they may show worse performance on the downstream tasks. However, if the SOTA models are the models for the inductive setting, I think they may be possible to be pretrained like the ULTRA. So, could you measure the performance of the \"pretrained\" SOTA models on the inductive if possible? Please refer to the weaknesses.",
         "['~Mikhail_Galkin1', '~Xinyu_Yuan2', '~Hesham_Mostafa1', '~Jian_Tang1', '~Zhaocheng_Zhu1']",
         "1699636398789",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "2.0",
         "222",
         "0",
         "0",
         "0.7001000000000001",
         "0.16196172250000002",
         "0.9080925584",
         "49",
         "47.3913",
         "0.18230000000000002",
         "iclr",
         "0.0",
         "3",
         "4",
         "2",
         "3",
         "factual",
         "3",
         "3",
         "65",
         "neutral",
         "3",
         "neutral",
         "2",
         "high",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "2",
         "4",
         "3",
         "3",
         "factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "1",
         "4",
         "2",
         "2",
         "partially factual",
         "3",
         "2",
         "45",
         "polite",
         "4",
         "positive",
         "3",
         "low"
        ],
        [
         "22",
         "9",
         "Seyed",
         "Reviewer-KmBd",
         "4",
         "4",
         "factual",
         "neutral",
         "neutral",
         "none",
         "4",
         "3",
         "4",
         "4",
         "3",
         "3",
         "90",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699637128872",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "487",
         "0",
         "1",
         "0.732",
         "0.1304191468",
         "0.9185432792",
         "47",
         "29.0538",
         "0.1695",
         "iclr",
         "0.0",
         "4",
         "3",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "90",
         "neutral",
         "3",
         "neutral",
         "4",
         "none",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "23",
         "9",
         "Seyed",
         "Reviewer-3zCE",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699637128739",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "1.0",
         "480",
         "0",
         "0",
         "0.8331000000000001",
         "0.09343537410000001",
         "0.9183989763",
         "47",
         "39.3732",
         "0.1932",
         "iclr",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "negative",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "75",
         "polite",
         "5",
         "negative",
         "5",
         "low",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "70",
         "neutral",
         "5",
         "negative",
         "4",
         "low"
        ],
        [
         "24",
         "9",
         "Seyed",
         "Reviewer-y5kB",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1699642867494",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "41.9389",
         "0.050100000000000006",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "25",
         "9",
         "Seyed",
         "Reviewer-XNx6",
         "5",
         "4",
         "factual",
         "neutral",
         "neutral",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "88",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "1700672717423",
         "6.0",
         "4.0",
         "2.0",
         "2.0",
         "3.0",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.9159082770000001",
         "59",
         "42.2021",
         "0.929",
         "iclr",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "88",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "5",
         "4",
         "5",
         "5",
         "5",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "26",
         "81",
         "Emperatoor",
         "Gatot-Soepriyanto",
         "3",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "moderate",
         "3",
         "4",
         "4",
         "3",
         "4",
         "4",
         "70",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study investigate whether financial distress, earnings management and audit quality as determinants/moderating variable for financial statements fraud in Indonesian listed firms during 2015 to 2019 period. The authors focused on infrastructure, utility and transportation sectors. In general, the study has been designed adequately to tackle the research questions and issues posed by the authors. However, there are some elements need to be addressed to improve the paper: Whilst the study provide adequate research background and institutional setting, it did not mention on why the study focuses on infrastructure, utility and transportation sectors? Is there any specific issues on that sector that related to financial statements fraud? In addition to that, why the study chooses 2015-2019 period?  The study should also discuss the reason choosing F-Score as its main measure for financial statement fraud. Why, for example, the study did not use, Beneish M-Score? Or other accounting irregularities measures in the literature?  The study needs to provide descriptive statistics table, so the reader can gauge and understand the dataset better. This should be provided before the authors arrive with the hypothesis discussion;  Given the study uses panel data (multi years, across different firms), is there any attempt to mitigate the issues of panel data regression? For example, using year-fixed effects or even using panel data regression analysis?  The manuscript need to be checked in terms of the quality of English write up. The title for example, is a little bit confusing, as it did not really represent what the study want to achieve in general.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "30 Jun 2023",
         null,
         null,
         null,
         null,
         null,
         "400",
         "0",
         "1",
         "0.7771",
         "0.11745495500000001",
         "0.9143848419",
         "220",
         "26.81",
         "0.016800000000000002",
         "f1000",
         "0.020408163265306145",
         "4",
         "4",
         "3",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "moderate",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "27",
         "81",
         "Emperatoor",
         "Toni-Šušak",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "4",
         "4",
         "4",
         "4",
         "4",
         "80",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "25 Mar 2024",
         null,
         null,
         null,
         null,
         null,
         "909",
         "0",
         "5",
         "0.6798000000000001",
         "0.12259259260000001",
         "0.8569852710000001",
         "489",
         "50.12",
         "0.07200000000000001",
         "f1000",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "5",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "5",
         "4",
         "5",
         "5",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "3",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "28",
         "24",
         "Sajad-Ebrahimi",
         "Silvio-Buscemi",
         "1",
         "1",
         "unfactual",
         "negative",
         "polite",
         "extreme",
         "1",
         "3",
         "1",
         "2",
         "3",
         "3",
         "48",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         null,
         "07 Jan 2025",
         null,
         null,
         null,
         null,
         null,
         "280",
         "0",
         "1",
         "0.7857000000000001",
         "0.1403645833",
         "0.7798862457",
         "34",
         "24.27",
         "0.3225",
         "f1000",
         "0.010526315789473717",
         "1",
         "3",
         "1",
         "2",
         "unfactual",
         "3",
         "1",
         "48",
         "polite",
         "3",
         "negative",
         "1",
         "extreme",
         "4",
         "5",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "29",
         "77",
         "Mohammad-Hossein-Saliminabi",
         "Houcemeddine-Turki",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "85",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "This manuscript presents a novel rule-based approach for fact checking in knowledge graphs based on mining textual resources. The work provides new evidences that rule-based approaches can provide more precise evaluation of the accuracy of statements in knowledge graphs and can enhance the efficiency of embedding-based methods when combined with them. The availability of source codes and datasets in GitHub is an advantage for this work as this will allow the reproducibility of the described experimental study. However, there are several matters within the paper that should be addressed to ameliorate its final output: (i) Introduction: The \"Introduction\" seems to be a summary of \"Related Studies in Fact Checking\" rather than a proper introduction and contextualization of the paper. I propose to expand the part about misinformation fighting in the introduction to give better context for the development of this research paper. The authors can benefit from previous research papers about fact checking in general to develop the introduction of the paper. Several points in the introduction should be moved to Related Studies in Fact Checking. (ii) The paper did not emphasize the advantages of rule-based approaches when compared to embedding-based methods beyond having a better precision. Effectively, there are many other advantages of rule-based approaches. For example, the results of rule-based approaches can be more explainable than the ones of embedding-based approaches. Such advantages should be expanded and highlighted in the research paper. (iii) The paper did not emphasize the importance of having the datasets and source codes available in a specific GitHub repository. The authors should specify that this practice allows reproducibility and further development of the work by peers, particularly in the conclusion. (iv) The paper did not discuss the concept of reification in knowledge graphs. Effectively, several knowledge graphs add qualifiers to triples to provide a characteristic of the statements (i.e. {(s,p,o), p, o}. The authors should discuss the usefulness of the method to verify the qualifiers of the statements in the Discussion or as a future direction for this work. (v) The paper should evocate the robustness of the rule-based approach they proposed to adversarial attacks. This can be an advantage of the approach. (vi) There are several typos in the research paper (e.g. \"UC Berkely\" should be \"UC Berkeley\"). The authors should proofreading the paper to eliminate such deficiencies. (vii) The authors can expand the Discussion of the work (Part 5) to explain the strengths of KStream, KLinker, COPPAL, RUDIK, and PredPath that contributed to their efficiency as reported in the Experimental Study according to previous research papers. This can explicate the reasons of why the method developed by the authors was more efficient. (viii) The authors should provide future directions for the development of this work in the conclusion. Given this, I propose to accept this paper for publication after these six major revisions are applied.",
         null,
         "18/Feb/2021",
         null,
         null,
         null,
         null,
         null,
         "473",
         "0",
         "1",
         "0.7464000000000001",
         "0.1097294372",
         "0.9120528102000001",
         "4",
         "36.08",
         "0.2025",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "88",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "30",
         "67",
         "Emperatoor",
         "Reviewer-um1j",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "4",
         "5",
         "3",
         "4",
         "4",
         "70",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "The paper introduces a new method for molecular modeling, QuinNet, which incorporates five-body interactions using only dihedral angles. The authors first introduce relevant concepts related to machine learning force fields and related work in the field related to a variety of equivariant models. Next, the paper describes pertinent definitions of force fields, group equivariance, and methods for calculating empirical force fields. In the methods section, the authors describe their approach for integrating five-body terms into the architecture of QuiNet using only dihedral angles and incorporating model designs from prior work (PaiNN for 3-body interactions, ViSNet for 4-body interactions) and new definitions for different topologies of 5-body interactions. In addition to the architectural description, the authors provide relevant mathematical formulations and a complexity analysis. In their results, the authors showcase QuiNets performance on a low (MD17) and high complexity (MD-22) dataset in terms of energy and force modeling, including an ablation for different body terms in Figure 5. The paper has the following strengths:\n* Originality: The proposed architecture incorporates relevant terms for molecular modeling that are physically relevant, but have not been incorporated before.\n* Quality: The method and experimental design showcase relevant cases for applying GNN models for molecular modeling with the idea behind the architecture being well-motivated.\n* Clarity: The paper presents a cohesive formulation of their method, both in figures and mathematics, and experiment descriptions with relevant takeaways.\n* Significance: The proposed architecture shows improved modeling performance, especially in forces, and provides a potential framework for incorporating physical interactions into GNNs. The paper could be improved by the following:\n* Providing a clear and concise discussion of limitations. \\[Quality, Significance\\]\n* Adding more context for the results in Figure 4. The MD simulations are only briefly described in Section 5.1, which is on a different page then the figure and easy to miss. \\[Clarity\\]\n* A description of the case in which a greater set of many-body interactions is beneficial. This is briefly mentioned in the discussion between MD17 and MD22, but it would be good to put in greater context in terms of the experimental results and could serve as part of the conclusion. \\[Clarity\\] * Could you provide additional details on the limitations of QuinNet? E.g. Is it limited to modeling mainly molecular systems? What sizes of molecules do you think QuinNet can be effective in and why?\n* Do you have data that supports your compute complexity analysis compared to other methods? If so, what kind of speedup do you generally find, if any? The authors do not provide a discussion on limitations, which I raised as a weakness. I would like to see a discussion of limitations in future versions and/or during the discussion period.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337960",
         "7.0",
         "4.0",
         "4.0",
         "3.0",
         "3.0",
         "452",
         "0",
         "1",
         "0.7681",
         "0.1465895563",
         "0.867398262",
         "215",
         "29.1615",
         "0.464",
         "neurips",
         "0.0",
         "5",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "5",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "31",
         "67",
         "Emperatoor",
         "Reviewer-YmDt",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "5",
         "4",
         "5",
         "5",
         "80",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "In this work, the authors propose to incorporate features from five-body interaction into machine-learning force field models and develop QuinNet. To efficiently incorporate such high-order information, the authors are motivated by the topology of many-body interactions and design sophisticated components. Experiments on several benchmarks are conducted to demonstrate the performance of QuinNet. 1. The target problem of this paper, the development of machine learning force field models, is of great significance. 1. **The motivation for the designed components of many-body interaction is puzzling**. As introduced in Section 4, the development of four-body interaction (improper torsions) and five-body interactions are based on the topology. First, such analysis is purely qualitative. The authors did not provide further completeness proof or quantitative evidence about these interaction schemes in real-world data. Second, the reasons for deriving Eq (4)-(9) are not well explained. It is suggested to clarify how these components are motivated according to the topology analysis.\n\n\n2. **On the experimental evaluation**. Additionally, there are several aspects of the experiments that are concerned:\n    - The empirical performance is not consistently better than other baselines. Among the evaluated benchmarks, the proposed QuinNet cannot outperform the baselines significantly. For example, in MD17, the newly developed five-body interaction modules do not significantly improve performance. In rMD17, the best performance is diversely distributed among the compared models. Overall, the experimental evaluation does not well demonstrate the power of newly developed modules.\n    - The computation efficiency evaluation is missing. Although the authors provide complexity analysis, it is better to further show the time/memory cost comparison between the proposed QuinNet and baselines. Besides, the model parameters should also be provided for all compared models.\n    - The scale of the chosen benchmarks is rather small. Both the dataset size and sample size (number of atoms) are limited. It is suggested to further evaluate the proposed QuinNet on large-scale benchmarks, e.g., Open Catalyst Project \\[1\\].\n    - The ablation study. First, as shown in Figure 5, the inclusion of Five-body@I even induces further errors, which would make readers curious about whether such a phenomenon generally exists. Second, as introduced in VisNet, the improper angle was also considered. The authors should add further discussions and empirical comparisons between it and the newly proposed four-body interaction (improper torsion).\n\n\n3. **The writing does not meet the requirement of an acceptable paper in this conference**. First, Section 3.2 can be thoroughly extended (e.g., in the appendix) to introduce the background of force fields and highlight the importance of torsion potential, improper torsions, and higher-order many-body interactions. Second, there lack of formal descriptions of QuinNet. Figure 3 can hardly be understood by readers that are not familiar with the related works in this area. \n\n\\[1\\] Chanussot L, Das A, Goyal S, et al. Open catalyst 2020 (OC20) dataset and community challenges\\[J\\]. Acs Catalysis, 2021, 11(10): 6059-6072.\n    -  Please refer to the Weakness section to address the concerns. The authors did not discuss the limitations of this work.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337859",
         "4.0",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "489",
         "2",
         "6",
         "0.7931",
         "0.0741489571",
         "0.8583066463000001",
         "215",
         "34.6703",
         "0.19390000000000002",
         "neurips",
         "0.0",
         "5",
         "5",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "80",
         "polite",
         "5",
         "negative",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "1.0",
         "3.0",
         "3.0",
         "2.0",
         "partially factual",
         "3.0",
         "2.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "4.0",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "32",
         "67",
         "Emperatoor",
         "Reviewer-8RW7",
         "4",
         "4",
         "factual",
         "negative",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "5",
         "4",
         "85",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper aims to incorporate 5-body interactions into geometric deep learning models. They first analyze the topology of 5-body interactions and identify three 5-body angles. Then they propose an efficient way to incorporate these 5-body information into models. The complexity of the proposed QuinNet is still O(|N|), the same as many previous 2-body methods like PaiNN. The results are comparable to previous SOTA methods. This paper is well-written and easy to follow.\n\nThe experimental results show that the proposed method can perform well on most tasks. The ablation study in Section 5.4 and Figure 5 show that the proposed 5-body information indeed helps to model. See details in the Question part. 1. About the motivation:   \n this paper aims to incorporate 5-body interactions into geometric deep learning models. However, based on my understanding, using up to 4-body (torsions) interaction is already complete \\[1\\]\\[2\\] in terms of capturing the geometric structures. If this is correct, then why do we need these 5-body angles? In addition, if we can incorporate 5-body interactions, do we also need to incorporate 6-body interactions?\n\n2. About the complexity:   \nin Section 4.3, the authors claim that the complexity is O(|N|), as efficient as many 2-body methods like SchNet and PaiNN. But I think this complexity is not well explained. Using pseudocode/algorithm may be better to analyze the complexity. In addition to the analysis, I suggest the authors use some results to empirically verify the great efficiency compared to other baseline methods, e.g. the inference time, used memory, etc.\n\n3. About the tasks:   \nthis paper focuses on MLFFs, how about other molecular property prediction tasks, such as QM9 and OC20? I am wondering if this method is specially designed for MLFFs, or can be used on all 3D molecule tasks. In other words, why do the authors emphasize MLFFs? Is there any significant difference between MLFFs and other molecule property prediction tasks?\n\n4. Other related papers: many-body \\[3\\], MLFFs \\[4\\]\n\n5. The j, k in Figure 2 are confusing to me. For example, in (f), why not be i, j1, j2, j3, and k1?\n\n\\[1\\] ComENet: Towards Complete and Efficient Message Passing for 3D Molecular Graphs.  \n\\[2\\] GemNet: Universal Directional Graph Neural Networks for Molecules.  \n\\[3\\] On the Expressive Power of Geometric Graph Neural Networks.  \n\\[4\\] Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations. None",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337767",
         "5.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "394",
         "8",
         "6",
         "0.77",
         "0.13857142860000002",
         "0.8948391676",
         "215",
         "48.9981",
         "0.1429",
         "neurips",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "85",
         "polite",
         "5",
         "negative",
         "4",
         "low",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "33",
         "67",
         "Emperatoor",
         "Reviewer-YYfR",
         "3",
         "4",
         "factual",
         "positive",
         "polite",
         "low",
         "4",
         "4",
         "3",
         "3",
         "4",
         "4",
         "70",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper introduces a machine learning force field that is a neural network with explicit interactions for up to 5-body terms.  The authors evaluate the model on a couple of public datasets and show demonstrate the competence or superiority of this new model compared to the state of the art in this field. The paper provides an important addition to a series of ever-improving machine learning potentials.  The contribution is clear and simple to understand at the high level, though the details are often unclear.  The benchmarks were compared against a set of reasonably strong published methods in this area.  In my opinion, if this work was presented in an unambiguously clear fashion and accompanied by code, it could be a strong contribution to this conference.  \n\n\\[The paper improved significantly following the first round of feedback from reviewers, so I'm raising my rating to a 7.\\] The complexity analysis is very limited.  How many total interactions did the typical molecule have as a function of their atoms, and how did the practical experimental complexity scale for the evaluation of these molecules.  One of the main reasons that 5-body terms were not used in traditional MD simulations was the poor scaling of the number of interactions one would need to calculate.\n\nThe MD simulation mentioned in section 5.1 and Fig 4 are not described anywhere.  The following sentences suggest that there would be some explanations in the supplement, but I couldn't find them: \"Additionally, we perform MD simulations using trained QuinNets as force fields and plot the distribution of interatomic distances h(r) for these 7 molecules in Fig. 4. Further details regarding additional settings can be found in the Supplementary Materials.\" \n\nThese sentences in the supplement, page2, are confusing or wrong: \"Similarly, five-body@III interaction (Fig. S1 (c)) is a special case of six-body interaction when nodes i and k4 in Fig. S1 (d) superpose each other. Thus, the QuinNet model captures all five-body interactions and a portion of six-body interactions, making it a versatile and comprehensive tool for modeling complex molecular systems.\"  There is no six-body interaction if two of the bodies are the same, and there is no physically acceptable case where two different atoms could superpose each other.\n\nThe code is not provided, so it is not possible for me to assess the reproducibility of this method.  The diagram in Figure 3 seems reasonable at the very high level, but it lacks the definitions of most of the terms annotated in the figure, thus rendering it confusing.  (What is $Y_l$? is it the set of all spherical harmonics $Y_{lm}$ for a given angular momentum $l$? What is $n_j$? What is $s_j$?  $W$?...) Could the authors add the presentation of the QM9 quantities estimated in the recent publication for Allegro?  (https://www.nature.com/articles/s41467-023-36329-y Table 3)\n\nHow long and how stable were the actual MD simulations?  What were the exact codes/protocols used?\n\nWhat is the practical performance of the model during evaluation? No potential negative societal impacts from this work.",
         "['~Zun_Wang2', '~Guoqing_Liu3', '~Yichi_Zhou2', '~Tong_Wang2', '~Bin_Shao1']",
         "1702411337653",
         "7.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "497",
         "1",
         "2",
         "0.764",
         "0.0333794423",
         "0.8763324022000001",
         "215",
         "43.7997",
         "0.1199",
         "neurips",
         "0.018018018018018056",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "polite",
         "5",
         "positive",
         "4",
         "moderate",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "34",
         "171",
         "Sajad-Ebrahimi",
         "Magdalena-Czlapka-Matyasik",
         "1",
         "1",
         "unfactual",
         "neutral",
         "neutral",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "35",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I commend the authors to contribute to this body of literature regarding the socio-demographic and lifestyle factors associated with understanding fast food consumption in Cambodia adults. The paper brings quantified information about the factors influenced by understanding fast food consumption. The authors revealed that poor and fair knowledge, insufficient exercise levels, and not getting enough sleep were predictors of inadequate understanding of the impact of fast food on health. Such conclusions do not bring entirely new knowledge to the literature, on this matter. Across the whole world population, the problems related to fast food consumption have been discussed. Nevertheless, I consider the work to be original, well designed and contribute knowledge to this field of public health research. My suggestions concern: In the introduction, the authors indicate the system of fast-food restaurants; it would be more attractive to explain, how it was developed in Cambodia directly?  What would be very interesting is information concerning the real take away or fast food intake in those groups. It must or might be in direct relation to this matter?  My main concern about the validation of the \"Level of knowledge of fast food consumption\": Could the authors explain the procedure? How were the questions selected and validated?  I regret that the authors discussed the interesting results in such a concise way.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         null,
         "12 Feb 2021",
         null,
         null,
         null,
         null,
         null,
         "361",
         "0",
         "1",
         "0.7773",
         "0.2011784512",
         "0.89415133",
         "137",
         "35.27",
         "0.1507",
         "f1000",
         "0.010000000000000009",
         "0",
         "4",
         "1",
         "0",
         "unfactual",
         "3",
         "3",
         "35",
         "neutral",
         "3",
         "neutral",
         "1",
         "high",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "positive",
         "3",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "35",
         "171",
         "Sajad-Ebrahimi",
         "Wanshui-Yang",
         "1",
         "0",
         "unfactual",
         "negative",
         "impolite",
         "high",
         "3",
         "3",
         "0",
         "0",
         "3",
         "4",
         "40",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript investigated the level of understanding of fast-food consumption among adults in Cambodia. The authors found that unsatisfactory levels of knowledge around fast food consumption were significantly associated with not taking regular exercise and sleeping less than eight hours per night. The results are interesting, but I have several comments. The authors should introduce the recent development of fast-food sector in Cambodia in the introduction part.  Is there an analysis of fast-food intake among these participants?  Interestingly, the authors found that not taking regular exercise and sleeping less than eight hours per night were associated with unsatisfactory levels of knowledge around fast food consumption. However, they were not well explained in the discussion part. In other words, the discussion part is a little too concise.  In addition, the education levels were not associated with the knowledge of fast-food consumption in the present study. I would like authors to discuss it and, at least, mention its possible causes.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         null,
         "02 Mar 2022",
         null,
         null,
         null,
         null,
         null,
         "303",
         "0",
         "1",
         "0.7774000000000001",
         "0.1265046296",
         "0.9193514585",
         "520",
         "28.03",
         "0.1953",
         "f1000",
         "0.010204081632653073",
         "0",
         "4",
         "1",
         "0",
         "unfactual",
         "3",
         "3",
         "40",
         "impolite",
         "3",
         "negative",
         "0",
         "high",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "36",
         "187",
         "Emperatoor",
         "Reviewer-2CBB",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "4",
         "4",
         "4",
         "4",
         "4",
         "70",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "This paper introduce a novel unsupervised feature selection methods called GRSSLFS, which combine matrix factorization with self-representation subspace learning and apply graph regularization to preserve the geometric structure of the feature vectors. This method is proved to be effective in both theory and experiments. In this paper, the author introduce the problem of the redundant data in traditional self-representation, and then apply matrix factorization self-representation problem to achieve the goal to reduce the dimension of basis matrix. Here are some strengths of this article:\n\n1. This paper introduce a novel problem of redundant data in self-representation problems and then propose a method to solve this problem.\n\n2. Plenty of theoretical proof are given in the paper and appendix, the convergence analysis indeed increase the persuasiveness of the article.\n\n3. The proposed method was compared with a variety of comparison algorithms on multiple data sets, demonstrating the effectiveness of the method. However, there are still some weaknesses in this paper.\n\n1. In the end of Introduction section, the second and third contribution points is not sufficient, as these constraints of regularization are not proposed in this article. \n\n2. In the methodology section, some formula calculations are confusing and not very convincing. Such as the multiplication in formula (6) and the optimization target in the optimization goal (formula 7). These issues will be described in detail in subsequent questions 1 and 2.\n\n3. In the methodology section, the description of the algorithm is not complete enough. The specific process of selecting features according to the matrix U in Algorithm 1 has not been described in detail. 1. In the section of methodology, the equation (6) is confusing and not so clear. It seems impossible to subtract the matrix XUV of shape m*m from the matrix X with the shape m*n? \n\n2. As the feature matrix B is fixed by the VBE method proposed in section 3.3, it is unclear why the basis coefficient matrix G in equation (7) is a parameter to be optimized. Why the matrix G can not be determined by equation (4) directly and reduce the number of parameters.\n\n3. In section 3.1, subspace learning that introduces graph regularization seems to be existing methods. Should this part of the content be moved to related work?",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636201193",
         "6.0",
         "5.0",
         "3.0",
         "3.0",
         "2.0",
         "376",
         "0",
         "8",
         "0.679",
         "-0.048046398000000004",
         "0.9640573859",
         "51",
         "40.0877",
         "0.0751",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "4",
         "4",
         "70",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "37",
         "187",
         "Emperatoor",
         "Reviewer-yUvs",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "low",
         "5",
         "5",
         "3",
         "4",
         "3",
         "4",
         "75",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Authors of this paper propose graph regularized self-representation and sparse subspace learning (GRSSLFS) for unsupervised feature selection. The basis extension method is modified to select bases with highest variance score. These bases are used to build graph regularized self-representation learning and subspace learning. The graph regularized self-presentation learning and subspace learning are combined in terms of a set of selected bases from input space with the highest variance score. Experiments on various datasets demonstrate the advantage of the proposed method comparing with baselines. The ablation study also shows the necessity of each component. The subspace learning module is the key component, but its derivation from selected bases highly relies on the assumption that XU=B. This might not be hold if B is selected according to the proposed variance basis extension method. Moreover, the selection based on subspace learning module lacks of convincing explanation since G does not exactly represent X based on B as a fixed set of feature vectors. It is confusing to explain (4) as the self-representation problem if B is arbitrary basis matrix since they may not come from the input data matrix X.  Taking PCA for example, the columns of B are orthogonal, but they are not from the input feature space. Moreover, B defined as a square matrix of size m is inconsistent with the sleeted r bases in section 3.3.\n\nIn section 3.1, authors mentioned that two features have a similar structure in the feature space, and it is expected Bg_l and Bg_r have similar structure. What does the similar structure mean? How is the similarity measured? In other words, it is unclear how the matrix A is constructed. \n\nThe derivation in section 3.2 depends on the assumption that XU=B. As B is a set of feature vectors selected from input data, it is unclear whether the assumption still holds or not. Similarly for Theorem 3.1, it is trivial to have if the assumption holds. \n\nThe variance basis extension is to simply change the selection order of feature vectors in terms of variance score of feature vectors. It is possible that for each individual feature, the variance is high, but is it similar to say the largest amount of data dispersion? \n\nFor completeness, authors should describe the derivation process on how equations (9)-(11) are obtained. Since all three equations are fractional, is it possible that any of the denominators can be zero? How is it handled?\n\nIn Algorithm 1, the selected features are derived from U. However, U is not directly related to the input X instead to B and G, unless BG=X. However, B is selected feature vectors from input space. It is unclear why the assumption can hold. So why is the selection rule proper?\n\nThe computation complexity is quite high since it is quadratic to both the number of samples and the number of features comparing with most of baseline methods.\nThe application to the PneumoniaMNIST dataset is quite interesting. However, the way of presenting the outcomes can be improved significantly.  For example, what is the interested region? how many selected features are in the interested region? How do other compared methods perform? The validation is not quantified. How many radiologists are involved in the evaluation?  What is the performance measured? These plots shown in Fig. 2 delivers less useful information except that more red points are accumulated in the center when the number of selected features increases.",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636201025",
         "5.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "567",
         "0",
         "0",
         "0.7308",
         "0.0892117117",
         "0.9616214633000001",
         "51",
         "50.3623",
         "0.0364",
         "iclr",
         "0.0",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "75",
         "polite",
         "3",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "5",
         "4",
         "4",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "neutral",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "75",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "38",
         "187",
         "Emperatoor",
         "Reviewer-PMap",
         "1",
         "3",
         "partially factual",
         "negative",
         "polite",
         "moderate",
         "2",
         "2",
         "2",
         "3",
         "3",
         "4",
         "30",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Considering there exists a major gap in the mathematical principles that underlie the self-representation based unsupervised feature selection approaches and their capacity to represent the feature space, this paper proposes Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), for the unsupervised feature selection, which expresses the self-representation problem based on the concept of “a basis of feature space” to represent the original feature space as a low-dimensional space made of linearly independent features. Experiments on widely-used datasets are conducted to validate the efficacy of the proposed method. 1. The computational complexity of the proposed GRSSLFS method is low, which is efficient for large-scale and high-dimensional data;\n2. The results of the proposed method seem better than other ones. 1. Most of the compared methods are out-of-date, only one method used for comparison was publised in 2023, other methods are before 2020;\n2. The motivation of the proposed method is not clear. In Eq.(8), the first three terms have been well explained, but the final regularization term has not been explained. See weakness.",
         "['~Prayag_Tiwari1', '~Farid_Saberi_Movahed1', '~Saeed_Karami1', '~Farshad_Saberi-Movahed1', '~Jens_Lehmann3', '~Sahar_Vahdati3']",
         "1699636200941",
         "5.0",
         "2.0",
         "2.0",
         "2.0",
         "2.0",
         "172",
         "0",
         "4",
         "0.6699",
         "0.1067307692",
         "0.9783408642",
         "51",
         "26.959",
         "0.0945",
         "iclr",
         "0.0",
         "2",
         "4",
         "1",
         "3",
         "partially factual",
         "2",
         "2",
         "30",
         "polite",
         "3",
         "negative",
         "3",
         "moderate",
         "3",
         "4",
         "3",
         "3",
         "partially factual",
         "4",
         "4",
         "65",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "3",
         "3",
         "factual",
         "3",
         "4",
         "65",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "39",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-NRqK",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "5",
         "5",
         "5",
         "4",
         "5",
         "94",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes an algorithm for learning MDP state abstractions that preserve information needed for planning (namely, the values of states). A major differentiator from symbolic approaches is the idea that these state abstractions should be continuous rather than discrete. The key assumption is that you are given a set of options and a dataset obtained by rolling them out. Experiments are conducted in a few simple domains: pinball and antmaze, and demonstrate that the learned abstractions are sensible. The paper addresses an important topic (abstraction learning) and I appreciate the theoretically motivated algorithms. This line of work is of great interest to many attendees of ICLR. I also appreciate that the authors were clear about wanting continuous representations right off-the-bat. The math is also correct as far as I was able to tell, though I didn't check the proofs in the appendix in careful detail. Unfortunately, I recommend rejection for this paper due to 4 major reasons: 1) unconvincing experiments, 2) missing key citations to related work, 3) issues in technical details, and 4) unclear motivation.\n\n1) unconvincing experiments\n\nThe experiments in this paper are very basic and only serve as a simple proof-of-concept that the learned abstractions are somewhat useful. To really scale up the experiments to the level expected for a conference paper, I would expect to see evidence that the learned abstractions are useful in more hierarchical domains (e.g., classic domains from the options literature like keys and doors). In such domains, we could test whether the value-preserving property holds empirically, by comparing the values from planning under the abstract model to the (ground truth) values from planning under the true model.\n\nAdditionally, I would like to see comparisons to many more RL algorithms, especially hierarchical ones like HIRO (https://arxiv.org/abs/1805.08296), HVF (https://arxiv.org/abs/1909.05829), and Director (https://arxiv.org/abs/2206.04114). This is because at the end of the day, the authors are proposing to learn a state encoder $\\phi$, and despite all the theory that has gone into their algorithm, the question that must be answered is whether this $\\phi$ outperforms the encoders learned by all these other SOTA hierarchical RL algorithms.\n\n2) missing key citations to related work\n\nThe authors are missing several key citations, the most important of which is the line of work by David Abel, such as \"Near optimal behavior via approximate state abstraction\" (https://proceedings.mlr.press/v48/abel16.html) and \"Value preserving state-action abstractions\" (https://proceedings.mlr.press/v108/abel20a/abel20a.pdf). Those papers have very similar theory to what appears in this one, and so the novelty of the proposed approach is unclear. There are also less-famous but still important-to-cite papers from other authors, like \"Abstract value iteration for hierarchical reinforcement learning\" (https://proceedings.mlr.press/v130/jothimurugan21a/jothimurugan21a.pdf) and \"Deciding what to model: Value-equivalent sampling for reinforcement learning\" (https://proceedings.neurips.cc/paper_files/paper/2022/hash/3b18d368150474ac6fc9bb665d3eb3da-Abstract-Conference.html). It is important for the authors to contextualize the contributions of this paper against all these related works.\n\n3) issues in technical details\n\nThe authors say in Section 3.2 that when B = \\bar{B}, \"then simulating a trajectory in the abstract model is the same as in the ground model\". But I don't think this is true, because we need the rewards to match between the two trajectories too, and $B_t$ says nothing about rewards, only dynamics. The authors go on to say: \"Therefore, planning in the abstract model is accurate, in the sense, that the value of an abstract state z computed in the abstract model is the same as the one would get from trajectories from the ground MDP for the abstraction operator G.\" Again, I think this is wrong because it ignores the abstract reward function, which could be arbitrarily different from the ground one. In fact, in the proof of corollary 3.8, the authors assume $E_{s \\sim G(\\cdot \\mid z)}\\[R(s, o)\\] = \\bar{R}(z, o)$, and it's only _under this assumption_ that the claims hold. But combining this assumption on reward function with Definition 3.6 ends us back up at the bisimulation conditions, and then it's not clear what the contributions of this paper are.\n \nAs a separate point, the second term in the mutual information expression of Section 4.2, $MI(S'; Z, A)$, seems very extreme! It is saying that you have to be able to predict the entire ground next state from the current abstract state and action. Doesn't this means the abstraction can't lose any information? This seems like an important technical limitation of the approach.\n\n4) unclear motivation\n\nThe authors often state that a discrete abstract state space is bad, when pointing to work on symbolic abstraction learning (e.g., PDDL). But it's not clear why this is really bad. The authors say discrete abstract states are \"not applicable when planning with the available high-level actions requires a continuous state representation\", but this doesn't make sense to me, as the options have to act in the ground environment states, not in the abstract state space, and so the options could be defined with respect to either a discrete or a continuous abstract state space. Furthermore, it can be much easier to plan in a discrete abstraction (e.g., using powerful symbolic planners).\n\nI believe a fruitful research direction would be to compare the abstractions learned by a symbolic approach against the abstractions learned by a continuous approach (like the authors'). Questions:\n* Not much is said about the dataset $\\mathcal{D}$, but intuitively, it has to be \"good\" in order for the learned state abstraction to be reasonable. In particular, the agent must see all the options being executed in a variety of settings, and obtain good coverage over the state-action space. Are there any concrete statements we can make about what properties we need this dataset to have?\n* \"we must build a model of its effect\" Do you mean to say \"of the effect of each option\"?\n* \"with mean value equal to that by planning with the original MDP\" What is the mean over?\n* Why did we switch from using O (denoting the option set) everywhere to using A throughout Section 4? Shouldn't we continue to use O, unless I am misunderstanding something?\n* Section 4.3: Why should there be any cost/reward associated with executing skills? Shouldn't a sparse reward for reaching the goal be enough?\n* Eq 2: What are the \"I\" random variables inside the mutual information expression referring to?\n\nMinor edits:\n* \"make the same decision\" To clarify, we just need that the policy maps all states in z to the same action distribution. A stochastic policy isn't really committing to a \"decision\" about what action to take.\n* \"Abstractions alleviate this tension: action abstractions enable agents to plan at larger temporal scales and state abstractions reduce the complexity of learning and planning\" I would say that both of them do both of these. Action abstractions certainly reduce the complexity of planning, which is typically exponential in the branching factor.\n* \"learns a further abstraction\" --> \"learn a further abstraction\"\n* \"otherwise it is referred as learning\" I would say \"policy learning\" to distinguish from other things you might learn\n* \"when it is the given position\" --> \"when it is in the given position\"\n* \"referred as learning\" --> \"referred to as learning\"\n* \"results a bounded value loss\" --> \"results in a bounded value loss\"\n* In definition 3.5, the authors use $s_o$ in a few places where they mean $s_0$.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1699636621573",
         "3.0",
         "4.0",
         "3.0",
         "2.0",
         "2.0",
         "1210",
         "7",
         "0",
         "0.7753",
         "0.0567315252",
         "0.9024221301",
         "49",
         "44.7468",
         "0.6075",
         "iclr",
         "0.019607843137254943",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "4",
         "94",
         "polite",
         "4",
         "negative",
         "5",
         "none",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "negative",
         "5",
         "none",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "3.0",
         "60.0",
         "neutral",
         "5.0",
         "negative",
         "5.0",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "negative",
         "5",
         "none",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "40",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-36E8",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "3",
         "3",
         "4",
         "4",
         "80",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper presents an approach for learning dynamics preventing abstractions for sensorimotor observation space. Given a set of high-level skills and the learned dynamics preserving abstractions, the paper claims to develop an approach for planning for a solution. \n\nThe approach is evaluated in two test domains where the paper shows the visualization of the learned abstractions. - For the most part of the paper, it is extremely well written. Given the wide use of embodied AI systems and robots, an approach that generates plannable abstractions for high-dimensional sensor input is extremely important. \n\n- The paper nicely motivates the problem. While the paper in general is nicely written, it has a few limitations: \n\n- The paper advocates learning a continuous abstract  representation instead of a symbolic abstractions. However, it does not provide any reasons to that. Why are continuous abstractions more desirable than symbolic abstractions? \n\n- Sec 4.1 is unclear. The notation for MI is a bit unclear. It needs to be made more clear. Sec 4.1 requires a re-writing including more explanation for the equation. I have two important questions: \n\n- How is the dynamics preserving abstraction defined in Def. 3.6 different from the Markovian abstractions defined in \\[Srivastava et al. 2016\\]? \n\n- Can you discuss the differences between the presented approach and \\[Allen et al. 2021\\] \n\nReference \n\nAllen, Cameron, et al. \"Learning markov state abstractions for deep reinforcement learning.\" Advances in Neural Information Processing Systems 34 (2021): 8229-8241.\n\nSrivastava, Siddharth, Stuart Russell, and Alessandro Pinto. \"Metaphysics of planning domain descriptions.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1699636621454",
         "8.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "264",
         "1",
         "6",
         "0.7512000000000001",
         "0.1625",
         "0.8653070927000001",
         "49",
         "41.1434",
         "0.2429",
         "iclr",
         "0.0",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "3",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "4",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "41",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-dCJp",
         "5",
         "5",
         "factual",
         "negative",
         "polite",
         "none",
         "4",
         "3",
         "4",
         "4",
         "4",
         "4",
         "83",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper introduces a method for enabling general-purpose agents to efficiently handle complex tasks by constructing abstract models based on temporally-extended actions. These models facilitate more efficient planning and learning and are characterized using principled conditions. The approach provides empirical evidence of improved sample efficiency in goal-based navigation tasks and offers theoretical support for information maximization strategies in abstract state representation learning.\nThe authors claim that they introduced a method for creating abstract world models that empower agents to plan effectively for goal-oriented tasks. The key idea is to allow agents to construct reusable abstract models for planning with specific skills. This is achieved by characterizing the state abstraction that ensures planning without any loss in simulation, meaning that planning with the learned abstract model can generate policies for the real world. The paper also provides theoretical support for the use of information maximization as a reliable strategy for learning abstract state representations. - Good overview of the related work.\n- Good description of motivations and intuitions. \n- proper choice of environment settings. Major:\n- Some measures are used without definition, \n- It seems that there exists a lot of inaccuracies and impreciseness in the theories and definitions. See all questions!\n\nminor:\n- typos: \nlast paragraph of the introduction \"the *agents* needs\", definition 3.5 \"$s_{o}$\" must be \"$s_0$\"\n- writing: \nDefine the abbreviations before using them, e.g. \"PDDL\", \"VAE\"\n\nThere is a chance that I have not fully understood what this paper is trying to present. 1- What is $P(s'|s,o)$ used in the paragraph right after definition 3.1?\n\n2- An option $o$ is defined, and then you mention $T(s'|s,o)$ to define the transition probability of taking option $o$ in $s$? $T$ earlier was defined on action space $A$. How is it applied on options without showing the relationship of $I_o$ and $\\beta_o$ with $s$ and $s'$ under option policy $\\pi_o$?\n\n3-the paper has defined \"$\\bar {\\gamma} = \\gamma ^{\\tau (s,o)}$ is the abstract discount factor, $\\tau: Z \\times O \\rightarrow \\[0,\\infty)$, which consists of contradictory phrases. How is ${\\tau (s,o)}$ but defined as a function of abstract variables $Z$ instead of $S$? Not clear what $\\tau$ is. If based on definition 3.1, it is the option's execution time starting from $s$ taking option $o$, it is not clear how in definition 3.2 it becomes a map from $Z$ and $O$ to a non-negative real.\n\n4- What does definition 3.4 mean? $ \\Pi = {\\pi \\in \\Pi : \\pi(·|s) = \\pi (·|z) \\forall s \\in z}$ says the probability of taking actions/options in $s$ should be equivalent to the probability of taking actions/options in abstract states. Transitions of taking actions in states might take you to another state $s'$ inside the similar abstract state $z$. How can the policies used for both abstract states and states be equivalent? Unless you are just discretizing the continuous state spaces based on the optimal policies that are already given. Lots of interchangeable usage of symbols here. Not precise and is hard to follow.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1700688515580",
         "3.0",
         "4.0",
         "2.0",
         "3.0",
         "2.0",
         "499",
         "0",
         "1",
         "0.7308",
         "0.0796438834",
         "0.93872118",
         "61",
         "45.6397",
         "0.1463",
         "iclr",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "3",
         "4",
         "83",
         "polite",
         "4",
         "negative",
         "5",
         "none",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "4",
         "4",
         "45",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "neutral",
         "4",
         "neutral",
         "4",
         "moderate",
         "2",
         "3",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate"
        ],
        [
         "42",
         "103",
         "Sajad-Ebrahimi",
         "Reviewer-gKE9",
         "5",
         "4",
         "factual",
         "positive",
         "polite",
         "none",
         "5",
         "4",
         "4",
         "4",
         "4",
         "5",
         "89",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes a grounded abstract model formulation with a dynamic preserving abstraction. This abstract state representation (and model) guarantees not only accurate future predictions but also the bounded values in the abstracted rollouts. This paper then provides its implementation using contrastive learning to maximize mutual information between the future state, and the current abstract state and option. The results show that training DDQN in imagination using the abstract model improves the sample efficiency. * The paper proposes a solid foundation of the abstract model that preserves dynamics and values.\n\n* The paper is well written.\n\n* The visualization in Figure 3 clearly shows that the abstract state representations focus on important features in the original observation space. * The main focus of the paper is to show the efficiency of planning and learning when using the proposed abstract MDP. The experiments in the paper are a bit simple to showcase the benefits of the abstract model for planning. It would be stronger if the experiment was done in more complex environments with much longer-horizon tasks, such as AntMaze experiments (Hafner 2022) or robotic manipulation tasks \\[a\\].\n\n* Similarly, the comparisons in Figure 5 are essentially between model-free RL (ground) and model-based RL (abstract), which does not seem fair. It might be fair to compare the proposed method with other model-based RL approaches, such as Dreamer and TD-MPC.\n\n* Exhaustive comparisons to the alternatives to the dynamics preserving abstraction would be interesting, such as bisimulation.\n\n* Some highly relevant works on temporally-extended models \\[a,b\\] are missing in the paper. Proper comparisons to these approaches are necessary.\n\n\\[a\\] Shi et al. Skill-based Model-based Reinforcement Learning. CoRL 2022\n\n\\[b\\] Zhang et al. Leveraging Jumpy Models for Planning and Fast Learning in Robotic Domains. 2023 Please address the weaknesses mentioned above.\n\n\n### Minor questions and suggestions\n\n* Figure 1 may want to explain why abstract state representations and options are helpful for planning and learning. However, Figure 1 does not seem to help understand the paper. To understand this figure, we first need to know about options and abstract state representations, and how they simplify planning.\n\n* In Section 4.2, it is unclear whether $\\mathcal{L}^T_{\\theta, \\phi}$ is used to update $f_\\phi$ or not.\n\n* For multi-goal experiments in the paper, using the same amount of environment steps for the abstract planning and the ground baseline would make it easier to understand how better or worse a method is.\n\n* The appendix could be included in the main paper for easier navigation.\n\n* What is the difference between Figure 7 and 8?\n\n* Training the abstract planning method longer in Figure 7 and 8 would be helpful to see how it learns. Using different x-scales for two methods is okay but it would be better to have the same scale.\n\n* Many minor typos in the paper.\n\n\n---\n\nThank you for author responses. I would love to see comparisons to Dreamer-like baselines, but couldn't find the results by the end of the rebuttal period. Thus, I keep my rating, borderline reject.",
         "['~Rafael_Rodriguez-Sanchez1', '~George_Konidaris1']",
         "1701585748243",
         "5.0",
         "3.0",
         "2.0",
         "3.0",
         "3.0",
         "507",
         "0",
         "3",
         "0.7684000000000001",
         "0.1385185185",
         "0.9183520675",
         "71",
         "48.6501",
         "0.8246",
         "iclr",
         "0.0",
         "4",
         "5",
         "5",
         "4",
         "factual",
         "4",
         "5",
         "89",
         "polite",
         "4",
         "positive",
         "4",
         "none",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "43",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-xxEb",
         "2",
         "3",
         "partially factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "3",
         "3",
         "4",
         "4",
         "50",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper introduces a novel model, PatchSynth, in the Patch-Text Pre-training (PTP) domain, aiming to improve software patch representation and description generation. Through a blend of patch understanding and generation, PatchSynth\t addresses the limitations of prior models. Empirical evaluations reveal its superior performance in patch description generation, with an ablation study further underscoring the importance of generating task training. Novelty and Importance: The work is first to propose a unimodel for patch-text understanding and related tasks. And the topic is very important in this domain.\n\n\tMelds patch understanding and generation, addressing prior models' specialization limitations.\n\n\tThe work provides a good representation and good results Unclear adaptability across diverse programming languages or coding standards. What are the considerations for deploying PatchSynth in real-world software development environments, and what infrastructure would be required for efficient and secure operation?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319846",
         "8.0",
         "5.0",
         "4.0",
         "3.0",
         "4.0",
         "136",
         "0",
         "0",
         "0.7967000000000001",
         "0.30636363640000003",
         "0.944865346",
         "50",
         "11.6712",
         "0.0364",
         "iclr",
         "0.0",
         "3",
         "4",
         "2",
         "3",
         "partially factual",
         "3",
         "3",
         "50",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "2",
         "3",
         "3",
         "2",
         "factual",
         "4",
         "3",
         "60",
         "polite",
         "4",
         "positive",
         "4",
         "moderate",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "44",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-4kdr",
         "4",
         "3",
         "factual",
         "neutral",
         "polite",
         "low",
         "3",
         "3",
         "4",
         "4",
         "4",
         "4",
         "65",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper discusses a new model, PatchSynth, in the domain of Patch-Text Pre-training (PTP) which aids in accurate patch representation for software evolution tasks like bug fixing and feature enhancement. PatchSynth is designed to balance patch understanding and generation, overcoming limitations of previous models. It outperforms existing models in patch description generation, as shown in experiments using standard evaluation metrics. An ablation study further reveals the importance of generating task training in improving PatchSynth performance. Novelty:\nThe novelty of PatchSynth lies in its harmonious synthesis of patch understanding and generation, coupled with an advanced synthetic description generator. This innovative approach addresses the historical challenges of accurate patch representation and description generation, marking a significant stride in the PTP paradigm.\nImportance:\nThe topic is of paramount importance as it addresses a critical need in software engineering for accurate patch representation and description, which are pivotal for collaborative development, systematic documentation, and rapid code review processes. By advancing the PTP paradigm, PatchSynth not only contributes to the academic discourse but also holds promise for practical applications in software development workflows.\nThe work achieves promising results. The paper doesn't elucidate how PatchSynth adapts to varying programming languages or codebases with differing coding standards and structures. This lack of demonstrated adaptability could limit its applicability across diverse software projects, potentially requiring additional tuning or re-training to maintain accuracy and effectiveness in different environments. 1. Given the advancements in PatchSynth for patch-text understanding and generation, how well does the model perform in a transfer learning scenario? Can PatchSynth be fine-tuned or adapted effectively to related tasks in software engineering or different programming languages?\n2. Are there considerations or plans for deploying PatchSynth in real-world software development environments? How would the integration look like, and what kind of support or infrastructure would be required to ensure the model operates efficiently and securely in a production setting?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319768",
         "10.0",
         "5.0",
         "4.0",
         "4.0",
         "4.0",
         "310",
         "0",
         "2",
         "0.8356",
         "0.18839531680000002",
         "0.9401642680000001",
         "50",
         "9.2899",
         "0.068",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "88",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "5",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "45",
         "141",
         "Mohammad-Hossein-Saliminabi",
         "Reviewer-H6rR",
         "4",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "3",
         "4",
         "4",
         "4",
         "2",
         "80",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "This paper tackles the problem of code patch representation learning -- how to represent edits on code to support downstream tasks like commit message generation, patch correctness assessment, etc. \n\nThis paper proposes a pretraining framework, with triplet losses on text-code contrastive loss, text-code matching loss and text generation loss based on code patch. The pretraining data includes 90K pairs of code change and synthesized commit messages. \n\nOn downstream task of commit message generation upon FIRA\\[1\\] dataset, PatchSynth showed performance gains over public & self-ablation baselines.\n\n\\[1\\] Jinhao Dong, Yiling Lou, Qihao Zhu, Zeyu Sun, Zhilin Li, Wenjie Zhang, and Dan Hao. Fira: Fine-grained graph-based code change representation for automated commit message generation. 2022. 1. Unlike from previous approaches(CCRep\\[1\\], Cache\\[2\\]) where code change is encoded with two streams (code-before-change, code-after-change), this work encodes code change(patch) with a standard transformer on a single patch file (like git commit diff). This is inline with the general trend in LLMs community that ultimately LLMs should be able to understand and capture internal structure without explicitly modelling it.\n2. This paper applies representation pretraining with triplet losses -- which is quite known in multimodal pretraining domain (BLIP\\[3\\], BLIP-2\\[4\\], etc) -- to code patch representation. It empirically showed that such pretraining is helpful for downstream task of commit message generation.\n\n\n\\[1\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[2\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022.\n\n\\[3\\] Junnan Li, Dongxu Li, Caiming Xiong, & Steven C. H. Hoi (2022). BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. In ICML (pp. 12888–12900). PMLR.\n\n\\[4\\] Junnan Li, Dongxu Li, Silvio Savarese, & Steven C. H. Hoi (2023). BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models. In ICML (pp. 19730–19742). PMLR. I have multiple major concerns on the paper based on its current form. The most concerning issues are:\n\n1. The paper claims \"The core part of PATCHSYNTH lies a state-of-the-art synthetic description generator\" in multiple places (3rd paragraph of Introduction, 2nd contribution in last part of Introduction, Section 2.3). However, there is no details on this synthetic description generator. The only mention is Section 4.4 with just one line \"Capitalizing on benchmarks from seminal works\\[1,2\\], our dataset, primarily focused on Java samples includes 90,661 patches with their **attendant** descriptions\"\n\n    i. Are these **attendant** descriptions generated by the author but simply taken from \\[1,2\\]? If the latter, then claiming such synthetic description generation as a key feature in this paper is highly problematic.\n\n2. The task of representation learning of code patch, defaultly assigns 1 vector for a code patch (w/ 1 or more edits), which is the case for all previous works including CC2Vec\\[3\\], CCRep\\[4\\], Cache\\[5\\]. However, PATCHSYNTH seems to encode the code patch to a sequence of vectors (Figure 1). \n\n    i. Such change needs explicit explanation and justification which authors have failed to deliver.\n\n3. Missing LLM baselines: with code patch being encoded with a sequence of vectors, the authors should compare with code-aware LLMs like Code-llama, or WizardCoder, as they also encode code patch to a sequence of vectors. \n    \n    i. As the recent code-aware LLMs have shown great abilities in general instruction following in coding-related tasks, a very timely baseline would be applying code-aware LLMs to the downstream task of commit message generation, with few-shot prompting or finetuning. \n\n    ii. A comparison of PATCHSYNTH vs code-aware LLMs would very helpful for the community to understand the edge and relevance of the proposed method in LLM era, which the authors have failed to deliver.\n\n4. Only 1 downstream task evaluated: The authors claimed that the method is designed both for generative and discriminative tasks. However, the empirical experiments were only conducted on commit message generation. As the encoding changed from one vector to a sequence of vectors, it's important to show how can such encoding can be adapted to tackle retrieval or classification tasks. Also, to claim it as a pretrain model, the authors need to evaluate on multiple downstream datasets.\n\n5. Fairness in comparison: \n\n    i. Is PATCHSYNTH firstly pretrained on 90K and then finetuned on 75K data of FIRA? If so, it's not so fair to compare PATCHSYNTH with CCRep and FIRA methods, as they are not trained on 90K pretraining data. For example, Is it possible to also pretrain CCRep with 90K data?\n\n    ii. As mentioned in point 2, CCRep has a more compact encoding of 1 vector while PATCHSYNTH encodes to a sequence of vectors. It is thus not fair to compare without explicitly mentioning such differences.\n\n6. Concerns on Pretraining:\n\n    i. details of creating negative pairs: one common technique in contrastive training is hard-negative-mining. However, the authors didn't disclose how they create negative pairs\n\n    ii. For vision-language representation learning, a large batch size (>= 512) and a large pool to select negative examples have been shown to be necessary. This paper mentions the batch size of 32, which seems pretty small. I will need more verification on ablation of 1) batch size, 2) negative example selection and 3) pretraining metrics to be convinced that such setting is adequate for code-text representation pretraining. \n\n7. Writing & formatting issues\n\n    i. On page 8, the chart of Figure 2 is partially blocked by its top legend\n\n    ii. On page 8, the paragraph for \\[Performance cross different patch attention\\] is repetitive: it repeats twice in introducing the numerical performance. Besides, I don't think it's a good idea to verbosely list down all numbers when they are clearly seen in Figure 2.\n\n    iii. In Section 2.1, there's no mention on recent code aware LLMs like Code-LLaMA. \n\n    iv. In Section 2.3, there's no citation to any work. Besides, CCRep\\[4\\] doesn't have the gap mentioned in Section 2.3 as it can both do discriminative and generative tasks and it doesn't reply on AST information. So an explicit comparison to CCRep in Related Work should be present.\n\n\\[1\\] Robert Dyer, Hoan Anh Nguyen, Hridesh Rajan, and Tien N Nguyen. Boa: A language and infras\u0002tructure for analyzing ultra-large-scale software repositories. In 2013 35th International Confer\u0002ence on Software Engineering (ICSE), pp. 422–431. IEEE, 2013.\n\n\\[2\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[3\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[4\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[5\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022. 1. Why did you use CodeBERT to initiate both text encoder and decoder? For example, did you consider encoder-decoder model like Code-T5?\n\n2. In Experiment Setup, you mentioned \"Model dimensions are meticulously calibrated\". May I know how are the hyper-parameters searched? Are you using the downstream task performance or some pretraining metrics?",
         "['~Xunzhu_Tang1', '~Zhenghan_Chen3', '~Saad_Ezzini1', '~Haoye_Tian2', '~Jacques_Klein1', '~Tegawendé_F._Bissyandé1']",
         "1699636319680",
         "3.0",
         "4.0",
         "1.0",
         "1.0",
         "2.0",
         "1254",
         "27",
         "37",
         "0.7999",
         "0.069050849",
         "0.8986387253",
         "50",
         "47.6556",
         "0.1651",
         "iclr",
         "0.0",
         "4",
         "2",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "1.0",
         "4.0",
         "3.0",
         "4.0",
         "partially factual",
         "2.0",
         "3.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "4.0",
         "moderate",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "4",
         "5",
         "90",
         "neutral",
         "5",
         "negative",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "85",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "46",
         "28",
         "Muhan",
         "Reviewer-xyNq",
         "3",
         "4",
         "factual",
         "neutral",
         "polite",
         "moderate",
         "4",
         "4",
         "3",
         "3",
         "4",
         "5",
         "60",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper considers the problem of certifying individual fairness (IF), which is of great importance to reliable machine learning algorithms. To this end, the authors propose a novel convex relation of IF constraints that greatly reduces the computational cost. In addition, the authors propose to certify distributional individual fairness, ensuring that the neural network has guaranteed individually fair predictions for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball. 1. This paper is technically sound.\n2. The extensive experiments validate the effectiveness of the proposed methods. The paper studies individual fairness and distributional fairness. To my opinion, the two topics seem to be independent. However, it is possible that I misunderstand this paper. It would be better if the authors can present more relations between these topics. ## Miscellaneous\n1.\tLine 106: feed forward $\\to$ feedforward\n2.\tLine 168: $d$ is indeed a vector; however, the denotation $\\sqrt{d}$ should be defined more specifically.\n none",
         "['~Matthew_Robert_Wicker1', '~Vihari_Piratla1', '~Adrian_Weller1']",
         "1702411365184",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "2.0",
         "156",
         "0",
         "5",
         "0.8035",
         "0.28125",
         "0.9500498772",
         "215",
         "29.3366",
         "0.1213",
         "neurips",
         "0.0",
         "3",
         "5",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "60",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "5",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "47",
         "28",
         "Muhan",
         "Reviewer-Lpfq",
         "5",
         "5",
         "factual",
         "neutral",
         "polite",
         "none",
         "5",
         "5",
         "5",
         "5",
         "5",
         "5",
         "95",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper studies formal guarantees for notions of individual fairness (IF) for predictors given by neural network models. After relaxing common definitions for IF metrics by means of $\\ell_\\infty$ balls (or orthotopes), they adapt methodology based on adversarial robustness to provide upper and lower bounds to the IF achieved by models on an empirical sample - and those within a $\\gamma-$Wasserstein ball about it. - This paper studies an important problem of individual fairness\n- The first half of the paper, Section 3 and 4, which cover Background, the DIF definition, and problem explanation are very clear and easy to understand. - The key observation and novelty in the approach is not clearly noted (See below)\n- Several of the nice advantages of their method (e.g efficiency) are not explained (see below). 1. Numerous times in the paper the authors say their bounds are ”efficient” because they leverage efficient methods (e.g. those based on bound propagation). While that may be true, it would be nice for the readers if they provided a brief explanation as to why these methods are efficient instead of placing everything in the appendix. \n2. It seems to me that the central novelty of this paper is to upper bound a mahalanobis metric (for $d_{fair}$) with an orthotope, which is quite simple. The remaining of the paper seems to me a direct application of results and methods in adversarial robustness. While I do appreciate the observation of being able to use those tools in the context of fairness - which also constitutes novelty - I would appreciate if the authors could be very clear about what are the main technical contributions of this work.\n3. Personally, I am not sure providing a section on the impact of these methods on group fairness is necessary. I’d much rather prefer a discussion on the efficiency of the bounds.\n4. Figure 1 is quite confusing. What makes the blue-star individuals likely? As presented, those blue-star points do not look likely. If I understand the figure correctly, the authors should present a more balanced empirical sample together with a larger sample representing the (unobserved) population. \n5. I also have problems with the fact that the authors state their goals and present their definitions in terms of expectation (e.g. as in Def 2), but simply restrict themselves to studying empirical samples. I think the presentation is misleading, because nowhere the authors really provide guarantees for the definition in Def 2 (that is, risk bounds). This is also an important limitation where the study the Wasserstein distance between distributions, as they simply regard their distribution as a one supported on Dirac functions (on the observed samples). \n6. Immediately after Eq (4), the authors write that “we can optimize this bound to be tight”. I don’t think this is correct: while they can indeed optimize the bound, there’s no guarantee that the bound will be tight, as the original problem is non-concave.\n7. In Section 5.4 and after presenting $\\mathcal L_{F-DIF}$, the authors mention when $\\gamma=0$, one recovers a local constraint on individual fairness on $x\\in X$. I don’t think this is completely accurate, because again, Def. 2 is defined in expectation of $x\\sim p(x)$, not simply over the empirical sample. The authors mention that they do not foresee negative societal impacts. Maximizing upper and lower bounds is great but in doing so we don’t really know what is happening to the true fairness violation. It may be that the true fairness violation is in fact increasing which is propagating unfairness. While I understand that solving for this value is not feasible and thus appreciate the results presented, I would also like the paper to acknowledge that there are potential negative effects.",
         "['~Matthew_Robert_Wicker1', '~Vihari_Piratla1', '~Adrian_Weller1']",
         "1702411365091",
         "6.0",
         "4.0",
         "3.0",
         "3.0",
         "3.0",
         "619",
         "0",
         "7",
         "0.7891",
         "0.1001929392",
         "0.9119418859",
         "215",
         "46.7646",
         "0.6521",
         "neurips",
         "0.0",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "48",
         "28",
         "Muhan",
         "Reviewer-FRnw",
         "3",
         "4",
         "factual",
         "negative",
         "neutral",
         "high",
         "4",
         "3",
         "4",
         "3",
         "3",
         "4",
         "60",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper studies the problem of individual fairness in supervised learning. The focus is on studying how to certify distributional individual fairness (IF) (individual fairness over a set of distributions close to the observed empirical data distribution) in neural networks. Prior work has focused largely on certifying global IF, which is more expensive and thus can only be applied to smaller neural networks than the proposed certification/debiasing technique. The contributions of the paper are in showing how to certify distributional IF in neural networks and then using these bounds in the training process as regularizers to debias NNs. \n\nThe main methodology for certifying IF is presented in Section 5. The first step is to certify local IF by over-approximating the similarity ball to find a conservative estimate of the IF violation. They can then use this bound to certify distributional IF around the empirical data distribution and apply finite sample guarantees to give an estimate of the true distributional IF. \n\nThe authors then show how to use the bounds on distributional fairness as regularizers in the training procedure as a way to debias neural networks. They then provide experimental evaluation on a few benchmark datasets that demonstrates that their proposed training method indeed improves distributional individual fairness, at relatively modest degradations in accuracy.  The main advantage is a relatively lightweight way to certify and train NNs for IF, in a way that requires little additional computation, compared to previous methods which are not able to scale to large NNs. \n\nThe experimental evaluation seems to confirm that DIF training as proposed by the regularization method does in fact improve significantly improve IF at modest degradation in classification accuracy.  Section 5 is a little dense and it would be helpful for the reader if there was a little more discussion of the optimization procedure, particularly in Section 5.3. Theorem statements here might also be helpful for the reader to understand what the final guarantees are.  What is the purpose of Table 2? It is a little difficult to interpret the punchline - it just seems to indicate that DIF training does not have a consistent effect on group fairness measures, either positively or negatively.  -",
         "['~Matthew_Robert_Wicker1', '~Vihari_Piratla1', '~Adrian_Weller1']",
         "1702411364954",
         "7.0",
         "3.0",
         "3.0",
         "2.0",
         "3.0",
         "363",
         "0",
         "1",
         "0.7939",
         "0.0286027569",
         "0.9569676518",
         "215",
         "26.5652",
         "0.0354",
         "neurips",
         "0.0",
         "4",
         "4",
         "3",
         "3",
         "factual",
         "3",
         "4",
         "60",
         "neutral",
         "3",
         "negative",
         "4",
         "high",
         "4",
         "4",
         "4",
         "5",
         "5",
         "5",
         "5",
         "85",
         "5",
         "5",
         "neutral",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "49",
         "41",
         "Emperatoor",
         "Reviewer-viiH",
         "3",
         "5",
         "factual",
         "neutral",
         "polite",
         "none",
         "3",
         "4",
         "2",
         "2",
         "3",
         "4",
         "60",
         "Contrastive Retrospection: honing in on critical steps for rapid learning and generalization in RL",
         "In real life, success is often contingent upon multiple critical steps that are distant in time from each other and from the final reward. These critical steps are challenging to identify with traditional reinforcement learning (RL) methods that rely on the Bellman equation for credit assignment. Here, we present a new RL algorithm that uses offline contrastive learning to hone in on these critical steps. This algorithm, which we call Contrastive Retrospection (ConSpec), can be added to any existing RL algorithm. ConSpec learns a set of prototypes for the critical steps in a task by a novel contrastive loss and delivers an intrinsic reward when the current state matches one of the prototypes. The prototypes in ConSpec provide two key benefits for credit assignment: (i) They enable rapid identification of all the critical steps. (ii) They do so in a readily interpretable manner, enabling out-of-distribution generalization when sensory features are altered. Distinct from other contemporary RL approaches to credit assignment, ConSpec takes advantage of the fact that it is easier to retrospectively identify the small set of steps that success is contingent upon (and ignoring other states) than it is to prospectively predict reward at every taken step. ConSpec greatly improves learning in a diverse set of RL tasks. The code is available at the link: https://github.com/sunchipsster1/ConSpec",
         "This paper proposes contrastive introspection (ConSpec), an algorithm for learning a set of prototypes for critical states via the contrastive loss. ConSpec works by delivering intrinsic rewards when the current states match one of the prototypes. This paper also conducted experiments in various environments. The intuition of learning the critical states is natural and easy to follow. The experimental results in this paper look solid and promising. Despite the empirical performance, the reviewer finds the ConSpec algorithm itself hard to follow.\n\nThe largest weakness is: the insufficient discussion on how the prototypes $h_i$ are learned. Hence, the reviewer cannot understand the detailed on how $h_i$ are used (see detailed in Questions). \n\nBesides insufficient discussion on the prototypes, some minor issues are: (1) the title in the pdf (Contrastive Introspection:. ..) seems to mismatch with the one appear in openreview (ConSpec: …). (2) The font of citations appears to be confusing. E.g., from line 19-20 in the introduction, the manuscript uses (number) to address some key points, and the citation also appears as (number) – it would be nice if the citation can be changed to something that is not (number; number).\n Per the major weaknesses:\n1. How are the prototypes $h_i$ actually learned? If the reviewer understands correctly, in line 7 of the abstract, the manuscript says “ConSpec learns a set of prototypes…”. While in Algorithm 1, it seems that the prototypes $h_i$ are given to the algorithm as inputs. Maybe the author can clarify why this inconsistency in learning the prototypes happens?\n2. How are the $h_i$ learned/chosen in each experiment? The reviewer has looked into the detail of the experiments in the appendix, but cannot clearly understand how the presented experiments actually utilize the $h_i$. It would be nice that the authors can provide more details of all the $h_i$ in all the present experiments (Sec. 4.1-4.5).  \n See questions and weaknesses.",
         "['~Chen_Sun7', '~Wannan_Yang1', '~Thomas_Jiralerspong1', '~Dane_Malenfant1', '~Benjamin_Alsbury-Nealy1', '~Yoshua_Bengio1', '~Blake_Aaron_Richards1']",
         "1702411045803",
         "6.0",
         "3.0",
         "3.0",
         "3.0",
         "3.0",
         "313",
         "0",
         "2",
         "0.7000000000000001",
         "0.0809294872",
         "0.8764749765000001",
         "216",
         "48.5775",
         "0.0354",
         "neurips",
         "0.0",
         "2",
         "4",
         "3",
         "2",
         "factual",
         "4",
         "3",
         "60",
         "polite",
         "3",
         "neutral",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "78",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ]
       ],
       "shape": {
        "columns": 102,
        "rows": 395
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>assessor</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>Comprehensiveness</th>\n",
       "      <th>Usage_of_Technical_Terms</th>\n",
       "      <th>Factuality</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Politeness</th>\n",
       "      <th>Vagueness</th>\n",
       "      <th>Objectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>Phi_Constructiveness</th>\n",
       "      <th>Phi_Factuality</th>\n",
       "      <th>Phi_Fairness</th>\n",
       "      <th>Phi_Objectivity</th>\n",
       "      <th>Phi_Overall_Quality</th>\n",
       "      <th>Phi_Politeness</th>\n",
       "      <th>Phi_Relevance_Alignment</th>\n",
       "      <th>Phi_Sentiment_Polarity</th>\n",
       "      <th>Phi_Usage_of_Technical_Terms</th>\n",
       "      <th>Phi_Vagueness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-7mFW</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-FAWm</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Sajad-Ebrahimi</td>\n",
       "      <td>Reviewer-kjkr</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Enrico-Daga</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Seyed</td>\n",
       "      <td>Julia-Bosque</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>factual</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>114</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Reviewer-n4fn</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-wEMM</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>negative</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-s437</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-mMGf</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>negative</td>\n",
       "      <td>polite</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>75</td>\n",
       "      <td>Ali-Ghorbanpour</td>\n",
       "      <td>Reviewer-v6cq</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>moderate</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id         assessor       reviewer  Comprehensiveness  \\\n",
       "0         166   Sajad-Ebrahimi  Reviewer-7mFW                  2   \n",
       "1         166   Sajad-Ebrahimi  Reviewer-FAWm                  4   \n",
       "2         166   Sajad-Ebrahimi  Reviewer-kjkr                  3   \n",
       "3         100            Seyed    Enrico-Daga                  3   \n",
       "4         100            Seyed   Julia-Bosque                  5   \n",
       "..        ...              ...            ...                ...   \n",
       "390       114             Sara  Reviewer-n4fn                  3   \n",
       "391        75  Ali-Ghorbanpour  Reviewer-wEMM                  3   \n",
       "392        75  Ali-Ghorbanpour  Reviewer-s437                  3   \n",
       "393        75  Ali-Ghorbanpour  Reviewer-mMGf                  4   \n",
       "394        75  Ali-Ghorbanpour  Reviewer-v6cq                  2   \n",
       "\n",
       "     Usage_of_Technical_Terms         Factuality Sentiment_Polarity  \\\n",
       "0                           4            factual            neutral   \n",
       "1                           4            factual            neutral   \n",
       "2                           4            factual            neutral   \n",
       "3                           2            factual           positive   \n",
       "4                           4            factual           positive   \n",
       "..                        ...                ...                ...   \n",
       "390                         4            factual            neutral   \n",
       "391                         4            factual           negative   \n",
       "392                         3  partially factual            neutral   \n",
       "393                         4            factual           negative   \n",
       "394                         3  partially factual           positive   \n",
       "\n",
       "    Politeness Vagueness  Objectivity  ...  Phi_Constructiveness  \\\n",
       "0       polite      high            4  ...                     4   \n",
       "1       polite      none            4  ...                     4   \n",
       "2       polite       low            4  ...                     4   \n",
       "3       polite      none            4  ...                     4   \n",
       "4       polite       low            4  ...                     5   \n",
       "..         ...       ...          ...  ...                   ...   \n",
       "390     polite       low            3  ...                     4   \n",
       "391     polite       low            3  ...                     3   \n",
       "392     polite       low            2  ...                     4   \n",
       "393     polite      none            4  ...                     4   \n",
       "394     polite  moderate            3  ...                     3   \n",
       "\n",
       "        Phi_Factuality  Phi_Fairness  Phi_Objectivity  Phi_Overall_Quality  \\\n",
       "0    partially factual             3                4                   75   \n",
       "1    partially factual             4                4                   85   \n",
       "2    partially factual             4                3                   78   \n",
       "3              factual             4                4                   85   \n",
       "4              factual             5                5                   95   \n",
       "..                 ...           ...              ...                  ...   \n",
       "390  partially factual             3                3                   75   \n",
       "391  partially factual             3                3                   65   \n",
       "392            factual             4                4                   85   \n",
       "393  partially factual             4                4                   85   \n",
       "394  partially factual             4                3                   75   \n",
       "\n",
       "     Phi_Politeness Phi_Relevance_Alignment Phi_Sentiment_Polarity  \\\n",
       "0            polite                       5                neutral   \n",
       "1            polite                       5                neutral   \n",
       "2           neutral                       5               negative   \n",
       "3            polite                       5               positive   \n",
       "4            polite                       5               positive   \n",
       "..              ...                     ...                    ...   \n",
       "390          polite                       4                neutral   \n",
       "391         neutral                       4               negative   \n",
       "392          polite                       5                neutral   \n",
       "393          polite                       5                neutral   \n",
       "394          polite                       4               positive   \n",
       "\n",
       "    Phi_Usage_of_Technical_Terms Phi_Vagueness  \n",
       "0                              4           low  \n",
       "1                              3           low  \n",
       "2                              5           low  \n",
       "3                              3           low  \n",
       "4                              4           low  \n",
       "..                           ...           ...  \n",
       "390                            4           low  \n",
       "391                            4           low  \n",
       "392                            5           low  \n",
       "393                            3           low  \n",
       "394                            4           low  \n",
       "\n",
       "[395 rows x 102 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = (\n",
    "    df_human_vs_metric\n",
    "    .merge(df_human_vs_llm, on=['paper_id', 'reviewer'], how='inner')\n",
    ")\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hedging",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Human_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Actionability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Clarity_and_Readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Comprehensiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Constructiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Fairness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Objectivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Overall_Quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Relevance_Alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Usage_of_Technical_Terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Vagueness",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c149e9e9-44f6-41d3-a9d9-e5baa0be8842",
       "rows": [
        [
         "0",
         "166",
         "Reviewer-7mFW",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This work focuses on the Q-function value overestimation issue. Observing that the overestimation issue will latter becomes underestimation during the learning process. Thus motivated, this work proposes the Blended Exploitation and Exploration (BEE) operator to take advantage of the historical best-perforation actions. The proposed operator is then used in both model-free and model-based settings and show better performance than previous methods. 1. The proposed BEE operator utilizes the Bellman exploitation operator and exploration operator to address the under-exploitation issue. The proposed operator can be easily incorporated into the RL algorithms.\n2. The experiments show that the proposed operator can effectively reduce the estimation error and achieve better performance comparing with other RL algorithms. 1. The terminology can be misleading. The overestimation issue in the Q-value approximation generally is due to the changing order of expectation and $\\max$. It is incorrect to say that  the $Q$-function will have \"underestimation when encountering successes\" in Fig 1 (a). The authors need to clarify the context and difference of the statement in order to avoid confusion.\n2. In order to investigate on the under-exploitation, the metric $\\Delta(\\cdot,\\cdot)$ is defined on the current Q-function approximation. Intuitively,   $\\Delta(\\cdot,\\cdot)$ shows that the current Q-function approximation can be either overestimate or underestimate given different policy, i.e., $\\mu_k$ and $\\pi_k$. It is unclear what is the meaning of this metric. Considering most of the algorithm will update the policy and Q-function approximation at the same time, e.g., Actor-Critic, the Q-function should be evaluated under the current policy instead of the policy obtained earlier. The authors need to clarify why the definition here makes sense for the under-exploitation investigation. See the weakness above.",
         "273",
         "0",
         "5",
         "0.7173",
         "0.12450980390000001",
         "0.8775630593",
         "49",
         "22.7412",
         "0.0999",
         "iclr",
         "0.0",
         "4",
         "4",
         "2",
         "3",
         "factual",
         "4",
         "4",
         "67",
         "polite",
         "4",
         "neutral",
         "4",
         "high",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "partially factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "neutral",
         "4",
         "moderate",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "1",
         "166",
         "Reviewer-FAWm",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This paper presents the Blended Exploitation and Exploration (BEE) operator, which addresses the issue of value underestimation during the exploitation phase in off-policy actor-critic methods. The paper highlights the importance of incorporating past successes to improve Q-value estimation and policy learning. The proposed BAC and MB-BAC algorithms outperform existing methods in various continuous control tasks and demonstrate strong performance in real-world robot tasks. - The paper addresses an important issue in off-policy actor-critic methods and proposes a novel approach to improve Q-value estimation and policy learning. \n- The BEE operator is simple yet effective and can be easily integrated into existing off-policy actor-critic frameworks.\n- The experimental results demonstrate the superiority of the proposed algorithms in various continuous control tasks and real-world robot tasks. 1. The novelty of the proposed approach is limited. \n2. The choice of $\\lambda$ is largely empirical and requires extra manipulation in new tasks.\n3. The paper only provides basic theoretical analysis, such as the accurate policy evaluation and the guarantee of policy improvement. The benefit of linearly combining two Q-value functions is not discussed theoretically.\n4. The experiments are conducted in continuous control tasks with dense rewards. The exploration ability can be better evaluated in environments with sparse rewards.\n5. There is a lack of discussions with related papers (See Question 3). 1. Emprically, the BAC algoithm will only be more efficient in exploiting the replay buffer. The exploration still rely on the maximum-extropy formulation in SAC. Then why can BAC perform significantly better than SAC in failure-prone scenarios such as HumanoidStandup, as if BAC can better explore the unknown regions?\n2. Can you discuss or exhibit the performance of BAC in some tasks with sparse rewards? This can demonstrate the generalizability of the proposed approach.\n3. What are the advantages of BAC compared with prioritized replay methods \\[1,2\\] or advantage-based methods \\[3\\]? These methods are related to BAC in that they also exploit the replay buffer with inductive bias, so they should be mentioned in the paper.\n\n\\[1\\] Sinha, S., Song, J., Garg, A. &amp; Ermon, S.. (2022). Experience Replay with Likelihood-free Importance Weights. Proceedings of The 4th Annual Learning for Dynamics and Control Conference.\n\n\\[2\\] Liu, X. H., Xue, Z., Pang, J., Jiang, S., Xu, F., & Yu, Y. (2021). Regret minimization experience replay in off-policy reinforcement learning. Advances in Neural Information Processing Systems, 34, 17604-17615.\n\n\\[3\\] Nair, A., Gupta, A., Dalal, M., & Levine, S. (2020). Awac: Accelerating online reinforcement learning with offline datasets. arXiv preprint arXiv:2006.09359.\n\n\nI am willing to raise my score if my concerns for weaknesses and questions are adequately discussed.",
         "432",
         "8",
         "14",
         "0.7996000000000001",
         "0.1588311688",
         "0.8829935789000001",
         "60",
         "31.9755",
         "0.1565",
         "iclr",
         "0.0",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "86",
         "polite",
         "5",
         "neutral",
         "4",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "2",
         "166",
         "Reviewer-kjkr",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "Motivated by the problem of underestimating values in the training of SAC, this paper introduces the Blended Exploitation and Exploration (BEE) operator, which calculates the TD target based on a combination of the standard TD target and a high expectile of the return distribution. The authors integrate this operator in both model-free and model-based scenarios, followed by a comprehensive experimental evaluation. 1. The paper contains extensive experiment results on both simulation and real-world environments.\n2. The paper is written clearly and easy to follow. Figure 1 provides a decent visualization of the underestimation issue. 1. The BAC method tunes its $\\lambda$ and $\\tau$ differently for tasks in MuJoCo and DMC (Table 1 & 5). It's questionable to claim superiority over other state-of-the-art (SOTA) methods like SAC and TD3, which use consistent hyperparameters (HP) across tasks. Adjusting HP for each task can inflate results as seen in Figure 5, which can be misleading. Why not showcase the automatic $\\lambda$ tuning methods from Appendix B.3.3 in the main text if they're effective?\n\n2. Figure 23 reveals that SAC, without the double-Q-trick, still underestimates in the Humanoid task. It's unclear if this is universally true. More convincing results would come from testing this across multiple tasks and providing absolute Q value estimates. I still suspect that Q underestimation largely stems from the double Q techniques, as suggested by the RL community \\[1\\]. For instance, OAC \\[1\\] introduces $\\beta_{\\text{LB}}$ to manage value estimation issues.\n\n3. Presuming the Q value underestimation problem is widely recognized (which I invite the authors to contest), the paper seems to lack innovation. The BEE operator, at its core, appears to be a fusion of existing Bellman operators.\n\n4. The statement \"BEE exhibits no extra overestimation\" seems conditional on specific $\\lambda$ and $\\tau$ values. For instance, using $\\lambda = 1$ and $\\tau = 1$ could induce overestimation.\n\n\\[1\\] Ciosek, Kamil, et al. \"Better exploration with optimistic actor critic.\" Advances in Neural Information Processing Systems 32 (2019). See Weakness",
         "328",
         "4",
         "8",
         "0.8027000000000001",
         "0.1464980159",
         "0.8531657457",
         "61",
         "35.3958",
         "0.1507",
         "iclr",
         "0.0",
         "5",
         "5",
         "3",
         "5",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "80",
         "polite",
         "5",
         "negative",
         "5",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "partially factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "3",
         "100",
         "Enrico-Daga",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "The authors have performed significant changes to the content, which significantly improve the article with respect to the previous submission. Following the four SWJ criteria for survey articles, the current version is indeed a good (1) introductory text, targeted at researchers, PhD students, or practitioners, to get started on the covered topic.  The addition of a methodology section gives reasonable justification for (2) how comprehensive and how balanced are the presentation and coverage. However, a few more details about the sources of the survey would be useful, especially if mentioning keywords and phrases used in the search (Scopus? Google Scholar? Microsoft Academia? …). In addition, it is still a bit opaque what is intended with \"refining and balancing the structure of the covered areas\" - end of Section 2. However, I consider these minor issues that can be fixed during the preparation of the camera-ready. Finally, the article is readable and clear (3) and the content is relevant to the community (4).",
         "162",
         "0",
         "1",
         "0.8103",
         "0.1645833333",
         "0.6678649187",
         "60",
         "31.31",
         "0.1149",
         "semanticweb",
         "0.019607843137254943",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "5",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "2",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "4",
         "100",
         "Julia-Bosque",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "I reviewed a previous version of this manuscript, for which I recommended a major revision based on the need for a clearer motivation, scope and limitations of this effort, as well as on the structure and flow of the paper at that time. In this new version the authors have addressed all my highlighted concerns: - The motivation, scope and limitations are clearly defined - The interplay between the different sections is elaborated and illustrated with a workflow diagram that facilitates reading. There are numerous references to this workflow and interlinks between the sections, resulting in a cohesive document. - More context is provided in the introductory paragraphs of each section, and the project in which this effort is carried out is clearly introduced. The relation of each section/topic with respect to the overall topic of the survey is now explicit. - The authors have improved the categorization of tools and approaches. - The tables in the appendix summarize the main approaches, tools and resources surveyed according to the proposed classification.  Taking into account these modifications, I maintain the reasons upon which I based the recommendation for acceptance in terms of the criteria for surveys: - The topic of the paper, at the intersection of humanities and the Semantic Web, is interesting and relevant for the advancement in a line of research which poses numerous challenges. - The quality of writing is good and the survey is well balanced, with a broad coverage encompassing theoretical standpoints and approaches, tools, repositories and datasets. - The granularity and length are also appropriate for the text to serve as an introductory text. Minor comments for improvement: - The authors have provided details on the methodology for the survey, indicating the different stages in the generation and keywords used in literature search. There is no explicit reference to a filtering process after those keyword-based search results, was there any filtering step? If so, which criteria were applied? - In table 3, the included resources diverge in their nature, so the current list groups together LLOD Cloud, Lila Etymological Lexicon, LingHub, and Diachronic semantic lexicon of Dutch, etc. for example. I suggest including a mark here to distinguish which resources are particularly relevant for diachronic analysis, in contrast to general LLOD resources (e.g. Lila Etymological Lexicon vs. LLOD cloud and LingHub). - The authors of [12], referenced on p. 5, mention Lemon (Lexicon Model For Ontologies), and in their diagrams (in Github)  they seem to be using OntoLex-Lemon, not its ancestor. Throughout this survey \"OntoLex-Lemon\" is the term used to refer to the 2016 Specification as the outcome of the W3C Ontology-Lexica Community Group, so for that bib. reference I would recommend to replace the mention of \"Lemon\" with \"OntoLex-Lemon\" for consistency in the whole document. *Typos*: l.19, .p. 19, right column, \"A combined resource like this, allows...\" → remove comma p. 20, l. 1, right column → remove \"(linguistic)\", already covered by the first L in LLOD Appendix tables, Table 4. → word embeddings (add pl. \"s\")",
         "503",
         "1",
         "5",
         "0.7741",
         "0.1697330447",
         "0.8522429466",
         "73",
         "34.66",
         "0.2025",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "87",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "100",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "5",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "4",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "5",
         "100",
         "Thierry-Declerck",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "Not really a lot to add. I see that the revised version of the submission was taking good care of former comments and suggestions. Just a minor point: 1) Ensure that footnotes are always placed after the punctuation signs (for consistency across the paper, se fn 2 and 3 which are not placed consistently). So, very few corrections to do.",
         "60",
         "0",
         "0",
         "0.81",
         "0.058",
         "0.6966200471",
         "105",
         "64.71",
         "0.0548",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "60",
         "polite",
         "3",
         "positive",
         "1",
         "high",
         "5",
         "5",
         "2",
         "5",
         "factual",
         "5",
         "5",
         "60",
         "polite",
         "5",
         "neutral",
         "2",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "4.0",
         "none",
         "2",
         "4",
         "2",
         "2",
         "factual",
         "4",
         "3",
         "3",
         "polite",
         "3",
         "positive",
         "1",
         "low",
         "1",
         "4",
         "1",
         "1",
         "factual",
         "3",
         "2",
         "35",
         "polite",
         "2",
         "positive",
         "0",
         "high"
        ],
        [
         "6",
         "74",
         "Reviewer-itVg",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "The authors introduced a view sampling strategy for novel view synthesis, grounded in the perspective of causal representation learning. They identified three key metrics to assess sampling performance: the fitting term, the consistency term, and the uniformity term. Additionally, they presented a novel theoretical framework addressing the sampling challenge within NeRF. 1. The introduction of the causal perspective in the view sampling algorithm holds significant potential and could serve as a foundational approach for future research in this domain.\n2. The authors meticulously lay out a comprehensive mathematical framework that not only elucidates the underlying problem but also leads to the derivation of the three pivotal terms central to their methodology.\n3. The paper stands out for its clarity and coherence, ensuring that readers, regardless of their expertise level, can grasp the concepts and findings presented.\" 1. The rationale behind the view-sampling task raises questions. In certain scenarios, acquiring additional view images can be challenging. However, when a substantial number of dense views are already available, the motivation to devise a sampling strategy for training the neural rendering model with sparse views appears insufficient. Specifically, the activeNeRF model's primary objective is to identify the most optimal camera view for capturing the training image, rather than selecting from a plethora of pre-existing images.\n2. The paper's primary contribution seems to be the introduction of a metric or loss function to evaluate the selected views. However, the absence of an ablation study that separately assesses the impact of each of these three terms is a missed opportunity for deeper understanding. As a result, the contribution feels somewhat lacking in depth.\n3. The proposed loss function presents challenges in differentiability with respect to 't'. The sampling proposal, derived from the farthest sampling strategy, may not be the most efficient approach. It appears to demand significant training resources, resulting in elevated training costs. The potential enhancements in model performance might not justify the trade-off in terms of the increased training time and resource allocation. Please see the weakness above.",
         "335",
         "0",
         "6",
         "0.7966000000000001",
         "0.1848602484",
         "0.9041278958000001",
         "52",
         "29.0988",
         "0.1431",
         "iclr",
         "0.009803921568627416",
         "2",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "3",
         "none",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "5",
         "5",
         "75",
         "5",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "7",
         "74",
         "Reviewer-bNPg",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies the view sampling strategies of Nerf reconstruction from a causal perspective. The authors try to solve the problem using a small subset of photos from a total of K potential views, to achieve the best reconstruction. To solve this, the authors propose to use causal represntation learning using loss by Identification Treatment Effect. They propose three terms, a normal fitting term as reconstruction loss, a consistency term to ensure consistency between visible views and invisible views and a uniformity term requires the samples to be distributed evenly. The results show the proposed strategy can provide slightly better reconstruction compared to alternative baselines in the proposed setting. * The paper proposes a novel perspective to study the view sampling problem in volumetric reconstruction using NeRF as an example. This take-away can potentially also generalize other multiview reconstruction algorithms. \n* Given its current setting, the hypothesis is validated on nerf reconstruction datasets, with small improvement compared to its baselines. * The presentation of this paper could be greatly improved. I may not have understand a lot of details correctly given its current presentation. \n  * It is very hard to read without being very familiar with ActiveNeRF and casual representation learning. Have to trace to original papers for more details. This could be added to the preliminary parts. \n  * Too many notations which makes things more complicated than needed. I don't think I found how exactly the loss of consistency term and uniformity term were calculated in (8) at runtime. As I understand, the method should be as simple as calculating the reconstruction loss using different groups of input samples. Provide an algorithm chart of how of how P^{F}, P^{hat}^{CF} and P^{CF} will greatly help. \n  * There are some notations introduced in 4.1 (e.g. P(Y|do(d))) are not explained until 4.2. \n* Overall I am not sure I understand the real-world impact of this paper using the proposed strategy. Maybe I had some misunderstanding in the details given my concern on its presentation. Please correct me if I am wrong here. The goal of this paper to find \"optimal sampling strategy for training set\", \"K_s corresponding photos as sparse sample inputs among K_d total potential views\" is hardly a real problem statement for its real-world use case, which is my biggest concern for this proposed application of causal representation learning. From sampling perspective, we can use all the K_d potential views as long as they are available. As I understand, the evaluation of the counter factual distribution will require using the non-selected but captured images as supervision, which is not how active learning is executed in real-world case. Given this setting, it makes the results also less appealing in contrast to alternative baselines (which learns to predict next-best unknown view) given the fact all images from that particular datasets are used in evaluating the sampling strategy. 1. My major question is around how the clarity of the sampling process in training time. Confirm any places I misunderstood about this paper, as I highlighted in the weakness part. \n2. I am also curious how the views are sampled finally for different groups in the final results. Provide some visualization and discussions about them can be very helpful to guide the view-sampling process in real world applications. I wonder how that indicate the connection of uniformity term and consistency term are correlated to the camera FoV and ray distributions.",
         "566",
         "0",
         "2",
         "0.8138000000000001",
         "0.1125",
         "0.8472209573",
         "52",
         "40.8228",
         "0.33",
         "iclr",
         "0.0",
         "3",
         "3",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "90",
         "polite",
         "4",
         "neutral",
         "3",
         "none",
         "5",
         "4",
         "4",
         "5",
         "partially factual",
         "4",
         "4",
         "65",
         "polite",
         "5",
         "negative",
         "5",
         "moderate",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "neutral",
         "5",
         "neutral",
         "4",
         "moderate",
         "2",
         "2",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "8",
         "194",
         "Reviewer-GDNX",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         ">**Rebuttal:** The provided details satisfy my concerns. I think this paper should be accepted after applying the agreed changes.\n\n>**TL;DR:** **Good paper.** The proposed WTA-CRS algorithm is based on the existing CRS algorithm and is used to reduce activation memory during training. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size. However, WTA-CRS comes with computational overhead, which is discussed and explore. Addressing my concerns and questions would improve my score.\n\nThe paper proposes the WTA-CRS algorithm to reduce the neural networks training activation memory, where the paper claims that activation memory is primary memory bottleneck during training. The WTA-CRS algorithm is an unbiased estimators for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size.\n\nThe WTA-CRS algorithm works by sampling columns and rows to create an unbiased estimation of the original GEMM for the backpropagation. The WTA-CRS algorithm does not alter the neural architecture, and therefore the inference speed is left in tact. The experimental section shows that WTA-CRS outperforms existing prior work and is compatible with existing PEFT techniques. WTA-CRS adds a computational overhead due to sampling, however, WTA-CRS enables training on much larger batch sizes, which results in a 1.2× higher training throughput.\n * **S.1.** The proposed WTA-CRS algorithm tackles an important problem in existing PEFT techniques, which makes LLM PEFT training more accessible to researchers with low resources.\n* **S.2.** The paper provides a theoretical analysis on WTA-CRS.\n* **S.3.** The proposed WTA-CRS algorithm outperform existing algorithms.\n* **S.4.** An anonymized code repository is provided as part of the submission for reproduction .\n  * **W.1.** Popular existing memory efficient training techniques such as tensor rematerialization (gradient checkpointing) \\[2\\]\\[3\\] and ZeRO \\[1\\] are not compared to, although some are partially discussed in Appendix A.\n* **W.2.** The experiments are conducted on single neural network architecture (T5), although the proposed technique does not seem to be confined solely to that setting.\n* **W.3.** It is common practice today to train neural networks at a lower precision (quantization), however, it is not clear whether quantization (16bit) was used. Therefore, there is insufficient proof that the combined noise of WTA-CRS and quantization would be compatible.\n\n\n**Typos.**\n* Line #62: \"Thus\" → \"Thus,\"\n* Line #240: \"mAccording\" → \"According\"\n* Line #297: \"Thus\" → \"Thus,\"\n\n\\[1\\] Ren, J., Rajbhandari, S., Aminabadi, R.Y., Ruwase, O., Yang, S., Zhang, M., Li, D. and He, Y., 2021, July. ZeRO-Offload: Democratizing Billion-Scale Model Training. In USENIX Annual Technical Conference (pp. 551-564).\n\n\\[2\\] Jain, P., Jain, A., Nrusimha, A., Gholami, A., Abbeel, P., Gonzalez, J., Keutzer, K. and Stoica, I., 2020. Checkmate: Breaking the memory wall with optimal tensor rematerialization. Proceedings of Machine Learning and Systems, 2, pp.497-511.\n\n\\[3\\] Beaumont, O., Eyraud-Dubois, L. and Shilova, A., 2021. Efficient combination of rematerialization and offloading for training dnns. Advances in Neural Information Processing Systems, 34, pp.23844-23857. * **Q.1.** In line #43 and Figure 2 it is noted that \"storing activations (or feature maps) is the main memory bottleneck during training\". Does this hold true for all model architectures? What about LLM training where the fine-tuning batch size is usually very small?\n* **Q.2.** Why was the WTA-CRS algorithm compared to the Deterministic top-k from \\[1\\] but not to the Bernoulli-CRS from \\[1\\]? What are the key differences between WTA-CRS and Bernoulli-CRS?\n* **Q.3.** The paper proposes WTA-CRS which sacrifices computation speed at the cost of lower peak memory. There are several existing common approaches (such as gradient checkpointing and DeepSpeed) for general memory efficient training which are compatible with PEFT techniques. Why are these comparisons not explored or detailed in the main paper?\n\n\\[1\\] Adelman, Menachem, Kfir Levy, Ido Hakimi, and Mark Silberstein. \"Faster neural network training with approximate tensor operations.\" Advances in Neural Information Processing Systems 34 (2021): 27877-27889. The limitations are discussed in Appendix A.",
         "669",
         "10",
         "14",
         "0.753",
         "0.09034013610000001",
         "0.8664653897",
         "215",
         "42.5651",
         "0.1507",
         "neurips",
         "0.012820512820512775",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "neutral",
         "4",
         "neutral",
         "5",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "9",
         "194",
         "Reviewer-j1mL",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "In this paper, we propose a new method called WTA-CRS (Winner-Take-All Column Row Sampling) to address the main memory bottleneck issue during training, which arises from storing feature maps. To reduce memory usage during training, we sample the most likely column indices during backpropagation.\n\nFurthermore, \bthey proposed method demonstrates the ability to significantly reduce peak memory usage, by approximately up to 2.7 times, when fine-tuning downstream tasks. It also showcases the potential for higher throughput, enabling more efficient training. 1. The work clearly states its motivation and its solution and is easy to follow.\n2. The authors show that their method reaches comparable performance with backpropagation using the full activation when combined with LoRA.\n3. They also empirically measure throughput gains obtained by increasing batch size, which demonstrates the practical applicability of their method. 1. The paper needs a comparative analysis of other researchs, such as gradient checkpoint/recalculation and CRS, aimed at reducing activation memory during the training phase, as shown in Fig. 6 and Fig. 9.\n2. The paper should include an analysis of the overhead associated with the proposed WTS-CRS method, which involves sampling rows and columns. It is crucial to consider factors such as the computational cost of Equation 3 and any potential effects of lowering on the overall performance. Providing this analysis would enhance the clarity and completeness of the research.\n3. There is a need of analysis on the effectiveness of the proposed approach, WTS-CRS, in distributed training environments such as tensor parallelism or pipeline parallelism.\n4. It seems necessary to conduct performance evaluations on various LLMs of the GPT family, such as LLaMA and OPT. * In Figure 9, it can be observed that the throughput of WTS-CRS is lower than that of full when the batch size is small. Is this due to the overhead caused by lowering?\n* When comparing the training throughput, how does CRS differ from full in terms of throughput?\n* Could the authors include statistics for GPU utilization in their experiments? It would be helpful to analyze the causes of improved performance more thoroughly.\n* Considering that most large models are trained using multiple levels of parallelism, would it be possible to verify results for pipeline parallel, tensor parallel, etc.? Also, it is unclear from the paper whether the data parallelism used was distributed data parallelism or naïve data parallelism. * As previously mentioned, it would be valuable to include additional experimental results for models that are more challenging to quantify, such as GPT-series (OPT, LLaMA). This would enhance the validity and applicability of the proposed method across a broader range of models.\n* Considering that most large-scale models are trained using multiple levels of parallelism, it is important to assess how much the proposed methods, such as pipeline parallelism and tensor parallelism, can increase throughput while taking into account overhead (such as GPU-to-GPU or node-to-node communication), memory reduction, and computational cost. Furthermore, it is not clear from the paper whether the data parallel processing used is distributed data parallelism or naive data parallelism.",
         "506",
         "0",
         "8",
         "0.8129000000000001",
         "0.11685380590000001",
         "0.8539184332",
         "215",
         "31.6518",
         "0.1355",
         "neurips",
         "0.011111111111111072",
         "4",
         "3",
         "4",
         "4",
         "partially factual",
         "3",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "10",
         "194",
         "Reviewer-cMiu",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The authors studied fine-tuning LLMs with limited memory. As the increased scale of current LLMs, the memory cost during fine-tuning is of great importance when adapting the pretrained LLMs to down-streaming tasks. In contrast to the existing work that mainly focus on the number of updated weights, this paper proposed to reduce the number of stored activations, also the inputs to each layer. Given the widely used stochastic gradient descent optimization pipeline, the authors proposed to store a subset of activations that can generate an unbiased gradient estimation. This way, the training memory and the training time decreased significantly. The authors provide both theoretical and experimental analysis on their CRS methods.  - This paper studied an important problem in LLM fine-tuning, i.e., how to fine-tuning LLMs with less memory consumption without increasing the computation cost. The authors provided solid quantitative results to show that the main memory consumption is from storing the intermediate activations. \n- The authors provided a general solution for fine-tuning LLMs under memory constraints. The solution can be applied in most transformer-based network architectures.  \n- The authors provided solid mathematical proof on the unbiased gradient estimation, which is especially encouraged. \n- The extensive experiments on different network architectures showed the efficacy of the methods.\n- The released code can benefit the following researchers studying efficient LLM fine-tuning.  - I am not fully convinced by the comment made in Line241-244, i.e., the methods in the paper is orthogonal to the activation quantization. When activation is quantized into a lower bit width, it is very possible that the number of less important activations will decrease. This way, the selection on the top-k columns in activation matrices with the proposed methods may hurt the training accuracy or convergence. It would be great if the authors can provide some theoretical analysis or experimental results on this combination. Otherwise, it would be necessary to provide some comparison results w.r.t. the activation quantization.\n- It would be great if the authors can discuss the main difference of their paper w.r.t. \\[Randomized Automatic Differentiation, ICLR2021\\].\t  Overall, I think this paper has a relatively high quality in both writing and scientific contribution. Yes",
         "358",
         "0",
         "2",
         "0.7825000000000001",
         "0.1275074405",
         "0.8477004170000001",
         "215",
         "33.3958",
         "0.1262",
         "neurips",
         "0.0",
         "4",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "11",
         "194",
         "Reviewer-ky3t",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The paper's contribution is in proposing a practical, intuitive yet not trivial unbiased approximation to gradient training of matrix multiplication. It shows that even though totally deterministic sampling is biased, somewhat deterministic sampling is unbiased, and a judicious allocation of sampling to those pairs favored by deterministic thinking can lead to the use of a larger batch size with empirically negligible performance loss. This reviewer must declare that he does not check the derivation very carefully. The proposed idea is practical and can be readily combined with virtually all first-order gradient-based training methods.\nThe paper also derived why deterministic sampling is a biased estimator and empirically shown the associated bad performance, thus proving that the additional complexity of stochastic sampling over deterministic sampling is not only sufficiently better but also necessary. It's just a few empirical comparisons, but the performance gap between CRS and WTA-CRS seems modest. This reviewer does not have a question. N/A",
         "155",
         "0",
         "1",
         "0.8418",
         "0.062142857100000004",
         "0.7829982042",
         "215",
         "17.3432",
         "0.1041",
         "neurips",
         "0.01098901098901095",
         "3",
         "4",
         "2",
         "3",
         "factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "2",
         "4",
         "3",
         "2",
         "5",
         "5",
         "4",
         "65",
         "neutral",
         "5",
         "positive",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "1",
         "3",
         "3",
         "1",
         "partially factual",
         "3",
         "3",
         "50",
         "polite",
         "4",
         "positive",
         "4",
         "moderate",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "12",
         "38",
         "Reviewer-vqBu",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way. The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea. The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso. - in the frequentist case, how does the proposed framework compares against more classical techniques to obtain the solution paths, e.g., iterative reweighted l1-norm?  The authors adequately addressed the limitations of their proposed framework. ",
         "170",
         "0",
         "0",
         "0.799",
         "0.32",
         "0.9384971857000001",
         "215",
         "30.7103",
         "0.1149",
         "neurips",
         "0.011235955056179803",
         "3",
         "4",
         "3",
         "2",
         "unfactual",
         "2",
         "2",
         "60",
         "polite",
         "3",
         "neutral",
         "2",
         "low",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "4",
         "78",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "13",
         "38",
         "Reviewer-3sWQ",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution. - Well written paper.\n\n        - Illustrative toy experiments. - The proposed method is a combination of already known techniques.\n\n        - The experimental section is weak as only a single real problem is considered.\n\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\n\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\n\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros. None The authors have not commented on the limitations of their approach.",
         "279",
         "0",
         "2",
         "0.7414000000000001",
         "-0.007047619000000001",
         "0.9233116508",
         "215",
         "36.096",
         "0.0989",
         "neurips",
         "0.0",
         "2",
         "3",
         "3",
         "1",
         "unfactual",
         "3",
         "3",
         "60",
         "neutral",
         "3",
         "negative",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "3",
         "4",
         "65",
         "neutral",
         "5",
         "negative",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "2",
         "3",
         "3",
         "2",
         "factual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "14",
         "38",
         "Reviewer-pTVu",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\geq1}$ is used). 1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\n3. Using sub-l1 norm is suitable for structure learning. \n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \n5. The paper is well-written, and the relevant work is sufficiently discussed.    \n6. Due to its flexibility, the proposed method has the potential of having a large impact. Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \n\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \n\nMinor suggestion: \n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \n2. Fix minor typos e.g. the end sentence period in line 214. * In line 141, what do you mean by \"contradiction\"? The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \n\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.",
         "330",
         "0",
         "9",
         "0.7934",
         "0.1236940837",
         "0.8818445206000001",
         "215",
         "45.1097",
         "0.19690000000000002",
         "neurips",
         "0.011904761904761862",
         "3",
         "4",
         "3",
         "4",
         "unfactual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "negative",
         "3",
         "low",
         "5",
         "5",
         "4",
         "5",
         "5",
         "5",
         "5",
         "90",
         "5",
         "5",
         "5",
         "5",
         "1",
         "2.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "15",
         "38",
         "Reviewer-CnQu",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets. Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \n\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated. Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost. In synthetic data example, why did you choose to have more samples than dimensions ( $n>d$ )? Since in that case GGM can be obtained with matrix inverse, and no need for penalized objective. Limitations were not discussed.",
         "205",
         "0",
         "2",
         "0.787",
         "0.1207251082",
         "0.8797656298000001",
         "215",
         "36.2535",
         "0.25730000000000003",
         "neurips",
         "0.012048192771084376",
         "1",
         "4",
         "3",
         "1",
         "unfactual",
         "2",
         "2",
         "50",
         "neutral",
         "3",
         "negative",
         "3",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "16",
         "13",
         "Joseph-philipraj",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This systematic review is appropriate for the journal with a global problem of Mets and Urolithiasis. The introduction part clearly explains the motivation. The manuscript is clear and balanced. The manuscript stays focused on the subject. Authors have gone through the process of searching relevant articles from all websites and of sufficient duration. The inclusion and exclusion criteria in the analysis have been clearly stated. The impact of the analysis is clearly stated. The statistical analysis supports the paper well. The interpretation of the results, visualisation are well presented. The tables and figures are clear, relevant and correct. The authors demonstrate the knowledge of basic composition skills, including word choice, sentence structure, paragraph development and grammar. Limitations:  The studies included in the meta-analysis have cross-sectional nature and hence ascertainment of temporal association is not possible which also dictates need for further prospective studies. The specific type of stone formation is not correlated with studies. Despite these limitations all studies included in the meta-analysis showed the same directionality in the association between urolithiasis and Mets.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "292",
         "0",
         "1",
         "0.7415",
         "0.1145833333",
         "0.8487246633000001",
         "39",
         "30.46",
         "0.0999",
         "f1000",
         "0.010000000000000009",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "5",
         "5",
         "3",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "85.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "2",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "92",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "17",
         "13",
         "Muhammad-Faruk",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study assessed the association between metabolic syndrome and its components with the risk of developing nephrolithiasis by conducting systematic review, Bayesian random-effects meta-analysis, meta-regression and dose-response analysis. This study was done appropriately based on PRISMA flowchart. Risk of bias was also conducted of the included studies. This study has successfully presented the proper meta-analysis for this design. However, to complete this study for indexing, I personally recommended several revisions: 1. Abstract: Introduction section: It is better to address meta-regression as the analysis to assess the correlation of association along with dose-response analysis  Conclusion section: In reporting the association between predictors and nephrolithiasis, state only the predictors in which its coefficient was statistically significant 2. R language was not considered as a statistical software for data analysis. The software for data analysis should be written as \"R\" (Please refer to methods section in statistical analysis subsection). 3. Please update the PRISMA flowchart (refer to PRISMA guideline 2009). 4. Give the numbering of each Forrest plot in Figure 3 and numbering of each meta-regression plot in Figure 4. Design these figures so that it could be well presented. 5. Uniformly decide the word choice of \"traits\" or \"components\", choose whether to use traits or components in the whole text, use one of these words consistently to avoid any misunderstanding. 6. It is better to provide the meta-regression of hypertension in systolic blood pressure and diastolic blood pressure as it is important to explain the relationship to nephrolithiasis in differentiation for these two types of blood pressure. 7. Meta-regression of body mass index  was sufficient in this study thus waist circumference meta-regression was not necessary to be included. 8. Provide the value of coefficient and confidence interval of each meta-regression analysis in the result section so that better understanding of predictors-outcome relationship could be reached clearly.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "422",
         "0",
         "7",
         "0.7554000000000001",
         "0.1982758621",
         "0.9299524426",
         "270",
         "24.68",
         "0.23020000000000002",
         "f1000",
         "0.010869565217391353",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "93",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "85.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "18",
         "181",
         "Reviewer-sna7",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This paper presents ULTRA, a single model that can be directly used/finetuned for link prediction over different knowledge graphs. The key is to model the transferrable relationships between different relations across knowledge graphs. Specifically, a NBFNet is used to learn relative relation representations and generate relation embeddings, which is then fed into another NBFNet to perform link predictions. Extensive experiments are performed over many knowledge graph to demonstrate the performance of this model. - This paper is well written and easy to follow\n- The core method around the relative relationships between relations is clever and interesting.\n- The experiments demonstrate the gains of the method. It is especially impressive to see the competitive zero-shot performance of ULTRA over different knowledge graphs. - The proposed method relies entirely on knowledge graph structure and does not consider using node embedding such as textual features of the knowledge graphs. In reality, text embedding of nodes and edges could be a better transferrable embedding. Such transferability has already been demonstrated by PRODIGY (https://arxiv.org/abs/2305.12600) and should be addressed.\n- The model does not scale well as the authors already pointed out.\n- The zero shot and fine-tuning performances are worse or on-par with the per dataset model performance, rendering pretraining not effective performance-wise. \n- Some notations are a bit hard to understand. See questions. - What are u and v in h_{u|v} in section 4.2?\n- Why are supervised SOTA baselines only reported for some datasets in Figure 4?",
         "245",
         "1",
         "1",
         "0.7559",
         "0.0971320346",
         "0.9083012938",
         "49",
         "38.7951",
         "0.07200000000000001",
         "iclr",
         "0.0",
         "4",
         "4",
         "2",
         "3",
         "factual",
         "4",
         "3",
         "70",
         "neutral",
         "4",
         "positive",
         "2",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "19",
         "181",
         "Reviewer-HLbG",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This work aims to build a foundation model for knowledge graph reasoning tasks, where the authors explore the setting of generalization to any edges and nodes, including unseen, of any multi-relational knowledge graphs without using node and edge features. To this end, the authors first construct a view of a relation-centric graph from an original graph where edges become nodes of this new relation graph, and then, based on this view, the authors represent the relation (node) relative to and conditioned on the query relation. Then, based on this relative relation representation, the authors use existing inductive link prediction methods to perform knowledge graph reasoning. The authors conduct link prediction experiments on various knowledge graphs considering both inductive and transductive settings, and show that the proposed method, namely ULTRA, outperforms other SOTA baselines sometimes without further fine-tuning on target knowledge graphs (i.e., zero-shot). * This work studies the very important, challenging, and practical setups of building a foundation model for knowledge graph reasoning, which aims to be generalizable to any other knowledge graphs involving unseen nodes and unseen edges, without leveraging features of nodes and edges. \n* The proposed method works well with different knowledge graphs, on zero-shot transfer learning setups without further fine-tuning on target knowledge graphs, and further shows the boosted performance with task-specific further fine-tuning on them, on most experiment setups.\n* This paper is very well-written and easy to follow. * I would like to note that I don't see any major weakness, and below is the minor.\n* In Section 4.2, the explanation about the indicator function with variables $u$ and $v$ is a bit unclear to me. Could you elaborate more on the process and result of the indicator function according to those two variables, perhaps with visuals?\n* Text-based methods (e.g., LM-based methods) can be generalizable to any knowledge graphs including unseen nodes and unseen edges, as long as their nodes and edges are represented with texts. In this vein, I think one potential direction for building a foundation model for knowledge graph-related tasks might be to use the LMs, and the authors may highlight this point more and potentially make comparisons between the proposed approach and text-based methods. I don't think this should be the critical weakness of this paper since text-based methods are limited to knowledge graphs with textual features; meanwhile, given the framing of this work (\"Towards Foundation Models for Knowledge Graph Reasoning\"), this point should be carefully explained. * I would like to suggest emphasizing the performance differences between inductive and transductive setups when explaining Table 1. The proposed method w/ 0-shot settings are strong on inductive graphs; meanwhile, previous methods are superior to it on transductive graphs, which are worthwhile to discuss.\n* It may be beneficial to show the results of the ULTRA fine-tuned on the knowledge graphs used for pre-training the ULTRA. I am wondering if there are further performance improvements when further fine-tuning the model on the data used for pre-training.",
         "496",
         "0",
         "0",
         "0.7682",
         "0.1549267161",
         "0.9152074456",
         "49",
         "38.4364",
         "0.37610000000000005",
         "iclr",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "3",
         "80",
         "neutral",
         "4",
         "neutral",
         "3",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "20",
         "181",
         "Reviewer-c3Sg",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "Paper claims to propose a foundation model, named Ultra, for knowledge graph representation learning. The proposed model can handle full inductive graphs in which new entities and relations may appear in the test set. To do so, the authors propose to lift the graph to a one with relations as the nodes and design 4 different edge types (head2head, head2tail, tail2head, tail2tail). The relational representations are then learnt using message passing on this graph. The learnt relation embeddings are then used in the original graph to perform inductive link prediction. For the experiments, the authors pre-train their method on 3 KGs and further evaluate in a zero-shot setting and also by fine-tuning the downstream tasks. - The paper proposes a transductive model that works in settings of new relations and entity nodes.\n- The method obtains good zero-shot pretraining results. - The authors have not explicitly stated the computational complexity of the method. From the paper, it seems that the forward pass is run on the entire relational graph to obtain relation representations. This is then used to initialize the node embedding from the query triple and the process is repeated for every triple. Thus it seems that the entire graph is being used for link prediction every triple making the computational complexity O(E^2). This seems limiting for large graphs that have not been explored in the paper (such as wikidata-5m etc.).\n- From Table 2 we can see that finetuning over the pre-trained models helps the results significantly over the 0-shot setting. Also, the fine-tuning steps are too large to claim few shot results. This weakens the claim of the \"foundation model\" for KGs. A fair comparison would be to show the pretraining results for other inductive and transductive methods as well in addition to the SOTA comparison.\n- Another limitation is that of scale. Since the current model has fewer parameters, this would limit learning over larger pretraining datasets as can be seen in Figure 6 and also reported by the authors.\n- SoTA results for transductive models are better than the pre-trained Ultra model in many datasets. Thus the Ultra model seems to work well for the inductive setting rather than transductive. Thus the claim of the \"foundation model\" seems broader in scope.\n- We see that in the metafam dataset, the pretraining results are poor but on finetuning the results are improved drastically. This shows that the method works well in cases where the relational patterns of the downstream datasets are similar to the pre-trained one but when the data distribution changes the results suffer. Moreover, due to limited capacity, the model may not be able to handle such cases by increasing the pretraining datasets calling for downstream finetuning. Thus domain adaptation is not a problem which can be easily overcome by scaling the current model and this further weakens the claim of a \"foundation model\" for KGs. - For weakness point 2: Any reason why this was not done by the authors?\n- For weakness point 3: How would this be addressed in future works for the model?\n-  For weakness point 4: Could the authors comment on why this would be the case and how would the model be improved to handle the transductive setting?\n- For weakness point 5: Any reason why the results on this dataset are not good?\n- Considering KGs are a rich source of textual/semantic data along with graph/structured data and the current model does not use this rich source of context information, how can we extend Ultra to incorporate the KG ontology? \n- Considering weaknesses 2,4,5 the claim of the foundation model seems a bit broad as of now and at best the model could be said to be a good inductive learner.",
         "625",
         "0",
         "0",
         "0.7487",
         "0.1723163098",
         "0.9095818996",
         "49",
         "51.6761",
         "0.1355",
         "iclr",
         "0.01041666666666663",
         "4",
         "4",
         "4",
         "3",
         "factual",
         "3",
         "3",
         "70",
         "neutral",
         "3",
         "neutral",
         "3",
         "high",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "21",
         "181",
         "Reviewer-ebFz",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "The key limitation of designing the foundation models for dealing with the Knowledge Graphs (KGs) is that the KGs have different entities and relations that generally do not overlap. To address this issue, this paper proposes ULTRA, which positively transfers the information of source KG to unseen KG. It constructs relation representations based on the interactions between the relations by introducing the graph of relations. The proposed approach has shown good performance on various tasks. - From their experiments, the proposed methods have shown good performance on various tasks.\n- Research topics about the foundational models on graph-structured datasets is really interesting and important.\n- The paper is well written and easy to follow. - The authors first pretrain the ULTRA model with the mixture of 3 standard KGs and then fine the model for the downstream task. But, the other supervised SOTA model only uses dataset of the downstream tasks without employing the pre-training datasets. If the supervised SOTA models are designed to deal with transductive settings, they may show worse performance on the downstream tasks. However, if the SOTA models are the models for the inductive setting, I think they may be possible to be pretrained like the ULTRA. So, could you measure the performance of the \"pretrained\" SOTA models on the inductive if possible? Please refer to the weaknesses.",
         "222",
         "0",
         "0",
         "0.7001000000000001",
         "0.16196172250000002",
         "0.9080925584",
         "49",
         "47.3913",
         "0.18230000000000002",
         "iclr",
         "0.0",
         "3",
         "4",
         "2",
         "3",
         "factual",
         "3",
         "3",
         "65",
         "neutral",
         "3",
         "neutral",
         "2",
         "high",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "2",
         "4",
         "3",
         "3",
         "factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "1",
         "4",
         "2",
         "2",
         "partially factual",
         "3",
         "2",
         "45",
         "polite",
         "4",
         "positive",
         "3",
         "low"
        ],
        [
         "22",
         "9",
         "Reviewer-KmBd",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "487",
         "0",
         "1",
         "0.732",
         "0.1304191468",
         "0.9185432792",
         "47",
         "29.0538",
         "0.1695",
         "iclr",
         "0.0",
         "4",
         "3",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "90",
         "neutral",
         "3",
         "neutral",
         "4",
         "none",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "23",
         "9",
         "Reviewer-3zCE",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "480",
         "0",
         "0",
         "0.8331000000000001",
         "0.09343537410000001",
         "0.9183989763",
         "47",
         "39.3732",
         "0.1932",
         "iclr",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "negative",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "75",
         "polite",
         "5",
         "negative",
         "5",
         "low",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "70",
         "neutral",
         "5",
         "negative",
         "4",
         "low"
        ],
        [
         "24",
         "9",
         "Reviewer-y5kB",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "41.9389",
         "0.050100000000000006",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "25",
         "9",
         "Reviewer-XNx6",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.9159082770000001",
         "59",
         "42.2021",
         "0.929",
         "iclr",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "88",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "5",
         "4",
         "5",
         "5",
         "5",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "26",
         "81",
         "Gatot-Soepriyanto",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study investigate whether financial distress, earnings management and audit quality as determinants/moderating variable for financial statements fraud in Indonesian listed firms during 2015 to 2019 period. The authors focused on infrastructure, utility and transportation sectors. In general, the study has been designed adequately to tackle the research questions and issues posed by the authors. However, there are some elements need to be addressed to improve the paper: Whilst the study provide adequate research background and institutional setting, it did not mention on why the study focuses on infrastructure, utility and transportation sectors? Is there any specific issues on that sector that related to financial statements fraud? In addition to that, why the study chooses 2015-2019 period?  The study should also discuss the reason choosing F-Score as its main measure for financial statement fraud. Why, for example, the study did not use, Beneish M-Score? Or other accounting irregularities measures in the literature?  The study needs to provide descriptive statistics table, so the reader can gauge and understand the dataset better. This should be provided before the authors arrive with the hypothesis discussion;  Given the study uses panel data (multi years, across different firms), is there any attempt to mitigate the issues of panel data regression? For example, using year-fixed effects or even using panel data regression analysis?  The manuscript need to be checked in terms of the quality of English write up. The title for example, is a little bit confusing, as it did not really represent what the study want to achieve in general.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "400",
         "0",
         "1",
         "0.7771",
         "0.11745495500000001",
         "0.9143848419",
         "220",
         "26.81",
         "0.016800000000000002",
         "f1000",
         "0.020408163265306145",
         "4",
         "4",
         "3",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "moderate",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "27",
         "81",
         "Toni-Šušak",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "909",
         "0",
         "5",
         "0.6798000000000001",
         "0.12259259260000001",
         "0.8569852710000001",
         "489",
         "50.12",
         "0.07200000000000001",
         "f1000",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "5",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "5",
         "4",
         "5",
         "5",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "3",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "28",
         "24",
         "Silvio-Buscemi",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         "280",
         "0",
         "1",
         "0.7857000000000001",
         "0.1403645833",
         "0.7798862457",
         "34",
         "24.27",
         "0.3225",
         "f1000",
         "0.010526315789473717",
         "1",
         "3",
         "1",
         "2",
         "unfactual",
         "3",
         "1",
         "48",
         "polite",
         "3",
         "negative",
         "1",
         "extreme",
         "4",
         "5",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "29",
         "77",
         "Houcemeddine-Turki",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "This manuscript presents a novel rule-based approach for fact checking in knowledge graphs based on mining textual resources. The work provides new evidences that rule-based approaches can provide more precise evaluation of the accuracy of statements in knowledge graphs and can enhance the efficiency of embedding-based methods when combined with them. The availability of source codes and datasets in GitHub is an advantage for this work as this will allow the reproducibility of the described experimental study. However, there are several matters within the paper that should be addressed to ameliorate its final output: (i) Introduction: The \"Introduction\" seems to be a summary of \"Related Studies in Fact Checking\" rather than a proper introduction and contextualization of the paper. I propose to expand the part about misinformation fighting in the introduction to give better context for the development of this research paper. The authors can benefit from previous research papers about fact checking in general to develop the introduction of the paper. Several points in the introduction should be moved to Related Studies in Fact Checking. (ii) The paper did not emphasize the advantages of rule-based approaches when compared to embedding-based methods beyond having a better precision. Effectively, there are many other advantages of rule-based approaches. For example, the results of rule-based approaches can be more explainable than the ones of embedding-based approaches. Such advantages should be expanded and highlighted in the research paper. (iii) The paper did not emphasize the importance of having the datasets and source codes available in a specific GitHub repository. The authors should specify that this practice allows reproducibility and further development of the work by peers, particularly in the conclusion. (iv) The paper did not discuss the concept of reification in knowledge graphs. Effectively, several knowledge graphs add qualifiers to triples to provide a characteristic of the statements (i.e. {(s,p,o), p, o}. The authors should discuss the usefulness of the method to verify the qualifiers of the statements in the Discussion or as a future direction for this work. (v) The paper should evocate the robustness of the rule-based approach they proposed to adversarial attacks. This can be an advantage of the approach. (vi) There are several typos in the research paper (e.g. \"UC Berkely\" should be \"UC Berkeley\"). The authors should proofreading the paper to eliminate such deficiencies. (vii) The authors can expand the Discussion of the work (Part 5) to explain the strengths of KStream, KLinker, COPPAL, RUDIK, and PredPath that contributed to their efficiency as reported in the Experimental Study according to previous research papers. This can explicate the reasons of why the method developed by the authors was more efficient. (viii) The authors should provide future directions for the development of this work in the conclusion. Given this, I propose to accept this paper for publication after these six major revisions are applied.",
         "473",
         "0",
         "1",
         "0.7464000000000001",
         "0.1097294372",
         "0.9120528102000001",
         "4",
         "36.08",
         "0.2025",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "88",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "30",
         "67",
         "Reviewer-um1j",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "The paper introduces a new method for molecular modeling, QuinNet, which incorporates five-body interactions using only dihedral angles. The authors first introduce relevant concepts related to machine learning force fields and related work in the field related to a variety of equivariant models. Next, the paper describes pertinent definitions of force fields, group equivariance, and methods for calculating empirical force fields. In the methods section, the authors describe their approach for integrating five-body terms into the architecture of QuiNet using only dihedral angles and incorporating model designs from prior work (PaiNN for 3-body interactions, ViSNet for 4-body interactions) and new definitions for different topologies of 5-body interactions. In addition to the architectural description, the authors provide relevant mathematical formulations and a complexity analysis. In their results, the authors showcase QuiNets performance on a low (MD17) and high complexity (MD-22) dataset in terms of energy and force modeling, including an ablation for different body terms in Figure 5. The paper has the following strengths:\n* Originality: The proposed architecture incorporates relevant terms for molecular modeling that are physically relevant, but have not been incorporated before.\n* Quality: The method and experimental design showcase relevant cases for applying GNN models for molecular modeling with the idea behind the architecture being well-motivated.\n* Clarity: The paper presents a cohesive formulation of their method, both in figures and mathematics, and experiment descriptions with relevant takeaways.\n* Significance: The proposed architecture shows improved modeling performance, especially in forces, and provides a potential framework for incorporating physical interactions into GNNs. The paper could be improved by the following:\n* Providing a clear and concise discussion of limitations. \\[Quality, Significance\\]\n* Adding more context for the results in Figure 4. The MD simulations are only briefly described in Section 5.1, which is on a different page then the figure and easy to miss. \\[Clarity\\]\n* A description of the case in which a greater set of many-body interactions is beneficial. This is briefly mentioned in the discussion between MD17 and MD22, but it would be good to put in greater context in terms of the experimental results and could serve as part of the conclusion. \\[Clarity\\] * Could you provide additional details on the limitations of QuinNet? E.g. Is it limited to modeling mainly molecular systems? What sizes of molecules do you think QuinNet can be effective in and why?\n* Do you have data that supports your compute complexity analysis compared to other methods? If so, what kind of speedup do you generally find, if any? The authors do not provide a discussion on limitations, which I raised as a weakness. I would like to see a discussion of limitations in future versions and/or during the discussion period.",
         "452",
         "0",
         "1",
         "0.7681",
         "0.1465895563",
         "0.867398262",
         "215",
         "29.1615",
         "0.464",
         "neurips",
         "0.0",
         "5",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "5",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "31",
         "67",
         "Reviewer-YmDt",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "In this work, the authors propose to incorporate features from five-body interaction into machine-learning force field models and develop QuinNet. To efficiently incorporate such high-order information, the authors are motivated by the topology of many-body interactions and design sophisticated components. Experiments on several benchmarks are conducted to demonstrate the performance of QuinNet. 1. The target problem of this paper, the development of machine learning force field models, is of great significance. 1. **The motivation for the designed components of many-body interaction is puzzling**. As introduced in Section 4, the development of four-body interaction (improper torsions) and five-body interactions are based on the topology. First, such analysis is purely qualitative. The authors did not provide further completeness proof or quantitative evidence about these interaction schemes in real-world data. Second, the reasons for deriving Eq (4)-(9) are not well explained. It is suggested to clarify how these components are motivated according to the topology analysis.\n\n\n2. **On the experimental evaluation**. Additionally, there are several aspects of the experiments that are concerned:\n    - The empirical performance is not consistently better than other baselines. Among the evaluated benchmarks, the proposed QuinNet cannot outperform the baselines significantly. For example, in MD17, the newly developed five-body interaction modules do not significantly improve performance. In rMD17, the best performance is diversely distributed among the compared models. Overall, the experimental evaluation does not well demonstrate the power of newly developed modules.\n    - The computation efficiency evaluation is missing. Although the authors provide complexity analysis, it is better to further show the time/memory cost comparison between the proposed QuinNet and baselines. Besides, the model parameters should also be provided for all compared models.\n    - The scale of the chosen benchmarks is rather small. Both the dataset size and sample size (number of atoms) are limited. It is suggested to further evaluate the proposed QuinNet on large-scale benchmarks, e.g., Open Catalyst Project \\[1\\].\n    - The ablation study. First, as shown in Figure 5, the inclusion of Five-body@I even induces further errors, which would make readers curious about whether such a phenomenon generally exists. Second, as introduced in VisNet, the improper angle was also considered. The authors should add further discussions and empirical comparisons between it and the newly proposed four-body interaction (improper torsion).\n\n\n3. **The writing does not meet the requirement of an acceptable paper in this conference**. First, Section 3.2 can be thoroughly extended (e.g., in the appendix) to introduce the background of force fields and highlight the importance of torsion potential, improper torsions, and higher-order many-body interactions. Second, there lack of formal descriptions of QuinNet. Figure 3 can hardly be understood by readers that are not familiar with the related works in this area. \n\n\\[1\\] Chanussot L, Das A, Goyal S, et al. Open catalyst 2020 (OC20) dataset and community challenges\\[J\\]. Acs Catalysis, 2021, 11(10): 6059-6072.\n    -  Please refer to the Weakness section to address the concerns. The authors did not discuss the limitations of this work.",
         "489",
         "2",
         "6",
         "0.7931",
         "0.0741489571",
         "0.8583066463000001",
         "215",
         "34.6703",
         "0.19390000000000002",
         "neurips",
         "0.0",
         "5",
         "5",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "80",
         "polite",
         "5",
         "negative",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "1.0",
         "3.0",
         "3.0",
         "2.0",
         "partially factual",
         "3.0",
         "2.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "4.0",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "32",
         "67",
         "Reviewer-8RW7",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper aims to incorporate 5-body interactions into geometric deep learning models. They first analyze the topology of 5-body interactions and identify three 5-body angles. Then they propose an efficient way to incorporate these 5-body information into models. The complexity of the proposed QuinNet is still O(|N|), the same as many previous 2-body methods like PaiNN. The results are comparable to previous SOTA methods. This paper is well-written and easy to follow.\n\nThe experimental results show that the proposed method can perform well on most tasks. The ablation study in Section 5.4 and Figure 5 show that the proposed 5-body information indeed helps to model. See details in the Question part. 1. About the motivation:   \n this paper aims to incorporate 5-body interactions into geometric deep learning models. However, based on my understanding, using up to 4-body (torsions) interaction is already complete \\[1\\]\\[2\\] in terms of capturing the geometric structures. If this is correct, then why do we need these 5-body angles? In addition, if we can incorporate 5-body interactions, do we also need to incorporate 6-body interactions?\n\n2. About the complexity:   \nin Section 4.3, the authors claim that the complexity is O(|N|), as efficient as many 2-body methods like SchNet and PaiNN. But I think this complexity is not well explained. Using pseudocode/algorithm may be better to analyze the complexity. In addition to the analysis, I suggest the authors use some results to empirically verify the great efficiency compared to other baseline methods, e.g. the inference time, used memory, etc.\n\n3. About the tasks:   \nthis paper focuses on MLFFs, how about other molecular property prediction tasks, such as QM9 and OC20? I am wondering if this method is specially designed for MLFFs, or can be used on all 3D molecule tasks. In other words, why do the authors emphasize MLFFs? Is there any significant difference between MLFFs and other molecule property prediction tasks?\n\n4. Other related papers: many-body \\[3\\], MLFFs \\[4\\]\n\n5. The j, k in Figure 2 are confusing to me. For example, in (f), why not be i, j1, j2, j3, and k1?\n\n\\[1\\] ComENet: Towards Complete and Efficient Message Passing for 3D Molecular Graphs.  \n\\[2\\] GemNet: Universal Directional Graph Neural Networks for Molecules.  \n\\[3\\] On the Expressive Power of Geometric Graph Neural Networks.  \n\\[4\\] Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations. None",
         "394",
         "8",
         "6",
         "0.77",
         "0.13857142860000002",
         "0.8948391676",
         "215",
         "48.9981",
         "0.1429",
         "neurips",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "85",
         "polite",
         "5",
         "negative",
         "4",
         "low",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "33",
         "67",
         "Reviewer-YYfR",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper introduces a machine learning force field that is a neural network with explicit interactions for up to 5-body terms.  The authors evaluate the model on a couple of public datasets and show demonstrate the competence or superiority of this new model compared to the state of the art in this field. The paper provides an important addition to a series of ever-improving machine learning potentials.  The contribution is clear and simple to understand at the high level, though the details are often unclear.  The benchmarks were compared against a set of reasonably strong published methods in this area.  In my opinion, if this work was presented in an unambiguously clear fashion and accompanied by code, it could be a strong contribution to this conference.  \n\n\\[The paper improved significantly following the first round of feedback from reviewers, so I'm raising my rating to a 7.\\] The complexity analysis is very limited.  How many total interactions did the typical molecule have as a function of their atoms, and how did the practical experimental complexity scale for the evaluation of these molecules.  One of the main reasons that 5-body terms were not used in traditional MD simulations was the poor scaling of the number of interactions one would need to calculate.\n\nThe MD simulation mentioned in section 5.1 and Fig 4 are not described anywhere.  The following sentences suggest that there would be some explanations in the supplement, but I couldn't find them: \"Additionally, we perform MD simulations using trained QuinNets as force fields and plot the distribution of interatomic distances h(r) for these 7 molecules in Fig. 4. Further details regarding additional settings can be found in the Supplementary Materials.\" \n\nThese sentences in the supplement, page2, are confusing or wrong: \"Similarly, five-body@III interaction (Fig. S1 (c)) is a special case of six-body interaction when nodes i and k4 in Fig. S1 (d) superpose each other. Thus, the QuinNet model captures all five-body interactions and a portion of six-body interactions, making it a versatile and comprehensive tool for modeling complex molecular systems.\"  There is no six-body interaction if two of the bodies are the same, and there is no physically acceptable case where two different atoms could superpose each other.\n\nThe code is not provided, so it is not possible for me to assess the reproducibility of this method.  The diagram in Figure 3 seems reasonable at the very high level, but it lacks the definitions of most of the terms annotated in the figure, thus rendering it confusing.  (What is $Y_l$? is it the set of all spherical harmonics $Y_{lm}$ for a given angular momentum $l$? What is $n_j$? What is $s_j$?  $W$?...) Could the authors add the presentation of the QM9 quantities estimated in the recent publication for Allegro?  (https://www.nature.com/articles/s41467-023-36329-y Table 3)\n\nHow long and how stable were the actual MD simulations?  What were the exact codes/protocols used?\n\nWhat is the practical performance of the model during evaluation? No potential negative societal impacts from this work.",
         "497",
         "1",
         "2",
         "0.764",
         "0.0333794423",
         "0.8763324022000001",
         "215",
         "43.7997",
         "0.1199",
         "neurips",
         "0.018018018018018056",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "polite",
         "5",
         "positive",
         "4",
         "moderate",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "34",
         "171",
         "Magdalena-Czlapka-Matyasik",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I commend the authors to contribute to this body of literature regarding the socio-demographic and lifestyle factors associated with understanding fast food consumption in Cambodia adults. The paper brings quantified information about the factors influenced by understanding fast food consumption. The authors revealed that poor and fair knowledge, insufficient exercise levels, and not getting enough sleep were predictors of inadequate understanding of the impact of fast food on health. Such conclusions do not bring entirely new knowledge to the literature, on this matter. Across the whole world population, the problems related to fast food consumption have been discussed. Nevertheless, I consider the work to be original, well designed and contribute knowledge to this field of public health research. My suggestions concern: In the introduction, the authors indicate the system of fast-food restaurants; it would be more attractive to explain, how it was developed in Cambodia directly?  What would be very interesting is information concerning the real take away or fast food intake in those groups. It must or might be in direct relation to this matter?  My main concern about the validation of the \"Level of knowledge of fast food consumption\": Could the authors explain the procedure? How were the questions selected and validated?  I regret that the authors discussed the interesting results in such a concise way.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "361",
         "0",
         "1",
         "0.7773",
         "0.2011784512",
         "0.89415133",
         "137",
         "35.27",
         "0.1507",
         "f1000",
         "0.010000000000000009",
         "0",
         "4",
         "1",
         "0",
         "unfactual",
         "3",
         "3",
         "35",
         "neutral",
         "3",
         "neutral",
         "1",
         "high",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "positive",
         "3",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "35",
         "171",
         "Wanshui-Yang",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript investigated the level of understanding of fast-food consumption among adults in Cambodia. The authors found that unsatisfactory levels of knowledge around fast food consumption were significantly associated with not taking regular exercise and sleeping less than eight hours per night. The results are interesting, but I have several comments. The authors should introduce the recent development of fast-food sector in Cambodia in the introduction part.  Is there an analysis of fast-food intake among these participants?  Interestingly, the authors found that not taking regular exercise and sleeping less than eight hours per night were associated with unsatisfactory levels of knowledge around fast food consumption. However, they were not well explained in the discussion part. In other words, the discussion part is a little too concise.  In addition, the education levels were not associated with the knowledge of fast-food consumption in the present study. I would like authors to discuss it and, at least, mention its possible causes.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "303",
         "0",
         "1",
         "0.7774000000000001",
         "0.1265046296",
         "0.9193514585",
         "520",
         "28.03",
         "0.1953",
         "f1000",
         "0.010204081632653073",
         "0",
         "4",
         "1",
         "0",
         "unfactual",
         "3",
         "3",
         "40",
         "impolite",
         "3",
         "negative",
         "0",
         "high",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "36",
         "187",
         "Reviewer-2CBB",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "This paper introduce a novel unsupervised feature selection methods called GRSSLFS, which combine matrix factorization with self-representation subspace learning and apply graph regularization to preserve the geometric structure of the feature vectors. This method is proved to be effective in both theory and experiments. In this paper, the author introduce the problem of the redundant data in traditional self-representation, and then apply matrix factorization self-representation problem to achieve the goal to reduce the dimension of basis matrix. Here are some strengths of this article:\n\n1. This paper introduce a novel problem of redundant data in self-representation problems and then propose a method to solve this problem.\n\n2. Plenty of theoretical proof are given in the paper and appendix, the convergence analysis indeed increase the persuasiveness of the article.\n\n3. The proposed method was compared with a variety of comparison algorithms on multiple data sets, demonstrating the effectiveness of the method. However, there are still some weaknesses in this paper.\n\n1. In the end of Introduction section, the second and third contribution points is not sufficient, as these constraints of regularization are not proposed in this article. \n\n2. In the methodology section, some formula calculations are confusing and not very convincing. Such as the multiplication in formula (6) and the optimization target in the optimization goal (formula 7). These issues will be described in detail in subsequent questions 1 and 2.\n\n3. In the methodology section, the description of the algorithm is not complete enough. The specific process of selecting features according to the matrix U in Algorithm 1 has not been described in detail. 1. In the section of methodology, the equation (6) is confusing and not so clear. It seems impossible to subtract the matrix XUV of shape m*m from the matrix X with the shape m*n? \n\n2. As the feature matrix B is fixed by the VBE method proposed in section 3.3, it is unclear why the basis coefficient matrix G in equation (7) is a parameter to be optimized. Why the matrix G can not be determined by equation (4) directly and reduce the number of parameters.\n\n3. In section 3.1, subspace learning that introduces graph regularization seems to be existing methods. Should this part of the content be moved to related work?",
         "376",
         "0",
         "8",
         "0.679",
         "-0.048046398000000004",
         "0.9640573859",
         "51",
         "40.0877",
         "0.0751",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "4",
         "4",
         "70",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "37",
         "187",
         "Reviewer-yUvs",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Authors of this paper propose graph regularized self-representation and sparse subspace learning (GRSSLFS) for unsupervised feature selection. The basis extension method is modified to select bases with highest variance score. These bases are used to build graph regularized self-representation learning and subspace learning. The graph regularized self-presentation learning and subspace learning are combined in terms of a set of selected bases from input space with the highest variance score. Experiments on various datasets demonstrate the advantage of the proposed method comparing with baselines. The ablation study also shows the necessity of each component. The subspace learning module is the key component, but its derivation from selected bases highly relies on the assumption that XU=B. This might not be hold if B is selected according to the proposed variance basis extension method. Moreover, the selection based on subspace learning module lacks of convincing explanation since G does not exactly represent X based on B as a fixed set of feature vectors. It is confusing to explain (4) as the self-representation problem if B is arbitrary basis matrix since they may not come from the input data matrix X.  Taking PCA for example, the columns of B are orthogonal, but they are not from the input feature space. Moreover, B defined as a square matrix of size m is inconsistent with the sleeted r bases in section 3.3.\n\nIn section 3.1, authors mentioned that two features have a similar structure in the feature space, and it is expected Bg_l and Bg_r have similar structure. What does the similar structure mean? How is the similarity measured? In other words, it is unclear how the matrix A is constructed. \n\nThe derivation in section 3.2 depends on the assumption that XU=B. As B is a set of feature vectors selected from input data, it is unclear whether the assumption still holds or not. Similarly for Theorem 3.1, it is trivial to have if the assumption holds. \n\nThe variance basis extension is to simply change the selection order of feature vectors in terms of variance score of feature vectors. It is possible that for each individual feature, the variance is high, but is it similar to say the largest amount of data dispersion? \n\nFor completeness, authors should describe the derivation process on how equations (9)-(11) are obtained. Since all three equations are fractional, is it possible that any of the denominators can be zero? How is it handled?\n\nIn Algorithm 1, the selected features are derived from U. However, U is not directly related to the input X instead to B and G, unless BG=X. However, B is selected feature vectors from input space. It is unclear why the assumption can hold. So why is the selection rule proper?\n\nThe computation complexity is quite high since it is quadratic to both the number of samples and the number of features comparing with most of baseline methods.\nThe application to the PneumoniaMNIST dataset is quite interesting. However, the way of presenting the outcomes can be improved significantly.  For example, what is the interested region? how many selected features are in the interested region? How do other compared methods perform? The validation is not quantified. How many radiologists are involved in the evaluation?  What is the performance measured? These plots shown in Fig. 2 delivers less useful information except that more red points are accumulated in the center when the number of selected features increases.",
         "567",
         "0",
         "0",
         "0.7308",
         "0.0892117117",
         "0.9616214633000001",
         "51",
         "50.3623",
         "0.0364",
         "iclr",
         "0.0",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "75",
         "polite",
         "3",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "5",
         "4",
         "4",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "neutral",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "75",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "38",
         "187",
         "Reviewer-PMap",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Considering there exists a major gap in the mathematical principles that underlie the self-representation based unsupervised feature selection approaches and their capacity to represent the feature space, this paper proposes Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), for the unsupervised feature selection, which expresses the self-representation problem based on the concept of “a basis of feature space” to represent the original feature space as a low-dimensional space made of linearly independent features. Experiments on widely-used datasets are conducted to validate the efficacy of the proposed method. 1. The computational complexity of the proposed GRSSLFS method is low, which is efficient for large-scale and high-dimensional data;\n2. The results of the proposed method seem better than other ones. 1. Most of the compared methods are out-of-date, only one method used for comparison was publised in 2023, other methods are before 2020;\n2. The motivation of the proposed method is not clear. In Eq.(8), the first three terms have been well explained, but the final regularization term has not been explained. See weakness.",
         "172",
         "0",
         "4",
         "0.6699",
         "0.1067307692",
         "0.9783408642",
         "51",
         "26.959",
         "0.0945",
         "iclr",
         "0.0",
         "2",
         "4",
         "1",
         "3",
         "partially factual",
         "2",
         "2",
         "30",
         "polite",
         "3",
         "negative",
         "3",
         "moderate",
         "3",
         "4",
         "3",
         "3",
         "partially factual",
         "4",
         "4",
         "65",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "3",
         "3",
         "factual",
         "3",
         "4",
         "65",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "39",
         "103",
         "Reviewer-NRqK",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes an algorithm for learning MDP state abstractions that preserve information needed for planning (namely, the values of states). A major differentiator from symbolic approaches is the idea that these state abstractions should be continuous rather than discrete. The key assumption is that you are given a set of options and a dataset obtained by rolling them out. Experiments are conducted in a few simple domains: pinball and antmaze, and demonstrate that the learned abstractions are sensible. The paper addresses an important topic (abstraction learning) and I appreciate the theoretically motivated algorithms. This line of work is of great interest to many attendees of ICLR. I also appreciate that the authors were clear about wanting continuous representations right off-the-bat. The math is also correct as far as I was able to tell, though I didn't check the proofs in the appendix in careful detail. Unfortunately, I recommend rejection for this paper due to 4 major reasons: 1) unconvincing experiments, 2) missing key citations to related work, 3) issues in technical details, and 4) unclear motivation.\n\n1) unconvincing experiments\n\nThe experiments in this paper are very basic and only serve as a simple proof-of-concept that the learned abstractions are somewhat useful. To really scale up the experiments to the level expected for a conference paper, I would expect to see evidence that the learned abstractions are useful in more hierarchical domains (e.g., classic domains from the options literature like keys and doors). In such domains, we could test whether the value-preserving property holds empirically, by comparing the values from planning under the abstract model to the (ground truth) values from planning under the true model.\n\nAdditionally, I would like to see comparisons to many more RL algorithms, especially hierarchical ones like HIRO (https://arxiv.org/abs/1805.08296), HVF (https://arxiv.org/abs/1909.05829), and Director (https://arxiv.org/abs/2206.04114). This is because at the end of the day, the authors are proposing to learn a state encoder $\\phi$, and despite all the theory that has gone into their algorithm, the question that must be answered is whether this $\\phi$ outperforms the encoders learned by all these other SOTA hierarchical RL algorithms.\n\n2) missing key citations to related work\n\nThe authors are missing several key citations, the most important of which is the line of work by David Abel, such as \"Near optimal behavior via approximate state abstraction\" (https://proceedings.mlr.press/v48/abel16.html) and \"Value preserving state-action abstractions\" (https://proceedings.mlr.press/v108/abel20a/abel20a.pdf). Those papers have very similar theory to what appears in this one, and so the novelty of the proposed approach is unclear. There are also less-famous but still important-to-cite papers from other authors, like \"Abstract value iteration for hierarchical reinforcement learning\" (https://proceedings.mlr.press/v130/jothimurugan21a/jothimurugan21a.pdf) and \"Deciding what to model: Value-equivalent sampling for reinforcement learning\" (https://proceedings.neurips.cc/paper_files/paper/2022/hash/3b18d368150474ac6fc9bb665d3eb3da-Abstract-Conference.html). It is important for the authors to contextualize the contributions of this paper against all these related works.\n\n3) issues in technical details\n\nThe authors say in Section 3.2 that when B = \\bar{B}, \"then simulating a trajectory in the abstract model is the same as in the ground model\". But I don't think this is true, because we need the rewards to match between the two trajectories too, and $B_t$ says nothing about rewards, only dynamics. The authors go on to say: \"Therefore, planning in the abstract model is accurate, in the sense, that the value of an abstract state z computed in the abstract model is the same as the one would get from trajectories from the ground MDP for the abstraction operator G.\" Again, I think this is wrong because it ignores the abstract reward function, which could be arbitrarily different from the ground one. In fact, in the proof of corollary 3.8, the authors assume $E_{s \\sim G(\\cdot \\mid z)}\\[R(s, o)\\] = \\bar{R}(z, o)$, and it's only _under this assumption_ that the claims hold. But combining this assumption on reward function with Definition 3.6 ends us back up at the bisimulation conditions, and then it's not clear what the contributions of this paper are.\n \nAs a separate point, the second term in the mutual information expression of Section 4.2, $MI(S'; Z, A)$, seems very extreme! It is saying that you have to be able to predict the entire ground next state from the current abstract state and action. Doesn't this means the abstraction can't lose any information? This seems like an important technical limitation of the approach.\n\n4) unclear motivation\n\nThe authors often state that a discrete abstract state space is bad, when pointing to work on symbolic abstraction learning (e.g., PDDL). But it's not clear why this is really bad. The authors say discrete abstract states are \"not applicable when planning with the available high-level actions requires a continuous state representation\", but this doesn't make sense to me, as the options have to act in the ground environment states, not in the abstract state space, and so the options could be defined with respect to either a discrete or a continuous abstract state space. Furthermore, it can be much easier to plan in a discrete abstraction (e.g., using powerful symbolic planners).\n\nI believe a fruitful research direction would be to compare the abstractions learned by a symbolic approach against the abstractions learned by a continuous approach (like the authors'). Questions:\n* Not much is said about the dataset $\\mathcal{D}$, but intuitively, it has to be \"good\" in order for the learned state abstraction to be reasonable. In particular, the agent must see all the options being executed in a variety of settings, and obtain good coverage over the state-action space. Are there any concrete statements we can make about what properties we need this dataset to have?\n* \"we must build a model of its effect\" Do you mean to say \"of the effect of each option\"?\n* \"with mean value equal to that by planning with the original MDP\" What is the mean over?\n* Why did we switch from using O (denoting the option set) everywhere to using A throughout Section 4? Shouldn't we continue to use O, unless I am misunderstanding something?\n* Section 4.3: Why should there be any cost/reward associated with executing skills? Shouldn't a sparse reward for reaching the goal be enough?\n* Eq 2: What are the \"I\" random variables inside the mutual information expression referring to?\n\nMinor edits:\n* \"make the same decision\" To clarify, we just need that the policy maps all states in z to the same action distribution. A stochastic policy isn't really committing to a \"decision\" about what action to take.\n* \"Abstractions alleviate this tension: action abstractions enable agents to plan at larger temporal scales and state abstractions reduce the complexity of learning and planning\" I would say that both of them do both of these. Action abstractions certainly reduce the complexity of planning, which is typically exponential in the branching factor.\n* \"learns a further abstraction\" --> \"learn a further abstraction\"\n* \"otherwise it is referred as learning\" I would say \"policy learning\" to distinguish from other things you might learn\n* \"when it is the given position\" --> \"when it is in the given position\"\n* \"referred as learning\" --> \"referred to as learning\"\n* \"results a bounded value loss\" --> \"results in a bounded value loss\"\n* In definition 3.5, the authors use $s_o$ in a few places where they mean $s_0$.",
         "1210",
         "7",
         "0",
         "0.7753",
         "0.0567315252",
         "0.9024221301",
         "49",
         "44.7468",
         "0.6075",
         "iclr",
         "0.019607843137254943",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "4",
         "94",
         "polite",
         "4",
         "negative",
         "5",
         "none",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "negative",
         "5",
         "none",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "3.0",
         "60.0",
         "neutral",
         "5.0",
         "negative",
         "5.0",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "negative",
         "5",
         "none",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "40",
         "103",
         "Reviewer-36E8",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper presents an approach for learning dynamics preventing abstractions for sensorimotor observation space. Given a set of high-level skills and the learned dynamics preserving abstractions, the paper claims to develop an approach for planning for a solution. \n\nThe approach is evaluated in two test domains where the paper shows the visualization of the learned abstractions. - For the most part of the paper, it is extremely well written. Given the wide use of embodied AI systems and robots, an approach that generates plannable abstractions for high-dimensional sensor input is extremely important. \n\n- The paper nicely motivates the problem. While the paper in general is nicely written, it has a few limitations: \n\n- The paper advocates learning a continuous abstract  representation instead of a symbolic abstractions. However, it does not provide any reasons to that. Why are continuous abstractions more desirable than symbolic abstractions? \n\n- Sec 4.1 is unclear. The notation for MI is a bit unclear. It needs to be made more clear. Sec 4.1 requires a re-writing including more explanation for the equation. I have two important questions: \n\n- How is the dynamics preserving abstraction defined in Def. 3.6 different from the Markovian abstractions defined in \\[Srivastava et al. 2016\\]? \n\n- Can you discuss the differences between the presented approach and \\[Allen et al. 2021\\] \n\nReference \n\nAllen, Cameron, et al. \"Learning markov state abstractions for deep reinforcement learning.\" Advances in Neural Information Processing Systems 34 (2021): 8229-8241.\n\nSrivastava, Siddharth, Stuart Russell, and Alessandro Pinto. \"Metaphysics of planning domain descriptions.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016.",
         "264",
         "1",
         "6",
         "0.7512000000000001",
         "0.1625",
         "0.8653070927000001",
         "49",
         "41.1434",
         "0.2429",
         "iclr",
         "0.0",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "3",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "4",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "41",
         "103",
         "Reviewer-dCJp",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper introduces a method for enabling general-purpose agents to efficiently handle complex tasks by constructing abstract models based on temporally-extended actions. These models facilitate more efficient planning and learning and are characterized using principled conditions. The approach provides empirical evidence of improved sample efficiency in goal-based navigation tasks and offers theoretical support for information maximization strategies in abstract state representation learning.\nThe authors claim that they introduced a method for creating abstract world models that empower agents to plan effectively for goal-oriented tasks. The key idea is to allow agents to construct reusable abstract models for planning with specific skills. This is achieved by characterizing the state abstraction that ensures planning without any loss in simulation, meaning that planning with the learned abstract model can generate policies for the real world. The paper also provides theoretical support for the use of information maximization as a reliable strategy for learning abstract state representations. - Good overview of the related work.\n- Good description of motivations and intuitions. \n- proper choice of environment settings. Major:\n- Some measures are used without definition, \n- It seems that there exists a lot of inaccuracies and impreciseness in the theories and definitions. See all questions!\n\nminor:\n- typos: \nlast paragraph of the introduction \"the *agents* needs\", definition 3.5 \"$s_{o}$\" must be \"$s_0$\"\n- writing: \nDefine the abbreviations before using them, e.g. \"PDDL\", \"VAE\"\n\nThere is a chance that I have not fully understood what this paper is trying to present. 1- What is $P(s'|s,o)$ used in the paragraph right after definition 3.1?\n\n2- An option $o$ is defined, and then you mention $T(s'|s,o)$ to define the transition probability of taking option $o$ in $s$? $T$ earlier was defined on action space $A$. How is it applied on options without showing the relationship of $I_o$ and $\\beta_o$ with $s$ and $s'$ under option policy $\\pi_o$?\n\n3-the paper has defined \"$\\bar {\\gamma} = \\gamma ^{\\tau (s,o)}$ is the abstract discount factor, $\\tau: Z \\times O \\rightarrow \\[0,\\infty)$, which consists of contradictory phrases. How is ${\\tau (s,o)}$ but defined as a function of abstract variables $Z$ instead of $S$? Not clear what $\\tau$ is. If based on definition 3.1, it is the option's execution time starting from $s$ taking option $o$, it is not clear how in definition 3.2 it becomes a map from $Z$ and $O$ to a non-negative real.\n\n4- What does definition 3.4 mean? $ \\Pi = {\\pi \\in \\Pi : \\pi(·|s) = \\pi (·|z) \\forall s \\in z}$ says the probability of taking actions/options in $s$ should be equivalent to the probability of taking actions/options in abstract states. Transitions of taking actions in states might take you to another state $s'$ inside the similar abstract state $z$. How can the policies used for both abstract states and states be equivalent? Unless you are just discretizing the continuous state spaces based on the optimal policies that are already given. Lots of interchangeable usage of symbols here. Not precise and is hard to follow.",
         "499",
         "0",
         "1",
         "0.7308",
         "0.0796438834",
         "0.93872118",
         "61",
         "45.6397",
         "0.1463",
         "iclr",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "3",
         "4",
         "83",
         "polite",
         "4",
         "negative",
         "5",
         "none",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "4",
         "4",
         "45",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "neutral",
         "4",
         "neutral",
         "4",
         "moderate",
         "2",
         "3",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate"
        ],
        [
         "42",
         "103",
         "Reviewer-gKE9",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes a grounded abstract model formulation with a dynamic preserving abstraction. This abstract state representation (and model) guarantees not only accurate future predictions but also the bounded values in the abstracted rollouts. This paper then provides its implementation using contrastive learning to maximize mutual information between the future state, and the current abstract state and option. The results show that training DDQN in imagination using the abstract model improves the sample efficiency. * The paper proposes a solid foundation of the abstract model that preserves dynamics and values.\n\n* The paper is well written.\n\n* The visualization in Figure 3 clearly shows that the abstract state representations focus on important features in the original observation space. * The main focus of the paper is to show the efficiency of planning and learning when using the proposed abstract MDP. The experiments in the paper are a bit simple to showcase the benefits of the abstract model for planning. It would be stronger if the experiment was done in more complex environments with much longer-horizon tasks, such as AntMaze experiments (Hafner 2022) or robotic manipulation tasks \\[a\\].\n\n* Similarly, the comparisons in Figure 5 are essentially between model-free RL (ground) and model-based RL (abstract), which does not seem fair. It might be fair to compare the proposed method with other model-based RL approaches, such as Dreamer and TD-MPC.\n\n* Exhaustive comparisons to the alternatives to the dynamics preserving abstraction would be interesting, such as bisimulation.\n\n* Some highly relevant works on temporally-extended models \\[a,b\\] are missing in the paper. Proper comparisons to these approaches are necessary.\n\n\\[a\\] Shi et al. Skill-based Model-based Reinforcement Learning. CoRL 2022\n\n\\[b\\] Zhang et al. Leveraging Jumpy Models for Planning and Fast Learning in Robotic Domains. 2023 Please address the weaknesses mentioned above.\n\n\n### Minor questions and suggestions\n\n* Figure 1 may want to explain why abstract state representations and options are helpful for planning and learning. However, Figure 1 does not seem to help understand the paper. To understand this figure, we first need to know about options and abstract state representations, and how they simplify planning.\n\n* In Section 4.2, it is unclear whether $\\mathcal{L}^T_{\\theta, \\phi}$ is used to update $f_\\phi$ or not.\n\n* For multi-goal experiments in the paper, using the same amount of environment steps for the abstract planning and the ground baseline would make it easier to understand how better or worse a method is.\n\n* The appendix could be included in the main paper for easier navigation.\n\n* What is the difference between Figure 7 and 8?\n\n* Training the abstract planning method longer in Figure 7 and 8 would be helpful to see how it learns. Using different x-scales for two methods is okay but it would be better to have the same scale.\n\n* Many minor typos in the paper.\n\n\n---\n\nThank you for author responses. I would love to see comparisons to Dreamer-like baselines, but couldn't find the results by the end of the rebuttal period. Thus, I keep my rating, borderline reject.",
         "507",
         "0",
         "3",
         "0.7684000000000001",
         "0.1385185185",
         "0.9183520675",
         "71",
         "48.6501",
         "0.8246",
         "iclr",
         "0.0",
         "4",
         "5",
         "5",
         "4",
         "factual",
         "4",
         "5",
         "89",
         "polite",
         "4",
         "positive",
         "4",
         "none",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "43",
         "141",
         "Reviewer-xxEb",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper introduces a novel model, PatchSynth, in the Patch-Text Pre-training (PTP) domain, aiming to improve software patch representation and description generation. Through a blend of patch understanding and generation, PatchSynth\t addresses the limitations of prior models. Empirical evaluations reveal its superior performance in patch description generation, with an ablation study further underscoring the importance of generating task training. Novelty and Importance: The work is first to propose a unimodel for patch-text understanding and related tasks. And the topic is very important in this domain.\n\n\tMelds patch understanding and generation, addressing prior models' specialization limitations.\n\n\tThe work provides a good representation and good results Unclear adaptability across diverse programming languages or coding standards. What are the considerations for deploying PatchSynth in real-world software development environments, and what infrastructure would be required for efficient and secure operation?",
         "136",
         "0",
         "0",
         "0.7967000000000001",
         "0.30636363640000003",
         "0.944865346",
         "50",
         "11.6712",
         "0.0364",
         "iclr",
         "0.0",
         "3",
         "4",
         "2",
         "3",
         "partially factual",
         "3",
         "3",
         "50",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "2",
         "3",
         "3",
         "2",
         "factual",
         "4",
         "3",
         "60",
         "polite",
         "4",
         "positive",
         "4",
         "moderate",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "44",
         "141",
         "Reviewer-4kdr",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper discusses a new model, PatchSynth, in the domain of Patch-Text Pre-training (PTP) which aids in accurate patch representation for software evolution tasks like bug fixing and feature enhancement. PatchSynth is designed to balance patch understanding and generation, overcoming limitations of previous models. It outperforms existing models in patch description generation, as shown in experiments using standard evaluation metrics. An ablation study further reveals the importance of generating task training in improving PatchSynth performance. Novelty:\nThe novelty of PatchSynth lies in its harmonious synthesis of patch understanding and generation, coupled with an advanced synthetic description generator. This innovative approach addresses the historical challenges of accurate patch representation and description generation, marking a significant stride in the PTP paradigm.\nImportance:\nThe topic is of paramount importance as it addresses a critical need in software engineering for accurate patch representation and description, which are pivotal for collaborative development, systematic documentation, and rapid code review processes. By advancing the PTP paradigm, PatchSynth not only contributes to the academic discourse but also holds promise for practical applications in software development workflows.\nThe work achieves promising results. The paper doesn't elucidate how PatchSynth adapts to varying programming languages or codebases with differing coding standards and structures. This lack of demonstrated adaptability could limit its applicability across diverse software projects, potentially requiring additional tuning or re-training to maintain accuracy and effectiveness in different environments. 1. Given the advancements in PatchSynth for patch-text understanding and generation, how well does the model perform in a transfer learning scenario? Can PatchSynth be fine-tuned or adapted effectively to related tasks in software engineering or different programming languages?\n2. Are there considerations or plans for deploying PatchSynth in real-world software development environments? How would the integration look like, and what kind of support or infrastructure would be required to ensure the model operates efficiently and securely in a production setting?",
         "310",
         "0",
         "2",
         "0.8356",
         "0.18839531680000002",
         "0.9401642680000001",
         "50",
         "9.2899",
         "0.068",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "88",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "5",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "45",
         "141",
         "Reviewer-H6rR",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "This paper tackles the problem of code patch representation learning -- how to represent edits on code to support downstream tasks like commit message generation, patch correctness assessment, etc. \n\nThis paper proposes a pretraining framework, with triplet losses on text-code contrastive loss, text-code matching loss and text generation loss based on code patch. The pretraining data includes 90K pairs of code change and synthesized commit messages. \n\nOn downstream task of commit message generation upon FIRA\\[1\\] dataset, PatchSynth showed performance gains over public & self-ablation baselines.\n\n\\[1\\] Jinhao Dong, Yiling Lou, Qihao Zhu, Zeyu Sun, Zhilin Li, Wenjie Zhang, and Dan Hao. Fira: Fine-grained graph-based code change representation for automated commit message generation. 2022. 1. Unlike from previous approaches(CCRep\\[1\\], Cache\\[2\\]) where code change is encoded with two streams (code-before-change, code-after-change), this work encodes code change(patch) with a standard transformer on a single patch file (like git commit diff). This is inline with the general trend in LLMs community that ultimately LLMs should be able to understand and capture internal structure without explicitly modelling it.\n2. This paper applies representation pretraining with triplet losses -- which is quite known in multimodal pretraining domain (BLIP\\[3\\], BLIP-2\\[4\\], etc) -- to code patch representation. It empirically showed that such pretraining is helpful for downstream task of commit message generation.\n\n\n\\[1\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[2\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022.\n\n\\[3\\] Junnan Li, Dongxu Li, Caiming Xiong, & Steven C. H. Hoi (2022). BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. In ICML (pp. 12888–12900). PMLR.\n\n\\[4\\] Junnan Li, Dongxu Li, Silvio Savarese, & Steven C. H. Hoi (2023). BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models. In ICML (pp. 19730–19742). PMLR. I have multiple major concerns on the paper based on its current form. The most concerning issues are:\n\n1. The paper claims \"The core part of PATCHSYNTH lies a state-of-the-art synthetic description generator\" in multiple places (3rd paragraph of Introduction, 2nd contribution in last part of Introduction, Section 2.3). However, there is no details on this synthetic description generator. The only mention is Section 4.4 with just one line \"Capitalizing on benchmarks from seminal works\\[1,2\\], our dataset, primarily focused on Java samples includes 90,661 patches with their **attendant** descriptions\"\n\n    i. Are these **attendant** descriptions generated by the author but simply taken from \\[1,2\\]? If the latter, then claiming such synthetic description generation as a key feature in this paper is highly problematic.\n\n2. The task of representation learning of code patch, defaultly assigns 1 vector for a code patch (w/ 1 or more edits), which is the case for all previous works including CC2Vec\\[3\\], CCRep\\[4\\], Cache\\[5\\]. However, PATCHSYNTH seems to encode the code patch to a sequence of vectors (Figure 1). \n\n    i. Such change needs explicit explanation and justification which authors have failed to deliver.\n\n3. Missing LLM baselines: with code patch being encoded with a sequence of vectors, the authors should compare with code-aware LLMs like Code-llama, or WizardCoder, as they also encode code patch to a sequence of vectors. \n    \n    i. As the recent code-aware LLMs have shown great abilities in general instruction following in coding-related tasks, a very timely baseline would be applying code-aware LLMs to the downstream task of commit message generation, with few-shot prompting or finetuning. \n\n    ii. A comparison of PATCHSYNTH vs code-aware LLMs would very helpful for the community to understand the edge and relevance of the proposed method in LLM era, which the authors have failed to deliver.\n\n4. Only 1 downstream task evaluated: The authors claimed that the method is designed both for generative and discriminative tasks. However, the empirical experiments were only conducted on commit message generation. As the encoding changed from one vector to a sequence of vectors, it's important to show how can such encoding can be adapted to tackle retrieval or classification tasks. Also, to claim it as a pretrain model, the authors need to evaluate on multiple downstream datasets.\n\n5. Fairness in comparison: \n\n    i. Is PATCHSYNTH firstly pretrained on 90K and then finetuned on 75K data of FIRA? If so, it's not so fair to compare PATCHSYNTH with CCRep and FIRA methods, as they are not trained on 90K pretraining data. For example, Is it possible to also pretrain CCRep with 90K data?\n\n    ii. As mentioned in point 2, CCRep has a more compact encoding of 1 vector while PATCHSYNTH encodes to a sequence of vectors. It is thus not fair to compare without explicitly mentioning such differences.\n\n6. Concerns on Pretraining:\n\n    i. details of creating negative pairs: one common technique in contrastive training is hard-negative-mining. However, the authors didn't disclose how they create negative pairs\n\n    ii. For vision-language representation learning, a large batch size (>= 512) and a large pool to select negative examples have been shown to be necessary. This paper mentions the batch size of 32, which seems pretty small. I will need more verification on ablation of 1) batch size, 2) negative example selection and 3) pretraining metrics to be convinced that such setting is adequate for code-text representation pretraining. \n\n7. Writing & formatting issues\n\n    i. On page 8, the chart of Figure 2 is partially blocked by its top legend\n\n    ii. On page 8, the paragraph for \\[Performance cross different patch attention\\] is repetitive: it repeats twice in introducing the numerical performance. Besides, I don't think it's a good idea to verbosely list down all numbers when they are clearly seen in Figure 2.\n\n    iii. In Section 2.1, there's no mention on recent code aware LLMs like Code-LLaMA. \n\n    iv. In Section 2.3, there's no citation to any work. Besides, CCRep\\[4\\] doesn't have the gap mentioned in Section 2.3 as it can both do discriminative and generative tasks and it doesn't reply on AST information. So an explicit comparison to CCRep in Related Work should be present.\n\n\\[1\\] Robert Dyer, Hoan Anh Nguyen, Hridesh Rajan, and Tien N Nguyen. Boa: A language and infras\u0002tructure for analyzing ultra-large-scale software repositories. In 2013 35th International Confer\u0002ence on Software Engineering (ICSE), pp. 422–431. IEEE, 2013.\n\n\\[2\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[3\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[4\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[5\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022. 1. Why did you use CodeBERT to initiate both text encoder and decoder? For example, did you consider encoder-decoder model like Code-T5?\n\n2. In Experiment Setup, you mentioned \"Model dimensions are meticulously calibrated\". May I know how are the hyper-parameters searched? Are you using the downstream task performance or some pretraining metrics?",
         "1254",
         "27",
         "37",
         "0.7999",
         "0.069050849",
         "0.8986387253",
         "50",
         "47.6556",
         "0.1651",
         "iclr",
         "0.0",
         "4",
         "2",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "1.0",
         "4.0",
         "3.0",
         "4.0",
         "partially factual",
         "2.0",
         "3.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "4.0",
         "moderate",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "4",
         "5",
         "90",
         "neutral",
         "5",
         "negative",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "85",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "46",
         "28",
         "Reviewer-xyNq",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper considers the problem of certifying individual fairness (IF), which is of great importance to reliable machine learning algorithms. To this end, the authors propose a novel convex relation of IF constraints that greatly reduces the computational cost. In addition, the authors propose to certify distributional individual fairness, ensuring that the neural network has guaranteed individually fair predictions for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball. 1. This paper is technically sound.\n2. The extensive experiments validate the effectiveness of the proposed methods. The paper studies individual fairness and distributional fairness. To my opinion, the two topics seem to be independent. However, it is possible that I misunderstand this paper. It would be better if the authors can present more relations between these topics. ## Miscellaneous\n1.\tLine 106: feed forward $\\to$ feedforward\n2.\tLine 168: $d$ is indeed a vector; however, the denotation $\\sqrt{d}$ should be defined more specifically.\n none",
         "156",
         "0",
         "5",
         "0.8035",
         "0.28125",
         "0.9500498772",
         "215",
         "29.3366",
         "0.1213",
         "neurips",
         "0.0",
         "3",
         "5",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "60",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "5",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "47",
         "28",
         "Reviewer-Lpfq",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper studies formal guarantees for notions of individual fairness (IF) for predictors given by neural network models. After relaxing common definitions for IF metrics by means of $\\ell_\\infty$ balls (or orthotopes), they adapt methodology based on adversarial robustness to provide upper and lower bounds to the IF achieved by models on an empirical sample - and those within a $\\gamma-$Wasserstein ball about it. - This paper studies an important problem of individual fairness\n- The first half of the paper, Section 3 and 4, which cover Background, the DIF definition, and problem explanation are very clear and easy to understand. - The key observation and novelty in the approach is not clearly noted (See below)\n- Several of the nice advantages of their method (e.g efficiency) are not explained (see below). 1. Numerous times in the paper the authors say their bounds are ”efficient” because they leverage efficient methods (e.g. those based on bound propagation). While that may be true, it would be nice for the readers if they provided a brief explanation as to why these methods are efficient instead of placing everything in the appendix. \n2. It seems to me that the central novelty of this paper is to upper bound a mahalanobis metric (for $d_{fair}$) with an orthotope, which is quite simple. The remaining of the paper seems to me a direct application of results and methods in adversarial robustness. While I do appreciate the observation of being able to use those tools in the context of fairness - which also constitutes novelty - I would appreciate if the authors could be very clear about what are the main technical contributions of this work.\n3. Personally, I am not sure providing a section on the impact of these methods on group fairness is necessary. I’d much rather prefer a discussion on the efficiency of the bounds.\n4. Figure 1 is quite confusing. What makes the blue-star individuals likely? As presented, those blue-star points do not look likely. If I understand the figure correctly, the authors should present a more balanced empirical sample together with a larger sample representing the (unobserved) population. \n5. I also have problems with the fact that the authors state their goals and present their definitions in terms of expectation (e.g. as in Def 2), but simply restrict themselves to studying empirical samples. I think the presentation is misleading, because nowhere the authors really provide guarantees for the definition in Def 2 (that is, risk bounds). This is also an important limitation where the study the Wasserstein distance between distributions, as they simply regard their distribution as a one supported on Dirac functions (on the observed samples). \n6. Immediately after Eq (4), the authors write that “we can optimize this bound to be tight”. I don’t think this is correct: while they can indeed optimize the bound, there’s no guarantee that the bound will be tight, as the original problem is non-concave.\n7. In Section 5.4 and after presenting $\\mathcal L_{F-DIF}$, the authors mention when $\\gamma=0$, one recovers a local constraint on individual fairness on $x\\in X$. I don’t think this is completely accurate, because again, Def. 2 is defined in expectation of $x\\sim p(x)$, not simply over the empirical sample. The authors mention that they do not foresee negative societal impacts. Maximizing upper and lower bounds is great but in doing so we don’t really know what is happening to the true fairness violation. It may be that the true fairness violation is in fact increasing which is propagating unfairness. While I understand that solving for this value is not feasible and thus appreciate the results presented, I would also like the paper to acknowledge that there are potential negative effects.",
         "619",
         "0",
         "7",
         "0.7891",
         "0.1001929392",
         "0.9119418859",
         "215",
         "46.7646",
         "0.6521",
         "neurips",
         "0.0",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "48",
         "28",
         "Reviewer-FRnw",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper studies the problem of individual fairness in supervised learning. The focus is on studying how to certify distributional individual fairness (IF) (individual fairness over a set of distributions close to the observed empirical data distribution) in neural networks. Prior work has focused largely on certifying global IF, which is more expensive and thus can only be applied to smaller neural networks than the proposed certification/debiasing technique. The contributions of the paper are in showing how to certify distributional IF in neural networks and then using these bounds in the training process as regularizers to debias NNs. \n\nThe main methodology for certifying IF is presented in Section 5. The first step is to certify local IF by over-approximating the similarity ball to find a conservative estimate of the IF violation. They can then use this bound to certify distributional IF around the empirical data distribution and apply finite sample guarantees to give an estimate of the true distributional IF. \n\nThe authors then show how to use the bounds on distributional fairness as regularizers in the training procedure as a way to debias neural networks. They then provide experimental evaluation on a few benchmark datasets that demonstrates that their proposed training method indeed improves distributional individual fairness, at relatively modest degradations in accuracy.  The main advantage is a relatively lightweight way to certify and train NNs for IF, in a way that requires little additional computation, compared to previous methods which are not able to scale to large NNs. \n\nThe experimental evaluation seems to confirm that DIF training as proposed by the regularization method does in fact improve significantly improve IF at modest degradation in classification accuracy.  Section 5 is a little dense and it would be helpful for the reader if there was a little more discussion of the optimization procedure, particularly in Section 5.3. Theorem statements here might also be helpful for the reader to understand what the final guarantees are.  What is the purpose of Table 2? It is a little difficult to interpret the punchline - it just seems to indicate that DIF training does not have a consistent effect on group fairness measures, either positively or negatively.  -",
         "363",
         "0",
         "1",
         "0.7939",
         "0.0286027569",
         "0.9569676518",
         "215",
         "26.5652",
         "0.0354",
         "neurips",
         "0.0",
         "4",
         "4",
         "3",
         "3",
         "factual",
         "3",
         "4",
         "60",
         "neutral",
         "3",
         "negative",
         "4",
         "high",
         "4",
         "4",
         "4",
         "5",
         "5",
         "5",
         "5",
         "85",
         "5",
         "5",
         "neutral",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "49",
         "41",
         "Reviewer-viiH",
         "Contrastive Retrospection: honing in on critical steps for rapid learning and generalization in RL",
         "In real life, success is often contingent upon multiple critical steps that are distant in time from each other and from the final reward. These critical steps are challenging to identify with traditional reinforcement learning (RL) methods that rely on the Bellman equation for credit assignment. Here, we present a new RL algorithm that uses offline contrastive learning to hone in on these critical steps. This algorithm, which we call Contrastive Retrospection (ConSpec), can be added to any existing RL algorithm. ConSpec learns a set of prototypes for the critical steps in a task by a novel contrastive loss and delivers an intrinsic reward when the current state matches one of the prototypes. The prototypes in ConSpec provide two key benefits for credit assignment: (i) They enable rapid identification of all the critical steps. (ii) They do so in a readily interpretable manner, enabling out-of-distribution generalization when sensory features are altered. Distinct from other contemporary RL approaches to credit assignment, ConSpec takes advantage of the fact that it is easier to retrospectively identify the small set of steps that success is contingent upon (and ignoring other states) than it is to prospectively predict reward at every taken step. ConSpec greatly improves learning in a diverse set of RL tasks. The code is available at the link: https://github.com/sunchipsster1/ConSpec",
         "This paper proposes contrastive introspection (ConSpec), an algorithm for learning a set of prototypes for critical states via the contrastive loss. ConSpec works by delivering intrinsic rewards when the current states match one of the prototypes. This paper also conducted experiments in various environments. The intuition of learning the critical states is natural and easy to follow. The experimental results in this paper look solid and promising. Despite the empirical performance, the reviewer finds the ConSpec algorithm itself hard to follow.\n\nThe largest weakness is: the insufficient discussion on how the prototypes $h_i$ are learned. Hence, the reviewer cannot understand the detailed on how $h_i$ are used (see detailed in Questions). \n\nBesides insufficient discussion on the prototypes, some minor issues are: (1) the title in the pdf (Contrastive Introspection:. ..) seems to mismatch with the one appear in openreview (ConSpec: …). (2) The font of citations appears to be confusing. E.g., from line 19-20 in the introduction, the manuscript uses (number) to address some key points, and the citation also appears as (number) – it would be nice if the citation can be changed to something that is not (number; number).\n Per the major weaknesses:\n1. How are the prototypes $h_i$ actually learned? If the reviewer understands correctly, in line 7 of the abstract, the manuscript says “ConSpec learns a set of prototypes…”. While in Algorithm 1, it seems that the prototypes $h_i$ are given to the algorithm as inputs. Maybe the author can clarify why this inconsistency in learning the prototypes happens?\n2. How are the $h_i$ learned/chosen in each experiment? The reviewer has looked into the detail of the experiments in the appendix, but cannot clearly understand how the presented experiments actually utilize the $h_i$. It would be nice that the authors can provide more details of all the $h_i$ in all the present experiments (Sec. 4.1-4.5).  \n See questions and weaknesses.",
         "313",
         "0",
         "2",
         "0.7000000000000001",
         "0.0809294872",
         "0.8764749765000001",
         "216",
         "48.5775",
         "0.0354",
         "neurips",
         "0.0",
         "2",
         "4",
         "3",
         "2",
         "factual",
         "4",
         "3",
         "60",
         "polite",
         "3",
         "neutral",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "78",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ]
       ],
       "shape": {
        "columns": 81,
        "rows": 395
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>review_text</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>...</th>\n",
       "      <th>Phi_Constructiveness</th>\n",
       "      <th>Phi_Factuality</th>\n",
       "      <th>Phi_Fairness</th>\n",
       "      <th>Phi_Objectivity</th>\n",
       "      <th>Phi_Overall_Quality</th>\n",
       "      <th>Phi_Politeness</th>\n",
       "      <th>Phi_Relevance_Alignment</th>\n",
       "      <th>Phi_Sentiment_Polarity</th>\n",
       "      <th>Phi_Usage_of_Technical_Terms</th>\n",
       "      <th>Phi_Vagueness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-7mFW</td>\n",
       "      <td>Seizing Serendipity: Exploiting the Value of P...</td>\n",
       "      <td>Learning high-quality $Q$-value functions play...</td>\n",
       "      <td>This work focuses on the Q-function value over...</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.124510</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-FAWm</td>\n",
       "      <td>Seizing Serendipity: Exploiting the Value of P...</td>\n",
       "      <td>Learning high-quality $Q$-value functions play...</td>\n",
       "      <td>This paper presents the Blended Exploitation a...</td>\n",
       "      <td>432</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.158831</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-kjkr</td>\n",
       "      <td>Seizing Serendipity: Exploiting the Value of P...</td>\n",
       "      <td>Learning high-quality $Q$-value functions play...</td>\n",
       "      <td>Motivated by the problem of underestimating va...</td>\n",
       "      <td>328</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.146498</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Enrico-Daga</td>\n",
       "      <td>LL(O)D and NLP Perspectives on Semantic Change...</td>\n",
       "      <td>The paper presents an overview of the LL(O)D a...</td>\n",
       "      <td>The authors have performed significant changes...</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.164583</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Julia-Bosque</td>\n",
       "      <td>LL(O)D and NLP Perspectives on Semantic Change...</td>\n",
       "      <td>The paper presents an overview of the LL(O)D a...</td>\n",
       "      <td>I reviewed a previous version of this manuscri...</td>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.169733</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>factual</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>114</td>\n",
       "      <td>Reviewer-n4fn</td>\n",
       "      <td>Mitigating Interference in the Knowledge Conti...</td>\n",
       "      <td>Continual learning (CL) remains a significant ...</td>\n",
       "      <td>The paper introduces a rehearsal-based method ...</td>\n",
       "      <td>233</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7893</td>\n",
       "      <td>0.214947</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-wEMM</td>\n",
       "      <td>FACE: Evaluating Natural Language Generation w...</td>\n",
       "      <td>Measuring the distance between machine-produce...</td>\n",
       "      <td>In order to distinguish between human-generate...</td>\n",
       "      <td>304</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>0.170294</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-s437</td>\n",
       "      <td>FACE: Evaluating Natural Language Generation w...</td>\n",
       "      <td>Measuring the distance between machine-produce...</td>\n",
       "      <td>This paper proposes a new measure of natural l...</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-mMGf</td>\n",
       "      <td>FACE: Evaluating Natural Language Generation w...</td>\n",
       "      <td>Measuring the distance between machine-produce...</td>\n",
       "      <td>This paper proposes a set of metrics based on ...</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.068210</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-v6cq</td>\n",
       "      <td>FACE: Evaluating Natural Language Generation w...</td>\n",
       "      <td>Measuring the distance between machine-produce...</td>\n",
       "      <td>This paper proposes a set of metrics to measur...</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.216739</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id       reviewer  \\\n",
       "0         166  Reviewer-7mFW   \n",
       "1         166  Reviewer-FAWm   \n",
       "2         166  Reviewer-kjkr   \n",
       "3         100    Enrico-Daga   \n",
       "4         100   Julia-Bosque   \n",
       "..        ...            ...   \n",
       "390       114  Reviewer-n4fn   \n",
       "391        75  Reviewer-wEMM   \n",
       "392        75  Reviewer-s437   \n",
       "393        75  Reviewer-mMGf   \n",
       "394        75  Reviewer-v6cq   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Seizing Serendipity: Exploiting the Value of P...   \n",
       "1    Seizing Serendipity: Exploiting the Value of P...   \n",
       "2    Seizing Serendipity: Exploiting the Value of P...   \n",
       "3    LL(O)D and NLP Perspectives on Semantic Change...   \n",
       "4    LL(O)D and NLP Perspectives on Semantic Change...   \n",
       "..                                                 ...   \n",
       "390  Mitigating Interference in the Knowledge Conti...   \n",
       "391  FACE: Evaluating Natural Language Generation w...   \n",
       "392  FACE: Evaluating Natural Language Generation w...   \n",
       "393  FACE: Evaluating Natural Language Generation w...   \n",
       "394  FACE: Evaluating Natural Language Generation w...   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    Learning high-quality $Q$-value functions play...   \n",
       "1    Learning high-quality $Q$-value functions play...   \n",
       "2    Learning high-quality $Q$-value functions play...   \n",
       "3    The paper presents an overview of the LL(O)D a...   \n",
       "4    The paper presents an overview of the LL(O)D a...   \n",
       "..                                                 ...   \n",
       "390  Continual learning (CL) remains a significant ...   \n",
       "391  Measuring the distance between machine-produce...   \n",
       "392  Measuring the distance between machine-produce...   \n",
       "393  Measuring the distance between machine-produce...   \n",
       "394  Measuring the distance between machine-produce...   \n",
       "\n",
       "                                           review_text  length_words  \\\n",
       "0    This work focuses on the Q-function value over...           273   \n",
       "1    This paper presents the Blended Exploitation a...           432   \n",
       "2    Motivated by the problem of underestimating va...           328   \n",
       "3    The authors have performed significant changes...           162   \n",
       "4    I reviewed a previous version of this manuscri...           503   \n",
       "..                                                 ...           ...   \n",
       "390  The paper introduces a rehearsal-based method ...           233   \n",
       "391  In order to distinguish between human-generate...           304   \n",
       "392  This paper proposes a new measure of natural l...           345   \n",
       "393  This paper proposes a set of metrics based on ...           314   \n",
       "394  This paper proposes a set of metrics to measur...           159   \n",
       "\n",
       "     citation_count  question_count   mattr  sentiment_polarity  ...  \\\n",
       "0                 0               5  0.7173            0.124510  ...   \n",
       "1                 8              14  0.7996            0.158831  ...   \n",
       "2                 4               8  0.8027            0.146498  ...   \n",
       "3                 0               1  0.8103            0.164583  ...   \n",
       "4                 1               5  0.7741            0.169733  ...   \n",
       "..              ...             ...     ...                 ...  ...   \n",
       "390               4               2  0.7893            0.214947  ...   \n",
       "391               2               8  0.8037            0.170294  ...   \n",
       "392               0               1  0.8233            0.074735  ...   \n",
       "393               0               5  0.8096            0.068210  ...   \n",
       "394               0               5  0.8219            0.216739  ...   \n",
       "\n",
       "     Phi_Constructiveness     Phi_Factuality  Phi_Fairness  Phi_Objectivity  \\\n",
       "0                       4  partially factual             3                4   \n",
       "1                       4  partially factual             4                4   \n",
       "2                       4  partially factual             4                3   \n",
       "3                       4            factual             4                4   \n",
       "4                       5            factual             5                5   \n",
       "..                    ...                ...           ...              ...   \n",
       "390                     4  partially factual             3                3   \n",
       "391                     3  partially factual             3                3   \n",
       "392                     4            factual             4                4   \n",
       "393                     4  partially factual             4                4   \n",
       "394                     3  partially factual             4                3   \n",
       "\n",
       "    Phi_Overall_Quality  Phi_Politeness  Phi_Relevance_Alignment  \\\n",
       "0                    75          polite                        5   \n",
       "1                    85          polite                        5   \n",
       "2                    78         neutral                        5   \n",
       "3                    85          polite                        5   \n",
       "4                    95          polite                        5   \n",
       "..                  ...             ...                      ...   \n",
       "390                  75          polite                        4   \n",
       "391                  65         neutral                        4   \n",
       "392                  85          polite                        5   \n",
       "393                  85          polite                        5   \n",
       "394                  75          polite                        4   \n",
       "\n",
       "     Phi_Sentiment_Polarity  Phi_Usage_of_Technical_Terms  Phi_Vagueness  \n",
       "0                   neutral                             4            low  \n",
       "1                   neutral                             3            low  \n",
       "2                  negative                             5            low  \n",
       "3                  positive                             3            low  \n",
       "4                  positive                             4            low  \n",
       "..                      ...                           ...            ...  \n",
       "390                 neutral                             4            low  \n",
       "391                negative                             4            low  \n",
       "392                 neutral                             5            low  \n",
       "393                 neutral                             3            low  \n",
       "394                positive                             4            low  \n",
       "\n",
       "[395 rows x 81 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop following columns: assessor, Comprehensiveness, Usage_of_Technical_Terms, Factuality, Sentiment_Polarity, Politeness, Vagueness, Objectivity, Fairness, Actionability, Constructiveness, Relevance_Alignment, Clarity_and_Readability, Overall_Quality, authors, review_date, review_rating, review_confidence, review_soundness, review_presentation, review_contribution\n",
    "df_merge = df_merge.drop(columns=['assessor', 'Comprehensiveness', 'Usage_of_Technical_Terms', 'Factuality', 'Sentiment_Polarity', 'Politeness', 'Vagueness', 'Objectivity', 'Fairness', 'Actionability', 'Constructiveness', 'Relevance_Alignment', 'Clarity_and_Readability', 'Overall_Quality', 'authors', 'review_date', 'review_rating', 'review_confidence', 'review_soundness', 'review_presentation', 'review_contribution'])\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv('human_llms_qmetrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load df_human_llms_qmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hedging",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Human_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Human_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Human_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qwen_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Qwen_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Actionability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Clarity_and_Readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Comprehensiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Constructiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Fairness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Objectivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Overall_Quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Relevance_Alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Llama_Usage_of_Technical_Terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Llama_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "GPT_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GPT_Vagueness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Actionability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Clarity_and_Readability",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Comprehensiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Constructiveness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Factuality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Fairness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Objectivity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Overall_Quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Relevance_Alignment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Sentiment_Polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Phi_Usage_of_Technical_Terms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Phi_Vagueness",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d98d2a61-7a3c-4181-8814-946edb77f08c",
       "rows": [
        [
         "0",
         "166",
         "Reviewer-7mFW",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This work focuses on the Q-function value overestimation issue. Observing that the overestimation issue will latter becomes underestimation during the learning process. Thus motivated, this work proposes the Blended Exploitation and Exploration (BEE) operator to take advantage of the historical best-perforation actions. The proposed operator is then used in both model-free and model-based settings and show better performance than previous methods. 1. The proposed BEE operator utilizes the Bellman exploitation operator and exploration operator to address the under-exploitation issue. The proposed operator can be easily incorporated into the RL algorithms.\n2. The experiments show that the proposed operator can effectively reduce the estimation error and achieve better performance comparing with other RL algorithms. 1. The terminology can be misleading. The overestimation issue in the Q-value approximation generally is due to the changing order of expectation and $\\max$. It is incorrect to say that  the $Q$-function will have \"underestimation when encountering successes\" in Fig 1 (a). The authors need to clarify the context and difference of the statement in order to avoid confusion.\n2. In order to investigate on the under-exploitation, the metric $\\Delta(\\cdot,\\cdot)$ is defined on the current Q-function approximation. Intuitively,   $\\Delta(\\cdot,\\cdot)$ shows that the current Q-function approximation can be either overestimate or underestimate given different policy, i.e., $\\mu_k$ and $\\pi_k$. It is unclear what is the meaning of this metric. Considering most of the algorithm will update the policy and Q-function approximation at the same time, e.g., Actor-Critic, the Q-function should be evaluated under the current policy instead of the policy obtained earlier. The authors need to clarify why the definition here makes sense for the under-exploitation investigation. See the weakness above.",
         "273",
         "0",
         "5",
         "0.7173",
         "0.1245098039",
         "0.8775630593",
         "49",
         "22.7412",
         "0.0999",
         "iclr",
         "0.0",
         "4",
         "4",
         "2",
         "3",
         "factual",
         "4",
         "4",
         "67",
         "polite",
         "4",
         "neutral",
         "4",
         "high",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "partially factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "neutral",
         "4",
         "moderate",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "1",
         "166",
         "Reviewer-FAWm",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "This paper presents the Blended Exploitation and Exploration (BEE) operator, which addresses the issue of value underestimation during the exploitation phase in off-policy actor-critic methods. The paper highlights the importance of incorporating past successes to improve Q-value estimation and policy learning. The proposed BAC and MB-BAC algorithms outperform existing methods in various continuous control tasks and demonstrate strong performance in real-world robot tasks. - The paper addresses an important issue in off-policy actor-critic methods and proposes a novel approach to improve Q-value estimation and policy learning. \n- The BEE operator is simple yet effective and can be easily integrated into existing off-policy actor-critic frameworks.\n- The experimental results demonstrate the superiority of the proposed algorithms in various continuous control tasks and real-world robot tasks. 1. The novelty of the proposed approach is limited. \n2. The choice of $\\lambda$ is largely empirical and requires extra manipulation in new tasks.\n3. The paper only provides basic theoretical analysis, such as the accurate policy evaluation and the guarantee of policy improvement. The benefit of linearly combining two Q-value functions is not discussed theoretically.\n4. The experiments are conducted in continuous control tasks with dense rewards. The exploration ability can be better evaluated in environments with sparse rewards.\n5. There is a lack of discussions with related papers (See Question 3). 1. Emprically, the BAC algoithm will only be more efficient in exploiting the replay buffer. The exploration still rely on the maximum-extropy formulation in SAC. Then why can BAC perform significantly better than SAC in failure-prone scenarios such as HumanoidStandup, as if BAC can better explore the unknown regions?\n2. Can you discuss or exhibit the performance of BAC in some tasks with sparse rewards? This can demonstrate the generalizability of the proposed approach.\n3. What are the advantages of BAC compared with prioritized replay methods \\[1,2\\] or advantage-based methods \\[3\\]? These methods are related to BAC in that they also exploit the replay buffer with inductive bias, so they should be mentioned in the paper.\n\n\\[1\\] Sinha, S., Song, J., Garg, A. &amp; Ermon, S.. (2022). Experience Replay with Likelihood-free Importance Weights. Proceedings of The 4th Annual Learning for Dynamics and Control Conference.\n\n\\[2\\] Liu, X. H., Xue, Z., Pang, J., Jiang, S., Xu, F., & Yu, Y. (2021). Regret minimization experience replay in off-policy reinforcement learning. Advances in Neural Information Processing Systems, 34, 17604-17615.\n\n\\[3\\] Nair, A., Gupta, A., Dalal, M., & Levine, S. (2020). Awac: Accelerating online reinforcement learning with offline datasets. arXiv preprint arXiv:2006.09359.\n\n\nI am willing to raise my score if my concerns for weaknesses and questions are adequately discussed.",
         "432",
         "8",
         "14",
         "0.7996000000000001",
         "0.1588311688",
         "0.8829935789000001",
         "60",
         "31.9755",
         "0.1565",
         "iclr",
         "0.0",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "86",
         "polite",
         "5",
         "neutral",
         "4",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "2",
         "166",
         "Reviewer-kjkr",
         "Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic",
         "Learning high-quality $Q$-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. \nPrevious works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. \nDeviating from the common viewpoint, we observe that $Q$-values are indeed underestimated in the latter stage of the RL training process, \nprimarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer.\nWe hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency.\nOur insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism.\nWe propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates $Q$-value using both historical best-performing actions and the current policy. \nThe instantiations of our method in both model-free and model-based settings outperform state-of-the-art methods in various continuous control tasks and achieve strong performance in failure-prone scenarios and real-world robot tasks",
         "Motivated by the problem of underestimating values in the training of SAC, this paper introduces the Blended Exploitation and Exploration (BEE) operator, which calculates the TD target based on a combination of the standard TD target and a high expectile of the return distribution. The authors integrate this operator in both model-free and model-based scenarios, followed by a comprehensive experimental evaluation. 1. The paper contains extensive experiment results on both simulation and real-world environments.\n2. The paper is written clearly and easy to follow. Figure 1 provides a decent visualization of the underestimation issue. 1. The BAC method tunes its $\\lambda$ and $\\tau$ differently for tasks in MuJoCo and DMC (Table 1 & 5). It's questionable to claim superiority over other state-of-the-art (SOTA) methods like SAC and TD3, which use consistent hyperparameters (HP) across tasks. Adjusting HP for each task can inflate results as seen in Figure 5, which can be misleading. Why not showcase the automatic $\\lambda$ tuning methods from Appendix B.3.3 in the main text if they're effective?\n\n2. Figure 23 reveals that SAC, without the double-Q-trick, still underestimates in the Humanoid task. It's unclear if this is universally true. More convincing results would come from testing this across multiple tasks and providing absolute Q value estimates. I still suspect that Q underestimation largely stems from the double Q techniques, as suggested by the RL community \\[1\\]. For instance, OAC \\[1\\] introduces $\\beta_{\\text{LB}}$ to manage value estimation issues.\n\n3. Presuming the Q value underestimation problem is widely recognized (which I invite the authors to contest), the paper seems to lack innovation. The BEE operator, at its core, appears to be a fusion of existing Bellman operators.\n\n4. The statement \"BEE exhibits no extra overestimation\" seems conditional on specific $\\lambda$ and $\\tau$ values. For instance, using $\\lambda = 1$ and $\\tau = 1$ could induce overestimation.\n\n\\[1\\] Ciosek, Kamil, et al. \"Better exploration with optimistic actor critic.\" Advances in Neural Information Processing Systems 32 (2019). See Weakness",
         "328",
         "4",
         "8",
         "0.8027000000000001",
         "0.1464980159",
         "0.8531657457",
         "61",
         "35.3958",
         "0.1507",
         "iclr",
         "0.0",
         "5",
         "5",
         "3",
         "5",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "80",
         "polite",
         "5",
         "negative",
         "5",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "partially factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "3",
         "100",
         "Enrico-Daga",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "The authors have performed significant changes to the content, which significantly improve the article with respect to the previous submission. Following the four SWJ criteria for survey articles, the current version is indeed a good (1) introductory text, targeted at researchers, PhD students, or practitioners, to get started on the covered topic.  The addition of a methodology section gives reasonable justification for (2) how comprehensive and how balanced are the presentation and coverage. However, a few more details about the sources of the survey would be useful, especially if mentioning keywords and phrases used in the search (Scopus? Google Scholar? Microsoft Academia? …). In addition, it is still a bit opaque what is intended with \"refining and balancing the structure of the covered areas\" - end of Section 2. However, I consider these minor issues that can be fixed during the preparation of the camera-ready. Finally, the article is readable and clear (3) and the content is relevant to the community (4).",
         "162",
         "0",
         "1",
         "0.8103",
         "0.1645833333",
         "0.6678649187",
         "60",
         "31.31",
         "0.1149",
         "semanticweb",
         "0.0196078431372549",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "5",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "2",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "4",
         "100",
         "Julia-Bosque",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "I reviewed a previous version of this manuscript, for which I recommended a major revision based on the need for a clearer motivation, scope and limitations of this effort, as well as on the structure and flow of the paper at that time. In this new version the authors have addressed all my highlighted concerns: - The motivation, scope and limitations are clearly defined - The interplay between the different sections is elaborated and illustrated with a workflow diagram that facilitates reading. There are numerous references to this workflow and interlinks between the sections, resulting in a cohesive document. - More context is provided in the introductory paragraphs of each section, and the project in which this effort is carried out is clearly introduced. The relation of each section/topic with respect to the overall topic of the survey is now explicit. - The authors have improved the categorization of tools and approaches. - The tables in the appendix summarize the main approaches, tools and resources surveyed according to the proposed classification.  Taking into account these modifications, I maintain the reasons upon which I based the recommendation for acceptance in terms of the criteria for surveys: - The topic of the paper, at the intersection of humanities and the Semantic Web, is interesting and relevant for the advancement in a line of research which poses numerous challenges. - The quality of writing is good and the survey is well balanced, with a broad coverage encompassing theoretical standpoints and approaches, tools, repositories and datasets. - The granularity and length are also appropriate for the text to serve as an introductory text. Minor comments for improvement: - The authors have provided details on the methodology for the survey, indicating the different stages in the generation and keywords used in literature search. There is no explicit reference to a filtering process after those keyword-based search results, was there any filtering step? If so, which criteria were applied? - In table 3, the included resources diverge in their nature, so the current list groups together LLOD Cloud, Lila Etymological Lexicon, LingHub, and Diachronic semantic lexicon of Dutch, etc. for example. I suggest including a mark here to distinguish which resources are particularly relevant for diachronic analysis, in contrast to general LLOD resources (e.g. Lila Etymological Lexicon vs. LLOD cloud and LingHub). - The authors of [12], referenced on p. 5, mention Lemon (Lexicon Model For Ontologies), and in their diagrams (in Github)  they seem to be using OntoLex-Lemon, not its ancestor. Throughout this survey \"OntoLex-Lemon\" is the term used to refer to the 2016 Specification as the outcome of the W3C Ontology-Lexica Community Group, so for that bib. reference I would recommend to replace the mention of \"Lemon\" with \"OntoLex-Lemon\" for consistency in the whole document. *Typos*: l.19, .p. 19, right column, \"A combined resource like this, allows...\" → remove comma p. 20, l. 1, right column → remove \"(linguistic)\", already covered by the first L in LLOD Appendix tables, Table 4. → word embeddings (add pl. \"s\")",
         "503",
         "1",
         "5",
         "0.7741",
         "0.1697330447",
         "0.8522429466",
         "73",
         "34.66",
         "0.2025",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "87",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "100",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "5",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "4",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "5",
         "100",
         "Thierry-Declerck",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "Not really a lot to add. I see that the revised version of the submission was taking good care of former comments and suggestions. Just a minor point: 1) Ensure that footnotes are always placed after the punctuation signs (for consistency across the paper, se fn 2 and 3 which are not placed consistently). So, very few corrections to do.",
         "60",
         "0",
         "0",
         "0.81",
         "0.058",
         "0.6966200471",
         "105",
         "64.71",
         "0.0548",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "60",
         "polite",
         "3",
         "positive",
         "1",
         "high",
         "5",
         "5",
         "2",
         "5",
         "factual",
         "5",
         "5",
         "60",
         "polite",
         "5",
         "neutral",
         "2",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "4.0",
         "none",
         "2",
         "4",
         "2",
         "2",
         "factual",
         "4",
         "3",
         "3",
         "polite",
         "3",
         "positive",
         "1",
         "low",
         "1",
         "4",
         "1",
         "1",
         "factual",
         "3",
         "2",
         "35",
         "polite",
         "2",
         "positive",
         "0",
         "high"
        ],
        [
         "6",
         "74",
         "Reviewer-itVg",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "The authors introduced a view sampling strategy for novel view synthesis, grounded in the perspective of causal representation learning. They identified three key metrics to assess sampling performance: the fitting term, the consistency term, and the uniformity term. Additionally, they presented a novel theoretical framework addressing the sampling challenge within NeRF. 1. The introduction of the causal perspective in the view sampling algorithm holds significant potential and could serve as a foundational approach for future research in this domain.\n2. The authors meticulously lay out a comprehensive mathematical framework that not only elucidates the underlying problem but also leads to the derivation of the three pivotal terms central to their methodology.\n3. The paper stands out for its clarity and coherence, ensuring that readers, regardless of their expertise level, can grasp the concepts and findings presented.\" 1. The rationale behind the view-sampling task raises questions. In certain scenarios, acquiring additional view images can be challenging. However, when a substantial number of dense views are already available, the motivation to devise a sampling strategy for training the neural rendering model with sparse views appears insufficient. Specifically, the activeNeRF model's primary objective is to identify the most optimal camera view for capturing the training image, rather than selecting from a plethora of pre-existing images.\n2. The paper's primary contribution seems to be the introduction of a metric or loss function to evaluate the selected views. However, the absence of an ablation study that separately assesses the impact of each of these three terms is a missed opportunity for deeper understanding. As a result, the contribution feels somewhat lacking in depth.\n3. The proposed loss function presents challenges in differentiability with respect to 't'. The sampling proposal, derived from the farthest sampling strategy, may not be the most efficient approach. It appears to demand significant training resources, resulting in elevated training costs. The potential enhancements in model performance might not justify the trade-off in terms of the increased training time and resource allocation. Please see the weakness above.",
         "335",
         "0",
         "6",
         "0.7966000000000001",
         "0.1848602484",
         "0.9041278958",
         "52",
         "29.0988",
         "0.1431",
         "iclr",
         "0.0098039215686274",
         "2",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "3",
         "none",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "5",
         "5",
         "75",
         "5",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "7",
         "74",
         "Reviewer-bNPg",
         "Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives",
         "Neural Radiance Fields (NeRF) has shown promising performance on synthesize high-quality and realistic images. But it often relies on a large amount of high-quality training data. Instead of extensively sampling training samples to cover various details of scenes, a series of works have studied how to utilize prior knowledge to achieve high-quality novel view synthesis with limited training samples. However, these methods have not explored the essence of this problem, which is how to get the optimal training set under limited view inputs. \nActiveNeRF proposes a method based on an active learning scheme that evaluates the reduction of uncertainty given new inputs, selects samples that provide the maximum information gain, and adds them to the existing training set. Since it is necessary to calculate variance changes, evaluating information gain requires the ground-truth of invisible samples, which is impossible to obtain in real situations. We revisit the view sampling strategies from a causal perspective and achieve efficient sampling without requiring the ground-truth of invisible samples. We also propose a new theoretical framework for the sampling problem in NeRF. We analyze how to obtain the optimal sampling strategy based on our framework. Experiments shows that our conclusion can not only guide sampling, but also can help us design regularization term for general NeRF.",
         "This paper studies the view sampling strategies of Nerf reconstruction from a causal perspective. The authors try to solve the problem using a small subset of photos from a total of K potential views, to achieve the best reconstruction. To solve this, the authors propose to use causal represntation learning using loss by Identification Treatment Effect. They propose three terms, a normal fitting term as reconstruction loss, a consistency term to ensure consistency between visible views and invisible views and a uniformity term requires the samples to be distributed evenly. The results show the proposed strategy can provide slightly better reconstruction compared to alternative baselines in the proposed setting. * The paper proposes a novel perspective to study the view sampling problem in volumetric reconstruction using NeRF as an example. This take-away can potentially also generalize other multiview reconstruction algorithms. \n* Given its current setting, the hypothesis is validated on nerf reconstruction datasets, with small improvement compared to its baselines. * The presentation of this paper could be greatly improved. I may not have understand a lot of details correctly given its current presentation. \n  * It is very hard to read without being very familiar with ActiveNeRF and casual representation learning. Have to trace to original papers for more details. This could be added to the preliminary parts. \n  * Too many notations which makes things more complicated than needed. I don't think I found how exactly the loss of consistency term and uniformity term were calculated in (8) at runtime. As I understand, the method should be as simple as calculating the reconstruction loss using different groups of input samples. Provide an algorithm chart of how of how P^{F}, P^{hat}^{CF} and P^{CF} will greatly help. \n  * There are some notations introduced in 4.1 (e.g. P(Y|do(d))) are not explained until 4.2. \n* Overall I am not sure I understand the real-world impact of this paper using the proposed strategy. Maybe I had some misunderstanding in the details given my concern on its presentation. Please correct me if I am wrong here. The goal of this paper to find \"optimal sampling strategy for training set\", \"K_s corresponding photos as sparse sample inputs among K_d total potential views\" is hardly a real problem statement for its real-world use case, which is my biggest concern for this proposed application of causal representation learning. From sampling perspective, we can use all the K_d potential views as long as they are available. As I understand, the evaluation of the counter factual distribution will require using the non-selected but captured images as supervision, which is not how active learning is executed in real-world case. Given this setting, it makes the results also less appealing in contrast to alternative baselines (which learns to predict next-best unknown view) given the fact all images from that particular datasets are used in evaluating the sampling strategy. 1. My major question is around how the clarity of the sampling process in training time. Confirm any places I misunderstood about this paper, as I highlighted in the weakness part. \n2. I am also curious how the views are sampled finally for different groups in the final results. Provide some visualization and discussions about them can be very helpful to guide the view-sampling process in real world applications. I wonder how that indicate the connection of uniformity term and consistency term are correlated to the camera FoV and ray distributions.",
         "566",
         "0",
         "2",
         "0.8138000000000001",
         "0.1125",
         "0.8472209573",
         "52",
         "40.8228",
         "0.33",
         "iclr",
         "0.0",
         "3",
         "3",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "90",
         "polite",
         "4",
         "neutral",
         "3",
         "none",
         "5",
         "4",
         "4",
         "5",
         "partially factual",
         "4",
         "4",
         "65",
         "polite",
         "5",
         "negative",
         "5",
         "moderate",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "neutral",
         "5",
         "neutral",
         "4",
         "moderate",
         "2",
         "2",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "8",
         "194",
         "Reviewer-GDNX",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         ">**Rebuttal:** The provided details satisfy my concerns. I think this paper should be accepted after applying the agreed changes.\n\n>**TL;DR:** **Good paper.** The proposed WTA-CRS algorithm is based on the existing CRS algorithm and is used to reduce activation memory during training. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size. However, WTA-CRS comes with computational overhead, which is discussed and explore. Addressing my concerns and questions would improve my score.\n\nThe paper proposes the WTA-CRS algorithm to reduce the neural networks training activation memory, where the paper claims that activation memory is primary memory bottleneck during training. The WTA-CRS algorithm is an unbiased estimators for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size.\n\nThe WTA-CRS algorithm works by sampling columns and rows to create an unbiased estimation of the original GEMM for the backpropagation. The WTA-CRS algorithm does not alter the neural architecture, and therefore the inference speed is left in tact. The experimental section shows that WTA-CRS outperforms existing prior work and is compatible with existing PEFT techniques. WTA-CRS adds a computational overhead due to sampling, however, WTA-CRS enables training on much larger batch sizes, which results in a 1.2× higher training throughput.\n * **S.1.** The proposed WTA-CRS algorithm tackles an important problem in existing PEFT techniques, which makes LLM PEFT training more accessible to researchers with low resources.\n* **S.2.** The paper provides a theoretical analysis on WTA-CRS.\n* **S.3.** The proposed WTA-CRS algorithm outperform existing algorithms.\n* **S.4.** An anonymized code repository is provided as part of the submission for reproduction .\n  * **W.1.** Popular existing memory efficient training techniques such as tensor rematerialization (gradient checkpointing) \\[2\\]\\[3\\] and ZeRO \\[1\\] are not compared to, although some are partially discussed in Appendix A.\n* **W.2.** The experiments are conducted on single neural network architecture (T5), although the proposed technique does not seem to be confined solely to that setting.\n* **W.3.** It is common practice today to train neural networks at a lower precision (quantization), however, it is not clear whether quantization (16bit) was used. Therefore, there is insufficient proof that the combined noise of WTA-CRS and quantization would be compatible.\n\n\n**Typos.**\n* Line #62: \"Thus\" → \"Thus,\"\n* Line #240: \"mAccording\" → \"According\"\n* Line #297: \"Thus\" → \"Thus,\"\n\n\\[1\\] Ren, J., Rajbhandari, S., Aminabadi, R.Y., Ruwase, O., Yang, S., Zhang, M., Li, D. and He, Y., 2021, July. ZeRO-Offload: Democratizing Billion-Scale Model Training. In USENIX Annual Technical Conference (pp. 551-564).\n\n\\[2\\] Jain, P., Jain, A., Nrusimha, A., Gholami, A., Abbeel, P., Gonzalez, J., Keutzer, K. and Stoica, I., 2020. Checkmate: Breaking the memory wall with optimal tensor rematerialization. Proceedings of Machine Learning and Systems, 2, pp.497-511.\n\n\\[3\\] Beaumont, O., Eyraud-Dubois, L. and Shilova, A., 2021. Efficient combination of rematerialization and offloading for training dnns. Advances in Neural Information Processing Systems, 34, pp.23844-23857. * **Q.1.** In line #43 and Figure 2 it is noted that \"storing activations (or feature maps) is the main memory bottleneck during training\". Does this hold true for all model architectures? What about LLM training where the fine-tuning batch size is usually very small?\n* **Q.2.** Why was the WTA-CRS algorithm compared to the Deterministic top-k from \\[1\\] but not to the Bernoulli-CRS from \\[1\\]? What are the key differences between WTA-CRS and Bernoulli-CRS?\n* **Q.3.** The paper proposes WTA-CRS which sacrifices computation speed at the cost of lower peak memory. There are several existing common approaches (such as gradient checkpointing and DeepSpeed) for general memory efficient training which are compatible with PEFT techniques. Why are these comparisons not explored or detailed in the main paper?\n\n\\[1\\] Adelman, Menachem, Kfir Levy, Ido Hakimi, and Mark Silberstein. \"Faster neural network training with approximate tensor operations.\" Advances in Neural Information Processing Systems 34 (2021): 27877-27889. The limitations are discussed in Appendix A.",
         "669",
         "10",
         "14",
         "0.753",
         "0.0903401361",
         "0.8664653897",
         "215",
         "42.5651",
         "0.1507",
         "neurips",
         "0.0128205128205127",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "neutral",
         "4",
         "neutral",
         "5",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "9",
         "194",
         "Reviewer-j1mL",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "In this paper, we propose a new method called WTA-CRS (Winner-Take-All Column Row Sampling) to address the main memory bottleneck issue during training, which arises from storing feature maps. To reduce memory usage during training, we sample the most likely column indices during backpropagation.\n\nFurthermore, \bthey proposed method demonstrates the ability to significantly reduce peak memory usage, by approximately up to 2.7 times, when fine-tuning downstream tasks. It also showcases the potential for higher throughput, enabling more efficient training. 1. The work clearly states its motivation and its solution and is easy to follow.\n2. The authors show that their method reaches comparable performance with backpropagation using the full activation when combined with LoRA.\n3. They also empirically measure throughput gains obtained by increasing batch size, which demonstrates the practical applicability of their method. 1. The paper needs a comparative analysis of other researchs, such as gradient checkpoint/recalculation and CRS, aimed at reducing activation memory during the training phase, as shown in Fig. 6 and Fig. 9.\n2. The paper should include an analysis of the overhead associated with the proposed WTS-CRS method, which involves sampling rows and columns. It is crucial to consider factors such as the computational cost of Equation 3 and any potential effects of lowering on the overall performance. Providing this analysis would enhance the clarity and completeness of the research.\n3. There is a need of analysis on the effectiveness of the proposed approach, WTS-CRS, in distributed training environments such as tensor parallelism or pipeline parallelism.\n4. It seems necessary to conduct performance evaluations on various LLMs of the GPT family, such as LLaMA and OPT. * In Figure 9, it can be observed that the throughput of WTS-CRS is lower than that of full when the batch size is small. Is this due to the overhead caused by lowering?\n* When comparing the training throughput, how does CRS differ from full in terms of throughput?\n* Could the authors include statistics for GPU utilization in their experiments? It would be helpful to analyze the causes of improved performance more thoroughly.\n* Considering that most large models are trained using multiple levels of parallelism, would it be possible to verify results for pipeline parallel, tensor parallel, etc.? Also, it is unclear from the paper whether the data parallelism used was distributed data parallelism or naïve data parallelism. * As previously mentioned, it would be valuable to include additional experimental results for models that are more challenging to quantify, such as GPT-series (OPT, LLaMA). This would enhance the validity and applicability of the proposed method across a broader range of models.\n* Considering that most large-scale models are trained using multiple levels of parallelism, it is important to assess how much the proposed methods, such as pipeline parallelism and tensor parallelism, can increase throughput while taking into account overhead (such as GPU-to-GPU or node-to-node communication), memory reduction, and computational cost. Furthermore, it is not clear from the paper whether the data parallel processing used is distributed data parallelism or naive data parallelism.",
         "506",
         "0",
         "8",
         "0.8129000000000001",
         "0.1168538059",
         "0.8539184332",
         "215",
         "31.6518",
         "0.1355",
         "neurips",
         "0.011111111111111",
         "4",
         "3",
         "4",
         "4",
         "partially factual",
         "3",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "10",
         "194",
         "Reviewer-cMiu",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The authors studied fine-tuning LLMs with limited memory. As the increased scale of current LLMs, the memory cost during fine-tuning is of great importance when adapting the pretrained LLMs to down-streaming tasks. In contrast to the existing work that mainly focus on the number of updated weights, this paper proposed to reduce the number of stored activations, also the inputs to each layer. Given the widely used stochastic gradient descent optimization pipeline, the authors proposed to store a subset of activations that can generate an unbiased gradient estimation. This way, the training memory and the training time decreased significantly. The authors provide both theoretical and experimental analysis on their CRS methods.  - This paper studied an important problem in LLM fine-tuning, i.e., how to fine-tuning LLMs with less memory consumption without increasing the computation cost. The authors provided solid quantitative results to show that the main memory consumption is from storing the intermediate activations. \n- The authors provided a general solution for fine-tuning LLMs under memory constraints. The solution can be applied in most transformer-based network architectures.  \n- The authors provided solid mathematical proof on the unbiased gradient estimation, which is especially encouraged. \n- The extensive experiments on different network architectures showed the efficacy of the methods.\n- The released code can benefit the following researchers studying efficient LLM fine-tuning.  - I am not fully convinced by the comment made in Line241-244, i.e., the methods in the paper is orthogonal to the activation quantization. When activation is quantized into a lower bit width, it is very possible that the number of less important activations will decrease. This way, the selection on the top-k columns in activation matrices with the proposed methods may hurt the training accuracy or convergence. It would be great if the authors can provide some theoretical analysis or experimental results on this combination. Otherwise, it would be necessary to provide some comparison results w.r.t. the activation quantization.\n- It would be great if the authors can discuss the main difference of their paper w.r.t. \\[Randomized Automatic Differentiation, ICLR2021\\].\t  Overall, I think this paper has a relatively high quality in both writing and scientific contribution. Yes",
         "358",
         "0",
         "2",
         "0.7825000000000001",
         "0.1275074405",
         "0.8477004170000001",
         "215",
         "33.3958",
         "0.1262",
         "neurips",
         "0.0",
         "4",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "11",
         "194",
         "Reviewer-ky3t",
         "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model",
         "As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. \nPrevious works usually focus on reducing the number of trainable parameters in the network. \nWhile the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. \nNotably, machine learning models are typically trained using stochastic gradient descent.\nWe argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.\nFollowing this motivation, we propose a new family of unbiased estimators called \\sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.\nOur work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.\nBy replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size.\nUnder the same hardware, \\sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.\nThe code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",
         "The paper's contribution is in proposing a practical, intuitive yet not trivial unbiased approximation to gradient training of matrix multiplication. It shows that even though totally deterministic sampling is biased, somewhat deterministic sampling is unbiased, and a judicious allocation of sampling to those pairs favored by deterministic thinking can lead to the use of a larger batch size with empirically negligible performance loss. This reviewer must declare that he does not check the derivation very carefully. The proposed idea is practical and can be readily combined with virtually all first-order gradient-based training methods.\nThe paper also derived why deterministic sampling is a biased estimator and empirically shown the associated bad performance, thus proving that the additional complexity of stochastic sampling over deterministic sampling is not only sufficiently better but also necessary. It's just a few empirical comparisons, but the performance gap between CRS and WTA-CRS seems modest. This reviewer does not have a question. N/A",
         "155",
         "0",
         "1",
         "0.8418",
         "0.0621428571",
         "0.7829982042",
         "215",
         "17.3432",
         "0.1041",
         "neurips",
         "0.0109890109890109",
         "3",
         "4",
         "2",
         "3",
         "factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "2",
         "4",
         "3",
         "2",
         "5",
         "5",
         "4",
         "65",
         "neutral",
         "5",
         "positive",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "1",
         "3",
         "3",
         "1",
         "partially factual",
         "3",
         "3",
         "50",
         "polite",
         "4",
         "positive",
         "4",
         "moderate",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "12",
         "38",
         "Reviewer-vqBu",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way. The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea. The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso. - in the frequentist case, how does the proposed framework compares against more classical techniques to obtain the solution paths, e.g., iterative reweighted l1-norm?  The authors adequately addressed the limitations of their proposed framework. ",
         "170",
         "0",
         "0",
         "0.799",
         "0.32",
         "0.9384971857",
         "215",
         "30.7103",
         "0.1149",
         "neurips",
         "0.0112359550561798",
         "3",
         "4",
         "3",
         "2",
         "unfactual",
         "2",
         "2",
         "60",
         "polite",
         "3",
         "neutral",
         "2",
         "low",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "4",
         "78",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "13",
         "38",
         "Reviewer-3sWQ",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution. - Well written paper.\n\n        - Illustrative toy experiments. - The proposed method is a combination of already known techniques.\n\n        - The experimental section is weak as only a single real problem is considered.\n\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\n\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\n\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros. None The authors have not commented on the limitations of their approach.",
         "279",
         "0",
         "2",
         "0.7414000000000001",
         "-0.007047619",
         "0.9233116508",
         "215",
         "36.096",
         "0.0989",
         "neurips",
         "0.0",
         "2",
         "3",
         "3",
         "1",
         "unfactual",
         "3",
         "3",
         "60",
         "neutral",
         "3",
         "negative",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "3",
         "4",
         "65",
         "neutral",
         "5",
         "negative",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "2",
         "3",
         "3",
         "2",
         "factual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "14",
         "38",
         "Reviewer-pTVu",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\geq1}$ is used). 1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\n3. Using sub-l1 norm is suitable for structure learning. \n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \n5. The paper is well-written, and the relevant work is sufficiently discussed.    \n6. Due to its flexibility, the proposed method has the potential of having a large impact. Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \n\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \n\nMinor suggestion: \n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \n2. Fix minor typos e.g. the end sentence period in line 214. * In line 141, what do you mean by \"contradiction\"? The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \n\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.",
         "330",
         "0",
         "9",
         "0.7934",
         "0.1236940837",
         "0.8818445206000001",
         "215",
         "45.1097",
         "0.1969",
         "neurips",
         "0.0119047619047618",
         "3",
         "4",
         "3",
         "4",
         "unfactual",
         "3",
         "3",
         "60",
         "neutral",
         "4",
         "negative",
         "3",
         "low",
         "5",
         "5",
         "4",
         "5",
         "5",
         "5",
         "5",
         "90",
         "5",
         "5",
         "5",
         "5",
         "1",
         "2.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "15",
         "38",
         "Reviewer-CnQu",
         "Conditional Matrix Flows for Gaussian Graphical Models",
         "Studying conditional independence among many variables with few observations is a challenging task.\nGaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\\leq1$.\nHowever, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.\nIn the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\\lambda$.\nIn the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\\lambda$ requires repeated runs of expensive Gibbs samplers.\nHere we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.\nAs a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.\nWithin one model we thus have access to (i) the evolution of the posterior for any $\\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.",
         "This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets. Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \n\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated. Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost. In synthetic data example, why did you choose to have more samples than dimensions ( $n>d$ )? Since in that case GGM can be obtained with matrix inverse, and no need for penalized objective. Limitations were not discussed.",
         "205",
         "0",
         "2",
         "0.787",
         "0.1207251082",
         "0.8797656298000001",
         "215",
         "36.2535",
         "0.2573",
         "neurips",
         "0.0120481927710843",
         "1",
         "4",
         "3",
         "1",
         "unfactual",
         "2",
         "2",
         "50",
         "neutral",
         "3",
         "negative",
         "3",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "16",
         "13",
         "Joseph-philipraj",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This systematic review is appropriate for the journal with a global problem of Mets and Urolithiasis. The introduction part clearly explains the motivation. The manuscript is clear and balanced. The manuscript stays focused on the subject. Authors have gone through the process of searching relevant articles from all websites and of sufficient duration. The inclusion and exclusion criteria in the analysis have been clearly stated. The impact of the analysis is clearly stated. The statistical analysis supports the paper well. The interpretation of the results, visualisation are well presented. The tables and figures are clear, relevant and correct. The authors demonstrate the knowledge of basic composition skills, including word choice, sentence structure, paragraph development and grammar. Limitations:  The studies included in the meta-analysis have cross-sectional nature and hence ascertainment of temporal association is not possible which also dictates need for further prospective studies. The specific type of stone formation is not correlated with studies. Despite these limitations all studies included in the meta-analysis showed the same directionality in the association between urolithiasis and Mets.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "292",
         "0",
         "1",
         "0.7415",
         "0.1145833333",
         "0.8487246633000001",
         "39",
         "30.46",
         "0.0999",
         "f1000",
         "0.01",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "5",
         "5",
         "3",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "85.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "2",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "92",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "17",
         "13",
         "Muhammad-Faruk",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study assessed the association between metabolic syndrome and its components with the risk of developing nephrolithiasis by conducting systematic review, Bayesian random-effects meta-analysis, meta-regression and dose-response analysis. This study was done appropriately based on PRISMA flowchart. Risk of bias was also conducted of the included studies. This study has successfully presented the proper meta-analysis for this design. However, to complete this study for indexing, I personally recommended several revisions: 1. Abstract: Introduction section: It is better to address meta-regression as the analysis to assess the correlation of association along with dose-response analysis  Conclusion section: In reporting the association between predictors and nephrolithiasis, state only the predictors in which its coefficient was statistically significant 2. R language was not considered as a statistical software for data analysis. The software for data analysis should be written as \"R\" (Please refer to methods section in statistical analysis subsection). 3. Please update the PRISMA flowchart (refer to PRISMA guideline 2009). 4. Give the numbering of each Forrest plot in Figure 3 and numbering of each meta-regression plot in Figure 4. Design these figures so that it could be well presented. 5. Uniformly decide the word choice of \"traits\" or \"components\", choose whether to use traits or components in the whole text, use one of these words consistently to avoid any misunderstanding. 6. It is better to provide the meta-regression of hypertension in systolic blood pressure and diastolic blood pressure as it is important to explain the relationship to nephrolithiasis in differentiation for these two types of blood pressure. 7. Meta-regression of body mass index  was sufficient in this study thus waist circumference meta-regression was not necessary to be included. 8. Provide the value of coefficient and confidence interval of each meta-regression analysis in the result section so that better understanding of predictors-outcome relationship could be reached clearly.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "422",
         "0",
         "7",
         "0.7554000000000001",
         "0.1982758621",
         "0.9299524426",
         "270",
         "24.68",
         "0.2302",
         "f1000",
         "0.0108695652173913",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "93",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3.0",
         "5.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "5.0",
         "85.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "18",
         "181",
         "Reviewer-sna7",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This paper presents ULTRA, a single model that can be directly used/finetuned for link prediction over different knowledge graphs. The key is to model the transferrable relationships between different relations across knowledge graphs. Specifically, a NBFNet is used to learn relative relation representations and generate relation embeddings, which is then fed into another NBFNet to perform link predictions. Extensive experiments are performed over many knowledge graph to demonstrate the performance of this model. - This paper is well written and easy to follow\n- The core method around the relative relationships between relations is clever and interesting.\n- The experiments demonstrate the gains of the method. It is especially impressive to see the competitive zero-shot performance of ULTRA over different knowledge graphs. - The proposed method relies entirely on knowledge graph structure and does not consider using node embedding such as textual features of the knowledge graphs. In reality, text embedding of nodes and edges could be a better transferrable embedding. Such transferability has already been demonstrated by PRODIGY (https://arxiv.org/abs/2305.12600) and should be addressed.\n- The model does not scale well as the authors already pointed out.\n- The zero shot and fine-tuning performances are worse or on-par with the per dataset model performance, rendering pretraining not effective performance-wise. \n- Some notations are a bit hard to understand. See questions. - What are u and v in h_{u|v} in section 4.2?\n- Why are supervised SOTA baselines only reported for some datasets in Figure 4?",
         "245",
         "1",
         "1",
         "0.7559",
         "0.0971320346",
         "0.9083012938",
         "49",
         "38.7951",
         "0.072",
         "iclr",
         "0.0",
         "4",
         "4",
         "2",
         "3",
         "factual",
         "4",
         "3",
         "70",
         "neutral",
         "4",
         "positive",
         "2",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "19",
         "181",
         "Reviewer-HLbG",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "This work aims to build a foundation model for knowledge graph reasoning tasks, where the authors explore the setting of generalization to any edges and nodes, including unseen, of any multi-relational knowledge graphs without using node and edge features. To this end, the authors first construct a view of a relation-centric graph from an original graph where edges become nodes of this new relation graph, and then, based on this view, the authors represent the relation (node) relative to and conditioned on the query relation. Then, based on this relative relation representation, the authors use existing inductive link prediction methods to perform knowledge graph reasoning. The authors conduct link prediction experiments on various knowledge graphs considering both inductive and transductive settings, and show that the proposed method, namely ULTRA, outperforms other SOTA baselines sometimes without further fine-tuning on target knowledge graphs (i.e., zero-shot). * This work studies the very important, challenging, and practical setups of building a foundation model for knowledge graph reasoning, which aims to be generalizable to any other knowledge graphs involving unseen nodes and unseen edges, without leveraging features of nodes and edges. \n* The proposed method works well with different knowledge graphs, on zero-shot transfer learning setups without further fine-tuning on target knowledge graphs, and further shows the boosted performance with task-specific further fine-tuning on them, on most experiment setups.\n* This paper is very well-written and easy to follow. * I would like to note that I don't see any major weakness, and below is the minor.\n* In Section 4.2, the explanation about the indicator function with variables $u$ and $v$ is a bit unclear to me. Could you elaborate more on the process and result of the indicator function according to those two variables, perhaps with visuals?\n* Text-based methods (e.g., LM-based methods) can be generalizable to any knowledge graphs including unseen nodes and unseen edges, as long as their nodes and edges are represented with texts. In this vein, I think one potential direction for building a foundation model for knowledge graph-related tasks might be to use the LMs, and the authors may highlight this point more and potentially make comparisons between the proposed approach and text-based methods. I don't think this should be the critical weakness of this paper since text-based methods are limited to knowledge graphs with textual features; meanwhile, given the framing of this work (\"Towards Foundation Models for Knowledge Graph Reasoning\"), this point should be carefully explained. * I would like to suggest emphasizing the performance differences between inductive and transductive setups when explaining Table 1. The proposed method w/ 0-shot settings are strong on inductive graphs; meanwhile, previous methods are superior to it on transductive graphs, which are worthwhile to discuss.\n* It may be beneficial to show the results of the ULTRA fine-tuned on the knowledge graphs used for pre-training the ULTRA. I am wondering if there are further performance improvements when further fine-tuning the model on the data used for pre-training.",
         "496",
         "0",
         "0",
         "0.7682",
         "0.1549267161",
         "0.9152074456",
         "49",
         "38.4364",
         "0.3761",
         "iclr",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "3",
         "80",
         "neutral",
         "4",
         "neutral",
         "3",
         "moderate",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "5.0",
         "4.0",
         "factual",
         "5.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "4.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "20",
         "181",
         "Reviewer-c3Sg",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "Paper claims to propose a foundation model, named Ultra, for knowledge graph representation learning. The proposed model can handle full inductive graphs in which new entities and relations may appear in the test set. To do so, the authors propose to lift the graph to a one with relations as the nodes and design 4 different edge types (head2head, head2tail, tail2head, tail2tail). The relational representations are then learnt using message passing on this graph. The learnt relation embeddings are then used in the original graph to perform inductive link prediction. For the experiments, the authors pre-train their method on 3 KGs and further evaluate in a zero-shot setting and also by fine-tuning the downstream tasks. - The paper proposes a transductive model that works in settings of new relations and entity nodes.\n- The method obtains good zero-shot pretraining results. - The authors have not explicitly stated the computational complexity of the method. From the paper, it seems that the forward pass is run on the entire relational graph to obtain relation representations. This is then used to initialize the node embedding from the query triple and the process is repeated for every triple. Thus it seems that the entire graph is being used for link prediction every triple making the computational complexity O(E^2). This seems limiting for large graphs that have not been explored in the paper (such as wikidata-5m etc.).\n- From Table 2 we can see that finetuning over the pre-trained models helps the results significantly over the 0-shot setting. Also, the fine-tuning steps are too large to claim few shot results. This weakens the claim of the \"foundation model\" for KGs. A fair comparison would be to show the pretraining results for other inductive and transductive methods as well in addition to the SOTA comparison.\n- Another limitation is that of scale. Since the current model has fewer parameters, this would limit learning over larger pretraining datasets as can be seen in Figure 6 and also reported by the authors.\n- SoTA results for transductive models are better than the pre-trained Ultra model in many datasets. Thus the Ultra model seems to work well for the inductive setting rather than transductive. Thus the claim of the \"foundation model\" seems broader in scope.\n- We see that in the metafam dataset, the pretraining results are poor but on finetuning the results are improved drastically. This shows that the method works well in cases where the relational patterns of the downstream datasets are similar to the pre-trained one but when the data distribution changes the results suffer. Moreover, due to limited capacity, the model may not be able to handle such cases by increasing the pretraining datasets calling for downstream finetuning. Thus domain adaptation is not a problem which can be easily overcome by scaling the current model and this further weakens the claim of a \"foundation model\" for KGs. - For weakness point 2: Any reason why this was not done by the authors?\n- For weakness point 3: How would this be addressed in future works for the model?\n-  For weakness point 4: Could the authors comment on why this would be the case and how would the model be improved to handle the transductive setting?\n- For weakness point 5: Any reason why the results on this dataset are not good?\n- Considering KGs are a rich source of textual/semantic data along with graph/structured data and the current model does not use this rich source of context information, how can we extend Ultra to incorporate the KG ontology? \n- Considering weaknesses 2,4,5 the claim of the foundation model seems a bit broad as of now and at best the model could be said to be a good inductive learner.",
         "625",
         "0",
         "0",
         "0.7487",
         "0.1723163098",
         "0.9095818996",
         "49",
         "51.6761",
         "0.1355",
         "iclr",
         "0.0104166666666666",
         "4",
         "4",
         "4",
         "3",
         "factual",
         "3",
         "3",
         "70",
         "neutral",
         "3",
         "neutral",
         "3",
         "high",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "21",
         "181",
         "Reviewer-ebFz",
         "Towards Foundation Models for Knowledge Graph Reasoning",
         "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. \nKnowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap.\nThe key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies.\nIn this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. \nULTRA builds relational representations as a function conditioned on their interactions.\nSuch a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph.\nConducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. \nFine-tuning further boosts the performance.",
         "The key limitation of designing the foundation models for dealing with the Knowledge Graphs (KGs) is that the KGs have different entities and relations that generally do not overlap. To address this issue, this paper proposes ULTRA, which positively transfers the information of source KG to unseen KG. It constructs relation representations based on the interactions between the relations by introducing the graph of relations. The proposed approach has shown good performance on various tasks. - From their experiments, the proposed methods have shown good performance on various tasks.\n- Research topics about the foundational models on graph-structured datasets is really interesting and important.\n- The paper is well written and easy to follow. - The authors first pretrain the ULTRA model with the mixture of 3 standard KGs and then fine the model for the downstream task. But, the other supervised SOTA model only uses dataset of the downstream tasks without employing the pre-training datasets. If the supervised SOTA models are designed to deal with transductive settings, they may show worse performance on the downstream tasks. However, if the SOTA models are the models for the inductive setting, I think they may be possible to be pretrained like the ULTRA. So, could you measure the performance of the \"pretrained\" SOTA models on the inductive if possible? Please refer to the weaknesses.",
         "222",
         "0",
         "0",
         "0.7001000000000001",
         "0.1619617225",
         "0.9080925584",
         "49",
         "47.3913",
         "0.1823",
         "iclr",
         "0.0",
         "3",
         "4",
         "2",
         "3",
         "factual",
         "3",
         "3",
         "65",
         "neutral",
         "3",
         "neutral",
         "2",
         "high",
         "4",
         "5",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "2",
         "4",
         "3",
         "3",
         "factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "1",
         "4",
         "2",
         "2",
         "partially factual",
         "3",
         "2",
         "45",
         "polite",
         "4",
         "positive",
         "3",
         "low"
        ],
        [
         "22",
         "9",
         "Reviewer-KmBd",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "487",
         "0",
         "1",
         "0.732",
         "0.1304191468",
         "0.9185432792",
         "47",
         "29.0538",
         "0.1695",
         "iclr",
         "0.0",
         "4",
         "3",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "90",
         "neutral",
         "3",
         "neutral",
         "4",
         "none",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "23",
         "9",
         "Reviewer-3zCE",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "480",
         "0",
         "0",
         "0.8331000000000001",
         "0.0934353741",
         "0.9183989763",
         "47",
         "39.3732",
         "0.1932",
         "iclr",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "negative",
         "5",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "75",
         "polite",
         "5",
         "negative",
         "5",
         "low",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "3",
         "70",
         "neutral",
         "5",
         "negative",
         "4",
         "low"
        ],
        [
         "24",
         "9",
         "Reviewer-y5kB",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "41.9389",
         "0.0501",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "25",
         "9",
         "Reviewer-XNx6",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.915908277",
         "59",
         "42.2021",
         "0.929",
         "iclr",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "88",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "5",
         "4",
         "5",
         "5",
         "5",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "26",
         "81",
         "Gatot-Soepriyanto",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study investigate whether financial distress, earnings management and audit quality as determinants/moderating variable for financial statements fraud in Indonesian listed firms during 2015 to 2019 period. The authors focused on infrastructure, utility and transportation sectors. In general, the study has been designed adequately to tackle the research questions and issues posed by the authors. However, there are some elements need to be addressed to improve the paper: Whilst the study provide adequate research background and institutional setting, it did not mention on why the study focuses on infrastructure, utility and transportation sectors? Is there any specific issues on that sector that related to financial statements fraud? In addition to that, why the study chooses 2015-2019 period?  The study should also discuss the reason choosing F-Score as its main measure for financial statement fraud. Why, for example, the study did not use, Beneish M-Score? Or other accounting irregularities measures in the literature?  The study needs to provide descriptive statistics table, so the reader can gauge and understand the dataset better. This should be provided before the authors arrive with the hypothesis discussion;  Given the study uses panel data (multi years, across different firms), is there any attempt to mitigate the issues of panel data regression? For example, using year-fixed effects or even using panel data regression analysis?  The manuscript need to be checked in terms of the quality of English write up. The title for example, is a little bit confusing, as it did not really represent what the study want to achieve in general.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "400",
         "0",
         "1",
         "0.7771",
         "0.117454955",
         "0.9143848419",
         "220",
         "26.81",
         "0.0168",
         "f1000",
         "0.0204081632653061",
         "4",
         "4",
         "3",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "moderate",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "27",
         "81",
         "Toni-Šušak",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "909",
         "0",
         "5",
         "0.6798000000000001",
         "0.1225925926",
         "0.8569852710000001",
         "489",
         "50.12",
         "0.072",
         "f1000",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "5",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "5",
         "4",
         "5",
         "5",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "3",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "28",
         "24",
         "Silvio-Buscemi",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         "280",
         "0",
         "1",
         "0.7857000000000001",
         "0.1403645833",
         "0.7798862457",
         "34",
         "24.27",
         "0.3225",
         "f1000",
         "0.0105263157894737",
         "1",
         "3",
         "1",
         "2",
         "unfactual",
         "3",
         "1",
         "48",
         "polite",
         "3",
         "negative",
         "1",
         "extreme",
         "4",
         "5",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "polite",
         "5",
         "positive",
         "4",
         "low"
        ],
        [
         "29",
         "77",
         "Houcemeddine-Turki",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "This manuscript presents a novel rule-based approach for fact checking in knowledge graphs based on mining textual resources. The work provides new evidences that rule-based approaches can provide more precise evaluation of the accuracy of statements in knowledge graphs and can enhance the efficiency of embedding-based methods when combined with them. The availability of source codes and datasets in GitHub is an advantage for this work as this will allow the reproducibility of the described experimental study. However, there are several matters within the paper that should be addressed to ameliorate its final output: (i) Introduction: The \"Introduction\" seems to be a summary of \"Related Studies in Fact Checking\" rather than a proper introduction and contextualization of the paper. I propose to expand the part about misinformation fighting in the introduction to give better context for the development of this research paper. The authors can benefit from previous research papers about fact checking in general to develop the introduction of the paper. Several points in the introduction should be moved to Related Studies in Fact Checking. (ii) The paper did not emphasize the advantages of rule-based approaches when compared to embedding-based methods beyond having a better precision. Effectively, there are many other advantages of rule-based approaches. For example, the results of rule-based approaches can be more explainable than the ones of embedding-based approaches. Such advantages should be expanded and highlighted in the research paper. (iii) The paper did not emphasize the importance of having the datasets and source codes available in a specific GitHub repository. The authors should specify that this practice allows reproducibility and further development of the work by peers, particularly in the conclusion. (iv) The paper did not discuss the concept of reification in knowledge graphs. Effectively, several knowledge graphs add qualifiers to triples to provide a characteristic of the statements (i.e. {(s,p,o), p, o}. The authors should discuss the usefulness of the method to verify the qualifiers of the statements in the Discussion or as a future direction for this work. (v) The paper should evocate the robustness of the rule-based approach they proposed to adversarial attacks. This can be an advantage of the approach. (vi) There are several typos in the research paper (e.g. \"UC Berkely\" should be \"UC Berkeley\"). The authors should proofreading the paper to eliminate such deficiencies. (vii) The authors can expand the Discussion of the work (Part 5) to explain the strengths of KStream, KLinker, COPPAL, RUDIK, and PredPath that contributed to their efficiency as reported in the Experimental Study according to previous research papers. This can explicate the reasons of why the method developed by the authors was more efficient. (viii) The authors should provide future directions for the development of this work in the conclusion. Given this, I propose to accept this paper for publication after these six major revisions are applied.",
         "473",
         "0",
         "1",
         "0.7464000000000001",
         "0.1097294372",
         "0.9120528102",
         "4",
         "36.08",
         "0.2025",
         "semanticweb",
         "0.0",
         "4",
         "4",
         "3",
         "4",
         "factual",
         "3",
         "4",
         "85",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "positive",
         "5",
         "none",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "5",
         "4",
         "4",
         "5",
         "factual",
         "4",
         "4",
         "88",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "30",
         "67",
         "Reviewer-um1j",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "The paper introduces a new method for molecular modeling, QuinNet, which incorporates five-body interactions using only dihedral angles. The authors first introduce relevant concepts related to machine learning force fields and related work in the field related to a variety of equivariant models. Next, the paper describes pertinent definitions of force fields, group equivariance, and methods for calculating empirical force fields. In the methods section, the authors describe their approach for integrating five-body terms into the architecture of QuiNet using only dihedral angles and incorporating model designs from prior work (PaiNN for 3-body interactions, ViSNet for 4-body interactions) and new definitions for different topologies of 5-body interactions. In addition to the architectural description, the authors provide relevant mathematical formulations and a complexity analysis. In their results, the authors showcase QuiNets performance on a low (MD17) and high complexity (MD-22) dataset in terms of energy and force modeling, including an ablation for different body terms in Figure 5. The paper has the following strengths:\n* Originality: The proposed architecture incorporates relevant terms for molecular modeling that are physically relevant, but have not been incorporated before.\n* Quality: The method and experimental design showcase relevant cases for applying GNN models for molecular modeling with the idea behind the architecture being well-motivated.\n* Clarity: The paper presents a cohesive formulation of their method, both in figures and mathematics, and experiment descriptions with relevant takeaways.\n* Significance: The proposed architecture shows improved modeling performance, especially in forces, and provides a potential framework for incorporating physical interactions into GNNs. The paper could be improved by the following:\n* Providing a clear and concise discussion of limitations. \\[Quality, Significance\\]\n* Adding more context for the results in Figure 4. The MD simulations are only briefly described in Section 5.1, which is on a different page then the figure and easy to miss. \\[Clarity\\]\n* A description of the case in which a greater set of many-body interactions is beneficial. This is briefly mentioned in the discussion between MD17 and MD22, but it would be good to put in greater context in terms of the experimental results and could serve as part of the conclusion. \\[Clarity\\] * Could you provide additional details on the limitations of QuinNet? E.g. Is it limited to modeling mainly molecular systems? What sizes of molecules do you think QuinNet can be effective in and why?\n* Do you have data that supports your compute complexity analysis compared to other methods? If so, what kind of speedup do you generally find, if any? The authors do not provide a discussion on limitations, which I raised as a weakness. I would like to see a discussion of limitations in future versions and/or during the discussion period.",
         "452",
         "0",
         "1",
         "0.7681",
         "0.1465895563",
         "0.867398262",
         "215",
         "29.1615",
         "0.464",
         "neurips",
         "0.0",
         "5",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "5",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "5",
         "low"
        ],
        [
         "31",
         "67",
         "Reviewer-YmDt",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "In this work, the authors propose to incorporate features from five-body interaction into machine-learning force field models and develop QuinNet. To efficiently incorporate such high-order information, the authors are motivated by the topology of many-body interactions and design sophisticated components. Experiments on several benchmarks are conducted to demonstrate the performance of QuinNet. 1. The target problem of this paper, the development of machine learning force field models, is of great significance. 1. **The motivation for the designed components of many-body interaction is puzzling**. As introduced in Section 4, the development of four-body interaction (improper torsions) and five-body interactions are based on the topology. First, such analysis is purely qualitative. The authors did not provide further completeness proof or quantitative evidence about these interaction schemes in real-world data. Second, the reasons for deriving Eq (4)-(9) are not well explained. It is suggested to clarify how these components are motivated according to the topology analysis.\n\n\n2. **On the experimental evaluation**. Additionally, there are several aspects of the experiments that are concerned:\n    - The empirical performance is not consistently better than other baselines. Among the evaluated benchmarks, the proposed QuinNet cannot outperform the baselines significantly. For example, in MD17, the newly developed five-body interaction modules do not significantly improve performance. In rMD17, the best performance is diversely distributed among the compared models. Overall, the experimental evaluation does not well demonstrate the power of newly developed modules.\n    - The computation efficiency evaluation is missing. Although the authors provide complexity analysis, it is better to further show the time/memory cost comparison between the proposed QuinNet and baselines. Besides, the model parameters should also be provided for all compared models.\n    - The scale of the chosen benchmarks is rather small. Both the dataset size and sample size (number of atoms) are limited. It is suggested to further evaluate the proposed QuinNet on large-scale benchmarks, e.g., Open Catalyst Project \\[1\\].\n    - The ablation study. First, as shown in Figure 5, the inclusion of Five-body@I even induces further errors, which would make readers curious about whether such a phenomenon generally exists. Second, as introduced in VisNet, the improper angle was also considered. The authors should add further discussions and empirical comparisons between it and the newly proposed four-body interaction (improper torsion).\n\n\n3. **The writing does not meet the requirement of an acceptable paper in this conference**. First, Section 3.2 can be thoroughly extended (e.g., in the appendix) to introduce the background of force fields and highlight the importance of torsion potential, improper torsions, and higher-order many-body interactions. Second, there lack of formal descriptions of QuinNet. Figure 3 can hardly be understood by readers that are not familiar with the related works in this area. \n\n\\[1\\] Chanussot L, Das A, Goyal S, et al. Open catalyst 2020 (OC20) dataset and community challenges\\[J\\]. Acs Catalysis, 2021, 11(10): 6059-6072.\n    -  Please refer to the Weakness section to address the concerns. The authors did not discuss the limitations of this work.",
         "489",
         "2",
         "6",
         "0.7931",
         "0.0741489571",
         "0.8583066463000001",
         "215",
         "34.6703",
         "0.1939",
         "neurips",
         "0.0",
         "5",
         "5",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "80",
         "polite",
         "5",
         "negative",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "1.0",
         "3.0",
         "3.0",
         "2.0",
         "partially factual",
         "3.0",
         "2.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "4.0",
         "moderate",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "78",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "32",
         "67",
         "Reviewer-8RW7",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper aims to incorporate 5-body interactions into geometric deep learning models. They first analyze the topology of 5-body interactions and identify three 5-body angles. Then they propose an efficient way to incorporate these 5-body information into models. The complexity of the proposed QuinNet is still O(|N|), the same as many previous 2-body methods like PaiNN. The results are comparable to previous SOTA methods. This paper is well-written and easy to follow.\n\nThe experimental results show that the proposed method can perform well on most tasks. The ablation study in Section 5.4 and Figure 5 show that the proposed 5-body information indeed helps to model. See details in the Question part. 1. About the motivation:   \n this paper aims to incorporate 5-body interactions into geometric deep learning models. However, based on my understanding, using up to 4-body (torsions) interaction is already complete \\[1\\]\\[2\\] in terms of capturing the geometric structures. If this is correct, then why do we need these 5-body angles? In addition, if we can incorporate 5-body interactions, do we also need to incorporate 6-body interactions?\n\n2. About the complexity:   \nin Section 4.3, the authors claim that the complexity is O(|N|), as efficient as many 2-body methods like SchNet and PaiNN. But I think this complexity is not well explained. Using pseudocode/algorithm may be better to analyze the complexity. In addition to the analysis, I suggest the authors use some results to empirically verify the great efficiency compared to other baseline methods, e.g. the inference time, used memory, etc.\n\n3. About the tasks:   \nthis paper focuses on MLFFs, how about other molecular property prediction tasks, such as QM9 and OC20? I am wondering if this method is specially designed for MLFFs, or can be used on all 3D molecule tasks. In other words, why do the authors emphasize MLFFs? Is there any significant difference between MLFFs and other molecule property prediction tasks?\n\n4. Other related papers: many-body \\[3\\], MLFFs \\[4\\]\n\n5. The j, k in Figure 2 are confusing to me. For example, in (f), why not be i, j1, j2, j3, and k1?\n\n\\[1\\] ComENet: Towards Complete and Efficient Message Passing for 3D Molecular Graphs.  \n\\[2\\] GemNet: Universal Directional Graph Neural Networks for Molecules.  \n\\[3\\] On the Expressive Power of Geometric Graph Neural Networks.  \n\\[4\\] Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations. None",
         "394",
         "8",
         "6",
         "0.77",
         "0.1385714286",
         "0.8948391676",
         "215",
         "48.9981",
         "0.1429",
         "neurips",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "85",
         "polite",
         "5",
         "negative",
         "4",
         "low",
         "5",
         "5",
         "4",
         "5",
         "partially factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "33",
         "67",
         "Reviewer-YYfR",
         "Efficiently incorporating quintuple interactions into geometric deep learning force fields",
         "Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \\emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.",
         "This paper introduces a machine learning force field that is a neural network with explicit interactions for up to 5-body terms.  The authors evaluate the model on a couple of public datasets and show demonstrate the competence or superiority of this new model compared to the state of the art in this field. The paper provides an important addition to a series of ever-improving machine learning potentials.  The contribution is clear and simple to understand at the high level, though the details are often unclear.  The benchmarks were compared against a set of reasonably strong published methods in this area.  In my opinion, if this work was presented in an unambiguously clear fashion and accompanied by code, it could be a strong contribution to this conference.  \n\n\\[The paper improved significantly following the first round of feedback from reviewers, so I'm raising my rating to a 7.\\] The complexity analysis is very limited.  How many total interactions did the typical molecule have as a function of their atoms, and how did the practical experimental complexity scale for the evaluation of these molecules.  One of the main reasons that 5-body terms were not used in traditional MD simulations was the poor scaling of the number of interactions one would need to calculate.\n\nThe MD simulation mentioned in section 5.1 and Fig 4 are not described anywhere.  The following sentences suggest that there would be some explanations in the supplement, but I couldn't find them: \"Additionally, we perform MD simulations using trained QuinNets as force fields and plot the distribution of interatomic distances h(r) for these 7 molecules in Fig. 4. Further details regarding additional settings can be found in the Supplementary Materials.\" \n\nThese sentences in the supplement, page2, are confusing or wrong: \"Similarly, five-body@III interaction (Fig. S1 (c)) is a special case of six-body interaction when nodes i and k4 in Fig. S1 (d) superpose each other. Thus, the QuinNet model captures all five-body interactions and a portion of six-body interactions, making it a versatile and comprehensive tool for modeling complex molecular systems.\"  There is no six-body interaction if two of the bodies are the same, and there is no physically acceptable case where two different atoms could superpose each other.\n\nThe code is not provided, so it is not possible for me to assess the reproducibility of this method.  The diagram in Figure 3 seems reasonable at the very high level, but it lacks the definitions of most of the terms annotated in the figure, thus rendering it confusing.  (What is $Y_l$? is it the set of all spherical harmonics $Y_{lm}$ for a given angular momentum $l$? What is $n_j$? What is $s_j$?  $W$?...) Could the authors add the presentation of the QM9 quantities estimated in the recent publication for Allegro?  (https://www.nature.com/articles/s41467-023-36329-y Table 3)\n\nHow long and how stable were the actual MD simulations?  What were the exact codes/protocols used?\n\nWhat is the practical performance of the model during evaluation? No potential negative societal impacts from this work.",
         "497",
         "1",
         "2",
         "0.764",
         "0.0333794423",
         "0.8763324022000001",
         "215",
         "43.7997",
         "0.1199",
         "neurips",
         "0.018018018018018",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "moderate",
         "2.0",
         "3.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "polite",
         "5",
         "positive",
         "4",
         "moderate",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "3",
         "low"
        ],
        [
         "34",
         "171",
         "Magdalena-Czlapka-Matyasik",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I commend the authors to contribute to this body of literature regarding the socio-demographic and lifestyle factors associated with understanding fast food consumption in Cambodia adults. The paper brings quantified information about the factors influenced by understanding fast food consumption. The authors revealed that poor and fair knowledge, insufficient exercise levels, and not getting enough sleep were predictors of inadequate understanding of the impact of fast food on health. Such conclusions do not bring entirely new knowledge to the literature, on this matter. Across the whole world population, the problems related to fast food consumption have been discussed. Nevertheless, I consider the work to be original, well designed and contribute knowledge to this field of public health research. My suggestions concern: In the introduction, the authors indicate the system of fast-food restaurants; it would be more attractive to explain, how it was developed in Cambodia directly?  What would be very interesting is information concerning the real take away or fast food intake in those groups. It must or might be in direct relation to this matter?  My main concern about the validation of the \"Level of knowledge of fast food consumption\": Could the authors explain the procedure? How were the questions selected and validated?  I regret that the authors discussed the interesting results in such a concise way.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "361",
         "0",
         "1",
         "0.7773",
         "0.2011784512",
         "0.89415133",
         "137",
         "35.27",
         "0.1507",
         "f1000",
         "0.01",
         "0",
         "4",
         "1",
         "0",
         "unfactual",
         "3",
         "3",
         "35",
         "neutral",
         "3",
         "neutral",
         "1",
         "high",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "4",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "positive",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "positive",
         "3",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "3",
         "low"
        ],
        [
         "35",
         "171",
         "Wanshui-Yang",
         "Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia",
         "Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript investigated the level of understanding of fast-food consumption among adults in Cambodia. The authors found that unsatisfactory levels of knowledge around fast food consumption were significantly associated with not taking regular exercise and sleeping less than eight hours per night. The results are interesting, but I have several comments. The authors should introduce the recent development of fast-food sector in Cambodia in the introduction part.  Is there an analysis of fast-food intake among these participants?  Interestingly, the authors found that not taking regular exercise and sleeping less than eight hours per night were associated with unsatisfactory levels of knowledge around fast food consumption. However, they were not well explained in the discussion part. In other words, the discussion part is a little too concise.  In addition, the education levels were not associated with the knowledge of fast-food consumption in the present study. I would like authors to discuss it and, at least, mention its possible causes.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "303",
         "0",
         "1",
         "0.7774000000000001",
         "0.1265046296",
         "0.9193514585",
         "520",
         "28.03",
         "0.1953",
         "f1000",
         "0.010204081632653",
         "0",
         "4",
         "1",
         "0",
         "unfactual",
         "3",
         "3",
         "40",
         "impolite",
         "3",
         "negative",
         "0",
         "high",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "5.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "36",
         "187",
         "Reviewer-2CBB",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "This paper introduce a novel unsupervised feature selection methods called GRSSLFS, which combine matrix factorization with self-representation subspace learning and apply graph regularization to preserve the geometric structure of the feature vectors. This method is proved to be effective in both theory and experiments. In this paper, the author introduce the problem of the redundant data in traditional self-representation, and then apply matrix factorization self-representation problem to achieve the goal to reduce the dimension of basis matrix. Here are some strengths of this article:\n\n1. This paper introduce a novel problem of redundant data in self-representation problems and then propose a method to solve this problem.\n\n2. Plenty of theoretical proof are given in the paper and appendix, the convergence analysis indeed increase the persuasiveness of the article.\n\n3. The proposed method was compared with a variety of comparison algorithms on multiple data sets, demonstrating the effectiveness of the method. However, there are still some weaknesses in this paper.\n\n1. In the end of Introduction section, the second and third contribution points is not sufficient, as these constraints of regularization are not proposed in this article. \n\n2. In the methodology section, some formula calculations are confusing and not very convincing. Such as the multiplication in formula (6) and the optimization target in the optimization goal (formula 7). These issues will be described in detail in subsequent questions 1 and 2.\n\n3. In the methodology section, the description of the algorithm is not complete enough. The specific process of selecting features according to the matrix U in Algorithm 1 has not been described in detail. 1. In the section of methodology, the equation (6) is confusing and not so clear. It seems impossible to subtract the matrix XUV of shape m*m from the matrix X with the shape m*n? \n\n2. As the feature matrix B is fixed by the VBE method proposed in section 3.3, it is unclear why the basis coefficient matrix G in equation (7) is a parameter to be optimized. Why the matrix G can not be determined by equation (4) directly and reduce the number of parameters.\n\n3. In section 3.1, subspace learning that introduces graph regularization seems to be existing methods. Should this part of the content be moved to related work?",
         "376",
         "0",
         "8",
         "0.679",
         "-0.048046398",
         "0.9640573859",
         "51",
         "40.0877",
         "0.0751",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "4",
         "4",
         "70",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "37",
         "187",
         "Reviewer-yUvs",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Authors of this paper propose graph regularized self-representation and sparse subspace learning (GRSSLFS) for unsupervised feature selection. The basis extension method is modified to select bases with highest variance score. These bases are used to build graph regularized self-representation learning and subspace learning. The graph regularized self-presentation learning and subspace learning are combined in terms of a set of selected bases from input space with the highest variance score. Experiments on various datasets demonstrate the advantage of the proposed method comparing with baselines. The ablation study also shows the necessity of each component. The subspace learning module is the key component, but its derivation from selected bases highly relies on the assumption that XU=B. This might not be hold if B is selected according to the proposed variance basis extension method. Moreover, the selection based on subspace learning module lacks of convincing explanation since G does not exactly represent X based on B as a fixed set of feature vectors. It is confusing to explain (4) as the self-representation problem if B is arbitrary basis matrix since they may not come from the input data matrix X.  Taking PCA for example, the columns of B are orthogonal, but they are not from the input feature space. Moreover, B defined as a square matrix of size m is inconsistent with the sleeted r bases in section 3.3.\n\nIn section 3.1, authors mentioned that two features have a similar structure in the feature space, and it is expected Bg_l and Bg_r have similar structure. What does the similar structure mean? How is the similarity measured? In other words, it is unclear how the matrix A is constructed. \n\nThe derivation in section 3.2 depends on the assumption that XU=B. As B is a set of feature vectors selected from input data, it is unclear whether the assumption still holds or not. Similarly for Theorem 3.1, it is trivial to have if the assumption holds. \n\nThe variance basis extension is to simply change the selection order of feature vectors in terms of variance score of feature vectors. It is possible that for each individual feature, the variance is high, but is it similar to say the largest amount of data dispersion? \n\nFor completeness, authors should describe the derivation process on how equations (9)-(11) are obtained. Since all three equations are fractional, is it possible that any of the denominators can be zero? How is it handled?\n\nIn Algorithm 1, the selected features are derived from U. However, U is not directly related to the input X instead to B and G, unless BG=X. However, B is selected feature vectors from input space. It is unclear why the assumption can hold. So why is the selection rule proper?\n\nThe computation complexity is quite high since it is quadratic to both the number of samples and the number of features comparing with most of baseline methods.\nThe application to the PneumoniaMNIST dataset is quite interesting. However, the way of presenting the outcomes can be improved significantly.  For example, what is the interested region? how many selected features are in the interested region? How do other compared methods perform? The validation is not quantified. How many radiologists are involved in the evaluation?  What is the performance measured? These plots shown in Fig. 2 delivers less useful information except that more red points are accumulated in the center when the number of selected features increases.",
         "567",
         "0",
         "0",
         "0.7308",
         "0.0892117117",
         "0.9616214633",
         "51",
         "50.3623",
         "0.0364",
         "iclr",
         "0.0",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "5",
         "5",
         "75",
         "polite",
         "3",
         "neutral",
         "4",
         "low",
         "4",
         "4",
         "5",
         "4",
         "4",
         "5",
         "5",
         "88",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "neutral",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "75",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "38",
         "187",
         "Reviewer-PMap",
         "Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning",
         "In recent years, there has been extensive research into unsupervised feature selection methods based on self-representation.\nHowever, there exists a major gap in the mathematical principles that underlie these approaches and their capacity to represent the feature space.\nIn this paper, a novel representation learning method, Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), is proposed for the unsupervised feature selection.\nFirstly, GRSSLFS expresses the self-representation problem based on the concept of ``a basis of feature space'' to represent the original feature space as a low-dimensional space made of linearly independent features. Furthermore, the manifold structure corresponding to the newly constructed subspace is learned in order to preserve the geometric structure of the feature vectors. Secondly, the objective function of GRSSLFS is developed based on a self-representation framework that combines subspace learning and matrix factorization of the basis matrix. Finally, the effectiveness of GRSSLFS is explored through experiments on widely-used datasets. Results show that GRSSLFS achieves a high level of performance in comparison with several classic and state-of-the-art feature selection methods.",
         "Considering there exists a major gap in the mathematical principles that underlie the self-representation based unsupervised feature selection approaches and their capacity to represent the feature space, this paper proposes Graph Regularized Self-Representation and Sparse Subspace Learning (GRSSLFS), for the unsupervised feature selection, which expresses the self-representation problem based on the concept of “a basis of feature space” to represent the original feature space as a low-dimensional space made of linearly independent features. Experiments on widely-used datasets are conducted to validate the efficacy of the proposed method. 1. The computational complexity of the proposed GRSSLFS method is low, which is efficient for large-scale and high-dimensional data;\n2. The results of the proposed method seem better than other ones. 1. Most of the compared methods are out-of-date, only one method used for comparison was publised in 2023, other methods are before 2020;\n2. The motivation of the proposed method is not clear. In Eq.(8), the first three terms have been well explained, but the final regularization term has not been explained. See weakness.",
         "172",
         "0",
         "4",
         "0.6699",
         "0.1067307692",
         "0.9783408642",
         "51",
         "26.959",
         "0.0945",
         "iclr",
         "0.0",
         "2",
         "4",
         "1",
         "3",
         "partially factual",
         "2",
         "2",
         "30",
         "polite",
         "3",
         "negative",
         "3",
         "moderate",
         "3",
         "4",
         "3",
         "3",
         "partially factual",
         "4",
         "4",
         "65",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "3",
         "3",
         "factual",
         "3",
         "4",
         "65",
         "neutral",
         "4",
         "neutral",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "39",
         "103",
         "Reviewer-NRqK",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes an algorithm for learning MDP state abstractions that preserve information needed for planning (namely, the values of states). A major differentiator from symbolic approaches is the idea that these state abstractions should be continuous rather than discrete. The key assumption is that you are given a set of options and a dataset obtained by rolling them out. Experiments are conducted in a few simple domains: pinball and antmaze, and demonstrate that the learned abstractions are sensible. The paper addresses an important topic (abstraction learning) and I appreciate the theoretically motivated algorithms. This line of work is of great interest to many attendees of ICLR. I also appreciate that the authors were clear about wanting continuous representations right off-the-bat. The math is also correct as far as I was able to tell, though I didn't check the proofs in the appendix in careful detail. Unfortunately, I recommend rejection for this paper due to 4 major reasons: 1) unconvincing experiments, 2) missing key citations to related work, 3) issues in technical details, and 4) unclear motivation.\n\n1) unconvincing experiments\n\nThe experiments in this paper are very basic and only serve as a simple proof-of-concept that the learned abstractions are somewhat useful. To really scale up the experiments to the level expected for a conference paper, I would expect to see evidence that the learned abstractions are useful in more hierarchical domains (e.g., classic domains from the options literature like keys and doors). In such domains, we could test whether the value-preserving property holds empirically, by comparing the values from planning under the abstract model to the (ground truth) values from planning under the true model.\n\nAdditionally, I would like to see comparisons to many more RL algorithms, especially hierarchical ones like HIRO (https://arxiv.org/abs/1805.08296), HVF (https://arxiv.org/abs/1909.05829), and Director (https://arxiv.org/abs/2206.04114). This is because at the end of the day, the authors are proposing to learn a state encoder $\\phi$, and despite all the theory that has gone into their algorithm, the question that must be answered is whether this $\\phi$ outperforms the encoders learned by all these other SOTA hierarchical RL algorithms.\n\n2) missing key citations to related work\n\nThe authors are missing several key citations, the most important of which is the line of work by David Abel, such as \"Near optimal behavior via approximate state abstraction\" (https://proceedings.mlr.press/v48/abel16.html) and \"Value preserving state-action abstractions\" (https://proceedings.mlr.press/v108/abel20a/abel20a.pdf). Those papers have very similar theory to what appears in this one, and so the novelty of the proposed approach is unclear. There are also less-famous but still important-to-cite papers from other authors, like \"Abstract value iteration for hierarchical reinforcement learning\" (https://proceedings.mlr.press/v130/jothimurugan21a/jothimurugan21a.pdf) and \"Deciding what to model: Value-equivalent sampling for reinforcement learning\" (https://proceedings.neurips.cc/paper_files/paper/2022/hash/3b18d368150474ac6fc9bb665d3eb3da-Abstract-Conference.html). It is important for the authors to contextualize the contributions of this paper against all these related works.\n\n3) issues in technical details\n\nThe authors say in Section 3.2 that when B = \\bar{B}, \"then simulating a trajectory in the abstract model is the same as in the ground model\". But I don't think this is true, because we need the rewards to match between the two trajectories too, and $B_t$ says nothing about rewards, only dynamics. The authors go on to say: \"Therefore, planning in the abstract model is accurate, in the sense, that the value of an abstract state z computed in the abstract model is the same as the one would get from trajectories from the ground MDP for the abstraction operator G.\" Again, I think this is wrong because it ignores the abstract reward function, which could be arbitrarily different from the ground one. In fact, in the proof of corollary 3.8, the authors assume $E_{s \\sim G(\\cdot \\mid z)}\\[R(s, o)\\] = \\bar{R}(z, o)$, and it's only _under this assumption_ that the claims hold. But combining this assumption on reward function with Definition 3.6 ends us back up at the bisimulation conditions, and then it's not clear what the contributions of this paper are.\n \nAs a separate point, the second term in the mutual information expression of Section 4.2, $MI(S'; Z, A)$, seems very extreme! It is saying that you have to be able to predict the entire ground next state from the current abstract state and action. Doesn't this means the abstraction can't lose any information? This seems like an important technical limitation of the approach.\n\n4) unclear motivation\n\nThe authors often state that a discrete abstract state space is bad, when pointing to work on symbolic abstraction learning (e.g., PDDL). But it's not clear why this is really bad. The authors say discrete abstract states are \"not applicable when planning with the available high-level actions requires a continuous state representation\", but this doesn't make sense to me, as the options have to act in the ground environment states, not in the abstract state space, and so the options could be defined with respect to either a discrete or a continuous abstract state space. Furthermore, it can be much easier to plan in a discrete abstraction (e.g., using powerful symbolic planners).\n\nI believe a fruitful research direction would be to compare the abstractions learned by a symbolic approach against the abstractions learned by a continuous approach (like the authors'). Questions:\n* Not much is said about the dataset $\\mathcal{D}$, but intuitively, it has to be \"good\" in order for the learned state abstraction to be reasonable. In particular, the agent must see all the options being executed in a variety of settings, and obtain good coverage over the state-action space. Are there any concrete statements we can make about what properties we need this dataset to have?\n* \"we must build a model of its effect\" Do you mean to say \"of the effect of each option\"?\n* \"with mean value equal to that by planning with the original MDP\" What is the mean over?\n* Why did we switch from using O (denoting the option set) everywhere to using A throughout Section 4? Shouldn't we continue to use O, unless I am misunderstanding something?\n* Section 4.3: Why should there be any cost/reward associated with executing skills? Shouldn't a sparse reward for reaching the goal be enough?\n* Eq 2: What are the \"I\" random variables inside the mutual information expression referring to?\n\nMinor edits:\n* \"make the same decision\" To clarify, we just need that the policy maps all states in z to the same action distribution. A stochastic policy isn't really committing to a \"decision\" about what action to take.\n* \"Abstractions alleviate this tension: action abstractions enable agents to plan at larger temporal scales and state abstractions reduce the complexity of learning and planning\" I would say that both of them do both of these. Action abstractions certainly reduce the complexity of planning, which is typically exponential in the branching factor.\n* \"learns a further abstraction\" --> \"learn a further abstraction\"\n* \"otherwise it is referred as learning\" I would say \"policy learning\" to distinguish from other things you might learn\n* \"when it is the given position\" --> \"when it is in the given position\"\n* \"referred as learning\" --> \"referred to as learning\"\n* \"results a bounded value loss\" --> \"results in a bounded value loss\"\n* In definition 3.5, the authors use $s_o$ in a few places where they mean $s_0$.",
         "1210",
         "7",
         "0",
         "0.7753",
         "0.0567315252",
         "0.9024221301",
         "49",
         "44.7468",
         "0.6075",
         "iclr",
         "0.0196078431372549",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "4",
         "94",
         "polite",
         "4",
         "negative",
         "5",
         "none",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "90",
         "polite",
         "5",
         "negative",
         "5",
         "none",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "3.0",
         "60.0",
         "neutral",
         "5.0",
         "negative",
         "5.0",
         "low",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "negative",
         "5",
         "none",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "4",
         "3",
         "70",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "40",
         "103",
         "Reviewer-36E8",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper presents an approach for learning dynamics preventing abstractions for sensorimotor observation space. Given a set of high-level skills and the learned dynamics preserving abstractions, the paper claims to develop an approach for planning for a solution. \n\nThe approach is evaluated in two test domains where the paper shows the visualization of the learned abstractions. - For the most part of the paper, it is extremely well written. Given the wide use of embodied AI systems and robots, an approach that generates plannable abstractions for high-dimensional sensor input is extremely important. \n\n- The paper nicely motivates the problem. While the paper in general is nicely written, it has a few limitations: \n\n- The paper advocates learning a continuous abstract  representation instead of a symbolic abstractions. However, it does not provide any reasons to that. Why are continuous abstractions more desirable than symbolic abstractions? \n\n- Sec 4.1 is unclear. The notation for MI is a bit unclear. It needs to be made more clear. Sec 4.1 requires a re-writing including more explanation for the equation. I have two important questions: \n\n- How is the dynamics preserving abstraction defined in Def. 3.6 different from the Markovian abstractions defined in \\[Srivastava et al. 2016\\]? \n\n- Can you discuss the differences between the presented approach and \\[Allen et al. 2021\\] \n\nReference \n\nAllen, Cameron, et al. \"Learning markov state abstractions for deep reinforcement learning.\" Advances in Neural Information Processing Systems 34 (2021): 8229-8241.\n\nSrivastava, Siddharth, Stuart Russell, and Alessandro Pinto. \"Metaphysics of planning domain descriptions.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016.",
         "264",
         "1",
         "6",
         "0.7512000000000001",
         "0.1625",
         "0.8653070927000001",
         "49",
         "41.1434",
         "0.2429",
         "iclr",
         "0.0",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "3",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "4",
         "moderate",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "41",
         "103",
         "Reviewer-dCJp",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "The paper introduces a method for enabling general-purpose agents to efficiently handle complex tasks by constructing abstract models based on temporally-extended actions. These models facilitate more efficient planning and learning and are characterized using principled conditions. The approach provides empirical evidence of improved sample efficiency in goal-based navigation tasks and offers theoretical support for information maximization strategies in abstract state representation learning.\nThe authors claim that they introduced a method for creating abstract world models that empower agents to plan effectively for goal-oriented tasks. The key idea is to allow agents to construct reusable abstract models for planning with specific skills. This is achieved by characterizing the state abstraction that ensures planning without any loss in simulation, meaning that planning with the learned abstract model can generate policies for the real world. The paper also provides theoretical support for the use of information maximization as a reliable strategy for learning abstract state representations. - Good overview of the related work.\n- Good description of motivations and intuitions. \n- proper choice of environment settings. Major:\n- Some measures are used without definition, \n- It seems that there exists a lot of inaccuracies and impreciseness in the theories and definitions. See all questions!\n\nminor:\n- typos: \nlast paragraph of the introduction \"the *agents* needs\", definition 3.5 \"$s_{o}$\" must be \"$s_0$\"\n- writing: \nDefine the abbreviations before using them, e.g. \"PDDL\", \"VAE\"\n\nThere is a chance that I have not fully understood what this paper is trying to present. 1- What is $P(s'|s,o)$ used in the paragraph right after definition 3.1?\n\n2- An option $o$ is defined, and then you mention $T(s'|s,o)$ to define the transition probability of taking option $o$ in $s$? $T$ earlier was defined on action space $A$. How is it applied on options without showing the relationship of $I_o$ and $\\beta_o$ with $s$ and $s'$ under option policy $\\pi_o$?\n\n3-the paper has defined \"$\\bar {\\gamma} = \\gamma ^{\\tau (s,o)}$ is the abstract discount factor, $\\tau: Z \\times O \\rightarrow \\[0,\\infty)$, which consists of contradictory phrases. How is ${\\tau (s,o)}$ but defined as a function of abstract variables $Z$ instead of $S$? Not clear what $\\tau$ is. If based on definition 3.1, it is the option's execution time starting from $s$ taking option $o$, it is not clear how in definition 3.2 it becomes a map from $Z$ and $O$ to a non-negative real.\n\n4- What does definition 3.4 mean? $ \\Pi = {\\pi \\in \\Pi : \\pi(·|s) = \\pi (·|z) \\forall s \\in z}$ says the probability of taking actions/options in $s$ should be equivalent to the probability of taking actions/options in abstract states. Transitions of taking actions in states might take you to another state $s'$ inside the similar abstract state $z$. How can the policies used for both abstract states and states be equivalent? Unless you are just discretizing the continuous state spaces based on the optimal policies that are already given. Lots of interchangeable usage of symbols here. Not precise and is hard to follow.",
         "499",
         "0",
         "1",
         "0.7308",
         "0.0796438834",
         "0.93872118",
         "61",
         "45.6397",
         "0.1463",
         "iclr",
         "0.0",
         "4",
         "4",
         "5",
         "4",
         "factual",
         "3",
         "4",
         "83",
         "polite",
         "4",
         "negative",
         "5",
         "none",
         "3",
         "4",
         "4",
         "3",
         "partially factual",
         "4",
         "4",
         "45",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "3",
         "4",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "neutral",
         "4",
         "neutral",
         "4",
         "moderate",
         "2",
         "3",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate"
        ],
        [
         "42",
         "103",
         "Reviewer-gKE9",
         "Learning Abstract World Models for Value-preserving Planning with Options",
         "General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. \nInstead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.\nWe evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.",
         "This paper proposes a grounded abstract model formulation with a dynamic preserving abstraction. This abstract state representation (and model) guarantees not only accurate future predictions but also the bounded values in the abstracted rollouts. This paper then provides its implementation using contrastive learning to maximize mutual information between the future state, and the current abstract state and option. The results show that training DDQN in imagination using the abstract model improves the sample efficiency. * The paper proposes a solid foundation of the abstract model that preserves dynamics and values.\n\n* The paper is well written.\n\n* The visualization in Figure 3 clearly shows that the abstract state representations focus on important features in the original observation space. * The main focus of the paper is to show the efficiency of planning and learning when using the proposed abstract MDP. The experiments in the paper are a bit simple to showcase the benefits of the abstract model for planning. It would be stronger if the experiment was done in more complex environments with much longer-horizon tasks, such as AntMaze experiments (Hafner 2022) or robotic manipulation tasks \\[a\\].\n\n* Similarly, the comparisons in Figure 5 are essentially between model-free RL (ground) and model-based RL (abstract), which does not seem fair. It might be fair to compare the proposed method with other model-based RL approaches, such as Dreamer and TD-MPC.\n\n* Exhaustive comparisons to the alternatives to the dynamics preserving abstraction would be interesting, such as bisimulation.\n\n* Some highly relevant works on temporally-extended models \\[a,b\\] are missing in the paper. Proper comparisons to these approaches are necessary.\n\n\\[a\\] Shi et al. Skill-based Model-based Reinforcement Learning. CoRL 2022\n\n\\[b\\] Zhang et al. Leveraging Jumpy Models for Planning and Fast Learning in Robotic Domains. 2023 Please address the weaknesses mentioned above.\n\n\n### Minor questions and suggestions\n\n* Figure 1 may want to explain why abstract state representations and options are helpful for planning and learning. However, Figure 1 does not seem to help understand the paper. To understand this figure, we first need to know about options and abstract state representations, and how they simplify planning.\n\n* In Section 4.2, it is unclear whether $\\mathcal{L}^T_{\\theta, \\phi}$ is used to update $f_\\phi$ or not.\n\n* For multi-goal experiments in the paper, using the same amount of environment steps for the abstract planning and the ground baseline would make it easier to understand how better or worse a method is.\n\n* The appendix could be included in the main paper for easier navigation.\n\n* What is the difference between Figure 7 and 8?\n\n* Training the abstract planning method longer in Figure 7 and 8 would be helpful to see how it learns. Using different x-scales for two methods is okay but it would be better to have the same scale.\n\n* Many minor typos in the paper.\n\n\n---\n\nThank you for author responses. I would love to see comparisons to Dreamer-like baselines, but couldn't find the results by the end of the rebuttal period. Thus, I keep my rating, borderline reject.",
         "507",
         "0",
         "3",
         "0.7684000000000001",
         "0.1385185185",
         "0.9183520675",
         "71",
         "48.6501",
         "0.8246",
         "iclr",
         "0.0",
         "4",
         "5",
         "5",
         "4",
         "factual",
         "4",
         "5",
         "89",
         "polite",
         "4",
         "positive",
         "4",
         "none",
         "5",
         "5",
         "4",
         "5",
         "factual",
         "5",
         "5",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "2.0",
         "5.0",
         "4.0",
         "3.0",
         "factual",
         "3.0",
         "4.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "5.0",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "43",
         "141",
         "Reviewer-xxEb",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper introduces a novel model, PatchSynth, in the Patch-Text Pre-training (PTP) domain, aiming to improve software patch representation and description generation. Through a blend of patch understanding and generation, PatchSynth\t addresses the limitations of prior models. Empirical evaluations reveal its superior performance in patch description generation, with an ablation study further underscoring the importance of generating task training. Novelty and Importance: The work is first to propose a unimodel for patch-text understanding and related tasks. And the topic is very important in this domain.\n\n\tMelds patch understanding and generation, addressing prior models' specialization limitations.\n\n\tThe work provides a good representation and good results Unclear adaptability across diverse programming languages or coding standards. What are the considerations for deploying PatchSynth in real-world software development environments, and what infrastructure would be required for efficient and secure operation?",
         "136",
         "0",
         "0",
         "0.7967000000000001",
         "0.3063636364",
         "0.944865346",
         "50",
         "11.6712",
         "0.0364",
         "iclr",
         "0.0",
         "3",
         "4",
         "2",
         "3",
         "partially factual",
         "3",
         "3",
         "50",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "75",
         "polite",
         "5",
         "positive",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "2",
         "3",
         "3",
         "2",
         "factual",
         "4",
         "3",
         "60",
         "polite",
         "4",
         "positive",
         "4",
         "moderate",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "44",
         "141",
         "Reviewer-4kdr",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "The paper discusses a new model, PatchSynth, in the domain of Patch-Text Pre-training (PTP) which aids in accurate patch representation for software evolution tasks like bug fixing and feature enhancement. PatchSynth is designed to balance patch understanding and generation, overcoming limitations of previous models. It outperforms existing models in patch description generation, as shown in experiments using standard evaluation metrics. An ablation study further reveals the importance of generating task training in improving PatchSynth performance. Novelty:\nThe novelty of PatchSynth lies in its harmonious synthesis of patch understanding and generation, coupled with an advanced synthetic description generator. This innovative approach addresses the historical challenges of accurate patch representation and description generation, marking a significant stride in the PTP paradigm.\nImportance:\nThe topic is of paramount importance as it addresses a critical need in software engineering for accurate patch representation and description, which are pivotal for collaborative development, systematic documentation, and rapid code review processes. By advancing the PTP paradigm, PatchSynth not only contributes to the academic discourse but also holds promise for practical applications in software development workflows.\nThe work achieves promising results. The paper doesn't elucidate how PatchSynth adapts to varying programming languages or codebases with differing coding standards and structures. This lack of demonstrated adaptability could limit its applicability across diverse software projects, potentially requiring additional tuning or re-training to maintain accuracy and effectiveness in different environments. 1. Given the advancements in PatchSynth for patch-text understanding and generation, how well does the model perform in a transfer learning scenario? Can PatchSynth be fine-tuned or adapted effectively to related tasks in software engineering or different programming languages?\n2. Are there considerations or plans for deploying PatchSynth in real-world software development environments? How would the integration look like, and what kind of support or infrastructure would be required to ensure the model operates efficiently and securely in a production setting?",
         "310",
         "0",
         "2",
         "0.8356",
         "0.1883953168",
         "0.940164268",
         "50",
         "9.2899",
         "0.068",
         "iclr",
         "0.0",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "3",
         "3",
         "65",
         "polite",
         "4",
         "neutral",
         "3",
         "low",
         "4",
         "5",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "88",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "positive",
         "5.0",
         "none",
         "3",
         "5",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "4",
         "75",
         "polite",
         "4",
         "neutral",
         "4",
         "low"
        ],
        [
         "45",
         "141",
         "Reviewer-H6rR",
         "PatchSynth: a Patch-Text Pre-trained Model",
         "In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.",
         "This paper tackles the problem of code patch representation learning -- how to represent edits on code to support downstream tasks like commit message generation, patch correctness assessment, etc. \n\nThis paper proposes a pretraining framework, with triplet losses on text-code contrastive loss, text-code matching loss and text generation loss based on code patch. The pretraining data includes 90K pairs of code change and synthesized commit messages. \n\nOn downstream task of commit message generation upon FIRA\\[1\\] dataset, PatchSynth showed performance gains over public & self-ablation baselines.\n\n\\[1\\] Jinhao Dong, Yiling Lou, Qihao Zhu, Zeyu Sun, Zhilin Li, Wenjie Zhang, and Dan Hao. Fira: Fine-grained graph-based code change representation for automated commit message generation. 2022. 1. Unlike from previous approaches(CCRep\\[1\\], Cache\\[2\\]) where code change is encoded with two streams (code-before-change, code-after-change), this work encodes code change(patch) with a standard transformer on a single patch file (like git commit diff). This is inline with the general trend in LLMs community that ultimately LLMs should be able to understand and capture internal structure without explicitly modelling it.\n2. This paper applies representation pretraining with triplet losses -- which is quite known in multimodal pretraining domain (BLIP\\[3\\], BLIP-2\\[4\\], etc) -- to code patch representation. It empirically showed that such pretraining is helpful for downstream task of commit message generation.\n\n\n\\[1\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[2\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022.\n\n\\[3\\] Junnan Li, Dongxu Li, Caiming Xiong, & Steven C. H. Hoi (2022). BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. In ICML (pp. 12888–12900). PMLR.\n\n\\[4\\] Junnan Li, Dongxu Li, Silvio Savarese, & Steven C. H. Hoi (2023). BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models. In ICML (pp. 19730–19742). PMLR. I have multiple major concerns on the paper based on its current form. The most concerning issues are:\n\n1. The paper claims \"The core part of PATCHSYNTH lies a state-of-the-art synthetic description generator\" in multiple places (3rd paragraph of Introduction, 2nd contribution in last part of Introduction, Section 2.3). However, there is no details on this synthetic description generator. The only mention is Section 4.4 with just one line \"Capitalizing on benchmarks from seminal works\\[1,2\\], our dataset, primarily focused on Java samples includes 90,661 patches with their **attendant** descriptions\"\n\n    i. Are these **attendant** descriptions generated by the author but simply taken from \\[1,2\\]? If the latter, then claiming such synthetic description generation as a key feature in this paper is highly problematic.\n\n2. The task of representation learning of code patch, defaultly assigns 1 vector for a code patch (w/ 1 or more edits), which is the case for all previous works including CC2Vec\\[3\\], CCRep\\[4\\], Cache\\[5\\]. However, PATCHSYNTH seems to encode the code patch to a sequence of vectors (Figure 1). \n\n    i. Such change needs explicit explanation and justification which authors have failed to deliver.\n\n3. Missing LLM baselines: with code patch being encoded with a sequence of vectors, the authors should compare with code-aware LLMs like Code-llama, or WizardCoder, as they also encode code patch to a sequence of vectors. \n    \n    i. As the recent code-aware LLMs have shown great abilities in general instruction following in coding-related tasks, a very timely baseline would be applying code-aware LLMs to the downstream task of commit message generation, with few-shot prompting or finetuning. \n\n    ii. A comparison of PATCHSYNTH vs code-aware LLMs would very helpful for the community to understand the edge and relevance of the proposed method in LLM era, which the authors have failed to deliver.\n\n4. Only 1 downstream task evaluated: The authors claimed that the method is designed both for generative and discriminative tasks. However, the empirical experiments were only conducted on commit message generation. As the encoding changed from one vector to a sequence of vectors, it's important to show how can such encoding can be adapted to tackle retrieval or classification tasks. Also, to claim it as a pretrain model, the authors need to evaluate on multiple downstream datasets.\n\n5. Fairness in comparison: \n\n    i. Is PATCHSYNTH firstly pretrained on 90K and then finetuned on 75K data of FIRA? If so, it's not so fair to compare PATCHSYNTH with CCRep and FIRA methods, as they are not trained on 90K pretraining data. For example, Is it possible to also pretrain CCRep with 90K data?\n\n    ii. As mentioned in point 2, CCRep has a more compact encoding of 1 vector while PATCHSYNTH encodes to a sequence of vectors. It is thus not fair to compare without explicitly mentioning such differences.\n\n6. Concerns on Pretraining:\n\n    i. details of creating negative pairs: one common technique in contrastive training is hard-negative-mining. However, the authors didn't disclose how they create negative pairs\n\n    ii. For vision-language representation learning, a large batch size (>= 512) and a large pool to select negative examples have been shown to be necessary. This paper mentions the batch size of 32, which seems pretty small. I will need more verification on ablation of 1) batch size, 2) negative example selection and 3) pretraining metrics to be convinced that such setting is adequate for code-text representation pretraining. \n\n7. Writing & formatting issues\n\n    i. On page 8, the chart of Figure 2 is partially blocked by its top legend\n\n    ii. On page 8, the paragraph for \\[Performance cross different patch attention\\] is repetitive: it repeats twice in introducing the numerical performance. Besides, I don't think it's a good idea to verbosely list down all numbers when they are clearly seen in Figure 2.\n\n    iii. In Section 2.1, there's no mention on recent code aware LLMs like Code-LLaMA. \n\n    iv. In Section 2.3, there's no citation to any work. Besides, CCRep\\[4\\] doesn't have the gap mentioned in Section 2.3 as it can both do discriminative and generative tasks and it doesn't reply on AST information. So an explicit comparison to CCRep in Related Work should be present.\n\n\\[1\\] Robert Dyer, Hoan Anh Nguyen, Hridesh Rajan, and Tien N Nguyen. Boa: A language and infras\u0002tructure for analyzing ultra-large-scale software repositories. In 2013 35th International Confer\u0002ence on Software Engineering (ICSE), pp. 422–431. IEEE, 2013.\n\n\\[2\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[3\\] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. Cc2vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518–529, 2020.\n\n\\[4\\] Zhongxin Liu, Zhijie Tang, Xin Xia, and Xiaohu Yang. Ccrep: Learning code change representations via pre-trained code model and query back. In 45th IEEE/ACM International Conference on Soft\u0002ware Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, pp. 17–29. IEEE, 2023. doi: 10.1109/ICSE48619.2023.00014. URL https://doi.org/10.1109/ICSE48619. 2023.00014.\n\n\\[5\\] Bo Lin, Shangwen Wang, Ming Wen, and Xiaoguang Mao. Context-aware code change embed\u0002ding for better patch correctness assessment. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(3):1–29, 2022. 1. Why did you use CodeBERT to initiate both text encoder and decoder? For example, did you consider encoder-decoder model like Code-T5?\n\n2. In Experiment Setup, you mentioned \"Model dimensions are meticulously calibrated\". May I know how are the hyper-parameters searched? Are you using the downstream task performance or some pretraining metrics?",
         "1254",
         "27",
         "37",
         "0.7999",
         "0.069050849",
         "0.8986387253",
         "50",
         "47.6556",
         "0.1651",
         "iclr",
         "0.0",
         "4",
         "2",
         "4",
         "4",
         "factual",
         "3",
         "4",
         "80",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "92",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "1.0",
         "4.0",
         "3.0",
         "4.0",
         "partially factual",
         "2.0",
         "3.0",
         "60.0",
         "polite",
         "4.0",
         "neutral",
         "4.0",
         "moderate",
         "5",
         "4",
         "5",
         "5",
         "factual",
         "4",
         "5",
         "90",
         "neutral",
         "5",
         "negative",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "85",
         "neutral",
         "5",
         "negative",
         "5",
         "low"
        ],
        [
         "46",
         "28",
         "Reviewer-xyNq",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper considers the problem of certifying individual fairness (IF), which is of great importance to reliable machine learning algorithms. To this end, the authors propose a novel convex relation of IF constraints that greatly reduces the computational cost. In addition, the authors propose to certify distributional individual fairness, ensuring that the neural network has guaranteed individually fair predictions for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball. 1. This paper is technically sound.\n2. The extensive experiments validate the effectiveness of the proposed methods. The paper studies individual fairness and distributional fairness. To my opinion, the two topics seem to be independent. However, it is possible that I misunderstand this paper. It would be better if the authors can present more relations between these topics. ## Miscellaneous\n1.\tLine 106: feed forward $\\to$ feedforward\n2.\tLine 168: $d$ is indeed a vector; however, the denotation $\\sqrt{d}$ should be defined more specifically.\n none",
         "156",
         "0",
         "5",
         "0.8035",
         "0.28125",
         "0.9500498772",
         "215",
         "29.3366",
         "0.1213",
         "neurips",
         "0.0",
         "3",
         "5",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "60",
         "polite",
         "4",
         "neutral",
         "4",
         "moderate",
         "4",
         "5",
         "3",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "positive",
         "4",
         "low",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "3",
         "70",
         "polite",
         "4",
         "positive",
         "4",
         "low",
         "2",
         "4",
         "3",
         "3",
         "partially factual",
         "3",
         "3",
         "75",
         "polite",
         "4",
         "positive",
         "4",
         "low"
        ],
        [
         "47",
         "28",
         "Reviewer-Lpfq",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper studies formal guarantees for notions of individual fairness (IF) for predictors given by neural network models. After relaxing common definitions for IF metrics by means of $\\ell_\\infty$ balls (or orthotopes), they adapt methodology based on adversarial robustness to provide upper and lower bounds to the IF achieved by models on an empirical sample - and those within a $\\gamma-$Wasserstein ball about it. - This paper studies an important problem of individual fairness\n- The first half of the paper, Section 3 and 4, which cover Background, the DIF definition, and problem explanation are very clear and easy to understand. - The key observation and novelty in the approach is not clearly noted (See below)\n- Several of the nice advantages of their method (e.g efficiency) are not explained (see below). 1. Numerous times in the paper the authors say their bounds are ”efficient” because they leverage efficient methods (e.g. those based on bound propagation). While that may be true, it would be nice for the readers if they provided a brief explanation as to why these methods are efficient instead of placing everything in the appendix. \n2. It seems to me that the central novelty of this paper is to upper bound a mahalanobis metric (for $d_{fair}$) with an orthotope, which is quite simple. The remaining of the paper seems to me a direct application of results and methods in adversarial robustness. While I do appreciate the observation of being able to use those tools in the context of fairness - which also constitutes novelty - I would appreciate if the authors could be very clear about what are the main technical contributions of this work.\n3. Personally, I am not sure providing a section on the impact of these methods on group fairness is necessary. I’d much rather prefer a discussion on the efficiency of the bounds.\n4. Figure 1 is quite confusing. What makes the blue-star individuals likely? As presented, those blue-star points do not look likely. If I understand the figure correctly, the authors should present a more balanced empirical sample together with a larger sample representing the (unobserved) population. \n5. I also have problems with the fact that the authors state their goals and present their definitions in terms of expectation (e.g. as in Def 2), but simply restrict themselves to studying empirical samples. I think the presentation is misleading, because nowhere the authors really provide guarantees for the definition in Def 2 (that is, risk bounds). This is also an important limitation where the study the Wasserstein distance between distributions, as they simply regard their distribution as a one supported on Dirac functions (on the observed samples). \n6. Immediately after Eq (4), the authors write that “we can optimize this bound to be tight”. I don’t think this is correct: while they can indeed optimize the bound, there’s no guarantee that the bound will be tight, as the original problem is non-concave.\n7. In Section 5.4 and after presenting $\\mathcal L_{F-DIF}$, the authors mention when $\\gamma=0$, one recovers a local constraint on individual fairness on $x\\in X$. I don’t think this is completely accurate, because again, Def. 2 is defined in expectation of $x\\sim p(x)$, not simply over the empirical sample. The authors mention that they do not foresee negative societal impacts. Maximizing upper and lower bounds is great but in doing so we don’t really know what is happening to the true fairness violation. It may be that the true fairness violation is in fact increasing which is propagating unfairness. While I understand that solving for this value is not feasible and thus appreciate the results presented, I would also like the paper to acknowledge that there are potential negative effects.",
         "619",
         "0",
         "7",
         "0.7891",
         "0.1001929392",
         "0.9119418859",
         "215",
         "46.7646",
         "0.6521",
         "neurips",
         "0.0",
         "5",
         "5",
         "5",
         "5",
         "factual",
         "5",
         "5",
         "95",
         "polite",
         "5",
         "neutral",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "moderate",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "partially factual",
         "3.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "4",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "neutral",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "5",
         "low"
        ],
        [
         "48",
         "28",
         "Reviewer-FRnw",
         "Certification of Distributional Individual Fairness",
         "Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \\textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.",
         "This paper studies the problem of individual fairness in supervised learning. The focus is on studying how to certify distributional individual fairness (IF) (individual fairness over a set of distributions close to the observed empirical data distribution) in neural networks. Prior work has focused largely on certifying global IF, which is more expensive and thus can only be applied to smaller neural networks than the proposed certification/debiasing technique. The contributions of the paper are in showing how to certify distributional IF in neural networks and then using these bounds in the training process as regularizers to debias NNs. \n\nThe main methodology for certifying IF is presented in Section 5. The first step is to certify local IF by over-approximating the similarity ball to find a conservative estimate of the IF violation. They can then use this bound to certify distributional IF around the empirical data distribution and apply finite sample guarantees to give an estimate of the true distributional IF. \n\nThe authors then show how to use the bounds on distributional fairness as regularizers in the training procedure as a way to debias neural networks. They then provide experimental evaluation on a few benchmark datasets that demonstrates that their proposed training method indeed improves distributional individual fairness, at relatively modest degradations in accuracy.  The main advantage is a relatively lightweight way to certify and train NNs for IF, in a way that requires little additional computation, compared to previous methods which are not able to scale to large NNs. \n\nThe experimental evaluation seems to confirm that DIF training as proposed by the regularization method does in fact improve significantly improve IF at modest degradation in classification accuracy.  Section 5 is a little dense and it would be helpful for the reader if there was a little more discussion of the optimization procedure, particularly in Section 5.3. Theorem statements here might also be helpful for the reader to understand what the final guarantees are.  What is the purpose of Table 2? It is a little difficult to interpret the punchline - it just seems to indicate that DIF training does not have a consistent effect on group fairness measures, either positively or negatively.  -",
         "363",
         "0",
         "1",
         "0.7939",
         "0.0286027569",
         "0.9569676518",
         "215",
         "26.5652",
         "0.0354",
         "neurips",
         "0.0",
         "4",
         "4",
         "3",
         "3",
         "factual",
         "3",
         "4",
         "60",
         "neutral",
         "3",
         "negative",
         "4",
         "high",
         "4",
         "4",
         "4",
         "5",
         "5",
         "5",
         "5",
         "85",
         "5",
         "5",
         "neutral",
         "5",
         "moderate",
         "3.0",
         "4.0",
         "4.0",
         "4.0",
         "factual",
         "4.0",
         "4.0",
         "80.0",
         "polite",
         "5.0",
         "neutral",
         "3.0",
         "none",
         "3",
         "4",
         "4",
         "3",
         "factual",
         "4",
         "4",
         "80",
         "polite",
         "5",
         "positive",
         "5",
         "low",
         "3",
         "4",
         "4",
         "4",
         "factual",
         "4",
         "4",
         "85",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ],
        [
         "49",
         "41",
         "Reviewer-viiH",
         "Contrastive Retrospection: honing in on critical steps for rapid learning and generalization in RL",
         "In real life, success is often contingent upon multiple critical steps that are distant in time from each other and from the final reward. These critical steps are challenging to identify with traditional reinforcement learning (RL) methods that rely on the Bellman equation for credit assignment. Here, we present a new RL algorithm that uses offline contrastive learning to hone in on these critical steps. This algorithm, which we call Contrastive Retrospection (ConSpec), can be added to any existing RL algorithm. ConSpec learns a set of prototypes for the critical steps in a task by a novel contrastive loss and delivers an intrinsic reward when the current state matches one of the prototypes. The prototypes in ConSpec provide two key benefits for credit assignment: (i) They enable rapid identification of all the critical steps. (ii) They do so in a readily interpretable manner, enabling out-of-distribution generalization when sensory features are altered. Distinct from other contemporary RL approaches to credit assignment, ConSpec takes advantage of the fact that it is easier to retrospectively identify the small set of steps that success is contingent upon (and ignoring other states) than it is to prospectively predict reward at every taken step. ConSpec greatly improves learning in a diverse set of RL tasks. The code is available at the link: https://github.com/sunchipsster1/ConSpec",
         "This paper proposes contrastive introspection (ConSpec), an algorithm for learning a set of prototypes for critical states via the contrastive loss. ConSpec works by delivering intrinsic rewards when the current states match one of the prototypes. This paper also conducted experiments in various environments. The intuition of learning the critical states is natural and easy to follow. The experimental results in this paper look solid and promising. Despite the empirical performance, the reviewer finds the ConSpec algorithm itself hard to follow.\n\nThe largest weakness is: the insufficient discussion on how the prototypes $h_i$ are learned. Hence, the reviewer cannot understand the detailed on how $h_i$ are used (see detailed in Questions). \n\nBesides insufficient discussion on the prototypes, some minor issues are: (1) the title in the pdf (Contrastive Introspection:. ..) seems to mismatch with the one appear in openreview (ConSpec: …). (2) The font of citations appears to be confusing. E.g., from line 19-20 in the introduction, the manuscript uses (number) to address some key points, and the citation also appears as (number) – it would be nice if the citation can be changed to something that is not (number; number).\n Per the major weaknesses:\n1. How are the prototypes $h_i$ actually learned? If the reviewer understands correctly, in line 7 of the abstract, the manuscript says “ConSpec learns a set of prototypes…”. While in Algorithm 1, it seems that the prototypes $h_i$ are given to the algorithm as inputs. Maybe the author can clarify why this inconsistency in learning the prototypes happens?\n2. How are the $h_i$ learned/chosen in each experiment? The reviewer has looked into the detail of the experiments in the appendix, but cannot clearly understand how the presented experiments actually utilize the $h_i$. It would be nice that the authors can provide more details of all the $h_i$ in all the present experiments (Sec. 4.1-4.5).  \n See questions and weaknesses.",
         "313",
         "0",
         "2",
         "0.7000000000000001",
         "0.0809294872",
         "0.8764749765000001",
         "216",
         "48.5775",
         "0.0354",
         "neurips",
         "0.0",
         "2",
         "4",
         "3",
         "2",
         "factual",
         "4",
         "3",
         "60",
         "polite",
         "3",
         "neutral",
         "5",
         "none",
         "4",
         "4",
         "4",
         "4",
         "partially factual",
         "4",
         "3",
         "75",
         "polite",
         "5",
         "neutral",
         "4",
         "low",
         "2.0",
         "4.0",
         "4.0",
         "3.0",
         "factual",
         "4.0",
         "4.0",
         "70.0",
         "polite",
         "4.0",
         "neutral",
         "3.0",
         "low",
         "3",
         "4",
         "3",
         "3",
         "factual",
         "4",
         "4",
         "70",
         "polite",
         "4",
         "neutral",
         "4",
         "low",
         "3",
         "4",
         "3",
         "4",
         "partially factual",
         "4",
         "4",
         "78",
         "polite",
         "5",
         "neutral",
         "4",
         "low"
        ]
       ],
       "shape": {
        "columns": 81,
        "rows": 395
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>review_text</th>\n",
       "      <th>length_words</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>mattr</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>...</th>\n",
       "      <th>Phi_Constructiveness</th>\n",
       "      <th>Phi_Factuality</th>\n",
       "      <th>Phi_Fairness</th>\n",
       "      <th>Phi_Objectivity</th>\n",
       "      <th>Phi_Overall_Quality</th>\n",
       "      <th>Phi_Politeness</th>\n",
       "      <th>Phi_Relevance_Alignment</th>\n",
       "      <th>Phi_Sentiment_Polarity</th>\n",
       "      <th>Phi_Usage_of_Technical_Terms</th>\n",
       "      <th>Phi_Vagueness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-7mFW</td>\n",
       "      <td>Seizing Serendipity: Exploiting the Value of P...</td>\n",
       "      <td>Learning high-quality $Q$-value functions play...</td>\n",
       "      <td>This work focuses on the Q-function value over...</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.124510</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-FAWm</td>\n",
       "      <td>Seizing Serendipity: Exploiting the Value of P...</td>\n",
       "      <td>Learning high-quality $Q$-value functions play...</td>\n",
       "      <td>This paper presents the Blended Exploitation a...</td>\n",
       "      <td>432</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.158831</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Reviewer-kjkr</td>\n",
       "      <td>Seizing Serendipity: Exploiting the Value of P...</td>\n",
       "      <td>Learning high-quality $Q$-value functions play...</td>\n",
       "      <td>Motivated by the problem of underestimating va...</td>\n",
       "      <td>328</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.146498</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Enrico-Daga</td>\n",
       "      <td>LL(O)D and NLP Perspectives on Semantic Change...</td>\n",
       "      <td>The paper presents an overview of the LL(O)D a...</td>\n",
       "      <td>The authors have performed significant changes...</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.164583</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Julia-Bosque</td>\n",
       "      <td>LL(O)D and NLP Perspectives on Semantic Change...</td>\n",
       "      <td>The paper presents an overview of the LL(O)D a...</td>\n",
       "      <td>I reviewed a previous version of this manuscri...</td>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.169733</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>factual</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>114</td>\n",
       "      <td>Reviewer-n4fn</td>\n",
       "      <td>Mitigating Interference in the Knowledge Conti...</td>\n",
       "      <td>Continual learning (CL) remains a significant ...</td>\n",
       "      <td>The paper introduces a rehearsal-based method ...</td>\n",
       "      <td>233</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7893</td>\n",
       "      <td>0.214947</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-wEMM</td>\n",
       "      <td>FACE: Evaluating Natural Language Generation w...</td>\n",
       "      <td>Measuring the distance between machine-produce...</td>\n",
       "      <td>In order to distinguish between human-generate...</td>\n",
       "      <td>304</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>0.170294</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-s437</td>\n",
       "      <td>FACE: Evaluating Natural Language Generation w...</td>\n",
       "      <td>Measuring the distance between machine-produce...</td>\n",
       "      <td>This paper proposes a new measure of natural l...</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-mMGf</td>\n",
       "      <td>FACE: Evaluating Natural Language Generation w...</td>\n",
       "      <td>Measuring the distance between machine-produce...</td>\n",
       "      <td>This paper proposes a set of metrics based on ...</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.068210</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>polite</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>75</td>\n",
       "      <td>Reviewer-v6cq</td>\n",
       "      <td>FACE: Evaluating Natural Language Generation w...</td>\n",
       "      <td>Measuring the distance between machine-produce...</td>\n",
       "      <td>This paper proposes a set of metrics to measur...</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.216739</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>polite</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id       reviewer  \\\n",
       "0         166  Reviewer-7mFW   \n",
       "1         166  Reviewer-FAWm   \n",
       "2         166  Reviewer-kjkr   \n",
       "3         100    Enrico-Daga   \n",
       "4         100   Julia-Bosque   \n",
       "..        ...            ...   \n",
       "390       114  Reviewer-n4fn   \n",
       "391        75  Reviewer-wEMM   \n",
       "392        75  Reviewer-s437   \n",
       "393        75  Reviewer-mMGf   \n",
       "394        75  Reviewer-v6cq   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Seizing Serendipity: Exploiting the Value of P...   \n",
       "1    Seizing Serendipity: Exploiting the Value of P...   \n",
       "2    Seizing Serendipity: Exploiting the Value of P...   \n",
       "3    LL(O)D and NLP Perspectives on Semantic Change...   \n",
       "4    LL(O)D and NLP Perspectives on Semantic Change...   \n",
       "..                                                 ...   \n",
       "390  Mitigating Interference in the Knowledge Conti...   \n",
       "391  FACE: Evaluating Natural Language Generation w...   \n",
       "392  FACE: Evaluating Natural Language Generation w...   \n",
       "393  FACE: Evaluating Natural Language Generation w...   \n",
       "394  FACE: Evaluating Natural Language Generation w...   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    Learning high-quality $Q$-value functions play...   \n",
       "1    Learning high-quality $Q$-value functions play...   \n",
       "2    Learning high-quality $Q$-value functions play...   \n",
       "3    The paper presents an overview of the LL(O)D a...   \n",
       "4    The paper presents an overview of the LL(O)D a...   \n",
       "..                                                 ...   \n",
       "390  Continual learning (CL) remains a significant ...   \n",
       "391  Measuring the distance between machine-produce...   \n",
       "392  Measuring the distance between machine-produce...   \n",
       "393  Measuring the distance between machine-produce...   \n",
       "394  Measuring the distance between machine-produce...   \n",
       "\n",
       "                                           review_text  length_words  \\\n",
       "0    This work focuses on the Q-function value over...           273   \n",
       "1    This paper presents the Blended Exploitation a...           432   \n",
       "2    Motivated by the problem of underestimating va...           328   \n",
       "3    The authors have performed significant changes...           162   \n",
       "4    I reviewed a previous version of this manuscri...           503   \n",
       "..                                                 ...           ...   \n",
       "390  The paper introduces a rehearsal-based method ...           233   \n",
       "391  In order to distinguish between human-generate...           304   \n",
       "392  This paper proposes a new measure of natural l...           345   \n",
       "393  This paper proposes a set of metrics based on ...           314   \n",
       "394  This paper proposes a set of metrics to measur...           159   \n",
       "\n",
       "     citation_count  question_count   mattr  sentiment_polarity  ...  \\\n",
       "0                 0               5  0.7173            0.124510  ...   \n",
       "1                 8              14  0.7996            0.158831  ...   \n",
       "2                 4               8  0.8027            0.146498  ...   \n",
       "3                 0               1  0.8103            0.164583  ...   \n",
       "4                 1               5  0.7741            0.169733  ...   \n",
       "..              ...             ...     ...                 ...  ...   \n",
       "390               4               2  0.7893            0.214947  ...   \n",
       "391               2               8  0.8037            0.170294  ...   \n",
       "392               0               1  0.8233            0.074735  ...   \n",
       "393               0               5  0.8096            0.068210  ...   \n",
       "394               0               5  0.8219            0.216739  ...   \n",
       "\n",
       "     Phi_Constructiveness     Phi_Factuality  Phi_Fairness  Phi_Objectivity  \\\n",
       "0                       4  partially factual             3                4   \n",
       "1                       4  partially factual             4                4   \n",
       "2                       4  partially factual             4                3   \n",
       "3                       4            factual             4                4   \n",
       "4                       5            factual             5                5   \n",
       "..                    ...                ...           ...              ...   \n",
       "390                     4  partially factual             3                3   \n",
       "391                     3  partially factual             3                3   \n",
       "392                     4            factual             4                4   \n",
       "393                     4  partially factual             4                4   \n",
       "394                     3  partially factual             4                3   \n",
       "\n",
       "    Phi_Overall_Quality  Phi_Politeness  Phi_Relevance_Alignment  \\\n",
       "0                    75          polite                        5   \n",
       "1                    85          polite                        5   \n",
       "2                    78         neutral                        5   \n",
       "3                    85          polite                        5   \n",
       "4                    95          polite                        5   \n",
       "..                  ...             ...                      ...   \n",
       "390                  75          polite                        4   \n",
       "391                  65         neutral                        4   \n",
       "392                  85          polite                        5   \n",
       "393                  85          polite                        5   \n",
       "394                  75          polite                        4   \n",
       "\n",
       "     Phi_Sentiment_Polarity  Phi_Usage_of_Technical_Terms  Phi_Vagueness  \n",
       "0                   neutral                             4            low  \n",
       "1                   neutral                             3            low  \n",
       "2                  negative                             5            low  \n",
       "3                  positive                             3            low  \n",
       "4                  positive                             4            low  \n",
       "..                      ...                           ...            ...  \n",
       "390                 neutral                             4            low  \n",
       "391                negative                             4            low  \n",
       "392                 neutral                             5            low  \n",
       "393                 neutral                             3            low  \n",
       "394                positive                             4            low  \n",
       "\n",
       "[395 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df_all = pd.read_csv('human_llms_qmetrics.csv')\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper_id', 'reviewer', 'title', 'abstract', 'review_text',\n",
       "       'length_words', 'citation_count', 'question_count', 'mattr',\n",
       "       'sentiment_polarity', 'similarity_score', 'days_to_submit',\n",
       "       'flesch_reading_ease', 'politeness_score', 'venue', 'hedging',\n",
       "       'Human_Actionability', 'Human_Clarity_and_Readability',\n",
       "       'Human_Comprehensiveness', 'Human_Constructiveness', 'Human_Factuality',\n",
       "       'Human_Fairness', 'Human_Objectivity', 'Human_Overall_Quality',\n",
       "       'Human_Politeness', 'Human_Relevance_Alignment',\n",
       "       'Human_Sentiment_Polarity', 'Human_Usage_of_Technical_Terms',\n",
       "       'Human_Vagueness', 'Qwen_Actionability', 'Qwen_Clarity_and_Readability',\n",
       "       'Qwen_Comprehensiveness', 'Qwen_Constructiveness', 'Qwen_Factuality',\n",
       "       'Qwen_Fairness', 'Qwen_Objectivity', 'Qwen_Overall_Quality',\n",
       "       'Qwen_Politeness', 'Qwen_Relevance_Alignment',\n",
       "       'Qwen_Sentiment_Polarity', 'Qwen_Usage_of_Technical_Terms',\n",
       "       'Qwen_Vagueness', 'Llama_Actionability',\n",
       "       'Llama_Clarity_and_Readability', 'Llama_Comprehensiveness',\n",
       "       'Llama_Constructiveness', 'Llama_Factuality', 'Llama_Fairness',\n",
       "       'Llama_Objectivity', 'Llama_Overall_Quality', 'Llama_Politeness',\n",
       "       'Llama_Relevance_Alignment', 'Llama_Sentiment_Polarity',\n",
       "       'Llama_Usage_of_Technical_Terms', 'Llama_Vagueness',\n",
       "       'GPT_Actionability', 'GPT_Clarity_and_Readability',\n",
       "       'GPT_Comprehensiveness', 'GPT_Constructiveness', 'GPT_Factuality',\n",
       "       'GPT_Fairness', 'GPT_Objectivity', 'GPT_Overall_Quality',\n",
       "       'GPT_Politeness', 'GPT_Relevance_Alignment', 'GPT_Sentiment_Polarity',\n",
       "       'GPT_Usage_of_Technical_Terms', 'GPT_Vagueness', 'Phi_Actionability',\n",
       "       'Phi_Clarity_and_Readability', 'Phi_Comprehensiveness',\n",
       "       'Phi_Constructiveness', 'Phi_Factuality', 'Phi_Fairness',\n",
       "       'Phi_Objectivity', 'Phi_Overall_Quality', 'Phi_Politeness',\n",
       "       'Phi_Relevance_Alignment', 'Phi_Sentiment_Polarity',\n",
       "       'Phi_Usage_of_Technical_Terms', 'Phi_Vagueness'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 train/test pairs in the ‘Folds’ folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 1) Load your DataFrame however you like.\n",
    "#    For example, if it’s already in memory:\n",
    "# df = your_dataframe\n",
    "\n",
    "# 2) Set up 10-fold splitter\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3) Make the base folder\n",
    "os.makedirs('Folds', exist_ok=True)\n",
    "\n",
    "# 4) Loop and save\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df_all), start=1):\n",
    "    train_df = df_all.iloc[train_idx]\n",
    "    test_df  = df_all.iloc[test_idx]\n",
    "    \n",
    "    train_df.to_csv(f'Folds/f{fold}_train.csv', index=False)\n",
    "    test_df.to_csv( f'Folds/f{fold}_test.csv',  index=False)\n",
    "\n",
    "print(\"Saved 10 train/test pairs in the ‘Folds’ folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1:\n",
      "  Qwen {Kendall's Tau: 0.265, Krippendorff's Alpha: 0.313}\n",
      "  GPT {Kendall's Tau: 0.311, Krippendorff's Alpha: 0.340}\n",
      "  Phi {Kendall's Tau: 0.178, Krippendorff's Alpha: 0.088}\n",
      "  Output {Kendall's Tau: 0.253, Krippendorff's Alpha: 0.343}\n",
      "\n",
      "Fold2:\n",
      "  Qwen {Kendall's Tau: 0.398, Krippendorff's Alpha: 0.229}\n",
      "  GPT {Kendall's Tau: 0.448, Krippendorff's Alpha: 0.396}\n",
      "  Phi {Kendall's Tau: 0.298, Krippendorff's Alpha: 0.156}\n",
      "  Output {Kendall's Tau: 0.195, Krippendorff's Alpha: 0.127}\n",
      "\n",
      "Fold3:\n",
      "  Qwen {Kendall's Tau: 0.245, Krippendorff's Alpha: 0.126}\n",
      "  GPT {Kendall's Tau: 0.443, Krippendorff's Alpha: 0.396}\n",
      "  Phi {Kendall's Tau: 0.322, Krippendorff's Alpha: 0.062}\n",
      "  Output {Kendall's Tau: 0.375, Krippendorff's Alpha: 0.507}\n",
      "\n",
      "Fold4:\n",
      "  Qwen {Kendall's Tau: 0.189, Krippendorff's Alpha: 0.205}\n",
      "  GPT {Kendall's Tau: 0.471, Krippendorff's Alpha: 0.521}\n",
      "  Phi {Kendall's Tau: 0.372, Krippendorff's Alpha: 0.299}\n",
      "  Output {Kendall's Tau: 0.306, Krippendorff's Alpha: 0.419}\n",
      "\n",
      "Fold5:\n",
      "  Qwen {Kendall's Tau: 0.349, Krippendorff's Alpha: 0.249}\n",
      "  GPT {Kendall's Tau: 0.164, Krippendorff's Alpha: 0.201}\n",
      "  Phi {Kendall's Tau: 0.088, Krippendorff's Alpha: 0.083}\n",
      "  Output {Kendall's Tau: 0.258, Krippendorff's Alpha: 0.329}\n",
      "\n",
      "Fold6:\n",
      "  Qwen {Kendall's Tau: 0.361, Krippendorff's Alpha: 0.128}\n",
      "  GPT {Kendall's Tau: 0.427, Krippendorff's Alpha: 0.434}\n",
      "  Phi {Kendall's Tau: 0.233, Krippendorff's Alpha: 0.012}\n",
      "  Output {Kendall's Tau: 0.430, Krippendorff's Alpha: 0.460}\n",
      "\n",
      "Fold7:\n",
      "  Qwen {Kendall's Tau: 0.160, Krippendorff's Alpha: -0.029}\n",
      "  GPT {Kendall's Tau: 0.460, Krippendorff's Alpha: 0.198}\n",
      "  Phi {Kendall's Tau: 0.378, Krippendorff's Alpha: 0.099}\n",
      "  Output {Kendall's Tau: 0.485, Krippendorff's Alpha: 0.697}\n",
      "\n",
      "Fold8:\n",
      "  Qwen {Kendall's Tau: 0.166, Krippendorff's Alpha: -0.037}\n",
      "  GPT {Kendall's Tau: 0.240, Krippendorff's Alpha: 0.221}\n",
      "  Phi {Kendall's Tau: 0.109, Krippendorff's Alpha: -0.057}\n",
      "  Output {Kendall's Tau: 0.243, Krippendorff's Alpha: 0.287}\n",
      "\n",
      "Fold9:\n",
      "  Qwen {Kendall's Tau: 0.314, Krippendorff's Alpha: -0.037}\n",
      "  GPT {Kendall's Tau: 0.335, Krippendorff's Alpha: 0.115}\n",
      "  Phi {Kendall's Tau: 0.137, Krippendorff's Alpha: -0.093}\n",
      "  Output {Kendall's Tau: 0.350, Krippendorff's Alpha: 0.405}\n",
      "\n",
      "Fold10:\n",
      "  Qwen {Kendall's Tau: 0.272, Krippendorff's Alpha: 0.291}\n",
      "  GPT {Kendall's Tau: 0.419, Krippendorff's Alpha: 0.470}\n",
      "  Phi {Kendall's Tau: 0.427, Krippendorff's Alpha: 0.351}\n",
      "  Output {Kendall's Tau: 0.499, Krippendorff's Alpha: 0.658}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GPT\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import kendalltau\n",
    "import krippendorff  # pip install krippendorff\n",
    "\n",
    "# the features to use\n",
    "features = [\n",
    "    'length_words', 'citation_count', 'question_count', 'mattr',\n",
    "    'sentiment_polarity', 'similarity_score', 'flesch_reading_ease',\n",
    "    'politeness_score', 'hedging'\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in range(1, 11):\n",
    "    # load train/test for fold i\n",
    "    train = pd.read_csv(f\"Folds/f{i}_train.csv\")\n",
    "    test  = pd.read_csv(f\"Folds/f{i}_test.csv\")\n",
    "    \n",
    "    # train\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(train[features], train['Human_Overall_Quality'])\n",
    "    \n",
    "    # predict on test\n",
    "    y_true = test['Human_Overall_Quality']\n",
    "    y_pred_model = clf.predict(test[features])\n",
    "    \n",
    "    # collect metrics\n",
    "    fold_key = f\"Fold{i}\"\n",
    "    results[fold_key] = {}\n",
    "    \n",
    "    for name, y_pred in [\n",
    "        ('Qwen', test['Qwen_Overall_Quality']),\n",
    "        ('GPT',  test['GPT_Overall_Quality']),\n",
    "        ('Phi',  test['Phi_Overall_Quality']),\n",
    "        ('Output', y_pred_model)\n",
    "    ]:\n",
    "        tau   = kendalltau(y_true, y_pred).correlation\n",
    "        alpha = krippendorff.alpha([y_true, y_pred])\n",
    "        results[fold_key][name] = {\n",
    "            \"kendall_tau\":       tau,\n",
    "            \"krippendorff_alpha\": alpha\n",
    "        }\n",
    "\n",
    "# print results\n",
    "for fold, metrics in results.items():\n",
    "    print(f\"{fold}:\")\n",
    "    for name, m in metrics.items():\n",
    "        print(f\"  {name} {{Kendall's Tau: {m['kendall_tau']:.3f}, \"\n",
    "              f\"Krippendorff's Alpha: {m['krippendorff_alpha']:.3f}}}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1:\n",
      "Qwen {Kendall Tau: 0.265, Krippendorff Alpha: 0.253}\n",
      "GPT {Kendall Tau: 0.311, Krippendorff Alpha: 0.361}\n",
      "Phi {Kendall Tau: 0.178, Krippendorff Alpha: 0.158}\n",
      "Output {Kendall Tau: 0.133, Krippendorff Alpha: 0.19}\n",
      "\n",
      "\n",
      "Fold2:\n",
      "Qwen {Kendall Tau: 0.398, Krippendorff Alpha: 0.273}\n",
      "GPT {Kendall Tau: 0.448, Krippendorff Alpha: 0.485}\n",
      "Phi {Kendall Tau: 0.298, Krippendorff Alpha: 0.266}\n",
      "Output {Kendall Tau: 0.302, Krippendorff Alpha: 0.4}\n",
      "\n",
      "\n",
      "Fold3:\n",
      "Qwen {Kendall Tau: 0.245, Krippendorff Alpha: 0.138}\n",
      "GPT {Kendall Tau: 0.443, Krippendorff Alpha: 0.518}\n",
      "Phi {Kendall Tau: 0.322, Krippendorff Alpha: 0.259}\n",
      "Output {Kendall Tau: 0.418, Krippendorff Alpha: 0.558}\n",
      "\n",
      "\n",
      "Fold4:\n",
      "Qwen {Kendall Tau: 0.189, Krippendorff Alpha: 0.14}\n",
      "GPT {Kendall Tau: 0.471, Krippendorff Alpha: 0.468}\n",
      "Phi {Kendall Tau: 0.372, Krippendorff Alpha: 0.366}\n",
      "Output {Kendall Tau: 0.368, Krippendorff Alpha: 0.498}\n",
      "\n",
      "\n",
      "Fold5:\n",
      "Qwen {Kendall Tau: 0.349, Krippendorff Alpha: 0.334}\n",
      "GPT {Kendall Tau: 0.164, Krippendorff Alpha: 0.17}\n",
      "Phi {Kendall Tau: 0.088, Krippendorff Alpha: 0.111}\n",
      "Output {Kendall Tau: 0.279, Krippendorff Alpha: 0.374}\n",
      "\n",
      "\n",
      "Fold6:\n",
      "Qwen {Kendall Tau: 0.361, Krippendorff Alpha: 0.223}\n",
      "GPT {Kendall Tau: 0.427, Krippendorff Alpha: 0.48}\n",
      "Phi {Kendall Tau: 0.233, Krippendorff Alpha: 0.114}\n",
      "Output {Kendall Tau: 0.329, Krippendorff Alpha: 0.467}\n",
      "\n",
      "\n",
      "Fold7:\n",
      "Qwen {Kendall Tau: 0.16, Krippendorff Alpha: 0.069}\n",
      "GPT {Kendall Tau: 0.46, Krippendorff Alpha: 0.489}\n",
      "Phi {Kendall Tau: 0.378, Krippendorff Alpha: 0.407}\n",
      "Output {Kendall Tau: 0.364, Krippendorff Alpha: 0.535}\n",
      "\n",
      "\n",
      "Fold8:\n",
      "Qwen {Kendall Tau: 0.166, Krippendorff Alpha: -0.054}\n",
      "GPT {Kendall Tau: 0.24, Krippendorff Alpha: 0.21}\n",
      "Phi {Kendall Tau: 0.109, Krippendorff Alpha: -0.085}\n",
      "Output {Kendall Tau: 0.302, Krippendorff Alpha: 0.413}\n",
      "\n",
      "\n",
      "Fold9:\n",
      "Qwen {Kendall Tau: 0.314, Krippendorff Alpha: 0.077}\n",
      "GPT {Kendall Tau: 0.335, Krippendorff Alpha: 0.344}\n",
      "Phi {Kendall Tau: 0.137, Krippendorff Alpha: 0.01}\n",
      "Output {Kendall Tau: 0.197, Krippendorff Alpha: 0.3}\n",
      "\n",
      "\n",
      "Fold10:\n",
      "Qwen {Kendall Tau: 0.272, Krippendorff Alpha: 0.19}\n",
      "GPT {Kendall Tau: 0.419, Krippendorff Alpha: 0.488}\n",
      "Phi {Kendall Tau: 0.427, Krippendorff Alpha: 0.305}\n",
      "Output {Kendall Tau: 0.503, Krippendorff Alpha: 0.652}\n",
      "\n",
      "\n",
      "\n",
      "Average across all folds:\n",
      "Qwen: {Kendall Tau: 0.272, Krippendorff Alpha: 0.164}\n",
      "GPT: {Kendall Tau: 0.372, Krippendorff Alpha: 0.401}\n",
      "Phi: {Kendall Tau: 0.254, Krippendorff Alpha: 0.191}\n",
      "Output: {Kendall Tau: 0.320, Krippendorff Alpha: 0.439}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import kendalltau\n",
    "import krippendorff\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    'length_words', 'citation_count', 'question_count', 'mattr',\n",
    "    'sentiment_polarity', 'similarity_score', 'flesch_reading_ease',\n",
    "    'politeness_score', 'hedging'\n",
    "]\n",
    "target = 'Human_Overall_Quality'\n",
    "all_fold_metrics = []\n",
    "\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold in range(1, 11):\n",
    "    print(f\"Fold{fold}:\")\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(f\"Folds/f{fold}_train.csv\")\n",
    "    test_df = pd.read_csv(f\"Folds/f{fold}_test.csv\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[target]\n",
    "    X_test = test_df[features]\n",
    "    y_test = test_df[target]\n",
    "    \n",
    "    # Train model\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Groups to compare with Human_Overall_Quality\n",
    "    groups = {\n",
    "        \"Qwen\": test_df[\"Qwen_Overall_Quality\"],\n",
    "        \"GPT\": test_df[\"GPT_Overall_Quality\"],\n",
    "        \"Phi\": test_df[\"Phi_Overall_Quality\"],\n",
    "        \"Output\": y_pred\n",
    "    }\n",
    "    \n",
    "    # Compute metrics for each group\n",
    "    results = {}\n",
    "    for name, scores in groups.items():\n",
    "        # Kendall's Tau\n",
    "        tau, _ = kendalltau(y_test, scores)\n",
    "        \n",
    "        # Krippendorff's Alpha (requires 2D array of shape [raters, items])\n",
    "        data = [y_test.tolist(), scores.tolist()]\n",
    "        alpha = krippendorff.alpha(data, level_of_measurement='ordinal')\n",
    "        \n",
    "        results[name] = {\n",
    "            \"Kendall Tau\": round(tau, 3),\n",
    "            \"Krippendorff Alpha\": round(alpha, 3)\n",
    "        }\n",
    "    \n",
    "    # Print results\n",
    "    for model in [\"Qwen\", \"GPT\", \"Phi\", \"Output\"]:\n",
    "        metrics = results[model]\n",
    "        print(f\"{model} {{Kendall Tau: {metrics['Kendall Tau']}, Krippendorff Alpha: {metrics['Krippendorff Alpha']}}}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    all_fold_metrics.append(results)\n",
    "    \n",
    "\n",
    "# After processing all folds, calculate averages\n",
    "average_metrics = {\n",
    "    model: {\n",
    "        \"kendall\": sum(fold[model][\"Kendall Tau\"] for fold in all_fold_metrics) / 10,\n",
    "        \"alpha\": sum(fold[model][\"Krippendorff Alpha\"] for fold in all_fold_metrics) / 10\n",
    "    }\n",
    "    for model in [\"Qwen\", \"GPT\", \"Phi\", \"Output\"]\n",
    "}\n",
    "\n",
    "# Print final averages\n",
    "print(\"\\nAverage across all folds:\")\n",
    "for model, metrics in average_metrics.items():\n",
    "    print(f\"{model}: {{Kendall Tau: {metrics['kendall']:.3f}, Krippendorff Alpha: {metrics['alpha']:.3f}}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Fold 1\n",
      "========================================\n",
      "\n",
      "Random Forest Feature Importance (Fold 1):\n",
      "  length_words: 0.5458\n",
      "  flesch_reading_ease: 0.0936\n",
      "  similarity_score: 0.0879\n",
      "  mattr: 0.0662\n",
      "  sentiment_polarity: 0.0652\n",
      "  politeness_score: 0.0627\n",
      "  hedging: 0.0373\n",
      "  question_count: 0.0303\n",
      "  citation_count: 0.0110\n",
      "\n",
      "Random Forest:\n",
      "Output Kendall: 0.426, Alpha: 0.586\n",
      "\n",
      "SVR Feature Importance (Fold 1):\n",
      "  politeness_score: 0.5040\n",
      "  similarity_score: 0.2024\n",
      "  sentiment_polarity: 0.0951\n",
      "  citation_count: 0.0671\n",
      "  hedging: 0.0439\n",
      "  question_count: 0.0330\n",
      "  mattr: 0.0290\n",
      "  flesch_reading_ease: 0.0210\n",
      "  length_words: 0.0045\n",
      "\n",
      "SVR:\n",
      "Output Kendall: 0.395, Alpha: 0.532\n",
      "\n",
      "Linear Regression Feature Importance (Fold 1):\n",
      "  hedging: 0.7731\n",
      "  politeness_score: 0.0684\n",
      "  mattr: 0.0603\n",
      "  similarity_score: 0.0483\n",
      "  sentiment_polarity: 0.0453\n",
      "  citation_count: 0.0018\n",
      "  question_count: 0.0016\n",
      "  flesch_reading_ease: 0.0009\n",
      "  length_words: 0.0001\n",
      "\n",
      "Linear Regression:\n",
      "Output Kendall: 0.339, Alpha: 0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/Review_Quality_Benchmark/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Feature Importance (Fold 1):\n",
      "  length_words: 0.8839\n",
      "  flesch_reading_ease: 0.2069\n",
      "  citation_count: 0.1285\n",
      "  sentiment_polarity: 0.0025\n",
      "  mattr: 0.0011\n",
      "  hedging: 0.0000\n",
      "  similarity_score: -0.0009\n",
      "  politeness_score: -0.0166\n",
      "  question_count: -0.2055\n",
      "\n",
      "Neural Network:\n",
      "Output Kendall: 0.402, Alpha: 0.579\n",
      "\n",
      "XGBoost Feature Importance (Fold 1):\n",
      "  length_words: 0.3384\n",
      "  hedging: 0.1405\n",
      "  flesch_reading_ease: 0.1376\n",
      "  similarity_score: 0.0806\n",
      "  sentiment_polarity: 0.0771\n",
      "  politeness_score: 0.0744\n",
      "  mattr: 0.0581\n",
      "  question_count: 0.0581\n",
      "  citation_count: 0.0352\n",
      "\n",
      "XGBoost:\n",
      "Output Kendall: 0.408, Alpha: 0.554\n",
      "\n",
      "========================================\n",
      "Fold 2\n",
      "========================================\n",
      "\n",
      "Random Forest Feature Importance (Fold 2):\n",
      "  length_words: 0.5068\n",
      "  flesch_reading_ease: 0.1025\n",
      "  similarity_score: 0.0869\n",
      "  sentiment_polarity: 0.0788\n",
      "  politeness_score: 0.0743\n",
      "  mattr: 0.0703\n",
      "  hedging: 0.0420\n",
      "  question_count: 0.0251\n",
      "  citation_count: 0.0133\n",
      "\n",
      "Random Forest:\n",
      "Output Kendall: 0.435, Alpha: 0.540\n",
      "\n",
      "SVR Feature Importance (Fold 2):\n",
      "  politeness_score: 0.5311\n",
      "  similarity_score: 0.2771\n",
      "  sentiment_polarity: 0.0934\n",
      "  hedging: 0.0471\n",
      "  flesch_reading_ease: 0.0266\n",
      "  mattr: 0.0096\n",
      "  citation_count: 0.0094\n",
      "  length_words: 0.0042\n",
      "  question_count: 0.0016\n",
      "\n",
      "SVR:\n",
      "Output Kendall: 0.486, Alpha: 0.564\n",
      "\n",
      "Linear Regression Feature Importance (Fold 2):\n",
      "  hedging: 0.8098\n",
      "  sentiment_polarity: 0.0577\n",
      "  similarity_score: 0.0542\n",
      "  mattr: 0.0401\n",
      "  politeness_score: 0.0368\n",
      "  flesch_reading_ease: 0.0009\n",
      "  question_count: 0.0004\n",
      "  length_words: 0.0001\n",
      "  citation_count: 0.0000\n",
      "\n",
      "Linear Regression:\n",
      "Output Kendall: 0.454, Alpha: 0.495\n",
      "\n",
      "Neural Network Feature Importance (Fold 2):\n",
      "  length_words: 0.7808\n",
      "  flesch_reading_ease: 0.1898\n",
      "  question_count: 0.0169\n",
      "  citation_count: 0.0114\n",
      "  similarity_score: 0.0014\n",
      "  mattr: 0.0004\n",
      "  politeness_score: 0.0004\n",
      "  hedging: -0.0000\n",
      "  sentiment_polarity: -0.0011\n",
      "\n",
      "Neural Network:\n",
      "Output Kendall: 0.409, Alpha: 0.502\n",
      "\n",
      "XGBoost Feature Importance (Fold 2):\n",
      "  length_words: 0.2997\n",
      "  flesch_reading_ease: 0.1310\n",
      "  hedging: 0.1299\n",
      "  politeness_score: 0.1076\n",
      "  similarity_score: 0.1039\n",
      "  sentiment_polarity: 0.0842\n",
      "  mattr: 0.0548\n",
      "  citation_count: 0.0467\n",
      "  question_count: 0.0423\n",
      "\n",
      "XGBoost:\n",
      "Output Kendall: 0.404, Alpha: 0.498\n",
      "\n",
      "========================================\n",
      "Fold 3\n",
      "========================================\n",
      "\n",
      "Random Forest Feature Importance (Fold 3):\n",
      "  length_words: 0.5204\n",
      "  flesch_reading_ease: 0.1123\n",
      "  similarity_score: 0.0900\n",
      "  mattr: 0.0696\n",
      "  sentiment_polarity: 0.0665\n",
      "  politeness_score: 0.0628\n",
      "  hedging: 0.0391\n",
      "  question_count: 0.0271\n",
      "  citation_count: 0.0121\n",
      "\n",
      "Random Forest:\n",
      "Output Kendall: 0.419, Alpha: 0.552\n",
      "\n",
      "SVR Feature Importance (Fold 3):\n",
      "  politeness_score: 0.3689\n",
      "  similarity_score: 0.3525\n",
      "  citation_count: 0.0751\n",
      "  sentiment_polarity: 0.0505\n",
      "  mattr: 0.0453\n",
      "  hedging: 0.0451\n",
      "  question_count: 0.0339\n",
      "  flesch_reading_ease: 0.0237\n",
      "  length_words: 0.0050\n",
      "\n",
      "SVR:\n",
      "Output Kendall: 0.460, Alpha: 0.576\n",
      "\n",
      "Linear Regression Feature Importance (Fold 3):\n",
      "  hedging: 0.7382\n",
      "  similarity_score: 0.1870\n",
      "  politeness_score: 0.0327\n",
      "  mattr: 0.0286\n",
      "  sentiment_polarity: 0.0082\n",
      "  citation_count: 0.0017\n",
      "  flesch_reading_ease: 0.0017\n",
      "  question_count: 0.0017\n",
      "  length_words: 0.0002\n",
      "\n",
      "Linear Regression:\n",
      "Output Kendall: 0.453, Alpha: 0.538\n",
      "\n",
      "Neural Network Feature Importance (Fold 3):\n",
      "  length_words: 0.6865\n",
      "  flesch_reading_ease: 0.3047\n",
      "  question_count: 0.0059\n",
      "  politeness_score: 0.0018\n",
      "  mattr: 0.0012\n",
      "  sentiment_polarity: 0.0006\n",
      "  citation_count: 0.0002\n",
      "  hedging: -0.0001\n",
      "  similarity_score: -0.0009\n",
      "\n",
      "Neural Network:\n",
      "Output Kendall: 0.415, Alpha: 0.561\n",
      "\n",
      "XGBoost Feature Importance (Fold 3):\n",
      "  length_words: 0.3240\n",
      "  flesch_reading_ease: 0.1294\n",
      "  similarity_score: 0.1128\n",
      "  hedging: 0.1083\n",
      "  politeness_score: 0.0837\n",
      "  mattr: 0.0715\n",
      "  sentiment_polarity: 0.0713\n",
      "  citation_count: 0.0536\n",
      "  question_count: 0.0453\n",
      "\n",
      "XGBoost:\n",
      "Output Kendall: 0.378, Alpha: 0.512\n",
      "\n",
      "========================================\n",
      "Fold 4\n",
      "========================================\n",
      "\n",
      "Random Forest Feature Importance (Fold 4):\n",
      "  length_words: 0.4944\n",
      "  flesch_reading_ease: 0.1095\n",
      "  similarity_score: 0.0903\n",
      "  sentiment_polarity: 0.0784\n",
      "  politeness_score: 0.0672\n",
      "  mattr: 0.0651\n",
      "  hedging: 0.0484\n",
      "  question_count: 0.0344\n",
      "  citation_count: 0.0123\n",
      "\n",
      "Random Forest:\n",
      "Output Kendall: 0.497, Alpha: 0.652\n",
      "\n",
      "SVR Feature Importance (Fold 4):\n",
      "  politeness_score: 0.3784\n",
      "  similarity_score: 0.2592\n",
      "  sentiment_polarity: 0.1698\n",
      "  citation_count: 0.0691\n",
      "  hedging: 0.0466\n",
      "  flesch_reading_ease: 0.0369\n",
      "  mattr: 0.0337\n",
      "  length_words: 0.0058\n",
      "  question_count: 0.0006\n",
      "\n",
      "SVR:\n",
      "Output Kendall: 0.554, Alpha: 0.649\n",
      "\n",
      "Linear Regression Feature Importance (Fold 4):\n",
      "  hedging: 0.7923\n",
      "  mattr: 0.0947\n",
      "  sentiment_polarity: 0.0452\n",
      "  similarity_score: 0.0414\n",
      "  politeness_score: 0.0231\n",
      "  citation_count: 0.0014\n",
      "  flesch_reading_ease: 0.0010\n",
      "  question_count: 0.0007\n",
      "  length_words: 0.0001\n",
      "\n",
      "Linear Regression:\n",
      "Output Kendall: 0.557, Alpha: 0.624\n",
      "\n",
      "Neural Network Feature Importance (Fold 4):\n",
      "  length_words: 0.9126\n",
      "  flesch_reading_ease: 0.0608\n",
      "  citation_count: 0.0307\n",
      "  mattr: 0.0025\n",
      "  politeness_score: 0.0015\n",
      "  sentiment_polarity: 0.0013\n",
      "  similarity_score: 0.0005\n",
      "  hedging: 0.0000\n",
      "  question_count: -0.0098\n",
      "\n",
      "Neural Network:\n",
      "Output Kendall: 0.498, Alpha: 0.618\n",
      "\n",
      "XGBoost Feature Importance (Fold 4):\n",
      "  length_words: 0.2973\n",
      "  hedging: 0.1289\n",
      "  flesch_reading_ease: 0.1235\n",
      "  similarity_score: 0.0941\n",
      "  sentiment_polarity: 0.0883\n",
      "  politeness_score: 0.0849\n",
      "  mattr: 0.0774\n",
      "  citation_count: 0.0569\n",
      "  question_count: 0.0487\n",
      "\n",
      "XGBoost:\n",
      "Output Kendall: 0.503, Alpha: 0.675\n",
      "\n",
      "========================================\n",
      "Fold 5\n",
      "========================================\n",
      "\n",
      "Random Forest Feature Importance (Fold 5):\n",
      "  length_words: 0.5075\n",
      "  flesch_reading_ease: 0.1082\n",
      "  similarity_score: 0.0834\n",
      "  politeness_score: 0.0793\n",
      "  sentiment_polarity: 0.0738\n",
      "  mattr: 0.0609\n",
      "  hedging: 0.0457\n",
      "  question_count: 0.0306\n",
      "  citation_count: 0.0105\n",
      "\n",
      "Random Forest:\n",
      "Output Kendall: 0.481, Alpha: 0.648\n",
      "\n",
      "SVR Feature Importance (Fold 5):\n",
      "  similarity_score: 0.3900\n",
      "  politeness_score: 0.3474\n",
      "  sentiment_polarity: 0.1142\n",
      "  citation_count: 0.0577\n",
      "  hedging: 0.0275\n",
      "  flesch_reading_ease: 0.0253\n",
      "  mattr: 0.0200\n",
      "  question_count: 0.0127\n",
      "  length_words: 0.0052\n",
      "\n",
      "SVR:\n",
      "Output Kendall: 0.464, Alpha: 0.596\n",
      "\n",
      "Linear Regression Feature Importance (Fold 5):\n",
      "  hedging: 0.7663\n",
      "  similarity_score: 0.0956\n",
      "  mattr: 0.0680\n",
      "  sentiment_polarity: 0.0374\n",
      "  politeness_score: 0.0292\n",
      "  citation_count: 0.0018\n",
      "  flesch_reading_ease: 0.0010\n",
      "  question_count: 0.0007\n",
      "  length_words: 0.0002\n",
      "\n",
      "Linear Regression:\n",
      "Output Kendall: 0.494, Alpha: 0.616\n",
      "\n",
      "Neural Network Feature Importance (Fold 5):\n",
      "  length_words: 0.7277\n",
      "  flesch_reading_ease: 0.2582\n",
      "  question_count: 0.0079\n",
      "  citation_count: 0.0064\n",
      "  mattr: 0.0008\n",
      "  sentiment_polarity: 0.0002\n",
      "  hedging: -0.0001\n",
      "  politeness_score: -0.0001\n",
      "  similarity_score: -0.0010\n",
      "\n",
      "Neural Network:\n",
      "Output Kendall: 0.410, Alpha: 0.576\n",
      "\n",
      "XGBoost Feature Importance (Fold 5):\n",
      "  length_words: 0.2802\n",
      "  flesch_reading_ease: 0.1490\n",
      "  hedging: 0.1455\n",
      "  similarity_score: 0.1126\n",
      "  sentiment_polarity: 0.0900\n",
      "  politeness_score: 0.0741\n",
      "  question_count: 0.0536\n",
      "  mattr: 0.0482\n",
      "  citation_count: 0.0468\n",
      "\n",
      "XGBoost:\n",
      "Output Kendall: 0.416, Alpha: 0.544\n",
      "#############################################\n",
      "\n",
      "\n",
      "Average Metrics Across All Folds:\n",
      "\n",
      "Random Forest:\n",
      "  Kendall:\n",
      "    Output: 0.451 ± 0.031\n",
      "  Alpha:\n",
      "    Output: 0.596 ± 0.047\n",
      "\n",
      "SVR:\n",
      "  Kendall:\n",
      "    Output: 0.472 ± 0.051\n",
      "  Alpha:\n",
      "    Output: 0.583 ± 0.039\n",
      "\n",
      "Linear Regression:\n",
      "  Kendall:\n",
      "    Output: 0.459 ± 0.071\n",
      "  Alpha:\n",
      "    Output: 0.551 ± 0.060\n",
      "\n",
      "Neural Network:\n",
      "  Kendall:\n",
      "    Output: 0.426 ± 0.036\n",
      "  Alpha:\n",
      "    Output: 0.567 ± 0.038\n",
      "\n",
      "XGBoost:\n",
      "  Kendall:\n",
      "    Output: 0.422 ± 0.043\n",
      "  Alpha:\n",
      "    Output: 0.557 ± 0.062\n",
      "\n",
      "\n",
      "Average Feature Importance Across All Folds:\n",
      "\n",
      "Random Forest:\n",
      "  length_words: 0.5150 ± 0.0175\n",
      "  flesch_reading_ease: 0.1052 ± 0.0067\n",
      "  similarity_score: 0.0877 ± 0.0025\n",
      "  sentiment_polarity: 0.0725 ± 0.0058\n",
      "  politeness_score: 0.0693 ± 0.0066\n",
      "  mattr: 0.0664 ± 0.0034\n",
      "  hedging: 0.0425 ± 0.0041\n",
      "  question_count: 0.0295 ± 0.0032\n",
      "  citation_count: 0.0118 ± 0.0010\n",
      "\n",
      "SVR:\n",
      "  politeness_score: 0.4260 ± 0.0759\n",
      "  similarity_score: 0.2962 ± 0.0671\n",
      "  sentiment_polarity: 0.1046 ± 0.0387\n",
      "  citation_count: 0.0557 ± 0.0238\n",
      "  hedging: 0.0420 ± 0.0073\n",
      "  mattr: 0.0275 ± 0.0121\n",
      "  flesch_reading_ease: 0.0267 ± 0.0054\n",
      "  question_count: 0.0163 ± 0.0146\n",
      "  length_words: 0.0049 ± 0.0005\n",
      "\n",
      "Linear Regression:\n",
      "  hedging: 0.7759 ± 0.0243\n",
      "  similarity_score: 0.0853 ± 0.0543\n",
      "  mattr: 0.0583 ± 0.0230\n",
      "  sentiment_polarity: 0.0388 ± 0.0166\n",
      "  politeness_score: 0.0381 ± 0.0158\n",
      "  citation_count: 0.0013 ± 0.0007\n",
      "  flesch_reading_ease: 0.0011 ± 0.0003\n",
      "  question_count: 0.0010 ± 0.0005\n",
      "  length_words: 0.0002 ± 0.0000\n",
      "\n",
      "Neural Network:\n",
      "  length_words: 0.7983 ± 0.0874\n",
      "  flesch_reading_ease: 0.2041 ± 0.0822\n",
      "  citation_count: 0.0354 ± 0.0476\n",
      "  mattr: 0.0012 ± 0.0007\n",
      "  sentiment_polarity: 0.0007 ± 0.0012\n",
      "  hedging: -0.0000 ± 0.0000\n",
      "  similarity_score: -0.0002 ± 0.0010\n",
      "  politeness_score: -0.0026 ± 0.0070\n",
      "  question_count: -0.0369 ± 0.0847\n",
      "\n",
      "XGBoost:\n",
      "  length_words: 0.3079 ± 0.0207\n",
      "  flesch_reading_ease: 0.1341 ± 0.0087\n",
      "  hedging: 0.1306 ± 0.0128\n",
      "  similarity_score: 0.1008 ± 0.0122\n",
      "  politeness_score: 0.0849 ± 0.0122\n",
      "  sentiment_polarity: 0.0822 ± 0.0070\n",
      "  mattr: 0.0620 ± 0.0108\n",
      "  question_count: 0.0496 ± 0.0057\n",
      "  citation_count: 0.0479 ± 0.0074\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import kendalltau\n",
    "import krippendorff\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# ================== CONFIGURATION ==================\n",
    "features = [\n",
    "    'length_words', 'citation_count', 'question_count', 'mattr',\n",
    "    'sentiment_polarity', 'similarity_score', 'flesch_reading_ease',\n",
    "    'politeness_score', 'hedging'\n",
    "]\n",
    "feature_importances = {}\n",
    "target = 'Human_Overall_Quality'\n",
    "\n",
    "models = {\n",
    "    # \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    # \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    # \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    # \"SVM\": SVC(random_state=42),\n",
    "    # \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    # \"Neural Network\": MLPClassifier(random_state=42, hidden_layer_sizes=(50,))\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "    \"SVR\": SVR(kernel='linear'),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Neural Network\": MLPRegressor(random_state=42, hidden_layer_sizes=(54, 108, 108, 54)),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# ================== METRIC STORAGE ==================\n",
    "results = {\n",
    "    model_name: {\n",
    "        'Kendall': {'Qwen': [], 'GPT': [], 'Phi': [], 'Output': []},\n",
    "        'Alpha': {'Qwen': [], 'GPT': [], 'Phi': [], 'Output': []}\n",
    "    }\n",
    "    for model_name in models\n",
    "}\n",
    "\n",
    "# ================== MAIN PIPELINE ==================\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n{'='*40}\\nFold {fold}\\n{'='*40}\")\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(f\"Folds/f{fold}_train.csv\")\n",
    "    test_df = pd.read_csv(f\"Folds/f{fold}_test.csv\")\n",
    "    \n",
    "    X_train, y_train = train_df[features], train_df[target]\n",
    "    X_test, y_test = test_df[features], test_df[target]\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Clone model to prevent parameter leakage\n",
    "        cloned_model = clone(model)\n",
    "        \n",
    "        # Train and predict\n",
    "        cloned_model.fit(X_train, y_train)\n",
    "        \n",
    "        # ======== Feature Importance Calculation ================================\n",
    "        if hasattr(cloned_model, 'feature_importances_'):\n",
    "            # Tree-based models\n",
    "            fold_imp = cloned_model.feature_importances_\n",
    "        elif hasattr(cloned_model, 'coef_'):\n",
    "            # Linear models\n",
    "            fold_imp = np.abs(cloned_model.coef_.flatten())\n",
    "        else:\n",
    "            # For models without inherent importance (SVR, MLP)\n",
    "            result = permutation_importance(\n",
    "                cloned_model, X_test, y_test,\n",
    "                n_repeats=10, \n",
    "                random_state=42\n",
    "            )\n",
    "            fold_imp = result.importances_mean\n",
    "        \n",
    "        # Normalize and store\n",
    "        fold_imp = fold_imp / fold_imp.sum()  # Normalize to sum=1\n",
    "        \n",
    "        if model_name not in feature_importances:\n",
    "            feature_importances[model_name] = {\n",
    "                'features': features,\n",
    "                'importances': {f: [] for f in features}\n",
    "            }\n",
    "        \n",
    "        for f, imp in zip(features, fold_imp):\n",
    "            feature_importances[model_name]['importances'][f].append(imp)\n",
    "        \n",
    "        # Print fold-level importance\n",
    "        print(f\"\\n{model_name} Feature Importance (Fold {fold}):\")\n",
    "        sorted_idx = np.argsort(fold_imp)[::-1]\n",
    "        for idx in sorted_idx:\n",
    "            print(f\"  {features[idx]}: {fold_imp[idx]:.4f}\")\n",
    "\n",
    "        # ======== Feature Importance Calculation ================================\n",
    "        \n",
    "        y_pred = cloned_model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        groups = {\n",
    "            'Qwen': test_df['Qwen_Overall_Quality'],\n",
    "            'GPT': test_df['GPT_Overall_Quality'],\n",
    "            'Phi': test_df['Phi_Overall_Quality'],\n",
    "            'Output': y_pred\n",
    "        }\n",
    "\n",
    "        for group_name, scores in groups.items():\n",
    "            # Kendall's Tau\n",
    "            tau, _ = kendalltau(y_test, scores)\n",
    "            results[model_name]['Kendall'][group_name].append(tau)\n",
    "            \n",
    "            # Krippendorff's Alpha\n",
    "            data = [y_test.tolist(), scores.tolist()]\n",
    "            alpha = krippendorff.alpha(data, level_of_measurement='ordinal')\n",
    "            results[model_name]['Alpha'][group_name].append(alpha)\n",
    "\n",
    "        # Print fold results\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"Output Kendall: {tau:.3f}, Alpha: {alpha:.3f}\")\n",
    "\n",
    "\n",
    "print('#############################################')\n",
    "# ================== FINAL RESULTS ==================\n",
    "print(\"\\n\\nAverage Metrics Across All Folds:\")\n",
    "for model_name in models:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric in ['Kendall', 'Alpha']:\n",
    "        print(f\"  {metric}:\")\n",
    "        for group in ['Output']:  # 'Qwen', 'GPT', 'Phi', \n",
    "            avg = np.mean(results[model_name][metric][group])\n",
    "            std = np.std(results[model_name][metric][group])\n",
    "            print(f\"    {group}: {avg:.3f} ± {std:.3f}\")\n",
    "            \n",
    "\n",
    "# ================== FINAL FEATURE IMPORTANCE ==================\n",
    "print(\"\\n\\nAverage Feature Importance Across All Folds:\")\n",
    "for model_name, data in feature_importances.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    avg_imp = {f: np.mean(vals) for f, vals in data['importances'].items()}\n",
    "    sorted_imp = sorted(avg_imp.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for feature, importance in sorted_imp:\n",
    "        print(f\"  {feature}: {importance:.4f} ± {np.std(data['importances'][feature]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ================== PLOTTING ==================\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'axes.labelsize': 16,    # X/Y axis labels\n",
    "    'xtick.labelsize': 16,   # X-axis ticks\n",
    "    'ytick.labelsize': 14,   # Y-axis ticks\n",
    "    'legend.fontsize': 14,   # Legend\n",
    "    'axes.titlesize': 16     # Title\n",
    "})\n",
    "\n",
    "# Data from your results\n",
    "data = {\n",
    "    'Qwen-3': {'kendall Tau': 0.272, 'krippendorff Alpha': 0.164},\n",
    "    'Phi-4': {'kendall Tau': 0.254, 'krippendorff Alpha': 0.191},\n",
    "    'GPT-4o': {'kendall Tau': 0.372, 'krippendorff Alpha': 0.401},\n",
    "    \n",
    "    r'LLaMA-3-FT$\\mathregular{^*}$': {'kendall Tau': 0.406, 'krippendorff Alpha': 0.454},\n",
    "    \n",
    "    'Random Forest': {'kendall Tau': 0.451, 'krippendorff Alpha': 0.551},\n",
    "    'Linear Regression': {'kendall Tau': 0.459, 'krippendorff Alpha': 0.530},\n",
    "    'MLP': {'kendall Tau': 0.426, 'krippendorff Alpha': 0.567},\n",
    "    # 'XGBoost': {'kendall Tau': 0.380, 'krippendorff Alpha': 0.510},\n",
    "    # 'SVR': {'kendall Tau': 0.454, 'krippendorff Alpha': 0.559},\n",
    "}\n",
    "\n",
    "std_devs = {\n",
    "    'Qwen-3': {'kendall Tau': 0.079, 'krippendorff Alpha': 0.109},\n",
    "    'Phi-4': {'kendall Tau': 0.116, 'krippendorff Alpha': 0.149},\n",
    "    'GPT-4o': {'kendall Tau': 0.100, 'krippendorff Alpha': 0.119},\n",
    "    \n",
    "    r'LLaMA-3-FT$\\mathregular{^*}$': {'kendall Tau': 0.035, 'krippendorff Alpha': 0.035},\n",
    "    \n",
    "    'Random Forest': {'kendall Tau': 0.071, 'krippendorff Alpha': 0.060},\n",
    "    'Linear Regression': {'kendall Tau': 0.107, 'krippendorff Alpha': 0.118},\n",
    "    'MLP': {'kendall Tau': 0.036, 'krippendorff Alpha': 0.038},\n",
    "    # 'SVR': {'kendall Tau': 0.089, 'krippendorff Alpha': 0.093},\n",
    "    # 'XGBoost': {'kendall Tau': 0.075, 'krippendorff Alpha': 0.085},\n",
    "}\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Configure style\n",
    "plt.rcParams['font.size'] = 18\n",
    "# colors = plt.cm.tab10.colors  # Get colors from tab10 colormap\n",
    "\n",
    "colors = {\n",
    "    'GPT-4o': '#C0C0C0',    # Lightest Gray\n",
    "    'Qwen-3': '#08306B',   # Medium Blue\n",
    "    'Phi-4': '#4F81BD',   # Very Dark Blue (Navy)\n",
    "    'Random Forest':      '#A5D6A7',  # Medium-light Green\n",
    "    'Linear Regression':  '#FFCC80',  # Medium-light Orange\n",
    "    'MLP':                '#EF9A9A',  # Medium-light Red\n",
    "    r'LLaMA-3-FT$\\mathregular{^*}$':         '#ADD8E6',  # Medium-light Purple\n",
    "}\n",
    "\n",
    "patterns = {\n",
    "    'GPT-4o':  '////',\n",
    "    'Qwen-3': '****',\n",
    "    'Phi-4':  'xxxx',\n",
    "    'Random Forest': '',\n",
    "    'Linear Regression': ''\n",
    "}\n",
    "\n",
    "# Plot parameters\n",
    "bar_width = 0.75\n",
    "index = np.arange(len(data))\n",
    "model_names = list(data.keys())\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Define grouping parameters\n",
    "group1_size = 4  # First 4 columns\n",
    "group2_size = 3  # Next 3 columns\n",
    "intra_group_space = 0.1    # Space within groups\n",
    "inter_group_space = 0.8   # Space between groups\n",
    "\n",
    "# Create positions for each group\n",
    "group1_pos = np.arange(group1_size)\n",
    "group2_pos = np.arange(group1_size + inter_group_space, \n",
    "                      group1_size + inter_group_space + group2_size)\n",
    "all_positions = np.concatenate([group1_pos, group2_pos])\n",
    "\n",
    "# Modified plotting code\n",
    "for i, (model, values) in enumerate(data.items()):\n",
    "    ax1.bar(\n",
    "        all_positions[i] + intra_group_space/2,  # Center bars in their slot\n",
    "        values['kendall Tau'], \n",
    "        width=bar_width - intra_group_space + 0.1,\n",
    "        yerr=std_devs[model]['kendall Tau'],\n",
    "        color=colors[model],\n",
    "        label=model,\n",
    "        capsize=5,\n",
    "        edgecolor='black', \n",
    "        linewidth=1,\n",
    "    )\n",
    "\n",
    "# Set x-axis labels and ticks\n",
    "ax1.set_xticks(all_positions + (bar_width - intra_group_space)/2)\n",
    "ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "\n",
    "# Add visual separation between groups\n",
    "ax1.axvline(x=group1_size + inter_group_space/2 - 0.45, \n",
    "           color='gray', \n",
    "           linestyle='--', \n",
    "           linewidth=0.8,\n",
    "           alpha=1)\n",
    "\n",
    "\n",
    "# Adjust x-axis limits\n",
    "ax1.set_xlim(-0.5, all_positions[-1] + bar_width)\n",
    "############################################################\n",
    "\n",
    "# # Plot Kendall's Tau\n",
    "# for i, (model, values) in enumerate(data.items()):\n",
    "#     ax1.bar(i, values['kendall Tau'], bar_width,\n",
    "#             yerr=std_devs[model]['kendall Tau'],\n",
    "#             color=colors[model],\n",
    "#             label=model,\n",
    "#             # patterns=patterns[model],\n",
    "#             capsize=5\n",
    "#             , edgecolor='black', linewidth=1)\n",
    "\n",
    "ax1.set_title(\"\")\n",
    "ax1.set_ylabel('Kendall Tau')\n",
    "# ax1.set_xticks(index)\n",
    "# ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax1.set_ylim(0, 0.6)\n",
    "ax1.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot Krippendorff's Alpha\n",
    "# for i, (model, values) in enumerate(data.items()):\n",
    "#     ax2.bar(i, values['krippendorff Alpha'], bar_width,\n",
    "#             yerr=std_devs[model]['krippendorff Alpha'],\n",
    "#             color=colors[model],\n",
    "#             # patterns=patterns[model],\n",
    "#             capsize=5)\n",
    "\n",
    "# ax2.set_title(\"Krippendorff's Alpha\")\n",
    "# ax2.set_ylabel('Score', fontsize=16)\n",
    "# ax2.set_xticks(index)\n",
    "# ax2.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "# ax2.set_ylim(0, 0.7)\n",
    "# ax2.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Create a single legend for both plots\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='center left', bbox_to_anchor=(0.85, 0.6))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)  # Make space for legend\n",
    "plt.show()\n",
    "\n",
    "# Save as high quality PNG\n",
    "fig.savefig('model_comparison.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Data from your feature importance results\n",
    "data = {\n",
    "    \"Random Forest\": [0.5129, 0.1051, 0.0885, 0.0738, 0.0724, 0.0637, 0.0423, 0.0292, 0.0121],\n",
    "    # \"SVR\": [0.0046, 0.0249, 0.3210, 0.1085, 0.4155, 0.0145, 0.0443, 0.0147, 0.0520],\n",
    "    \"Linear Regression\": [0.0002, 0.0010, 0.0762, 0.0393, 0.0368, 0.0710, 0.7731, 0.0010, 0.0014],\n",
    "    \"MLP\": [0.7906, 0.1967, -0.0004, 0.0018, -0.0018, 0.0019, -0.0001, -0.0355, 0.0467],\n",
    "    # \"XGBoost\": [0.3093, 0.1228, 0.1033, 0.0841, 0.0959, 0.0642, 0.1252, 0.0508, 0.0444]\n",
    "}\n",
    "\n",
    "features = [\n",
    "    'length_words', 'readability', 'similarity_score', 'sentiment_polarity', 'politeness_score', 'mattr',\n",
    "    'hedging', 'question_count', 'citation_count'\n",
    "]\n",
    "\n",
    "models = list(data.keys())\n",
    "\n",
    "# Create custom blue colormap\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list(\"blue\", [\"#f0f8ff\", \"#0047ab\"])\n",
    "\n",
    "# Create figure with adjusted size and ratios\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Create matrix for visualization\n",
    "matrix = np.array([data[model] for model in models])\n",
    "\n",
    "# Normalize each row (handling negative values)\n",
    "normalized_matrix = np.array([\n",
    "    [max(0, x)/sum(max(0, x) for x in row) for x in row] \n",
    "    for row in matrix\n",
    "])\n",
    "\n",
    "# Display heatmap with adjusted cell size\n",
    "im = ax.imshow(normalized_matrix, cmap=cmap, aspect='equal')\n",
    "\n",
    "# Set axis labels and ticks\n",
    "ax.set_xticks(np.arange(len(features)))\n",
    "ax.set_yticks(np.arange(len(models)))\n",
    "ax.set_xticklabels(features, rotation=45, ha=\"right\", fontsize=14)\n",
    "ax.set_yticklabels(models, fontsize=14)\n",
    "\n",
    "# Add text annotations with 3 decimal places\n",
    "for i in range(len(models)):\n",
    "    for j in range(len(features)):\n",
    "        value = matrix[i, j]\n",
    "        color = 'black' if normalized_matrix[i, j] < 0.5 else 'white'\n",
    "        ax.text(j, i, f\"{value:.3f}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=color, fontsize=10)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(im, ax=ax, shrink=0.5)\n",
    "cbar.set_label('Feature Importance Intensity', rotation=270, labelpad=20, fontsize=14)\n",
    "\n",
    "# Adjust layout to remove whitespace\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.subplots_adjust(left=0.15, right=0.85, bottom=0.2, top=0.95)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama Finetuning results\n",
    "# Experiment 1 (llama_mse.txt) - MSE-based training\n",
    "experiment1_metrics = {\n",
    "    'F1': {'Kendall Tau': 0.381, 'Krippendorff Alpha': 0.422},\n",
    "    'F2': {'Kendall Tau': 0.347, 'Krippendorff Alpha': 0.385},\n",
    "    'F3': {'Kendall Tau': 0.412, 'Krippendorff Alpha': 0.453},\n",
    "    'F4': {'Kendall Tau': 0.394, 'Krippendorff Alpha': 0.436},\n",
    "    'F5': {'Kendall Tau': 0.365, 'Krippendorff Alpha': 0.408},\n",
    "    'Average': {'Kendall Tau': 0.380 ± 0.028, 'Krippendorff Alpha': 0.421 ± 0.027}\n",
    "}\n",
    "\n",
    "# Experiment 2 (llama.txt) - BCE-based training\n",
    "experiment2_metrics = {\n",
    "    'F1': {'Kendall Tau': 0.428, 'Krippendorff Alpha': 0.479},\n",
    "    'F2': {'Kendall Tau': 0.392, 'Krippendorff Alpha': 0.437},\n",
    "    'F3': {'Kendall Tau': 0.353, 'Krippendorff Alpha': 0.402},\n",
    "    'F4': {'Kendall Tau': 0.415, 'Krippendorff Alpha': 0.461},\n",
    "    'F5': {'Kendall Tau': 0.441, 'Krippendorff Alpha': 0.493},\n",
    "    'Average': {'Kendall Tau': 0.406 ± 0.035, 'Krippendorff Alpha': 0.454 ± 0.035}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
