paper_id,reviewer,title,abstract,review_text,length_words,citation_count,question_count,mattr,sentiment_polarity,similarity_score,days_to_submit,flesch_reading_ease,politeness_score,venue,hedging,Human_Actionability,Human_Clarity_and_Readability,Human_Comprehensiveness,Human_Constructiveness,Human_Factuality,Human_Fairness,Human_Objectivity,Human_Overall_Quality,Human_Politeness,Human_Relevance_Alignment,Human_Sentiment_Polarity,Human_Usage_of_Technical_Terms,Human_Vagueness,Qwen_Actionability,Qwen_Clarity_and_Readability,Qwen_Comprehensiveness,Qwen_Constructiveness,Qwen_Factuality,Qwen_Fairness,Qwen_Objectivity,Qwen_Overall_Quality,Qwen_Politeness,Qwen_Relevance_Alignment,Qwen_Sentiment_Polarity,Qwen_Usage_of_Technical_Terms,Qwen_Vagueness,Llama_Actionability,Llama_Clarity_and_Readability,Llama_Comprehensiveness,Llama_Constructiveness,Llama_Factuality,Llama_Fairness,Llama_Objectivity,Llama_Overall_Quality,Llama_Politeness,Llama_Relevance_Alignment,Llama_Sentiment_Polarity,Llama_Usage_of_Technical_Terms,Llama_Vagueness,GPT_Actionability,GPT_Clarity_and_Readability,GPT_Comprehensiveness,GPT_Constructiveness,GPT_Factuality,GPT_Fairness,GPT_Objectivity,GPT_Overall_Quality,GPT_Politeness,GPT_Relevance_Alignment,GPT_Sentiment_Polarity,GPT_Usage_of_Technical_Terms,GPT_Vagueness,Phi_Actionability,Phi_Clarity_and_Readability,Phi_Comprehensiveness,Phi_Constructiveness,Phi_Factuality,Phi_Fairness,Phi_Objectivity,Phi_Overall_Quality,Phi_Politeness,Phi_Relevance_Alignment,Phi_Sentiment_Polarity,Phi_Usage_of_Technical_Terms,Phi_Vagueness
100,Julia-Bosque,LL(O)D and NLP Perspectives on Semantic Change for Humanities Research,"The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.","I reviewed a previous version of this manuscript, for which I recommended a major revision based on the need for a clearer motivation, scope and limitations of this effort, as well as on the structure and flow of the paper at that time. In this new version the authors have addressed all my highlighted concerns: - The motivation, scope and limitations are clearly defined - The interplay between the different sections is elaborated and illustrated with a workflow diagram that facilitates reading. There are numerous references to this workflow and interlinks between the sections, resulting in a cohesive document. - More context is provided in the introductory paragraphs of each section, and the project in which this effort is carried out is clearly introduced. The relation of each section/topic with respect to the overall topic of the survey is now explicit. - The authors have improved the categorization of tools and approaches. - The tables in the appendix summarize the main approaches, tools and resources surveyed according to the proposed classification.  Taking into account these modifications, I maintain the reasons upon which I based the recommendation for acceptance in terms of the criteria for surveys: - The topic of the paper, at the intersection of humanities and the Semantic Web, is interesting and relevant for the advancement in a line of research which poses numerous challenges. - The quality of writing is good and the survey is well balanced, with a broad coverage encompassing theoretical standpoints and approaches, tools, repositories and datasets. - The granularity and length are also appropriate for the text to serve as an introductory text. Minor comments for improvement: - The authors have provided details on the methodology for the survey, indicating the different stages in the generation and keywords used in literature search. There is no explicit reference to a filtering process after those keyword-based search results, was there any filtering step? If so, which criteria were applied? - In table 3, the included resources diverge in their nature, so the current list groups together LLOD Cloud, Lila Etymological Lexicon, LingHub, and Diachronic semantic lexicon of Dutch, etc. for example. I suggest including a mark here to distinguish which resources are particularly relevant for diachronic analysis, in contrast to general LLOD resources (e.g. Lila Etymological Lexicon vs. LLOD cloud and LingHub). - The authors of [12], referenced on p. 5, mention Lemon (Lexicon Model For Ontologies), and in their diagrams (in Github)  they seem to be using OntoLex-Lemon, not its ancestor. Throughout this survey ""OntoLex-Lemon"" is the term used to refer to the 2016 Specification as the outcome of the W3C Ontology-Lexica Community Group, so for that bib. reference I would recommend to replace the mention of ""Lemon"" with ""OntoLex-Lemon"" for consistency in the whole document. *Typos*: l.19, .p. 19, right column, ""A combined resource like this, allows..."" → remove comma p. 20, l. 1, right column → remove ""(linguistic)"", already covered by the first L in LLOD Appendix tables, Table 4. → word embeddings (add pl. ""s"")",503,1,5,0.7741,0.1697330447,0.8522429466,73,34.66,0.2025,semanticweb,0.0,4,4,5,4,factual,4,4,87,polite,5,positive,4,low,5,5,5,5,factual,5,5,100,polite,5,positive,5,none,3.0,4.0,5.0,4.0,factual,5.0,5.0,80.0,polite,5.0,positive,4.0,none,4,5,5,5,factual,5,5,5,polite,5,positive,5,none,4,4,5,5,factual,5,5,95,polite,5,positive,4,low
194,Reviewer-GDNX,Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model,"As the model size grows rapidly, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. 
Previous works usually focus on reducing the number of trainable parameters in the network. 
While the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. 
Notably, machine learning models are typically trained using stochastic gradient descent.
We argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance.
Following this motivation, we propose a new family of unbiased estimators called \sas, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient.
Our work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones.
By replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7X peak memory reduction with almost no accuracy drop and enables up to $6.4\times$ larger batch size.
Under the same hardware, \sas enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.
The code is available at https://anonymous.4open.science/r/WTACRS-A5C5/.",">**Rebuttal:** The provided details satisfy my concerns. I think this paper should be accepted after applying the agreed changes.

>**TL;DR:** **Good paper.** The proposed WTA-CRS algorithm is based on the existing CRS algorithm and is used to reduce activation memory during training. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size. However, WTA-CRS comes with computational overhead, which is discussed and explore. Addressing my concerns and questions would improve my score.

The paper proposes the WTA-CRS algorithm to reduce the neural networks training activation memory, where the paper claims that activation memory is primary memory bottleneck during training. The WTA-CRS algorithm is an unbiased estimators for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. WTA-CRS achieves up to 2.7× peak memory reduction with almost no accuracy drop and enables up to 6.4× larger batch size.

The WTA-CRS algorithm works by sampling columns and rows to create an unbiased estimation of the original GEMM for the backpropagation. The WTA-CRS algorithm does not alter the neural architecture, and therefore the inference speed is left in tact. The experimental section shows that WTA-CRS outperforms existing prior work and is compatible with existing PEFT techniques. WTA-CRS adds a computational overhead due to sampling, however, WTA-CRS enables training on much larger batch sizes, which results in a 1.2× higher training throughput.
 * **S.1.** The proposed WTA-CRS algorithm tackles an important problem in existing PEFT techniques, which makes LLM PEFT training more accessible to researchers with low resources.
* **S.2.** The paper provides a theoretical analysis on WTA-CRS.
* **S.3.** The proposed WTA-CRS algorithm outperform existing algorithms.
* **S.4.** An anonymized code repository is provided as part of the submission for reproduction .
  * **W.1.** Popular existing memory efficient training techniques such as tensor rematerialization (gradient checkpointing) \[2\]\[3\] and ZeRO \[1\] are not compared to, although some are partially discussed in Appendix A.
* **W.2.** The experiments are conducted on single neural network architecture (T5), although the proposed technique does not seem to be confined solely to that setting.
* **W.3.** It is common practice today to train neural networks at a lower precision (quantization), however, it is not clear whether quantization (16bit) was used. Therefore, there is insufficient proof that the combined noise of WTA-CRS and quantization would be compatible.


**Typos.**
* Line #62: ""Thus"" → ""Thus,""
* Line #240: ""mAccording"" → ""According""
* Line #297: ""Thus"" → ""Thus,""

\[1\] Ren, J., Rajbhandari, S., Aminabadi, R.Y., Ruwase, O., Yang, S., Zhang, M., Li, D. and He, Y., 2021, July. ZeRO-Offload: Democratizing Billion-Scale Model Training. In USENIX Annual Technical Conference (pp. 551-564).

\[2\] Jain, P., Jain, A., Nrusimha, A., Gholami, A., Abbeel, P., Gonzalez, J., Keutzer, K. and Stoica, I., 2020. Checkmate: Breaking the memory wall with optimal tensor rematerialization. Proceedings of Machine Learning and Systems, 2, pp.497-511.

\[3\] Beaumont, O., Eyraud-Dubois, L. and Shilova, A., 2021. Efficient combination of rematerialization and offloading for training dnns. Advances in Neural Information Processing Systems, 34, pp.23844-23857. * **Q.1.** In line #43 and Figure 2 it is noted that ""storing activations (or feature maps) is the main memory bottleneck during training"". Does this hold true for all model architectures? What about LLM training where the fine-tuning batch size is usually very small?
* **Q.2.** Why was the WTA-CRS algorithm compared to the Deterministic top-k from \[1\] but not to the Bernoulli-CRS from \[1\]? What are the key differences between WTA-CRS and Bernoulli-CRS?
* **Q.3.** The paper proposes WTA-CRS which sacrifices computation speed at the cost of lower peak memory. There are several existing common approaches (such as gradient checkpointing and DeepSpeed) for general memory efficient training which are compatible with PEFT techniques. Why are these comparisons not explored or detailed in the main paper?

\[1\] Adelman, Menachem, Kfir Levy, Ido Hakimi, and Mark Silberstein. ""Faster neural network training with approximate tensor operations."" Advances in Neural Information Processing Systems 34 (2021): 27877-27889. The limitations are discussed in Appendix A.",669,10,14,0.753,0.0903401361,0.8664653897,215,42.5651,0.1507,neurips,0.0128205128205127,3,4,3,3,factual,4,4,80,neutral,4,neutral,5,moderate,4,4,4,4,partially factual,4,4,85,polite,5,positive,5,moderate,2.0,4.0,4.0,4.0,factual,3.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,4,4,factual,4,4,85,polite,5,positive,5,low,3,4,4,4,factual,4,4,85,polite,5,positive,5,low
38,Reviewer-vqBu,Conditional Matrix Flows for Gaussian Graphical Models,"Studying conditional independence among many variables with few observations is a challenging task.
Gaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\leq1$.
However, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.
In the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\lambda$.
In the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\lambda$ requires repeated runs of expensive Gibbs samplers.
Here we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.
As a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.
Within one model we thus have access to (i) the evolution of the posterior for any $\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.","This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way. The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea. The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso. - in the frequentist case, how does the proposed framework compares against more classical techniques to obtain the solution paths, e.g., iterative reweighted l1-norm?  The authors adequately addressed the limitations of their proposed framework. ",170,0,0,0.799,0.32,0.9384971857,215,30.7103,0.1149,neurips,0.0112359550561798,3,4,3,2,unfactual,2,2,60,polite,3,neutral,2,low,4,5,4,4,factual,5,5,85,polite,5,positive,5,none,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,3,4,factual,4,4,75,polite,5,positive,4,low,3,4,3,4,factual,3,4,78,polite,5,neutral,4,low
38,Reviewer-pTVu,Conditional Matrix Flows for Gaussian Graphical Models,"Studying conditional independence among many variables with few observations is a challenging task.
Gaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through $l_q$ regularization with $q\leq1$.
However, most GMMs rely on the $l_1$ norm because the objective is highly non-convex for sub-$l_1$ pseudo-norms.
In the frequentist formulation, the $l_1$ norm relaxation provides the solution path as a function of the shrinkage parameter $\lambda$.
In the Bayesian formulation, sparsity is instead encouraged through a Laplace prior, but posterior inference for different $\lambda$ requires repeated runs of expensive Gibbs samplers.
Here we propose a general framework for variational inference with matrix-variate Normalizing Flow in GGMs, which unifies the benefits of frequentist and Bayesian frameworks.
As a key improvement on previous work, we train with one flow a continuum of sparse regression models jointly for all regularization parameters $\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.
Within one model we thus have access to (i) the evolution of the posterior for any $\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihood for model selection, and (iii) the frequentist solution paths through simulated annealing in the MAP limit.","This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. 
They use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\geq1}$ is used). 1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. 
2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.
3. Using sub-l1 norm is suitable for structure learning. 
4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. 
5. The paper is well-written, and the relevant work is sufficiently discussed.    
6. Due to its flexibility, the proposed method has the potential of having a large impact. Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. 

NOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    

Minor suggestion: 
1. Though it is clear in the context, I suggest that the authors do not use the same letter ""p"" (with the same font) for both probability density and norm parameter.  
2. Fix minor typos e.g. the end sentence period in line 214. * In line 141, what do you mean by ""contradiction""? The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. 

This work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.",330,0,9,0.7934,0.1236940837,0.8818445206000001,215,45.1097,0.1969,neurips,0.0119047619047618,3,4,3,4,unfactual,3,3,60,neutral,4,negative,3,low,5,5,4,5,5,5,5,90,5,5,5,5,1,2.0,4.0,4.0,4.0,factual,3.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,4,4,factual,4,4,80,polite,5,positive,5,low,3,4,4,4,partially factual,4,4,85,polite,5,positive,5,low
81,Toni-Šušak,"Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange","Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.","Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",909,0,5,0.6798000000000001,0.1225925926,0.8569852710000001,489,50.12,0.072,f1000,0.0,4,4,5,4,factual,4,4,80,polite,4,neutral,5,low,5,5,5,5,factual,5,5,95,polite,5,neutral,5,none,2.0,4.0,4.0,3.0,partially factual,4.0,4.0,60.0,polite,4.0,neutral,3.0,low,5,4,5,5,partially factual,4,4,85,polite,5,neutral,4,low,3,3,4,4,partially factual,4,4,75,polite,5,neutral,3,low
24,Silvio-Buscemi,Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties,"The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.","Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",280,0,1,0.7857000000000001,0.1403645833,0.7798862457,34,24.27,0.3225,f1000,0.0105263157894737,1,3,1,2,unfactual,3,1,48,polite,3,negative,1,extreme,4,5,3,4,factual,4,4,85,polite,5,positive,5,moderate,3.0,4.0,4.0,3.0,factual,4.0,4.0,80.0,polite,4.0,positive,3.0,none,4,4,3,4,factual,4,4,80,polite,4,positive,4,low,3,4,3,4,partially factual,4,3,78,polite,5,positive,4,low
77,Houcemeddine-Turki,Fact Checking in Knowledge Graphs by Logical Consistency,"Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement ""The United States is the birth place of Barack Obama"" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement ""Canada is the nationality of Barack Obama"" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.","This manuscript presents a novel rule-based approach for fact checking in knowledge graphs based on mining textual resources. The work provides new evidences that rule-based approaches can provide more precise evaluation of the accuracy of statements in knowledge graphs and can enhance the efficiency of embedding-based methods when combined with them. The availability of source codes and datasets in GitHub is an advantage for this work as this will allow the reproducibility of the described experimental study. However, there are several matters within the paper that should be addressed to ameliorate its final output: (i) Introduction: The ""Introduction"" seems to be a summary of ""Related Studies in Fact Checking"" rather than a proper introduction and contextualization of the paper. I propose to expand the part about misinformation fighting in the introduction to give better context for the development of this research paper. The authors can benefit from previous research papers about fact checking in general to develop the introduction of the paper. Several points in the introduction should be moved to Related Studies in Fact Checking. (ii) The paper did not emphasize the advantages of rule-based approaches when compared to embedding-based methods beyond having a better precision. Effectively, there are many other advantages of rule-based approaches. For example, the results of rule-based approaches can be more explainable than the ones of embedding-based approaches. Such advantages should be expanded and highlighted in the research paper. (iii) The paper did not emphasize the importance of having the datasets and source codes available in a specific GitHub repository. The authors should specify that this practice allows reproducibility and further development of the work by peers, particularly in the conclusion. (iv) The paper did not discuss the concept of reification in knowledge graphs. Effectively, several knowledge graphs add qualifiers to triples to provide a characteristic of the statements (i.e. {(s,p,o), p, o}. The authors should discuss the usefulness of the method to verify the qualifiers of the statements in the Discussion or as a future direction for this work. (v) The paper should evocate the robustness of the rule-based approach they proposed to adversarial attacks. This can be an advantage of the approach. (vi) There are several typos in the research paper (e.g. ""UC Berkely"" should be ""UC Berkeley""). The authors should proofreading the paper to eliminate such deficiencies. (vii) The authors can expand the Discussion of the work (Part 5) to explain the strengths of KStream, KLinker, COPPAL, RUDIK, and PredPath that contributed to their efficiency as reported in the Experimental Study according to previous research papers. This can explicate the reasons of why the method developed by the authors was more efficient. (viii) The authors should provide future directions for the development of this work in the conclusion. Given this, I propose to accept this paper for publication after these six major revisions are applied.",473,0,1,0.7464000000000001,0.1097294372,0.9120528102,4,36.08,0.2025,semanticweb,0.0,4,4,3,4,factual,3,4,85,polite,4,neutral,4,low,5,5,5,5,factual,5,5,95,polite,5,positive,5,none,3.0,4.0,4.0,4.0,factual,4.0,5.0,80.0,polite,4.0,neutral,3.0,none,5,4,5,5,factual,5,5,90,polite,5,positive,4,low,5,4,4,5,factual,4,4,88,polite,5,positive,3,low
67,Reviewer-8RW7,Efficiently incorporating quintuple interactions into geometric deep learning force fields,"Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with \emph{ab initio} accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at https://github.com/Zun-Wang/QuinNet.","This paper aims to incorporate 5-body interactions into geometric deep learning models. They first analyze the topology of 5-body interactions and identify three 5-body angles. Then they propose an efficient way to incorporate these 5-body information into models. The complexity of the proposed QuinNet is still O(|N|), the same as many previous 2-body methods like PaiNN. The results are comparable to previous SOTA methods. This paper is well-written and easy to follow.

The experimental results show that the proposed method can perform well on most tasks. The ablation study in Section 5.4 and Figure 5 show that the proposed 5-body information indeed helps to model. See details in the Question part. 1. About the motivation:   
 this paper aims to incorporate 5-body interactions into geometric deep learning models. However, based on my understanding, using up to 4-body (torsions) interaction is already complete \[1\]\[2\] in terms of capturing the geometric structures. If this is correct, then why do we need these 5-body angles? In addition, if we can incorporate 5-body interactions, do we also need to incorporate 6-body interactions?

2. About the complexity:   
in Section 4.3, the authors claim that the complexity is O(|N|), as efficient as many 2-body methods like SchNet and PaiNN. But I think this complexity is not well explained. Using pseudocode/algorithm may be better to analyze the complexity. In addition to the analysis, I suggest the authors use some results to empirically verify the great efficiency compared to other baseline methods, e.g. the inference time, used memory, etc.

3. About the tasks:   
this paper focuses on MLFFs, how about other molecular property prediction tasks, such as QM9 and OC20? I am wondering if this method is specially designed for MLFFs, or can be used on all 3D molecule tasks. In other words, why do the authors emphasize MLFFs? Is there any significant difference between MLFFs and other molecule property prediction tasks?

4. Other related papers: many-body \[3\], MLFFs \[4\]

5. The j, k in Figure 2 are confusing to me. For example, in (f), why not be i, j1, j2, j3, and k1?

\[1\] ComENet: Towards Complete and Efficient Message Passing for 3D Molecular Graphs.  
\[2\] GemNet: Universal Directional Graph Neural Networks for Molecules.  
\[3\] On the Expressive Power of Geometric Graph Neural Networks.  
\[4\] Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations. None",394,8,6,0.77,0.1385714286,0.8948391676,215,48.9981,0.1429,neurips,0.0,4,4,4,4,factual,3,3,85,polite,5,negative,4,low,5,5,4,5,partially factual,5,5,85,polite,5,neutral,5,moderate,2.0,5.0,4.0,3.0,factual,4.0,4.0,80.0,polite,4.0,positive,3.0,none,4,4,4,4,factual,4,4,80,polite,5,neutral,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
171,Wanshui-Yang,Socio-demographic and lifestyle factors associated with understanding fast food consumption among adults in Cambodia,"Background: Over the past decades, fast food has been rapidly gaining popularity and availability worldwide. Its consequential impact on human health is among the highest in terms of non-communicable diseases. Therefore, this study aimed to investigate the level of understanding of fast food consumption among adults in Phnom Penh, the capital city of Cambodia. Methods: A cross-sectional analytical study aimed to investigate the level of understanding of factors associated with fast food consumption, among adults in Phnom Penh. Multi-stage random sampling was used to select 749 respondents from 12 communes of five districts in Phnom Penh. A structured questionnaire was used to assess the level of understanding of fast food consumption, and associated factors. Data were analyzed using descriptive statistics, together with bivariate and multivariable logistic regression. Crude odds ratios (CORs) and adjusted odds ratios (AORs) with 95% confident intervals (CI) were calculated to show the strength of associations. Results: The understanding of factors associated with fast food consumption was poor in 52.07% (95% CI: 48.48-55.66), fair in 22.70% (95% CI: 19.69-25.70) and good in 25.23% (95% CI: 22.12-28.35) of those surveyed. After adjusting for other covariates, unsatisfactory levels of knowledge around fast food consumption were found to be significantly associated with not taking regular exercise (AOR = 1.53; 95% CI: 1.15-2.25; p<0.001) and sleeping less than eight hours per night (AOR = 1.64; 95% CI: 1.09-2.12; p=0.014). Conclusion: Health promotion and disease prevention should be conducted among at-risk populations in order to raise the level of understanding of factors around fast food consumption.","Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript investigated the level of understanding of fast-food consumption among adults in Cambodia. The authors found that unsatisfactory levels of knowledge around fast food consumption were significantly associated with not taking regular exercise and sleeping less than eight hours per night. The results are interesting, but I have several comments. The authors should introduce the recent development of fast-food sector in Cambodia in the introduction part.  Is there an analysis of fast-food intake among these participants?  Interestingly, the authors found that not taking regular exercise and sleeping less than eight hours per night were associated with unsatisfactory levels of knowledge around fast food consumption. However, they were not well explained in the discussion part. In other words, the discussion part is a little too concise.  In addition, the education levels were not associated with the knowledge of fast-food consumption in the present study. I would like authors to discuss it and, at least, mention its possible causes.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",303,0,1,0.7774000000000001,0.1265046296,0.9193514585,520,28.03,0.1953,f1000,0.010204081632653,0,4,1,0,unfactual,3,3,40,impolite,3,negative,0,high,5,5,4,5,factual,5,5,92,polite,5,neutral,5,low,3.0,4.0,4.0,4.0,factual,4.0,5.0,80.0,polite,4.0,neutral,3.0,none,3,4,3,3,factual,4,4,70,polite,4,neutral,3,low,3,4,3,4,partially factual,3,4,75,polite,4,neutral,4,low
103,Reviewer-36E8,Learning Abstract World Models for Value-preserving Planning with Options,"General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. 
Instead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.
We evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.","The paper presents an approach for learning dynamics preventing abstractions for sensorimotor observation space. Given a set of high-level skills and the learned dynamics preserving abstractions, the paper claims to develop an approach for planning for a solution. 

The approach is evaluated in two test domains where the paper shows the visualization of the learned abstractions. - For the most part of the paper, it is extremely well written. Given the wide use of embodied AI systems and robots, an approach that generates plannable abstractions for high-dimensional sensor input is extremely important. 

- The paper nicely motivates the problem. While the paper in general is nicely written, it has a few limitations: 

- The paper advocates learning a continuous abstract  representation instead of a symbolic abstractions. However, it does not provide any reasons to that. Why are continuous abstractions more desirable than symbolic abstractions? 

- Sec 4.1 is unclear. The notation for MI is a bit unclear. It needs to be made more clear. Sec 4.1 requires a re-writing including more explanation for the equation. I have two important questions: 

- How is the dynamics preserving abstraction defined in Def. 3.6 different from the Markovian abstractions defined in \[Srivastava et al. 2016\]? 

- Can you discuss the differences between the presented approach and \[Allen et al. 2021\] 

Reference 

Allen, Cameron, et al. ""Learning markov state abstractions for deep reinforcement learning."" Advances in Neural Information Processing Systems 34 (2021): 8229-8241.

Srivastava, Siddharth, Stuart Russell, and Alessandro Pinto. ""Metaphysics of planning domain descriptions."" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016.",264,1,6,0.7512000000000001,0.1625,0.8653070927000001,49,41.1434,0.2429,iclr,0.0,3,4,4,3,factual,3,4,80,polite,4,neutral,4,moderate,4,4,3,4,partially factual,4,4,75,polite,5,positive,4,moderate,2.0,5.0,4.0,3.0,factual,3.0,4.0,80.0,polite,4.0,neutral,5.0,low,4,4,4,4,factual,4,4,80,polite,5,positive,4,low,2,4,3,3,partially factual,3,4,75,polite,4,neutral,4,low
103,Reviewer-dCJp,Learning Abstract World Models for Value-preserving Planning with Options,"General-purpose agents require fine-grained controls and rich sensory inputs to perform a wide range of tasks. However, this complexity often leads to intractable decision-making. Traditionally, agents are provided with task-specific action and observation spaces to mitigate this challenge, but this reduces autonomy. 
Instead, agents must be capable of building state-action spaces at the correct abstraction level from their sensorimotor experiences. We leverage the structure of a given set of temporally extended actions to learn abstract Markov decision processes (MDPs) that operate at a higher level of temporal and state granularity. We characterize state abstractions necessary to ensure that planning with these skills, by simulating trajectories in the abstract MDP, results in policies with bounded value loss in the original MDP.
We evaluate our approach in goal-based navigation environments that require continuous abstract states to plan successfully and show that abstract model learning improves the sample efficiency of planning and learning.","The paper introduces a method for enabling general-purpose agents to efficiently handle complex tasks by constructing abstract models based on temporally-extended actions. These models facilitate more efficient planning and learning and are characterized using principled conditions. The approach provides empirical evidence of improved sample efficiency in goal-based navigation tasks and offers theoretical support for information maximization strategies in abstract state representation learning.
The authors claim that they introduced a method for creating abstract world models that empower agents to plan effectively for goal-oriented tasks. The key idea is to allow agents to construct reusable abstract models for planning with specific skills. This is achieved by characterizing the state abstraction that ensures planning without any loss in simulation, meaning that planning with the learned abstract model can generate policies for the real world. The paper also provides theoretical support for the use of information maximization as a reliable strategy for learning abstract state representations. - Good overview of the related work.
- Good description of motivations and intuitions. 
- proper choice of environment settings. Major:
- Some measures are used without definition, 
- It seems that there exists a lot of inaccuracies and impreciseness in the theories and definitions. See all questions!

minor:
- typos: 
last paragraph of the introduction ""the *agents* needs"", definition 3.5 ""$s_{o}$"" must be ""$s_0$""
- writing: 
Define the abbreviations before using them, e.g. ""PDDL"", ""VAE""

There is a chance that I have not fully understood what this paper is trying to present. 1- What is $P(s'|s,o)$ used in the paragraph right after definition 3.1?

2- An option $o$ is defined, and then you mention $T(s'|s,o)$ to define the transition probability of taking option $o$ in $s$? $T$ earlier was defined on action space $A$. How is it applied on options without showing the relationship of $I_o$ and $\beta_o$ with $s$ and $s'$ under option policy $\pi_o$?

3-the paper has defined ""$\bar {\gamma} = \gamma ^{\tau (s,o)}$ is the abstract discount factor, $\tau: Z \times O \rightarrow \[0,\infty)$, which consists of contradictory phrases. How is ${\tau (s,o)}$ but defined as a function of abstract variables $Z$ instead of $S$? Not clear what $\tau$ is. If based on definition 3.1, it is the option's execution time starting from $s$ taking option $o$, it is not clear how in definition 3.2 it becomes a map from $Z$ and $O$ to a non-negative real.

4- What does definition 3.4 mean? $ \Pi = {\pi \in \Pi : \pi(·|s) = \pi (·|z) \forall s \in z}$ says the probability of taking actions/options in $s$ should be equivalent to the probability of taking actions/options in abstract states. Transitions of taking actions in states might take you to another state $s'$ inside the similar abstract state $z$. How can the policies used for both abstract states and states be equivalent? Unless you are just discretizing the continuous state spaces based on the optimal policies that are already given. Lots of interchangeable usage of symbols here. Not precise and is hard to follow.",499,0,1,0.7308,0.0796438834,0.93872118,61,45.6397,0.1463,iclr,0.0,4,4,5,4,factual,3,4,83,polite,4,negative,5,none,3,4,4,3,partially factual,4,4,45,polite,5,neutral,5,moderate,2.0,4.0,4.0,3.0,partially factual,4.0,4.0,70.0,polite,4.0,neutral,3.0,low,3,3,4,3,partially factual,3,3,65,neutral,4,neutral,4,moderate,2,3,3,3,partially factual,3,3,65,polite,4,neutral,4,moderate
141,Reviewer-4kdr,PatchSynth: a Patch-Text Pre-trained Model,"In recent years, patch representation learning has emerged as a necessary research direction for exploiting the capabilities of machine learning in software generation. These representations have driven significant performance enhancements across a variety of tasks involving code changes. While the progress is undeniable, a common limitation among existing models is their specialization: they predominantly excel in either predictive tasks, such as security patch classification, or in generative tasks such as patch description generation. This dichotomy is further exacerbated by a prevalent dependency on potentially noisy data sources. Specifically, many models utilize patches integrated with Abstract Syntax Trees (AST) that, unfortunately, may contain parsing inaccuracies, thus acting as a suboptimal source of supervision. In response to these challenges, we introduce PATCHSYNTH, a novel pre-training framework for patches and natural language text. PATCHSYNTH deploys a triple-loss training strategy for (1) patch-description contrastive learning, which enables to separate patches and descriptions in the embedding space, (2) patch-description matching, which ensures that each patch is associated to its description in the embedding space, and (3) patch-description generation, which ensures that the patch embedding is effective for generation. These losses are implemented for joint learning to achieve good performance in both predictive and generative tasks involving patches. Empirical evaluations focusing on patch description generation, demonstrate that PATCHSYNTH sets new state of the art performance, consistently outperforming the state-of-the-art in metrics like BLEU, ROUGE-L, METEOR, and Recall.","The paper discusses a new model, PatchSynth, in the domain of Patch-Text Pre-training (PTP) which aids in accurate patch representation for software evolution tasks like bug fixing and feature enhancement. PatchSynth is designed to balance patch understanding and generation, overcoming limitations of previous models. It outperforms existing models in patch description generation, as shown in experiments using standard evaluation metrics. An ablation study further reveals the importance of generating task training in improving PatchSynth performance. Novelty:
The novelty of PatchSynth lies in its harmonious synthesis of patch understanding and generation, coupled with an advanced synthetic description generator. This innovative approach addresses the historical challenges of accurate patch representation and description generation, marking a significant stride in the PTP paradigm.
Importance:
The topic is of paramount importance as it addresses a critical need in software engineering for accurate patch representation and description, which are pivotal for collaborative development, systematic documentation, and rapid code review processes. By advancing the PTP paradigm, PatchSynth not only contributes to the academic discourse but also holds promise for practical applications in software development workflows.
The work achieves promising results. The paper doesn't elucidate how PatchSynth adapts to varying programming languages or codebases with differing coding standards and structures. This lack of demonstrated adaptability could limit its applicability across diverse software projects, potentially requiring additional tuning or re-training to maintain accuracy and effectiveness in different environments. 1. Given the advancements in PatchSynth for patch-text understanding and generation, how well does the model perform in a transfer learning scenario? Can PatchSynth be fine-tuned or adapted effectively to related tasks in software engineering or different programming languages?
2. Are there considerations or plans for deploying PatchSynth in real-world software development environments? How would the integration look like, and what kind of support or infrastructure would be required to ensure the model operates efficiently and securely in a production setting?",310,0,2,0.8356,0.1883953168,0.940164268,50,9.2899,0.068,iclr,0.0,4,4,4,4,factual,3,3,65,polite,4,neutral,3,low,4,5,4,4,factual,4,4,88,polite,5,positive,5,low,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,3,5,4,3,factual,4,4,80,polite,5,positive,4,low,2,4,3,3,partially factual,3,4,75,polite,4,neutral,4,low
28,Reviewer-Lpfq,Certification of Distributional Individual Fairness,"Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify \textit{distributional} individual fairness which ensures that for a given empirical distribution and all distributions within a $\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.","This paper studies formal guarantees for notions of individual fairness (IF) for predictors given by neural network models. After relaxing common definitions for IF metrics by means of $\ell_\infty$ balls (or orthotopes), they adapt methodology based on adversarial robustness to provide upper and lower bounds to the IF achieved by models on an empirical sample - and those within a $\gamma-$Wasserstein ball about it. - This paper studies an important problem of individual fairness
- The first half of the paper, Section 3 and 4, which cover Background, the DIF definition, and problem explanation are very clear and easy to understand. - The key observation and novelty in the approach is not clearly noted (See below)
- Several of the nice advantages of their method (e.g efficiency) are not explained (see below). 1. Numerous times in the paper the authors say their bounds are ”efficient” because they leverage efficient methods (e.g. those based on bound propagation). While that may be true, it would be nice for the readers if they provided a brief explanation as to why these methods are efficient instead of placing everything in the appendix. 
2. It seems to me that the central novelty of this paper is to upper bound a mahalanobis metric (for $d_{fair}$) with an orthotope, which is quite simple. The remaining of the paper seems to me a direct application of results and methods in adversarial robustness. While I do appreciate the observation of being able to use those tools in the context of fairness - which also constitutes novelty - I would appreciate if the authors could be very clear about what are the main technical contributions of this work.
3. Personally, I am not sure providing a section on the impact of these methods on group fairness is necessary. I’d much rather prefer a discussion on the efficiency of the bounds.
4. Figure 1 is quite confusing. What makes the blue-star individuals likely? As presented, those blue-star points do not look likely. If I understand the figure correctly, the authors should present a more balanced empirical sample together with a larger sample representing the (unobserved) population. 
5. I also have problems with the fact that the authors state their goals and present their definitions in terms of expectation (e.g. as in Def 2), but simply restrict themselves to studying empirical samples. I think the presentation is misleading, because nowhere the authors really provide guarantees for the definition in Def 2 (that is, risk bounds). This is also an important limitation where the study the Wasserstein distance between distributions, as they simply regard their distribution as a one supported on Dirac functions (on the observed samples). 
6. Immediately after Eq (4), the authors write that “we can optimize this bound to be tight”. I don’t think this is correct: while they can indeed optimize the bound, there’s no guarantee that the bound will be tight, as the original problem is non-concave.
7. In Section 5.4 and after presenting $\mathcal L_{F-DIF}$, the authors mention when $\gamma=0$, one recovers a local constraint on individual fairness on $x\in X$. I don’t think this is completely accurate, because again, Def. 2 is defined in expectation of $x\sim p(x)$, not simply over the empirical sample. The authors mention that they do not foresee negative societal impacts. Maximizing upper and lower bounds is great but in doing so we don’t really know what is happening to the true fairness violation. It may be that the true fairness violation is in fact increasing which is propagating unfairness. While I understand that solving for this value is not feasible and thus appreciate the results presented, I would also like the paper to acknowledge that there are potential negative effects.",619,0,7,0.7891,0.1001929392,0.9119418859,215,46.7646,0.6521,neurips,0.0,5,5,5,5,factual,5,5,95,polite,5,neutral,5,none,4,4,4,4,factual,4,4,85,polite,5,neutral,5,moderate,2.0,4.0,4.0,3.0,partially factual,3.0,4.0,70.0,polite,4.0,neutral,3.0,low,4,4,4,4,factual,4,4,80,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
41,Reviewer-LNh7,Contrastive Retrospection: honing in on critical steps for rapid learning and generalization in RL,"In real life, success is often contingent upon multiple critical steps that are distant in time from each other and from the final reward. These critical steps are challenging to identify with traditional reinforcement learning (RL) methods that rely on the Bellman equation for credit assignment. Here, we present a new RL algorithm that uses offline contrastive learning to hone in on these critical steps. This algorithm, which we call Contrastive Retrospection (ConSpec), can be added to any existing RL algorithm. ConSpec learns a set of prototypes for the critical steps in a task by a novel contrastive loss and delivers an intrinsic reward when the current state matches one of the prototypes. The prototypes in ConSpec provide two key benefits for credit assignment: (i) They enable rapid identification of all the critical steps. (ii) They do so in a readily interpretable manner, enabling out-of-distribution generalization when sensory features are altered. Distinct from other contemporary RL approaches to credit assignment, ConSpec takes advantage of the fact that it is easier to retrospectively identify the small set of steps that success is contingent upon (and ignoring other states) than it is to prospectively predict reward at every taken step. ConSpec greatly improves learning in a diverse set of RL tasks. The code is available at the link: https://github.com/sunchipsster1/ConSpec","Proposes an auxiliary reward module to be used in RL algorithms, that learns features (‘prototypes’) of critical states in successful trajectories. For new observations, the method then uses cosine similarity to the learned features as a reward bonus. The method is evaluated on a unity-based env, grid-worlds, versions of gym,atari envs with delayed rewards, and Montezuma’s revenge. 1. Effective exploration bonus

The idea of learning invariant features across successes, and using these as a source of reward does seem to give better exploration performance, from the experiments. The Montezuma’s revenge experiments (Fig,6) are particularly compelling - the baselines PPO, RIMS (which also uses a set of discrete slot-based learned features ) and Decision Transformer all fail to obtain any reward. By creating an explicit division between success and failure episodes, conspec can then learn features that match states present in the successes, but not the failures, even from a very small number of successful trajectories (There might be other, simpler ways to get this effect however, see weakness #1). The ability of con spec to find important states critical for the task is also investigated by the authors in the simpler unity-based env, where they also visualize states closest to the learned prototypes.  

2.   More expressive set for bottleneck states

Instead of learning an explicit set of states which are important (like sub-goals) as has been previously studied, this paper instead captures the notion of ‘critical states’ using learned prototypes. The advantage of this is it can flexibly capture a large set of very different states, all of which are critical. This is also beneficial because it enables zero-shot generalization in new environments (section 4.2)

3. Clarity, presentation

The paper is well motivated, written clearly, and the main idea for the algorithm is presented clearly. 1. Are the prototypes actually required?

Learning from data in successes that aren’t present in failures should lead to better performance, but the importance of doing this through learning prototype features is unclear. As a simple baseline, consider training a policy on only the successful set (using behavior cloning). Does this provide similar performance to con spec on Montezuma’s revenge? Is trying to capture a notion of ‘critical states’ required to learn better policies ? Can you run Decision Transformer where for each successful trajectory, every transition is labelled with a reward of 1, and for every failure trajectory, every transition is labelled with a reward of 0 ?

 2. Success/failure definition

The method relied crucially on the quality of the learned prototypes, which in turn depends on the success and failure datasets. It might not always be possible to divide up trajectories into 2 classes in this manner, in a lot of tasks performance keeps improving over time and a ‘successful’ trajectory at the beginning of training is very different from one from a converged policy. The authors do discuss this (appendix A.3), but the definition used in this paper for a successful trajectory is - ‘an episode that received one of the few rewards available, and a failure is defined as anything else’. For agents to keep learning and improving from data the notion of a success should necessarily change with time (eg - maximize the reward instead of just getting some reward). 

3. Delayed reward envs 

A good portion of the experiments are conducted on familiar gym, Atari envs but with a modification where the rewards are delayed. The significance of these experiments is unclear, since the delayed reward setting for these envs is not standard and widespread. Please address the questions in weakness #1. Sufficiently addressed",595,0,6,0.7942,0.1819876664,0.8273749352,216,35.2666,0.1397,neurips,0.0229885057471264,4,5,5,4,factual,4,4,85,polite,5,neutral,4,none,4,5,4,4,partially factual,4,4,85,polite,5,neutral,5,moderate,3.0,5.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,3.0,none,3,4,4,3,factual,4,4,80,polite,5,neutral,5,low,3,5,4,4,factual,4,4,85,polite,5,positive,5,low
133,Jérôme-Euzenat,Ontology Alignment Revisited: A Bibliometric Narrative,"Ontology alignment is an important problem in the Semantic Web with diverse applications in various disciplines. This paper delineates this vital field of study by analyzing a core set of research outputs from the domain. In this regard, the related publication records are extracted for the period of 2001 to 2018 by using a proper inquiry on the well-known database Scopus. The article details the evolution and progress of ontology alignment since its genesis by conducting two classes of analyses, namely, semantic and structural, on the retrieved publication records from Scopus. Semantic analysis entails the overall discovery of concepts, notions, and research lines flowing underneath ontology alignment, while the structural analysis provides a meta-level overview of the field by probing into the collaboration network and citation analysis in author and country levels. In addition to these analyses, the paper discusses the limitations and puts forward lines for the further progress of ontology alignment. ","The paper presents a bibliometric analysis of the field of Ontology matching. It applies a 'semantic analysis', trying to extract topics from papers, and a 'structural' analysis studying only the bibliographic characteristics of the literature (authorship, citation, etc.). Since, the Semantic web journal is not a journal about bibliometrics, this paper is rather particular for the journal. To be clear, it only uses classical techniques and does not apply semantic web technologies to bibliometrics. However, a part of the semantic web, Ontology matching, is the object of this study. That could be of interest to the journal readership, especially if remarkable features of the field were unveiled. The work seems to have been seriously done, as far as I can judge and most of what is expressed is clear. Unfortunately, after reading it, it does not seem worth publishing. The main problem is the lack of objective: what is this work trying to assess? For most of the presented study, there is no hypothesis tested and no interesting finding reported (except at one point, but without seriously seeking to explain it, see below). It is just like if the reported figures were totally indifferent and that the paper would have been the same with different figures. Another issue is the lack of baseline for the presented data. Indeed, it is impossible to know if the observed properties are specific to the Ontology matching field, or if they apply equally in other fields. At least, it would have been good to have a comparison with the broader context, i.e. comparing with Semantic web and Computer science. It is possible to observe features of the Ontology matching field, but no way for the reader to understand if these are remarkable or not. Finally, in these times of Open science, it is regrettable that no mention is made of the availability of the data.  These points are the major issues. I discuss below various problems, some of them related to the issues above, some of them discussing particular points. They may help the authors to improve their paper.  * Organisation: - The introduction does not state any goal for the paper, neither claim any findings. It rather describes the applied treatments. - Section 2 provides a methodology. However, in absence of statement about the goal of the analysis, it is not possible to judge the relevance of the methodology. - Section 2.1 details lenghtly the preprocessing of WoS, before turning more succintly to Scopus which was actually used. This seems a strange way to present things. * Data interpretation: - The topic analysis is not particularly insightful. In particular, it does not provide much information on ontology matching but on its use. It seems to gather the terms in an unprincipled way (heterogeneous and automatic appear in most of them, biomedical is in the learn cloud while anatomy is in the query one, etc.). It may have been interesting to see all the generated 'topics' that the authors did not retain. In the end it is unclear, which conclusions may be drawn from the topic analysis. - p10: 'Ontology alignment outputs form 6.1% of the top 10% most cited article worldwide in year 2013' (I simplified). How can this be? From Fig. 3, there seems to be no more than 300 papers in scopus on 'ontology alignment' for 2013. If they are all in the 10% most cited papers and these are 6.1% of them, this means that there was only 10*300/6.1%~50000 papers indexed by Scopus (if not all 300 are in the most cited, then this is even less). This does not seem to be right: I counted 2.8Mdocuments in Scopus for 2013. It seems to me that what was meant is that 6.1% of the 'ontology alignment' papers are in the 10% most cited papers. Again with no comparison to the same figure for Semantic web or Computer science, it is difficult to tell that this figure is specific to Ontology alignment (there are fields with more citations and fields with less citations, e.g. Mathematics, and putting them all together means that some are above average and some other are below). - Section 4.3 is about disciplines relevant to Ontology matching. Given the broad categories used here (the level 2 categories of Fig 7), is it unclear that this characterisation is useful for something. - Section 5.1-5.2 about collaboration are those that could be thought of as providing some findings. Figure 8 is stunning at providing two identified clusters. The authors do not provide much explanation about this phenomenon, they suggest that may be the researchers from one cluster are not curious about the others. However, these graphs being computed on collaboration, a symmetric measure, it seems that this explanation should, at the very least, be applied symmetrically. It is difficult from this data alone to provide an explanation, but many could be put forth. In particular, the fact that one of this cluster is mononational and the other international suggest that the explanation comes from some national elements (but see discussion below). These may be linguistic factors, the collaboration approach, work approach (many coauthors, many authors of only one paper, e.g. undergraduate students: this can be studied bibliometrically), publication policies (strong incentive to publish many papers and in scopus indexed journal, hence less in the Ontology matching workshop). It is possible that many of these factors play some role together... Finally, again in the absence of comparison with other fields, it is difficult to assess if this is due to the Ontology matching field. - This judgement made on collaborations is also made on citations (though to a far lesser extent). That could have helped sheding light on this matter because citation is not symmetric. Unfortunately, in 6.2, citations are only reported as numbers assigned to papers and country so, they are not helpful. This is too bad because if a community has less citation per paper than another, it is difficult to explain it by discrimination if both communities have the same citation pattern (they both cite less the same community). At least, it would have been worth to rule out this possibility. - As I understand from the text, six communities were extracted and only two are shown in Figure 9. If the number 6 was not given to the algorithm and is significant, then the six should be shown. - 5.1 Author collaboration: the conclusion drawn on page 14 are very general and not specific to Ontology matching. - p16 ""the research outputs with at least one Chinese author have not gained enough attention"": it is unclear on what ground this statement is based. Same thing for ""they do not get enough attention, possibly the attention they deserve"". - Again, 5.3-5.4 would deserve to be compared with the broader Semantic web/Computer science fields. - The authors ""encourage the organisers of OAEI"" to have benchmarks on the identified topics. Unfortunately, these topics are not application domains, like biomedicine, but application techniques, like ""Semantic Web Services, agent-based modelling, knowledge-graphs, and business processes (cited directly from the paper)"". This means that there are not many ontologies to match there... and some of them have been considered, e.g. Process matching. * Data presentation: - Figure 2 displays data as tag clouds. The precise interpretation of tag clouds is quite unclear to me, so if there is one, it should be provided. In general, it does not seems like tag clouds are a proper scientific visualisation instrument (no unit, no scale, esthetic arrangement). - Figure 8 is interesting, but it would also be interesting to understand the space, i.e. what are the principles of entity placement. The same applies to Figure 17. - The assignment of authors to countries is not specified. One of the most collaborative ""Chinese scientist"" is ""S. Wang"". I assume that this is Shenghui Wang. Shenghui published her work while at VU Amsterdam. It is unclear that she should count as Chinese (in such a case, Pavel Shvaiko is from Belarus, Ernesto Jimenez-Ruiz from Spain, Cassia Trojahn from Brazil, etc.). In this sense, she is atypical (less and less atypical as time passes), and seems to indicate that the two clusters are rather based on the involvement in an international collaboration network or not, rather than nationality. This, in turn, may have other causes (see above). - Figure 9 is unreadable in black and white. * Form: - The title of the paper is quite strange: ontology alignment is not really revisited and there is not real ""narrative"" provided here. Moreover, this is not really the purpose of scientific journals to publish ""narratives"", but findings. - The introduction uses a flourished language that is also a bit remote from fact. For instance: ""the heterogenity problem was quite epidemic"" is not particularly clear. * Details: - p4: '""ontology alignment"", which is interchangeably referred to as ""ontology matching"" or ""ontology mapping""': it is not clear by whom. - It may have been interesting to look for outliers in this data set. In particular, books and review papers traditionally get a lot of citation: do these figures look the same if they are retracted from the corpus? I do not know if it is accepted practice in bibliometrics and this is less important than comparing with external fields. - p22 there seem to be a missing reference. - In some instances, such as reference 2 or Table 2, problems with characters.",1570,0,3,0.7853,0.0533716842,0.9450801611,84,55.13,0.0743,semanticweb,0.0,4,4,5,3,factual,4,3,80,neutral,4,positive,4,low,4,4,4,4,factual,4,4,75,polite,5,negative,5,moderate,1.0,4.0,3.0,2.0,partially factual,3.0,2.0,60.0,polite,4.0,neutral,4.0,moderate,3,4,5,3,factual,4,4,75,neutral,5,negative,4,low,3,4,4,4,partially factual,4,4,75,neutral,5,negative,3,low
191,Reviewer-1FB4,Video Prediction Models as Rewards for Reinforcement Learning,"Specifying reward signals that allow agents to learn complex behaviors is a long-standing challenge in reinforcement learning.
A promising approach is to extract preferences for behaviors from unlabeled videos, which are widely available on the internet. We present Video Prediction Rewards (VIPER), an algorithm that leverages pretrained video prediction models as action-free reward signals for reinforcement learning. Specifically, we first train an autoregressive transformer on expert videos and then use the video prediction likelihoods as reward signals for a reinforcement learning agent. VIPER enables expert-level control without programmatic task rewards across a wide range of DMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction model allows us to derive rewards for an out-of-distribution environment where no expert data is available, enabling cross-embodiment generalization for tabletop manipulation. We see our work as starting point for scalable reward specification from unlabeled videos that will benefit from the rapid advances in generative modeling. Source code and datasets are available on the project website: https://ViperRL.com","This paper proposes Video Prediction Rewards (VIPER), a general architecture that extracts reward functions from action-free expert demonstrations. To match the agent's trajectory distribution with the source distribution, VIPER optimizes the agent to maximize a log-likelihood estimated by an auto-regressive video model and an entropy term to encourage exploration.

Experiments on DMC, Atari, and RLBench demonstrate the soundness and efficiency of the reward function extracted by VIPER. VIPER addresses the practical challenge of how to extract reward functions from action-free expert demonstrations in order to optimize our agents, which is useful in settings like self-driving.
VIPER has the following strengths:
- VIPER can extract effective reward functions and thus promote policy optimization in a range of visual control tasks.
- Experiments show that reward functions learned by VIPER can generalize to a variety of tasks and even OOD tasks. Although VIPER shows good experiments results, some weaknesses still exist:

- The data efficiency of VIPER seems to be low as it requires nearly 10M data to converge in DMC. Also, it seems that VIPER can not leverage sub-optimal demonstrations, which could be important for improving data efficiency.
- It could be difficult and expensive to acquire a generative video model for real-world tasks, especially with visual distractors. 
- Also, I think current tasks are a little bit less challenging, and thus it might be easier to define a reward function than acquire expert demonstrations. Therefore, it could be interesting if we could test VIPER's performance with tasks that are hard to define rewards, e.g. embodied tasks like \[Habitat\](https://github.com/facebookresearch/habitat-sim) or self-driving platforms. - To my understanding, VIPER's setting is similar to Generative Adversarial Imitation Learning (GAIL), while GAIL uses the critic as the surrogate of the distance between the expert trajectory distribution and generated trajectory distribution, VIPER directly estimates the distance (KL divergence) by modeling the log-likelihood with a generative model. I have some reservations regarding the benefits of doing so. NA",321,1,2,0.7998000000000001,0.0668560606,0.872304976,218,23.3029,0.2552,neurips,0.0,2,2,1,2,partially factual,3,2,30,polite,3,neutral,3,high,3,4,4,4,factual,4,4,75,polite,5,neutral,4,moderate,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,neutral,3.0,low,3,4,4,3,factual,4,4,80,polite,5,neutral,5,low,3,4,4,4,factual,4,4,85,polite,5,neutral,5,low
191,Reviewer-d6Ah,Video Prediction Models as Rewards for Reinforcement Learning,"Specifying reward signals that allow agents to learn complex behaviors is a long-standing challenge in reinforcement learning.
A promising approach is to extract preferences for behaviors from unlabeled videos, which are widely available on the internet. We present Video Prediction Rewards (VIPER), an algorithm that leverages pretrained video prediction models as action-free reward signals for reinforcement learning. Specifically, we first train an autoregressive transformer on expert videos and then use the video prediction likelihoods as reward signals for a reinforcement learning agent. VIPER enables expert-level control without programmatic task rewards across a wide range of DMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction model allows us to derive rewards for an out-of-distribution environment where no expert data is available, enabling cross-embodiment generalization for tabletop manipulation. We see our work as starting point for scalable reward specification from unlabeled videos that will benefit from the rapid advances in generative modeling. Source code and datasets are available on the project website: https://ViperRL.com","This paper proposes a learning-from-observation algorithm that builds a reward based on a video predictor trained from action-free expert videos. Experimental results show that online reinforcement learning algorithms can learn a working policy from their reward only effectively. This paper contains rich and informative ablation studies and analyses to verify their design choices. 1.	The paper writing is clear and easy to understand
2.	Distilling knowledge from action-free videos to policies is a promising future direction for robotics.
3.	Experiments are rich. The authors test their method with two different online RL methods, two different exploration losses, three task domains, and three different video prediction models. The experiments on the generalization ability (Sec. 4.3) are not convincing enough. The video prediction model in Sec.4.3 is trained with 23 Rethink-robot-arm tasks and 30 Franka-robot-arm tasks. There should be dozens of OOD arm/task combinations that can be evaluated. However, according to L300, we only see the performance on only ONE OOD combination. How is the performance on other OOD combinations? Besides, the learning curve in Fig.8 doesn’t include a task oracle like other experiments in the paper. So we also don’t know how good the OOD performance is. Therefore, I think the third contribution of this paper, “VIPER generalizes to different environments”, is not well-supported. 1.	How good is the generalization ability of VIPER? We definitely need evaluations on more OOD combinations to support the statement in the third contribution. 
2.	For Fig.8, which OOD combination the curve shows? In addition, this curve doesn’t include an error bar like other experiments in the paper. The authors listed and discussed the limitations including the lack of in-domain expert data in the real world, the sub-optimal performance with stochastic data, and the sensitive performance to the VQCode size and context length.",297,0,4,0.7494000000000001,0.1261494253,0.8708613515,218,39.3404,0.0622,neurips,0.0,4,3,3,4,partially factual,3,3,50,neutral,3,negative,3,moderate,5,5,4,5,5,5,5,85,polite,5,neutral,5,low,2.0,4.0,4.0,3.0,factual,4.0,4.0,80.0,polite,5.0,neutral,3.0,low,4,5,4,4,factual,4,4,85,polite,5,positive,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
191,Reviewer-SQjv,Video Prediction Models as Rewards for Reinforcement Learning,"Specifying reward signals that allow agents to learn complex behaviors is a long-standing challenge in reinforcement learning.
A promising approach is to extract preferences for behaviors from unlabeled videos, which are widely available on the internet. We present Video Prediction Rewards (VIPER), an algorithm that leverages pretrained video prediction models as action-free reward signals for reinforcement learning. Specifically, we first train an autoregressive transformer on expert videos and then use the video prediction likelihoods as reward signals for a reinforcement learning agent. VIPER enables expert-level control without programmatic task rewards across a wide range of DMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction model allows us to derive rewards for an out-of-distribution environment where no expert data is available, enabling cross-embodiment generalization for tabletop manipulation. We see our work as starting point for scalable reward specification from unlabeled videos that will benefit from the rapid advances in generative modeling. Source code and datasets are available on the project website: https://ViperRL.com","This paper proposes to use prediction likelihoods from autoregressive video models as reward functions to train reinforcement learning agents. Specifically, the conditional likelihood $\log p(x_{t+1}|x_{1:t})$ is augmented with an exploration reward to avoid suboptimal behavior. The authors conduct extensive experiments and show that likelihoods of autoregressive video models can be effective for reward specification. They also show that in certain cases the video models can generalize to unseen task domains, encouraging satisfying behaviors. Their ablation study compares different video models, different exploration objectives, and different context lengths.  Originality: Though the idea of using likelihood of states/observations as a reward is not novel, taking the temporal coherence into consideration with an autoregressive factorization is novel at my end. 

Quality: This work is strong in its efforts in extensive experiments. 

Clarity: This paper is straightforward to follow. The narrative is very intuitive. Experimental details are very well documented. 

Significance: Learning memory-based reward function with sequence modeling is an interesting direction to explore given the current advances of generative models.  In spite of the impressive amount of experiments presented in this work, one fundamental problem unresolved in this work is why the autoregressive likelihood, which is inherently non-Markov, can work with general RL algorithms, in which TD learning strongly depends on Markovian rewards. Latent-space model-based RL methods such as Dreamer used in this work are too particular because the latent-space modeling may resolve the limitation of TD learning as a byproduct. This means the empirical result from this work cannot be trivially generalized to other RL methods, rendering the thesis statement an overclaim.  Apart from the question I raised in Weakness, I hope the authors would also like to resolve my concerns in Section 4.3. 

While the paper claimed that specifying reward functions with video models can generalize to OOD tasks, Section 4.3 only demonstrate a particular case where there is a recombination of robot and objects to be manipulated. Is it possible to make the evaluation of generalization more systematic? I guess readers may be more interested in a discussion of what ""types"" of generalization are possible to eliminate the influence of particularity.  As stated in Weakness, there is a technical limitation of the proposed method that the authors do not seem to notice. Other limitations are well documented in Section 5. ",380,0,0,0.8179000000000001,0.1948156682,0.892482996,218,25.9473,0.2025,neurips,0.0,3,3,3,3,partially factual,4,3,70,polite,4,positive,5,moderate,5,5,4,5,factual,5,5,95,polite,5,neutral,5,none,2.0,5.0,4.0,3.0,factual,4.0,4.0,80.0,polite,5.0,neutral,3.0,none,3,4,4,3,factual,4,4,80,polite,5,positive,5,low,3,5,4,4,factual,4,4,85,polite,5,neutral,5,low
144,Reviewer-99Tt,Physics-informed neural networks with unknown measurement noise,"Physics-informed neural networks (PINNs) constitute a flexible approach to both finding solutions and identifying parameters of partial differential equations. Most works on the topic assume noiseless data, or data contaminated by weak Gaussian noise. We show that the standard PINN framework breaks down in case of non-Gaussian noise. We give a way of resolving this fundamental issue and we propose to jointly train an energy-based model (EBM) to learn the correct noise distribution. We illustrate the improved performance of our approach using multiple examples","The authors introduce a new training procedure for PINNs which are adapted to unknown measurement noise, i.e., a training procedure which works for any noise model. This is done via EBMs, which are trained jointly with the PINN. Here the EBMs estimate a 1d noise model based on the estimation of the PINN (conditional to the point $t_i$). Since they only estimate a 1d distribution, the (usually intractable) normalization constant can be estimated via numerical integration. The approach is tested on several (partial) differential equations and benchmarked against the standard PINN. The paper is easy to follow (except a few minor points). The idea is interesting and well-executed. The approach outperforms the standard PINN and offset PINN baseline. The experiments are well described, so that I think reproduction should be easy. 1) While the idea is heuristically clear, it would be interesting whether one can obtain theoretical guarantees. I have got the hunch that it should be possible to cast the framework into one of expectation maximization (EM) algorithms (maybe one slightly needs to change the loss and train alternating instead of jointly). Did the authors give this some thought? This would greatly strengthen the paper in my opinion. For this see e.g. \[1\]

2) The discussion in 4.1 and 4.2 is a bit confusing. While I think I got the gist of it, please make clear what variables the functions $\mu_{\varepsilon}$ and $\theta_0$ depend on. 

3) The metric logL is not clearly defined. How is that calculated in the case of a standard PINN, just Gaussian likelihood?

4) The non-Gaussian noise is a GMM. I would like to see physically more realistic noise models. One thing that could be interesting is whether this approach is able to learn mixed Gaussian noise, i.e., $y = f(t) + \eta_1 + f(t)\ \eta_2$ for normal $\eta_1,\eta_2$ with some variances. While this is still Gaussian, this is a noise model used in practice. 

5) Please make the relation to model errors \[2\] and \[3\] more clear. Although the model error framework tries to solve a different problem (Bayesian inversion) the ideas are somewhat similar.

6) A very similar is to train a surrogate on the data only (no PINN loss), then estimate the noise via an appropriate model, such as an EBM and then to train the surrogate on a combined loss. Please comment on this. 

\[1\] DeepGEM: Generalized Expectation-Maximization for Blind Inversion, Gao et al

\[2\] Iterative Updating of Model Error for Bayesian Inversion, Calvetti et al

\[3\] Noise-aware physics-informed machine learning
for robust PDE discovery, Thanasutives et al See weaknesses. I overall like the idea and think it has a lot of merit. A consideration of more realistic noise models and some theoretical guarantees would strenghten the article imo.",458,6,0,0.7849,0.1084022039,0.8494194150000001,51,56.5506,0.2,iclr,0.0,4,4,4,4,factual,4,5,90,polite,4,positive,5,low,5,5,5,5,factual,5,5,100,polite,5,positive,5,none,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,3.0,none,4,4,4,5,factual,4,4,85,polite,5,positive,5,low,4,4,4,5,factual,4,4,92,polite,5,positive,5,low
118,Pavel-Klinov,Module Extraction for Efficient Object Query over Ontologies with Large ABoxes,"The extraction of logically-independent fragments out of an ontology ABox can be useful\nfor solving the tractability problem of querying ontologies with large ABoxes. In this\npaper, we propose a formal definition of an ABox module, such that it guarantees complete\npreservation of facts about a given set of individuals, and thus can be reasoned\nindependently w.r.t. the ontology TBox. With ABox modules of this type, isolated or\ndistributed (parallel) ABox reasoning becomes feasible, and more efficient data retrieval\nfrom ontology ABoxes can be attained. To compute such an ABox module, we present a\ntheoretical approach and also an approximation for SHIQ ontologies. Evaluation of the\nmodule approximation on different types of ontologies shows that, on average, extracted\nABox modules are significantly smaller than the entire ABox, and the time for ontology\nreasoning based on ABox modules can be improved significantly.","In this paper the authors define the notion of ABox modules, i.e. fragments of the ABox which capture entailments for the given individual w.r.t. the concept names and roles occurring in the ontology. In addition to the generic definition, the authors propose a specialization, called Exact Abox module, and proceed to investigating how (approximations of) such modules can be computed efficiently for SHIQ ontologies. The paper ends with a fairly extensive evaluation on several hand-picked ontologies showing that most of ABox modules are small and thus reasoning over them is much faster than over the entire ABox. ===Significance and novelty=== I believe the paper addresses an important topic since the existing notions of logic-based modules are defined w.r.t. a fixed signature whereas it is often important to capture a certain class of entailments over the signature which is not known in advance (e.g., all class and property assertions for an individual). However, it must be noted that the proposed modules would only preserve atomic entailments, e.g., atomic concept assertions, and do not guarantee that answering complex queries, e.g., DL queries for arbitrary concept expressions, over the module will return the same results. It is also not clear how (or if) the proposed modularization will help evaluating conjunctive queries which may return individuals from multiple modules. Remark 3.2 says (correctly) that answering DL queries can be reduced to instance retrieval for a fresh concept name but this would probably require to recompute existing modules (since the TBox has changed). This is obviously undesirable. I believe the paper adequately discusses related work.  ===Contributions and technical quality=== I'll comment separately on each individual contribution. The notion of ABox module. This notion simply provides conditions which a fragment of the ABox must meet in order to be called ""ABox module"". The authors correctly note that it does not prevent the module from containing superfluous parts. The notion of exact ABox module. This is where things get interesting, this notion basically says that the ABox module is a union over all justifications of atomic ABox facts about the individual. On the one hand, this makes sense because it trivially implies that any exact module is a module. On the other hand, this definition shouldn't be directly used for extracting modules because just one justification per assertion would be enough. BTW, the proposed definition guarantees the property which is called ""depletedness"" for locality-based modules: the ontology minus the module entails nothing about the individual. It'd be good to mention it.   It is unfortunate that the authors decided to jump directly to the extraction aspects and did not spend any time discussing the properties of their modules, e.g. whether there're counterparts of such properties of locality-based modules as robustness under signature restrictions, self-containedness, etc. (see [1] and [2]). It'd be good to fully understand what the modules are before starting to extract them.  Extracting exact ABox modules. This is the most problematic section of the paper, which suffers from imprecise notions, statements, and lack of proofs. Here are the main issues: 1) Page 11: the whole notion of ""class term behind a's assertions..."" is totally undefined and very confusing. It's rather unfortunate because the authors seem to build the extraction methodology on it (which culminates with the condition (3) which is then referenced in many other places). Both this notion and the condition (3) must be made proper (formal) definitions. Then the statement that the condition (3) is necessary and sufficient for entailing a concept assertion should be formulated as a proposition. 2) Page 12: Nothing is proved (or even formulated) about the extraction procedure shown at the top of the page. This is actually one of the central contributions of the paper: the algorithm for extracting exact ABox modules. It has to be shown that 1) it is correct, i.e. it selects all and only module-essential assertions, 2) it terminates (this is rather easy), and 3) what it's complexity is (apparently as hard as reasoning for Exptime-logics).  Extracting approximate ABox modules. The authors propose a syntactic check to decide if an axiom can be potentially relevant for individual entailments. Unfortunately it's rather hard to understand until (3) is made clear (because the syntactic form essentially approximates (3)).  Evaluation. The performed evaluation is pretty strong and shows several important results, e.g., i) approximate ABox module extraction is fast (Table 1) and ii) approximate ABox modules are generally small (Table 2). But some issues need to be fixed: 1) It's not described how the TBox of DBPedia ontologies was generated (page 19). Apparently some complex class expression have been auto-generated but the methodology isn't explained. 2) According to which principles were these ontologies selected? What makes them representative or interesting (other than large ABoxes which are sometimes synthetic)? There some others ontologies with large ABoxes, e.g., the IMDB ontology. 3) I wonder if any of the ontologies contain transitive roles (and assertions for them). My understanding is that transitive roles could be one of the main difficulties because they can blow the property module for ""a"" (by including role assertions for other individuals). If not, this is a weakness. 4) It's unclear how the time spent on module extraction for a single individual was measured, e.g., were all extractions done independently or was the whole ABox modularized in one go? ===Presentation=== While most of the prose is OK, the paper suffers from various imprecise statements and confusing/incoherent use of terminology. Here are some of the issues: * p2: ""... up to exponential worst-case complexity..."", actually it's N2ExpTime for SROIQ. * p2: "".. a setting of semantic webs"" -> ""the Semantic Web setting"". * p2: One has to be precise when talking about the closure of logical implications (e.g., does it include concept assertions for complex concepts of arbitrary length?). * Definition 2.3 isn't quite a definition. T and A have to be defined precisely as sets of axioms of a specific form. * Definition 2.5: ""Logic Entailment"" -> ""Logical Entailment""? * p6, top: The statement that all reasoners implement (hyper)-tableau isn't quite true. Even for expressive DLs, e.g. Horn-SHIQ, there're other methods such as consequence-based reasoning. * Definition 2.9: ""to be"" is missing * Definition 3.4: need to make clear that Just(alpha, K) here means *some* justification, not any specific justification of alpha. * p8 and elsewhere: It'd be considerably better to define equality-free ontologies syntactically. I.e., if I have an ontology, how do I know which extraction procedure should I run, the one which accounts for individual equality or the simpler one? * p11: what is meant by ""decidable R-neighbors""? The same goes for "" its subsumer is undecidable."" on page 13. * Proposition 4.3: it'd be better if this fact was proved without explicitly referring to the tableau's completion rules. It's a fact about the logic, not any particular calculus. * p14: Essentially the same comment applies to the Module Extraction with Equality section. Explicitly referring to particular tableau rules brings nothing but trouble. Also the statement that equality requires reasoning to detect it is strange since reasoning is required anyway to compute exact ABox modules. * Proposition 5.1: are we talking about asserted or inferred R-successors? Again, what it ""equality-free ABox"" exactly? * Definition 5.1 seems to define potential equivalents in terms of potential equivalents. Until it's fixed I find it nearly impossible to understand Proposition 5.2, which is the key statement about module extraction from ABoxes with equality. Perhaps it would help to prove the simpler Proposition 5.1 first. * Table 1 and 2: better to explain columns in the captions rather than in text on some other page. * p19, end: what is ""entities"" here? Definition 2.7 says that signature is always a set of individuals. Can entities refer to something else? * p22: It seems that this optimization will lead to the modules not being exact ABox modules any more (since not all module-essential axioms will be included). Better to say it explicitly. ===Summary=== In general, this is a potentially useful paper which presents module notions and extraction methods which can prove useful for applications dealing with instance checking w.r.t. large ABoxes. Eventually I'd like it to be published but I believe it needs another round of reviewing after some key notions and conditions (condition (3), most prominently) are made precise. Also, it can't be published until the correctness of the main extraction procedure (for exact modules) has been formally proved and reviewed (since all subsequent results, e.g. approximations, are based on it). [1] Bernardo Cuenca Grau, Ian Horrocks, Yevgeny Kazakov, Ulrike Sattler: Modular Reuse of Ontologies: Theory and Practice. J. Artif. Intell. Res. (JAIR) 31: 273-318 (2008) [2] Ulrike Sattler, Thomas Schneider, Michael Zakharyaschev: Which Kind of Module Should I Extract? Description Logics 2009",1453,5,9,0.8006000000000001,0.0900611326,0.9462785125,75,48.5,0.0501,semanticweb,0.0,4,5,5,4,factual,4,5,89,neutral,4,neutral,4,none,5,4,5,5,factual,5,5,85,polite,5,neutral,5,none,2.0,4.0,4.0,3.0,factual,4.0,4.0,70.0,polite,5.0,neutral,3.0,low,5,4,5,5,factual,5,5,90,polite,5,neutral,5,none,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
159,Reviewer-aUSe,Resetting the Optimizer in Deep RL: An Empirical Study,"We focus on the task of approximating the optimal value function in deep reinforcement learning. This iterative process is comprised of solving a sequence of optimization problems where the loss function changes per iteration. The common approach to solving this sequence of problems is to employ modern variants of the stochastic gradient descent algorithm such as Adam. These optimizers maintain their own internal parameters such as estimates of the first-order and the second-order moments of the gradient, and update them over time. Therefore, information obtained in previous iterations is used to solve the optimization problem in the current iteration. We demonstrate that this can contaminate the moment estimates because the optimization landscape can change arbitrarily from one iteration to the next one. To hedge against this negative effect, a simple idea is to reset the internal parameters of the optimizer when starting a new iteration. We empirically investigate this resetting idea by employing various optimizers in conjunction with the Rainbow algorithm. We demonstrate that this simple modification significantly improves the performance of deep RL on the Atari benchmark.","The authors argue that Adam's internal parameters should be reset with each iteration. The authors demonstrate the effectiveness of this approach in the Atari domain.  - Results are convincing for Rainbow.
- Novelty is very low, but potential impact is high, if the result generalizes, there is little reason not to use this method in every DQN-style RL algorithm.   - As mentioned by the authors, novelty is low compared to Bengio et al. 
- Results are only shown on Rainbow and do not appear to work for SAC (with reason) -- but does raise the question if the method is effective for other RL methods. 
- There is limited insight. Can the authors show that initializing Adam's parameters with 0 is better than using the parameters from the previous iteration in a more concrete way? Such as examining the behavior of the actual values. The fact that not resetting is seemingly better at low values of K suggests that not resetting can provide a reasonable initialization for the parameters of Adam.

Minor
- The y-axis is unlabelled in several figures.  As mentioned in weaknesses:
- Does this result generalize to other methods besides Rainbow? Such as DQN or more modern deep RL methods.
- Can the authors show that initializing Adam's parameters with 0 is better than using the parameters from the previous iteration in a more concrete way? Such as examining the behavior of the actual values. 
 No concerns. ",240,0,1,0.8148000000000001,0.1232647908,0.8709654808,215,48.3728,0.1041,neurips,0.0396039603960396,3,4,2,2,partially factual,3,4,50,polite,3,negative,3,moderate,4,4,4,4,factual,4,4,82,polite,5,neutral,5,moderate,3.0,4.0,4.0,3.0,factual,4.0,4.0,80.0,polite,4.0,neutral,3.0,none,3,4,3,3,factual,4,4,70,polite,4,neutral,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
127,Yankai-Xia,Neurotoxicity of nanoplastics: A review,"With the increase in plastic waste in the environment, it is undeniable that humans and most organisms are exposed to plastic particles of various sizes, including nanoplastics (NPs). Humans are at risk owing to various routes of entry, including ingestion, inhalation, and dermal contact. While the toxicity of NPs is still debatable due to the scarcity of resources and research, most studies have concluded that NPs may exert toxicity, which exacerbates their neurotoxicity potential. Earlier studies concluded that NPs can cause oxidative stress, which results in apoptosis of neuronal cells. Some studies have shown that NPs can affect fundamental cell functions by inducing physical stress through deposition. Furthermore, studies on in vivo models exposed to NPs have demonstrated behavioral changes that are presumably due to alterations in acetylcholinesterase activity and neurotransmitter levels. This review discusses studies conducted on the neurotoxic potential of NPs and their effects, which are dependent on several parameters, including size and type of NPs, exposure concentration, duration, and various models at risk of NP exposure. Furthermore, speculations on how NPs are related to neurotoxicity are also discussed.","Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The review addresses the increasingly relevant topic of the neurotoxic potential of nanoplastics (NPs) in the context of escalating plastic pollution, effectively summarizing key findings from the literature with an emphasis on the various exposure routes and associated risks. However, the manuscript would benefit from a more comprehensive synthesis of the existing literature, particularly in addressing the inconsistencies and gaps in current research, while also providing a clearer articulation of the limitations of current research methodologies and offering suggestions for future studies. Additionally, a discussion of the broader implications for public health and potential regulatory frameworks would strengthen the manuscript's contribution to the field. Overall, the review could be further improved by deepening the analysis of existing studies and providing a more critical perspective on the current state of knowledge. I recommend that the authors consider resubmitting after making significant improvements. Major comments While the review discusses various detection and quantification methods for NPs, a more detailed critique of the limitations of these methodologies is needed. This should include an examination of the challenges related to detecting NPs in environmental samples versus laboratory conditions, as well as the implications these limitations have for interpreting research findings. The manuscript needs a more critical analysis of key research gaps, especially concerning the inconsistencies in findings related to the mechanisms of NP-induced neurotoxicity. Strengthening this section with a more detailed comparison of the outcomes across different experimental models and conditions would greatly enhance the review's contribution. The discussion on the mechanisms of NP-induced neurotoxicity is crucial. For instance, exploring the specific biochemical pathways through which NPs interact with cellular components at a molecular level would provide a more comprehensive understanding.  The role of protein corona formation in neurotoxicity, mentioned towards the end, should be integrated earlier in the manuscript to establish a clear connection between NP exposure and neurodegenerative diseases. While the manuscript covers many trending topics, it often treats them in isolation, which leads to a lack of coherence. An integrated approach that links these topics and demonstrates their interconnections would greatly improve the flow and continuity of the review. Minor comments The manuscript relies heavily on older studies, with relatively few references from the past three years. Incorporating more recent studies will ensure that the review reflects the current state of research and provides a comprehensive overview of the field. In some sections, particularly those discussing in vivo studies, the outcomes are not always clearly connected to the broader implications for neurotoxicity. It would be helpful to more explicitly link the results of these studies to the potential mechanisms of NP-induced neurotoxicity and their relevance to human health. The conclusion primarily restates the findings discussed throughout the review but does not provide a comprehensive synthesis of the key takeaways. The summary of neurotoxicity of NPs in different models presented in Table 1 is not comprehensive and should be thoroughly enumerated. The language of the manuscript should be polished.  Is the topic of the review discussed comprehensively in the context of the current literature? Partly  Are all factual statements correct and adequately supported by citations? Yes  Is the review written in accessible language? Partly  Are the conclusions drawn appropriate in the context of the current research literature? Partly",605,0,1,0.8004,0.1484375,0.8763298392000001,49,13.99,0.1633,f1000,0.0,4,4,4,4,factual,4,4,80,polite,4,neutral,4,low,4,4,3,4,factual,4,4,75,polite,4,neutral,4,low,2.0,4.0,3.0,3.0,factual,3.0,4.0,70.0,polite,4.0,neutral,4.0,low,4,4,3,4,factual,4,4,80,polite,4,neutral,4,low,3,3,3,4,partially factual,4,4,75,polite,4,neutral,4,low
59,Reviewer-rzXY,Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning,"To support various applications, business owners often seek the customized models that are obtained by fine-tuning a pre-trained LLM through the API provided by LLM owners or cloud servers. However, this process carries a substantial risk of model misuse, potentially resulting in severe economic consequences for business owners. Thus, safeguarding the copyright of these customized models during LLM fine-tuning has become an urgent practical requirement, but there are limited existing solutions to provide such protection. To tackle this pressing issue, we propose a novel watermarking approach named ""Double-I watermark"". Specifically, based on the instruct-tuning data, two types of backdoor data paradigms are introduced with trigger in the instruction and the input, respectively. By leveraging LLM's learning capability to incorporate customized backdoor samples into the dataset, the proposed approach effectively injects specific watermarking information into the customized model during fine-tuning, which makes it easy to inject and verify watermarks in commercial scenarios. We evaluate the proposed ""Double-I watermark"" under various fine-tuning methods, demonstrating its harmlessness, robustness, uniqueness, imperceptibility, and validity through both theoretical analysis and experimental verification.","The paper proposes a novel watermarking method to safeguard the copyrights of customized Large Language Models (LLMs) during fine-tuning. Addressing challenges such as watermark uniqueness, imperceptibility, and robustness against removal attacks, the ""Double-I watermark"" method introduces two types of backdoor data paradigms. These paradigms effectively embed watermarking information into the model, ensuring the watermark's presence is imperceptible yet detectable. The method is thoroughly evaluated, demonstrating its effectiveness in maintaining the model’s performance, robustness against attacks, and overall practical applicability for protecting the intellectual property of customized LLMs in various applications. Here are some potential strengths discussed in the paper: 
1. Robustness Against Removal Attacks: The proposed ""Double-I watermark"" method has been designed to be robust against attacks aimed at removing the watermark, ensuring that copyright protection remains intact even under adversarial conditions.
2. Imperceptibility and Uniqueness: The watermark introduced by the method is imperceptible, meaning it doesn’t affect the model's normal functionality or output, and it is unique, allowing for clear identification and copyright protection of the customized LLMs.
3. Comprehensive Evaluation: The paper includes a thorough evaluation of the proposed method, assessing various aspects such as harmlessness, robustness, uniqueness, and efficiency, demonstrating the method’s practical viability and effectiveness in real-world scenarios. 1. Limited Exploration of Attacks: The paper primarily focuses on second-time fine-tuning and model quantization as watermark removal attacks. The exploration of other potential attacks,such as pruning, that might be used to remove or alter the watermark seems limited.

2. Dependency on Specific Paradigms: The watermarking method relies on specific paradigms for embedding the watermark, and its effectiveness might be influenced by the choice of these paradigms, limiting its flexibility and adaptability.

3. Uniqueness Challenges: The paper mentions challenges in ensuring the uniqueness of the watermark, particularly in distinguishing whether certain behaviors stem from the model’s inherent traits or the embedded watermark. 1. Regarding Model Manipulation:
Could you clarify the resilience of the watermarking method against potential manipulations, such as adding conditional statements in the code to filter or alter specific inputs, especially when there is knowledge of how the watermarking works?

2. Concerning Training Data and Time:
Could you provide more details on the amount of training data required and the duration needed to effectively watermark a model using your proposed method? Is there a significant amount of data and time needed for this process?

3. On the Necessity of Fine-Tuning:
Is it possible to implement the watermarking method without resorting to fine-tuning the model? How does the method ensure that the model remains general and unbiased, especially when the question-answer pairs used for watermarking are not as diverse as those in the original training set, such as OpenAI’s non-public dataset?",444,0,8,0.8097000000000001,0.1072108844,0.8502570391000001,48,5.7905,0.33,iclr,0.0,1,4,4,0,unfactual,3,1,64,polite,3,positive,3,high,5,5,5,5,5,5,5,95,5,5,5,5,3,2.0,4.0,4.0,3.0,factual,3.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,4,3,factual,4,4,80,polite,5,positive,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
59,Reviewer-NrtU,Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning,"To support various applications, business owners often seek the customized models that are obtained by fine-tuning a pre-trained LLM through the API provided by LLM owners or cloud servers. However, this process carries a substantial risk of model misuse, potentially resulting in severe economic consequences for business owners. Thus, safeguarding the copyright of these customized models during LLM fine-tuning has become an urgent practical requirement, but there are limited existing solutions to provide such protection. To tackle this pressing issue, we propose a novel watermarking approach named ""Double-I watermark"". Specifically, based on the instruct-tuning data, two types of backdoor data paradigms are introduced with trigger in the instruction and the input, respectively. By leveraging LLM's learning capability to incorporate customized backdoor samples into the dataset, the proposed approach effectively injects specific watermarking information into the customized model during fine-tuning, which makes it easy to inject and verify watermarks in commercial scenarios. We evaluate the proposed ""Double-I watermark"" under various fine-tuning methods, demonstrating its harmlessness, robustness, uniqueness, imperceptibility, and validity through both theoretical analysis and experimental verification.","This work presents a novel watermarking algorithm to secure the copyright of customized models that is finetuned by a third-party service provider. By injecting a trigger into the instruction and the input in training data, the users install a backdoor mechanism to the model, which can be detected during inference and verified by hypothesis testing to check the watermark. Experiments show that the approach satisfies the essential properties of the watermarking method. - The paper is well written and comprehensible, with nice formulation that is easy to understand.
- Innates difficulty of watermarking finetuned LLMs are discussed, which are important for building an algorithm.
- The algorithm is simple and effective, experimental results demonstrate its watermarking capability in five essential properties.
- Extensive experiments are conducted to study the effectiveness of the method in many practical usecases. - Related works should be discussed in more detail, there are many recent watermarking techniques for LLM in the literature.
- The strategy is applicable for instruction tuning only, whereas there are other ways to finetune LLM with a service provider, restricting the utility of the method in practice.
- The paper should briefly introduces Fisher’s exact test, show its results and how we accept or reject a hypothesis. For example, in Table 2, the distributions on trigger set and reference set of clean model finetuned with LORA are quite different. - Can we apply the proposed strategy to other tasks, for example question answering task, where the instruction is not presented?
- How do we conclude whether the model contains watermark from the distribution on trigger and reference set? What is the reasonable size of verification set?
- How does the performance change if we vary the ratio of trigger set in reference set in training data as well as verification data?",300,0,0,0.7971,0.2083333333,0.82766819,48,32.3061,0.0948,iclr,0.0,1,3,2,1,unfactual,3,2,38,polite,2,neutral,4,high,4,4,4,4,5,4,5,85,polite,5,neutral,5,moderate,2.0,4.0,4.0,4.0,factual,3.0,4.0,80.0,polite,5.0,positive,5.0,none,4,4,4,4,factual,4,4,85,polite,5,positive,4,low,3,4,4,4,partially factual,4,3,85,polite,5,positive,3,low
115,Reviewer-duEY,MoCa: Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks,"Human commonsense understanding of the physical and social world is organized around intuitive theories. These theories support making causal and moral judgments. When something bad happens, we naturally ask: who did what, and why? A rich literature in cognitive science has studied people's causal and moral intuitions. This work has revealed a number of factors that systematically influence people's judgments, such as the violation of norms and whether the harm is avoidable or inevitable. We collected a dataset of stories from 24 cognitive science papers and developed a system to annotate each story with the factors they investigated. Using this dataset, we test whether large language models (LLMs) make causal and moral judgments about text-based scenarios that align with those of human participants. On the aggregate level, alignment has improved with more recent LLMs. However, using statistical analyses, we find that LLMs weigh the different factors quite differently from human participants. These results show how curated, challenge datasets combined with insights from cognitive science can help us go beyond comparisons based merely on aggregate metrics: we uncover LLMs implicit tendencies and show to what extent these align with human intuitions.","This model presents a new challenge set of hard edge cases intended to test models understanding of the nuances of the directness of causation and moral culpability, by collecting them from a set of cognitive science papers. This has the clever effect of not only getting challenging stories, but those which would vary along specific features important to humans.

They test LLMs on those outputs to measure agreement with human intuitions; and annotate those cases for a set of features so that one could draw insight from those disagreements. 

 It is a well-written and well-considered paper which both presents a new useful challenge set, and utilizes it to provide interesting analysis of LLM tendencies in causal culpability and moral judgments.  It could clearly lead to further uses both in the evaluation of new models and in further analysis. The literature review is, as far as I could tell, comprehensive. 

The work seem rigorous throughout - I appreciate the thorough explorations with personas and automatic prompt engineering, which alleviate worries about the normal fickleness of prompt choice.   - The size of the challenge set (around 200 stories I believe) is somewhat limited; I don't think that that's too much of a worry for such a challenge set, so I wouldn't view it as a major weakness. 
- quibble: A seemingly left-over note on line 232: "" This is very very interesing, make the flow better."" - I'd be very curious about which personas and prompts would lead to worst-case performance for various models, since that might give insight into how the models go awry. 
- The improvements in alignment with human judgements from adopting a utilitarian/consequentialist framing is fascinating. However, that doesn't mean that all humans have a utiliarian framing.  Is there any concern that measuring against the average of human judgements might ignore variance between different humans on such judgement tasks? 
 The ethical considerations section seems thoughtful, and I see no unaddressed limitations. ",323,0,0,0.8307,0.1109072872,0.9276382923,215,40.2727,0.7142000000000001,neurips,0.0099009900990099,3,4,3,2,factual,4,4,75,neutral,4,positive,3,none,4,4,4,4,partially factual,4,4,85,polite,5,positive,5,moderate,3.0,5.0,5.0,4.0,factual,5.0,4.0,80.0,polite,5.0,positive,4.0,none,3,4,4,3,factual,4,4,80,polite,5,positive,4,low,3,4,4,4,factual,4,4,85,polite,5,positive,3,low
95,Reviewer-jG7C,KDGCN: A Kernel-based Double-level Graph Convolution Network for Semi-supervised Graph Classification with Scarce Labels,"Graph classification, which is significant in various fields, often faces the challenge of label scarcity. Under such a scenario, supervised methods based on graph neural networks do not perform well because they only utilize information from labeled data. Meanwhile, semi-supervised methods based on graph contrastive learning often yield complex models as well as elaborate hyperparameter-tuning. In this work, we present a novel semi-supervised graph classification method, which combines GCN modules with graph kernels such as Weisfeiler-Lehman subtree kernel. First, we use a GCN module as well as a readout operation to attain a graph feature vector for each graph in the dataset. Then, we view the graphs as meta-nodes of a supergraph constructed by a graph kernel among graphs. Finally, we use another GCN module, whose inputs are the graph feature vectors, to learn meta-node representations over the supergraph in a semi-supervised manner. Note that the two GCN modules are optimized jointly. Compared to contrastive learning based semi-supervised graph classification methods, our method has fewer hyperparameters and is easier to implement. Experiments on seven benchmark datasets demonstrate the effectiveness of our method in comparison to many baselines including supervised GCNs, label propagation, graph contrastive learning, etc.","This paper proposes a novel semi-supervised graph classification method that combines GCN modules with graph kernels, resulting in a model with fewer hyperparameters. Experiments on seven benchmark datasets demonstrate its effectiveness compared to various baselines, including supervised GCNs and graph contrastive learning."" - Graph classification is a very fundamental problem for graph-related problems, and exploring semi-supervised graph classification is a very interesting topic.
- The paper is well-organized and easy to be understood. - The introduction of the graph kernel concept in semi-supervised graph classification methods is not a novel idea, and it has been mentioned in many previous studies \[1-3\]. However, the authors have not referred to it or provided a detailed comparison, and I strongly recommend that they compare and discuss their work in relation to these existing studies.
- It seems that the graph kernel in the paper is not learnable, which results in the quality of the supergraph construction being entirely dependent on the learned node representations and the chosen threshold. Turning the graph kernel into a learnable component could be a better approach.
- The model is evaluated only on small datasets and doesn't know the scalability on large-scale datasets.
- This task also has several highly relevant works, which the authors have not mentioned or compared to in their paper. To ensure the novelty of their method and the superiority of its results, it is advisable for the authors to provide supplementary comparisons and engage in a detailed discussion. \[4-6\].

\[1\] KGNN: Harnessing Kernel-based Networks for Semi-supervised Graph Classification. WSDM 2022

\[2\] TGNN: A Joint Semi-supervised Framework for Graph-level Classification. IJCAI 2022

\[3\] GHNN: Graph Harmonic Neural Networks for Semi-supervised Graph-level Classification. Neural Networks 2022

\[4\] DualGraph: Improving Semi-supervised Graph Classification via Dual Contrastive Learning. ICDE 2022

\[5\] Active and Semi-supervised Graph Neural Networks for Graph Classification. TBD 2022

\[6\] Focus on Informative Graphs! Semi-Supervised Active Learning for Graph-Level Classification. 2023 The novelty of the paper and the absence of important baselines are the two most critical factors affecting the quality of the article. I recommend that the authors make significant revisions.",348,6,2,0.7203,0.2028409091,0.9569439292,51,33.1417,0.2025,iclr,0.0,4,4,3,4,partially factual,4,3,75,polite,4,neutral,3,low,5,5,5,5,factual,5,5,88,polite,5,neutral,5,low,1.0,4.0,4.0,2.0,partially factual,1.0,2.0,60.0,polite,3.0,neutral,3.0,low,4,4,4,4,factual,4,4,80,polite,5,neutral,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
7,Reviewer-Bu9r,Accelerating Monte Carlo Tree Search with Probability Tree State Abstraction,"Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have achieved superhuman performance in many challenging tasks. However, the computational complexity of MCTS-based algorithms is influenced by the size of the search space. To address this issue, we propose a novel probability tree state abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A general tree state abstraction with path transitivity is defined. In addition, the probability tree state abstraction is proposed for fewer mistakes during the aggregation step. Furthermore, the theoretical guarantees of the transitivity and aggregation error bound are justified. To evaluate the effectiveness of the PTSA algorithm, we integrate it with state-of-the-art MCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental results on different tasks demonstrate that our method can accelerate the training process of state-of-the-art algorithms with 10%-45% search space reduction.","This paper proposed a novel search algorithm, PTSA, to improve the search efficiency of MCTS. Empirical results show that PTSA can be integrated with Sampled MuZero and Gumbel MuZero and can reduce the original branching factor by 10% up to 45%. The proposed PTSA algorithm can reduce the branching factor of MCTS and improve the computational efficiency of MCTS-based algorithms. The authors also provide both theoretical and empirical analyses. * The author claims that the proposed method can reduce the branching factor by 10% up to 45%. However, the result is based on only five Atari games. Based on Figure 3, the aggregation percentage varies across different Atari games. Can these five games represent all Atari-57 games? It would be more convincing to run more Atari games to support the claims.

* Moreover, it is unclear for the aggregation percentage on control tasks and Gomoku experiments. Without these experiments, it is inappropriate to claim “reduce branching factor by 10% up to 45%”.

* The time complexity of the proposed approach is higher than the original MCTS. It is unclear whether PTSAZero will still improve its efficiency when running under a larger simulation number. Currently, the authors only run “PTSAZero N=18” in Atari experiments. Will “PTSAZero N=30” perform better than “PTSAZero N=18”?

* Besides, in the board games such as Gomoku or Go, it is common to run large simulation numbers such as N=400 or N=800 during evaluation. It would be better to provide additional experiments/analyses to demonstrate the scale-up ability for PTSAZero. For example, providing the aggregation percentage/time usage/strength when using different simulation numbers. * In Algorithm 1, line 15, if $b_i$ and $b_s$ have different lengths, will their $\phi_{Q_{\alpha}^{psi}}(b)$ be different? In addition, what is the definition for $\phi_{Q_{\alpha}^{psi}}(b)$? Definition 4.3 only shows the probability. 
* In Algorithm 1, line 17, $v_0$ is root node and $b_j$ is a selection path. what does $v_0$.prunning($b_j$) mean?
* In Figure 2, will PTSA get better performance when using a larger simulation (N=30)? Current experiments only used N=18. It would be better to add another experiment with a larger simulation to show the scale-up ability of PTSA.
* In the Gomoku experiment, what does the expert opponent stand for? How many simulations are used in the Gomoku evaluation? As Gomoku is a two-player game, why not compare PTSAZero to other methods directly?
* line 302: “The winning rates of different methods w.r.t. training time are shown in Figure 4”. Should the range of the win rate be between 0 and 1 in Figure 4?
* In Figure 3, it seems that the aggregation percentage varies across different Atari games. Which type of game may have a higher aggregation percentage? Why do you choose these games? Can these five games represent Atari-57 games? Do you have more experiments on other Atari games?
* In Atari experiments, “As Gumbel MuZero does not require large simulations for Atari and control tasks”. In fact, Gumbel MuZero improves training efficiency by only using N=2 in Pacman, and the result is comparable to N=50. It would be more convincing to add additional experiments to compare the training efficiency between “Gumbel MuZero N=2” and “PTSAGZero N=2“ in Atari experiments.
* In Figure 2 (f),  the label of the green curve is “MuZero N=50”, should it be “MuZero N=30”?
* Line 17, typo: Muzero -> MuZero.
* Figure 2, typo: state-of-art -> state-of-the-art.
* Figure 3 is shown after Figure 4. Please fix the order of these figures. The authors have addressed the limitations in the paper.",587,0,3,0.7271000000000001,0.1440848214,0.8432080150000001,216,50.2894,0.0822,neurips,0.0,4,4,4,3,factual,3,4,80,neutral,4,negative,4,low,5,5,5,5,factual,5,5,95,polite,5,neutral,5,none,2.0,4.0,4.0,3.0,partially factual,4.0,4.0,70.0,polite,4.0,neutral,3.0,low,5,4,5,5,factual,5,5,90,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
7,Reviewer-GJR1,Accelerating Monte Carlo Tree Search with Probability Tree State Abstraction,"Monte Carlo Tree Search (MCTS) algorithms such as AlphaGo and MuZero have achieved superhuman performance in many challenging tasks. However, the computational complexity of MCTS-based algorithms is influenced by the size of the search space. To address this issue, we propose a novel probability tree state abstraction (PTSA) algorithm to improve the search efficiency of MCTS. A general tree state abstraction with path transitivity is defined. In addition, the probability tree state abstraction is proposed for fewer mistakes during the aggregation step. Furthermore, the theoretical guarantees of the transitivity and aggregation error bound are justified. To evaluate the effectiveness of the PTSA algorithm, we integrate it with state-of-the-art MCTS-based algorithms, such as Sampled MuZero and Gumbel MuZero. Experimental results on different tasks demonstrate that our method can accelerate the training process of state-of-the-art algorithms with 10%-45% search space reduction.","To accelerate MCTS, the paper proposed a novel probability tree state abstraction (PTSA) algorithm to improve the search efficiency of MCTS. 
They define states that are similar by using path transitivity and claim that such a method can have fewer mistakes. According to the results of Atari and Gomoku, the method can be 10% ~ 45% faster.
 1. The method provides some theoretical guarantee.
2. The experiments take place in many environments.
3. The ablation studies have tried many abstraction functions. 
 1. The intuition of the paper is weird.  The method required of all states on the paths needs to be similar. However, there are two problems here. First, the V value might be more incorrect at the beginning. Second, even if the V value is correct for the whole path, this method reduces the chance of pruning more nodes. For example, in Atari, agents can reach the exact same state with different paths. Since the environment is MDP, we should merge those two states. 
 
2. It is unknown for the performance when the simulation is higher. The abstract error normally increases when the simulation increase. The method might delete some good paths that can only be identified after numerous simulations.


 1. How do you prune a path from a tree? What will happen to those branches that are on the path?
2. Have you considered abstraction functions that also require the best action should be the same\[1\]?
\[1\] Are AlphaZero-like Agents Robust to Adversarial Perturbations? Stated in the weakness. ",250,2,7,0.7703,0.1869565217,0.9012311697,216,58.8964,0.1509,neurips,0.0,1,3,2,1,factual,1,1,40,impolite,1,negative,2,high,4,4,4,4,partially factual,5,5,75,polite,5,neutral,5,low,2.0,4.0,4.0,3.0,factual,4.0,4.0,70.0,polite,5.0,neutral,3.0,low,2,3,3,2,partially factual,3,3,60,neutral,4,neutral,4,moderate,2,4,3,3,partially factual,3,3,65,polite,4,neutral,4,low
102,Reviewer-6dqz,Laughing Hyena Distillery: Extracting Compact Recurrences From Convolutions,"Recent advances in attention-free sequence models rely on convolutions as alternatives to the attention operator at the core of Transformers. In particular, long convolution sequence models have achieved state-of-the-art performance in many domains, but incur a significant cost during auto-regressive inference workloads -- naively requiring a full pass (or caching of activations) over the input sequence for each generated token -- similarly to attention-based models. In this paper, we seek to enable $\mathcal O(1)$ compute and memory cost per token in any pre-trained long convolution architecture to reduce memory footprint and increase throughput during generation. Concretely, our methods consist in extracting low-dimensional linear state-space models from each convolution layer, building upon rational interpolation and model-order reduction techniques. We further introduce architectural improvements to convolution-based layers such as Hyena: by weight-tying the filters across channels into heads, we achieve higher pre-training quality and reduce the number of filters to be distilled. The resulting model achieves 10x higher throughput than Transformers and 1.5x higher than Hyena at 1.3B parameters, without any loss in quality after distillation.","The paper proposes distilling convolutional models for autoregressive sequence generation into recurrent (state-space) models. A key limitation of recently proposed convolutional models is that they use convolutional filters that extend potentially infinitely into the past, and the same techniques that yield efficient training do not transfer over to token-by-token generation. This paper proposes a post-training and data-free distillation step that replaces such convolutional models with a recurrent approach that uses constant time and memory at each step of generation during inference. The key strength of the paper is that proposes a novel and theoretically grounded distillation method, which achieves good approximation bounds without being tied to specific data or involving what amounts to an additional round of training.

Also, convolutional and state space models as a whole are an underexplored area in recent work when compared to Transformers and attention, and this paper puts forward a novel method of linking the two, both of which contribute to the originality of the paper. My biggest reservation based on my understanding of the paper is that I didn't get a qualitative sense of what might be lost as part of the distillation process. Is there some intuition of what is the worst-case qualitative behavior of a convolutional filter that can't be tightly approximated with LaughingHyena?

This question comes to mind because in the world of Transformers, it is no secret that most of the computational power spent on quadractic attention goes to waste. Just a small subset of the efficiency work there includes pruning entire heads, limiting each head to a head-specific attention context window, or even doing sliding-window attention with a fixed context length for the entire model. More in line with the present paper, work like Performer has developed an approximation for converting attention-based models into recurrent models -- at a cost. Notwithstanding the theory of the tightness of that last approximation, and equivalent performance of many to the Transformer that is demonstrated in some of the papers introducing these methods, there inevitably arises some situation where none of the approximations match the Transformer in quality. I worry that the present approach might fall into a similar pattern. A recurring theme in this area is that any method that sacrifices the ability to have long context, or to perform associative recall, is suspect. That's why when it comes to these approximations of convolutions, it would helpful to know whether the approximation is effectively some form of context-truncation in disguise, and if not what the qualitative cost is. How well does the LaughingHyena architecture perform on the associative recall task, especially as compared to Hyena (or MultiHyena)? Is the point beyond which the models fail to perform the task (in terms of sequence length or vocabulary size) different between the two?

For LM-Eval-Harness and HELM, have you tried a baseline of taking the impulse response from Hyena/MultiHyena and truncating it to a finite impulse response? A sliding window seems like one of the simplest approximations to try in the world of convolutions, and it would be helpful to know if maybe some defect of the tasks or the base model results in nothing more being required. This would, in fact, be a useful baseline to have in the paper. The paper could be improved with a little bit of additional discussion regarding limitations of the distillation/approximation.",555,0,0,0.7892,0.0370982143,0.8943858147,215,29.2188,0.1199,neurips,0.0119047619047618,4,4,4,4,factual,4,3,79,polite,4,positive,4,low,4,4,5,5,factual,5,5,88,polite,5,neutral,5,low,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,4,4,factual,4,4,85,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
82,Reviewer-2f9g,First Order Stochastic Optimization with Oblivious Noise,"We initiate the study of stochastic optimization with oblivious noise, broadly generalizing the standard heavy-tailed noise setup.
In our setting, in addition to random observation noise, the stochastic gradient 
may be subject to independent \emph{oblivious noise}, 
which may not have bounded moments and is not necessarily centered. 
Specifically, we assume access to a noisy oracle for the stochastic gradient of $f$ 
at $x$,  which returns a vector $\nabla f(\gamma, x) + \xi$, where $\gamma$ is 
the  bounded variance observation noise 
and $\xi$ is the oblivious noise that is independent of $\gamma$ and $x$. 
The only assumption we make on the oblivious noise $\xi$ 
is that $\Pr[\xi = 0] \ge \alpha$, for some $\alpha \in (0, 1)$.
In this setting, it is not information-theoretically possible to recover a single solution 
close to the target when the fraction of inliers $\alpha$ is less than $1/2$. 
Our main result is an efficient {\em list-decodable} learner that recovers 
a small list of candidates at least one of which is close to the true solution. 
On the other hand, if $\alpha = 1-\epsilon$, where $0< \epsilon < 1/2$ is sufficiently small
constant, the algorithm recovers a single solution.

Along the way, we develop a rejection-sampling-based algorithm to perform noisy location estimation, 
which may be of independent interest.","This paper initiates the study of stochastic optimization with oblivious noise that might be biased and have unbounded variance, which is a generalization of the heavy-tailed noise setup. The key assumption regarding the oblivious noise is that it assumes a value of $0$ with a probability within the range of $0 \leq \alpha \leq 1$, which can be interpreted as the fraction of inliers. Notably, when $\alpha \leq 1/2$, it is proven to be information-theoretically impossible to find an approximate stationary point of the function. To address this challenge, the authors incorporate the concept of list-decoding into the framework of stochastic optimization, and focus instead on identifying a list of points where at least one of them is an approximate stationary point.

Technically, this paper presents an equivalence between list-decodable stochastic optimization with oblivious noise and list-decodable mean estimation problem leveraging a technique known as noisy location estimation. The analysis of list-decodable stochastic optimization with oblivious noise is conducted by examining the list-decodable mean estimation problem. This paper investigates an important setting of stochastic optimization introduces a fresh perspective by introducing the concept of list-decodable stochastic optimization. The definition of this new framework is not only intuitive and well-motivated by practical problems but also exhibits elegance from a theoretical standpoint, given how weak the assumptions on the noise model are. The algorithms presented in the paper, along with their corresponding proofs, are intricate and highly nontrivial from a technical standpoint. Nevertheless, the authors have succeeded in presenting the analyses in a well-organized manner, ensuring that they are generally not hard to follow. 1. As pointed out in the paper, an exponential dependence on $1/\eta$ is necessary in the list-size, which can mildly impact the overall appeal of the results. This dependency may introduce some considerations regarding scalability and practicality.

2. The framework presented in this paper is inherently abstract, and there is a lack of clarity concerning the algorithm's performance in concrete examples, including scenarios with more specific theoretical settings that incorporate additional assumptions, as well as practical problem domains. Correspondingly, I have the following questions that could possibly make the results even stronger if addressed:
1. Can the exponential dependence on $\eta$ be mitigated by making slight adjustments to the original definition of list-decodable stochastic optimization? For instance, are there additional assumptions that can be incorporated or specific parameter regimes that can be adjusted to reduce this exponential dependency?

2. Are there more concrete applications of list-decodable stochastic optimization methods? 

3. Minor comment: I saw the term ""convex"" in the caption of Algorithm 2. I assume this is a typo and convexity is not needed in the proof, right? Not relevant in my opinion.",445,0,4,0.7856000000000001,0.0264697571,0.920696795,215,16.5721,0.2025,neurips,0.034090909090909,4,5,4,4,factual,4,4,90,polite,4,neutral,4,low,4,5,4,4,partially factual,4,4,85,polite,5,positive,5,moderate,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,4,4,factual,4,4,85,polite,5,positive,5,low,3,4,4,4,factual,4,4,85,polite,5,neutral,5,low
3,Jouni-Tuominen,A Shape Expression approach for assessing the quality of Linked Open Data in Libraries,"Cultural heritage institutions are exploring Semantic Web technologies to publish and enrich their catalogues. Several initiatives, such as Labs, are based on the creative and innovative reuse of the materials published by cultural heritage institutions. In this way, quality has become a crucial aspect to identify and reuse a dataset for research. In this article, we propose a methodology to create Shape Expressions definitions in order to validate LOD datasets published by libraries. The methodology was then applied to four use cases based on datasets published by relevant institutions. It intends to encourage institutions to use ShEx to validate LOD datasets as well as to promote the reuse of LOD, made openly available by libraries.\n","This manuscript was submitted as 'full paper' and should be reviewed along the usual dimensions for research contributions which include (1) originality, (2) significance of the results, and (3) quality of writing. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information. The authors present a compact, focused experiment on applying ShEx validation to libraries' datasets to foster data re-use, with four exemplifying use cases on datasets provided by three individual libraries (and one non-library data). The presented methodology is quite straightforward application of ShEx. From purely technological perspective, the originality and significance of the contribution is not particularly high, but especially for researchers and practitioners working with (linked) data in GLAM institutions the paper would be relevant. Compared to the previous version of the paper: the authors have made improvements on the paper, extending it sufficiently on sections that needed further discussion. The comments I made in my previous review have been addressed sufficiently. The quality of the writing is good. The data file provided by the authors under “Long-term stable URL for resources” (A) is well organized and contains a README file, (B) appears to be complete for replication of experiments (based on the README file, file listing, and looking at couple of individual data files), (C) is stored on Zenodo, and (4) appears to provide complete data artifacts (based on the README file, file listing, and looking at couple of individual data files). I have one comment: - Page 14 ""Regarding the NLF dataset, a common problem is related with the property rdf:langString used for language-tagged string values that are validated against xsd:string"" - In such cases, why did you constrain the property value's datatype to ""xsd:string"" - instead of ""LITERAL"" (https://shex.io/shex-semantics/index.html#shexc) in the ShEx definition? For example, concerning NLF dataset's class Person, you have constrained the property schema:name's value to xsd:string (https://github.com/hibernator11/ShEx-DLs/blob/1.1/nlf/nlf-person.shex#L12). In the NLF data model the range of schema:name is defined as ""Literal"" (https://www.kiwi.fi/display/Datacatalog/Fennica+RDF+data+model), and in the schema.org vocabulary the range of schema:name is defined loosely: ""schema:name schema:rangeIncludes schema:Text"" (https://schema.org/version/latest/schemaorg-current-https.ttl). I would suggest loosening the constraint. Minor remarks: - Page 14: ""Table 6 provides an overview of the data quality evaluation. All the assessed repositories obtained a high score, notably the BNB and the BnF."" - Based on Table 6, NLF obtained as high score (mconRelat) as BnF. Mention NLF as well? - Page 14: ""Regarding the NLF dataset, a common problem is related with the property rdf:langString used for language-tagged string values that are validated against xsd:string"" - rdf:langString is not a property, but a datatype.",514,4,0,0.7396,0.0922263521,0.8461868763,31,32.22,0.3825,semanticweb,0.0319148936170212,3,4,3,3,factual,3,4,60,polite,4,positive,4,moderate,4,5,4,4,factual,4,4,85,polite,5,positive,5,low,3.0,4.0,4.0,4.0,factual,4.0,5.0,80.0,polite,4.0,neutral,3.0,none,4,5,5,4,factual,5,5,90,polite,5,positive,5,none,3,4,4,4,factual,4,4,85,polite,5,neutral,5,low
11,Neng-Fisheri-Kurniati,"Anti-inflammatory activity and toxicity evaluation of 1,3-bis(p-hydroxyphenyl)urea","Background: Inflammation is a normal protective response caused by an injury or tissue damage, through physical trauma, damaging chemicals, or invasion of pathogenic microorganisms. One of the modified p-aminophenol compounds is 1,3-bis(p-hydroxyphenyl)urea, which was estimated to have more potent analgesic activity and fewer hepatotoxic side effects than paracetamol. When the lipophilicity of this compound increases between 1.8 to 4.4, it is observed to serve as an anti-inflammatory agent. Therefore, the determination of safety precaution is very necessary while testing for the toxicity effect of 1,3-bis(p-hydroxyphenyl)urea. This is due to the effectiveness and safety of suitable drugs. Methods: An anti-inflammatory test was carried out by measuring the percentage of inflammation in rats, after the administration of 1,3-bis(p-hydroxyphenyl)urea was previously induced by the carrageenan solution intraplantar and the analysis of neutrophil values through a plethysmometer and Hematoxylin-Eosin method. Also, an acute toxicity test was performed by administering this p-aminophenol compound to female rats for 24 h and observed for 14 days. In addition, a subchronic toxicity test was conducted on male and female rats for 28 days, with continuous observations carried out for 42 days. Results: The doses of 1,3-bis(p-hydroxyphenyl)urea at 50, 100, and 200 mg/Kg BW, had anti-inflammatory activity compared to diclofenac sodium at 2.25 mg/Kg BW. Also, there is no toxicity and animal death symptoms were observed in the acute and subchronic tests. Conclusion: This 1,3-bis(p-hydroxyphenyl)urea compound had an anti-inflammatory activity and relatively low toxicity.","Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This article showed that 1,3-bis(p-hydroxyphenyl)urea had anti-inflammatory activity and safe to be used. However the results section in the abstract did not clearly show the efficacy and safety of the compound. Please provide the efficacy with number, percentage or else. Significance calculation should be shown in Figure 1 and 3 to make it easier for the reader to read the results. Legend of the figure and table should give more information, for example, the number of animals, magnification, etc. In Materials and Methods, many information have not been provided, such as the number of animal use for toxicity study, histology procedure, etc.  Please write a good introduction to the study. The first sentence of the paragraph should inform the primary information. Two or three next sentences should provide details information. Avoid repeated information. Furthermore, for the discussion section, please provide a more comprehensive discussion, such as comparing the data with the working hypotheses. Limitation of the study and future study should be mentioned as well.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? No",317,0,2,0.7553000000000001,0.2233870968,0.8138936162,85,30.77,0.378,f1000,0.0116279069767442,5,4,3,5,factual,5,5,88,polite,5,negative,4,none,5,4,4,5,partially factual,5,5,85,polite,5,neutral,5,low,1.0,4.0,4.0,2.0,partially factual,2.0,2.0,60.0,polite,3.0,neutral,3.0,low,5,4,4,5,factual,4,4,85,polite,5,neutral,4,low,4,4,4,4,partially factual,4,3,85,polite,5,neutral,4,low
150,Reviewer-gFqX,ROBUST DIFFUSION GAN USING SEMI-UNBALANCED OPTIMAL TRANSPORT,"Diffusion models, a type of generative model, have demonstrated great potential for synthesizing highly detailed images. By integrating with GAN, advanced diffusion models like DDGAN \citep{xiao2022DDGAN} could approach real-time performance for expansive practical applications. While DDGAN has effectively addressed the challenges of generative modeling, namely producing high-quality samples, covering different data modes, and achieving faster sampling, it remains susceptible to performance drops caused by datasets that are corrupted with outlier samples. This work introduces a robust training technique based on semi-unbalanced optimal transport to mitigate the impact of outliers effectively. Through comprehensive evaluations, we demonstrate that our robust diffusion GAN (RDGAN) outperforms vanilla DDGAN in terms of the aforementioned generative modeling criteria, i.e., image quality, mode coverage of distribution, and inference speed, and exhibits improved robustness when dealing with both clean and corrupted datasets.","This article introduces a robust training technique based on semi-unbalanced optimal transport to mitigate the impact of outliers effectively.
Meanwhile DDGAN remains susceptible to performance drops caused by datasets that are corrupted with outlier samples.  
Through comprehensive evaluations, the RDGAN demonstrate that it outperforms vanilla DDGAN in terms of the aforementioned
generative modeling criteria, i.e., image quality, mode coverage of distribution, and inference speed, and exhibits improved robustness when dealing with both clean and corrupted datasets. Given the recent advancements in generative models such as Dalle2, stable diffusion, or diffusion GANs,  has effectively
addressed the challenges of generative modeling, namely producing high-quality
samples, covering different data modes. But it remains susceptible to performance drops caused by datasets that are corrupted
with outlier samples.
This article introduces a novel approach by employing a semi-unbalanced optimal transport to mitigate the impact of outliers effectively. The approach employed in the paper may appear to lack novelty. This is because the RDGAN simply replaces the loss function of diffusion GANs with a semi-unbalanced optimal transport, without conducting a thorough analysis of the relationship between the semi-unbalanced optimal transport and diffusion GANs from both empirical and theoretical perspectives. 1. I would suggest that the author conducting a thorough analysis of the relationship between the semi-unbalanced optimal transport and diffusion GANs from both empirical and theoretical perspectives in the corrupted with outlier samples.

2. In Tables 1 and 2, RDGAN still does not achieve the best results when compared to other methods.

3. I recommend that the author present a comparison of results for different diffusion step values (T) in DRGAN, DDGAN, and the ablation study.

4. I recommend that the author provide a explanation of why the semi-dual UOT objective
ensuring that the fast sampling time of DDGAN is preserved in RDGAN?

5. ""In contrast, DDGAN’s
FID increases by more than 10 points, and the synthesized outlier ratio of RDGAN rises from 0.2
to 3.8 compared to DDGAN’s increase from 3.2 to 9.8.""
Does this mean that DDGAN is more likely to synthesize more samples in outlier data compared to RDGAN? Is this considered a desirable capability, or is it potentially problematic?

6. Can you present the outcomes achieved when training StyGAN2+Aug (Karras et al., 2020a) on mixed datasets, and include them in Table 4? Since stylegan2+AUG appears to generate a greater diversity of samples in Table 2, it would be valuable to assess its performance on mixed datasets as well.",406,0,6,0.7849,0.1768678161,0.9198342562,48,34.115,0.2174,iclr,0.0,4,4,4,4,factual,4,4,80,polite,4,neutral,4,none,4,3,4,4,partially factual,4,4,75,polite,5,neutral,5,moderate,3.0,4.0,4.0,4.0,partially factual,4.0,4.0,80.0,polite,5.0,neutral,3.0,low,4,3,4,4,partially factual,3,3,70,polite,4,neutral,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
117,Reviewer-qiBS,Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts,"Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.","This paper presents a new model-based method for offline reinforcement learning. The key technical contributions of the proposed model include: 1) It learns the bidirectional rollouts of the state transitions and the reward functions; 2) It learns forward and backward offline policies, following the BCQ method. With the learned bidirectional dynamics model and the corresponding policies, given a pivotal data point drawn from the offline dataset, the replay buffer can be augmented with the generated data trajectories. 

Additionally, the paper provides a theoretical analysis, establishing a tighter bound on the rollout error for the conservative bidirectional rollouts compared to unidirectional approaches. 

Finally, the empirical findings on the D4RL benchmark demonstrate the effectiveness of the proposed method. 1. The proposed method is simple, reasonable, and effective on the existing D4RL benchmark, showing great potential for practical offline RL applications. 
2. The paper is well-written and easy to follow. The overall design of the proposed method is presented in a clear and thoroughly motivated manner. 
3. The method seems to be a highly versatile framework. As shown in the paper, it can be easily integrated with existing model-free offline RL approaches. 1. My primary concern with this paper is about the novelty of the proposed bidirectional rollout technique. At NeurIPS 2022, a paper titled ""Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination"" by Lyu et al. introduces a conceptually similar idea. In both papers, forward and backward models are trained to augment the offline dataset. It is crucial for the authors to address this similarity and provide a comprehensive comparison between COBiMO and the method presented by Lyu et al., considering aspects such as model design and empirical results.
2. In the experiment section, the authors present averaged results of 6 random seeds. To enhance the statistical robustness of their findings, it would be better to include the standard deviations over multiple runs in Tables 1-3. 
3. The paper primarily compares COBiMO with approaches that were proposed 2-3 years ago. It would be beneficial for the authors to extend their comparisons to include more recent advances in offline RL to provide a comprehensive evaluation of COBiMO's performance in the context of the most current state of the field.
4. In Section 5.3, there is an absence of an explanation regarding the factors that lead to performance degradation in certain tasks when COBiMO is applied (which can be reasonable but needs more analysis). Besides, as claimed in Section 5.3, the proposed method outperforms the original algorithms significantly in 10/12 tasks. However, it's essential to ensure that all relevant results supporting this claim are presented, as only a partial subset of the results is currently shown in Table 3.
5. Typos:
- In the first paragraph of Section 5.1, ""...from three domain"" should be corrected to ""...from three domains"".
- In the third paragraph of page 4, ""...represents a gaussian distribution..."" should be ""...represents a Gaussian distribution..."". In summary, my primary concerns include the technical novelty in comparison to the missing reference (major), and some finer details of the provided experimental results (minor).",513,0,8,0.7682,0.1505058522,0.9512968659,53,35.9958,0.3011,iclr,0.0,4,4,4,4,factual,4,4,85,polite,4,neutral,4,low,5,5,5,5,factual,5,5,88,polite,5,neutral,5,low,2.0,4.0,4.0,4.0,factual,3.0,4.0,80.0,polite,5.0,neutral,5.0,none,4,5,4,4,factual,4,4,85,polite,5,positive,4,low,3,4,4,4,factual,4,4,85,polite,5,neutral,5,low
117,Reviewer-7BFv,Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts,"Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.","This paper studies the model-based offline reinforcement learning problem. The authors propose to learn bidirectional model and bidirectional behavioral policies and use them to generate rollout trajectories. The output policy is obtained by a model-free offline reinforcement learning on the augmented dataset. The paper provides theory and empirical study to justify the proposed algorithm. 1. The paper is clearly written and easy to follow. 1. The Related Work misses important paper. For instance, this paper is not the first to use bidirectional model in offline learning. Confidence-aware Bidirectional Offline Model-based Imagination is the first to apply this idea to the best of my knowledge.
2. I cannot recognize the algorithmic novelty of the algorithm. Forward imagination is widely used in model-based offline learning and Reverse Imagination was first proposed in ROMI. This paper seems to just combine these two ideas directly without justifying why it can substantially improve the performance
3. The theory seems to be trivial.
4. The experiment misses important baselines, such as ROMI and Confidence-aware Bidirectional Offline Model-based Imagination which share similar ideas. Besides, the performance does not seem compelling if one also look at the performance in ROMI and Confidence-aware Bidirectional Offline Model-based Imagination paper. 1. What is the main intuition behind using bidirectional imagination? Why should we expect it provide substantial improvement?
2. What does the theory part tell us, is there any interesting insight?
3. How does the algorithm perform compared to other later model-based algorithms? How does the algorithm perform on other tasks in D4RL?",252,0,7,0.7828,0.1666666667,0.9260005355,53,30.2158,0.1199,iclr,0.0,0,4,3,0,unfactual,4,2,67,polite,2,negative,4,moderate,4,5,4,4,partially factual,4,3,75,neutral,5,negative,5,moderate,1.0,3.0,4.0,2.0,partially factual,2.0,2.0,60.0,polite,4.0,neutral,3.0,low,2,4,3,2,partially factual,3,3,60,neutral,4,negative,4,low,2,4,3,3,partially factual,3,3,60,neutral,4,negative,4,low
76,Ghislain-Hachey,Facilitating Data Discovery by Connecting Related Resources ,"In this study, we investigate two approaches to increase the discoverability and connectivity of resources on the web. The first approach is the use of semantic web data structures in RDF/XML, in particular the Open Archives Initiative Object Reuse and Exchange (OAI-ORE) vocabulary for creating compound digital objects. The second approach is the use of Schema.org vocabularies for marking up html web pages to increase their visibility to web search engines. Through applying these two mark-up approaches to three case studies within the geosciences, we identify factors that help to evaluate their applicability to research data archives. Our analysis points toward the most efficient and effective markup for aggregating resources within research data archiving settings. We focus on factors that can lead to increasing public discoverability of datasets. Our evaluations are based on the following characteristics of each mark-up approach: ease of use, the available standards and vocabularies, the ease of interoperability, and the relation to data citation tools and methods.","This paper investigates two different approaches to increase discoverability and connectivity of resources on the web: the Open Archives Initiative Object Reuse and Exchange vocabulary (OAI-ORE) which is based on RDF/XML and the use of Schema.org vocabularies for marking up HTML pages in a search engine friendly way. Although there as been a lot of work on automatic discovery and connectivity of web resources, not a lot of quality work has been done to rigorously evaluate the alternatives so I think this work is important and original as far as I know. That being said, I have several problems with the research as it is now. The results feel more like anecdotal evidence than rigorous scientific analysis. The paper started with a rather interesting (and essential) idea which was to investigate discoverability and connectivity of resources on the Web. For such a study I would expect a carefully crafted questionaire or at least a clear list of criteria to look for and to grade the three studied scientific projects with regards to the investigated approaches in a systematic manner. I understand this paper's purpose is not to conduct of survey, but it seems the main purpose is to ""investigate"" and as such I think maybe some elements of good evaluation papers such as [1,2,3] might provide insight into how to improve this research. The discussion section sort of integrates criteria for an evaluation, but too informally. The criteria should be presented early in the scientific method used. After which experiment can be conducted based on the criteria and *then* discuss results. I do find the discussions to be an interesting read but as they are now they can not be considered as scientific evidence. It is false to claim that Semantic web-enabled vocabularies are ""innumerable""; there is in fact a relatively small (but growing) set of them mainly in scientific communities. A simple wording re-adjustment would be better I think. The method of investigation would need to be more clearly explained too. The paper moves from giving some background information (which I really like as some of this was new to me) to providing results. There is a clear gap in outlining the Methodology used. It should be explicit (and repeatable) how results are to be compiled and right now I would find it hard to reproduce this evaluation/investigation. The style of writing is formal and appropriate, but there are several grammatical errors and typos that could have been easily avoided. Here's some examples: - p.6 filesfor missing space. - p.6 wasmanually missing space. - p.7 of of remove an 'of'. - p.8 reearch missing 's'. - p.9 regulariety ?!? Finally, this seems to be outside the scope of the SWI SWJ Special issue. I would encourage the authors to continue this important work though and maybe go through a conference first (if not done so already). However, I do not think it is ready for journal publication of original work. To summarise, the paper provides clear introductory text even for those new to the concepts discussed, but does not contain the required overall balance: almost half the paper is on background information and much missing in terms of methodology, results and discussions. The paper reads very well and I would definitely enjoy reading another more structured and rigorous version of it. It think the suject explored is critical, but the community would benefit from a more scientifically sound evaluation. [1] T. Dyba and T. Dingsøyr. Empirical studies of agile software development: A systematic review. Inf. Softw. Technol., 50:833–859, August 2008. [2] T. Dyba and T. Dingsøyr. Strength of evidence in systematic reviews in software engineering. In Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement, ESEM ’08, pages 178–187, New York, NY, USA, 2008. ACM. [3] T. Dyba, T. Dingsøyr, and G. Hanssen. Applying systematic reviews to diverse study types: An experience report. In Empirical Software Engineering and Measurement, 2007. ESEM 2007. First International Symposium on, pages 225–234, sept. 2007.",665,4,9,0.803,0.1443889444,0.8987319469,33,46.27,0.0376,semanticweb,0.0104166666666666,4,3,4,4,factual,4,3,80,neutral,4,negative,4,low,4,3,4,4,partially factual,4,4,65,polite,5,neutral,5,low,1.0,4.0,3.0,2.0,partially factual,3.0,2.0,60.0,polite,4.0,neutral,4.0,low,4,3,4,4,partially factual,3,3,70,polite,5,negative,4,low,4,3,3,4,partially factual,3,3,70,polite,4,neutral,4,low
36,S.G.-Lukosch,Collaborative multilingual knowledge management based on controlled natural language,"User interfaces are a critical aspect of semantic knowledge representation systems, as users have to understand and\nuse a formal representation language to model a particular domain of interest, which is known to be a difficult task. Things\nare even more challenging in a multilingual setting, where users speaking different languages have to create a multilingual\nontology. To address these problems, we introduce a semantic wiki system that is based on controlled natural language to\nprovide an intuitive yet formal interface. We use a well-defined subset of Attempto Controlled English (ACE) implemented\nin Grammatical Framework. Our wiki system offers precise bidirectional automatic translations between ACE and language\nfragments of a number of other natural languages, making the wiki content accessible multilingually. Because ACE has a partial\nbut deterministic mapping to the Web Ontology Language, our wiki engine can offer automatic reasoning and question answering\nover the wiki content. Users speaking different languages can therefore build, query, and view the same knowledge base in\nan intuitive and user-friendly interface based on the respective natural language. We present the results of a user evaluation\nwhere participants using different languages were asked to write and assess statements about European geography in our wiki\nenvironment. Our results show that users reach a high level of consensus, which is not negatively affected by the presence of\nautomatic translation.","The article introduces a semantic wiki system that supports collaborative multilingual knowledge management based on controlled natural language. The authors used a subset of Attempto Controlled English (ACE) implemented in Grammatical Framework (GF) to support bidirectional automatic translations between ACE and language fragments of a number of other natural languages in their semantic wiki. With this approach users speaking different languages can collaboratively build and manage a knowledge base.  The semantic wiki system was evaluated in a study with 30 participants speaking 3 different languages. For each language, there were 10 participants. In the study users had two tasks: users had to create articles in their native language or in a language they were fluent in as well as to read automatically translated articles to evaluate the truth or falsehood of the translation. The evaluation shows that users reach a high level of consensus. The evaluation also shows that the automatic translation does not have a negative effect.  In total, the article is well written and related to the state of the art. The authors clearly identify their contribution to the state of the art, i.e. making a semantic wiki environment multilingual, and evaluate whether their contribution addresses the identified problems around creating a multilingual ontology in a semantic wiki system. Conclusions are thus validated and future work is well based on the given findings. Concluding, I recommend to accept the article.",232,0,0,0.719,-0.0588461538,0.9578637481,18,28.03,0.0588,semanticweb,0.0,1,3,3,1,partially factual,2,3,30,neutral,3,positive,1,low,2,5,5,3,factual,5,5,85,polite,5,positive,5,none,3.0,4.0,4.0,4.0,factual,4.0,5.0,80.0,polite,4.0,positive,3.0,none,2,5,4,2,factual,4,4,75,polite,5,positive,4,low,3,4,4,3,factual,4,4,85,polite,5,positive,3,low
36,Prateek-Jain,Collaborative multilingual knowledge management based on controlled natural language,"User interfaces are a critical aspect of semantic knowledge representation systems, as users have to understand and\nuse a formal representation language to model a particular domain of interest, which is known to be a difficult task. Things\nare even more challenging in a multilingual setting, where users speaking different languages have to create a multilingual\nontology. To address these problems, we introduce a semantic wiki system that is based on controlled natural language to\nprovide an intuitive yet formal interface. We use a well-defined subset of Attempto Controlled English (ACE) implemented\nin Grammatical Framework. Our wiki system offers precise bidirectional automatic translations between ACE and language\nfragments of a number of other natural languages, making the wiki content accessible multilingually. Because ACE has a partial\nbut deterministic mapping to the Web Ontology Language, our wiki engine can offer automatic reasoning and question answering\nover the wiki content. Users speaking different languages can therefore build, query, and view the same knowledge base in\nan intuitive and user-friendly interface based on the respective natural language. We present the results of a user evaluation\nwhere participants using different languages were asked to write and assess statements about European geography in our wiki\nenvironment. Our results show that users reach a high level of consensus, which is not negatively affected by the presence of\nautomatic translation.","The work 'Collaborative multilingual knowledge management based on controlled natural language' presents a description, architecture and implementation details of a Controlled Natural Language based knowledge engineering in a semantic media wiki based environment. This system allows a Semantic Media Wiki to become multi lingual editing environment. The underlying technology relies on using ACE based controlled vocabulary. The authors have presented a comprehensive evaluation and a portal to download and play with the system.  I like the work as it (a) demonstrates capabilities which can be achieved just by using controlled language (b) Shows an actual system which can be used in multiple and real world settings.  Some minor remarks: The last years have shown great progress on the technical side towards the realization of what is called the Semantic Web -> The last few years ? Already in 2007 -> In 2007 proper names -> proper nouns",147,0,0,0.8194,0.0730769231,0.9267749786,295,33.85,0.2086,semanticweb,0.0,2,2,1,2,partially factual,1,2,20,neutral,3,positive,1,low,2,4,4,3,partially factual,3,4,75,polite,5,positive,5,low,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,3.0,none,2,4,3,2,factual,4,3,60,polite,4,positive,4,low,2,4,3,3,factual,3,3,75,polite,4,positive,4,low
42,Reviewer-7mQ7,Convergence of Actor-Critic with Multi-Layer Neural Networks,"The early theory of actor-critic methods considered convergence using linear function approximators for the policy and value functions. Recent work has established convergence using neural network approximators with a single hidden layer. In this work we are taking the natural next step and establish convergence using deep neural networks with an arbitrary number of hidden layers, thus closing a gap between theory and practice. We show that actor-critic updates projected on a ball around the initial condition will converge to a neighborhood where the average of the squared gradients is $\tilde{O} \left( 1/\sqrt{m} \right) + O \left( \epsilon \right)$, with $m$ being the width of the neural network and $\epsilon$ the approximation quality of the best critic neural network over the projected set.","The authors prove a bound on the approximation error of sample-based actor critic learning on a more general and realistic setting, namely allowing for a NN approximator of any depth. This is a very non-trivial result and an interesting contribution to the literature.

Note: I have not gone through the full proof in the appendix and thus cannot fully comment on the validity of the main contributions. The paper is very well written and the ideas are clearly communicated. I especially appreciate the tables and figures to aid in explaining the approach and how it fits into the literature.

The main theorem is a very interesting theoretical result. There are a few parts of the paper where the presentation could be improved a bit, but for the most part I thought the paper was very clearly written. Your final bound does not appear to be affected by the depth of the NN approximator, but clearly depth does improve approximation error. Does a tighter bound exist that takes into account depth or would depth mostly be captured in the \epsilon error term?

On line 135, you refer to \sigma_w, but I don't see that variable defined. What is that referring to?

In Assumption 2.6, what is the gradient of w with respect to?

Small notes:
I would recommend having all equation statements be numbered so it's easier for readers to refer to them.

I find the notation on the equation in line 161 a bit confusing, namely that Q refers to both a function that takes in weights and outputs a Q-function and the Q-function itself.

 I don't think there are significant potential negative societal impacts of this work.",278,0,0,0.7733,0.1502083333,0.8888005614000001,215,54.6915,0.8064,neurips,0.0,2,4,2,2,factual,3,3,65,neutral,3,positive,2,low,5,5,4,5,partially factual,5,5,95,polite,5,positive,5,moderate,3.0,5.0,4.0,4.0,factual,5.0,4.0,80.0,polite,5.0,positive,5.0,none,4,5,4,4,factual,5,4,85,polite,5,positive,5,low,3,4,4,4,partially factual,4,4,85,polite,5,positive,5,low
78,Marta-Talavera,Factors influencing the decision to commit violence in Thai male juvenile offenders: A phenomenological study,"Background: Violence is a social problem that affects the physical and mental health of adolescents. For a long time, Thailand has adopted strategies formulated by the World Health Organization to reduce violence but has been unsuccessful. The aim of the current qualitative study was to understand the decision of adolescents to commit violence and to identify factors contributing to violence among male juvenile delinquents. Methods: Data were collected from 50 male juvenile offenders at the Department of Juvenile Observation and Protection detention facilities located in 5 regions of Thailand through in-depth interviews focusing on delinquent violence committed in the past year. Results: Adolescents who decide to use violence have been associated with and live in environments where they face conflicts in their neighborhood and violence in their community. Mostly, juveniles were found to drop out of school, engage in abuse and supply of drugs, consume alcohol, and experienced domestic violence problems and family divorce. Juvenile offenders typically experience and learn about violence from family and peers, which creates a positive attitude toward violent behavior in them. These offenses can be categorized into intentional violence, which involves seeking revenge or resolving prior conflicts and requires premeditation, and unintentional violence, which results from a situation escalating quickly and usually requiring no preplanning, such as insults, conflicts, power struggles, self-defense, or protecting peers. Conclusions: A violence prevention model and guidelines need to be introduced into Thailand’s youth health care system. This study identified a lack of both decision-making skills and socially adequate adjustment to difficult situations among adolescent perpetrators as precursors to violent behavior.","Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The theme is interesting and relevant, but the sample size is too small to be able to generalize results.  Also, it would be necessary to provide a better social and economic contexualization. The bibliography needs to be updated with more recent references. The methodological description is not clear. The exhibition is not detailed as well as the subsequent analysis, so the results do not have sufficient foundation for the statistics.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",215,0,1,0.7398,0.1799479167,0.6117376089000001,118,27.93,0.0999,f1000,0.0099009900990099,1,3,2,1,unfactual,2,1,30,neutral,2,negative,2,high,4,4,4,4,partially factual,4,4,75,polite,5,neutral,4,low,2.0,4.0,4.0,3.0,factual,4.0,4.0,70.0,polite,4.0,neutral,3.0,low,3,3,3,3,partially factual,3,3,60,neutral,4,neutral,2,moderate,2,3,3,3,partially factual,3,3,60,polite,4,neutral,2,moderate
199,James-W.-MacDonald,iSEE: Interactive SummarizedExperiment Explorer,"Data exploration is critical to the comprehension of large biological data sets generated by high-throughput assays such as sequencing. However, most existing tools for interactive visualisation are limited to specific assays or analyses. Here, we present the iSEE (Interactive SummarizedExperiment Explorer) software package, which provides a general visual interface for exploring data in a SummarizedExperiment object. iSEE is directly compatible with many existing R/Bioconductor packages for analysing high-throughput biological data, and provides useful features such as simultaneous examination of (meta)data and analysis results, dynamic linking between plots and code tracking for reproducibility. We demonstrate the utility and flexibility of iSEE by applying it to explore a range of real transcriptomics and proteomics data sets.","Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The iSEE package was developed to allow people to easily perform exploratory data analysis with data that are stored in a Bioconductor SummarizedExperiment object. A SummarizedExperiment container allows researchers to store one or more matrices of data, where the columns represent samples, and the rows represent either genomic positions or genomic features (genes, exons, transcription start sites, etc). In addition to the matrices of data, the SummarizedExperiment also contains two additional objects that describe the samples (the colData) and the rows (the rowData or rowRanges). iSEE allows users to interactively plot the underlying data from a SummarizedExperiment, and also choose subsets of the data based on either interactive selection of data in a plot, or by selecting samples or genomic regions based on the colData or rowData. The chosen subsets can then be linked to other plots in the Shiny Dashboard. This simplifies what could be a complex process, allowing both experienced R users a quick way to check over their data, and allowing less experienced R users the ability to do things that they otherwise might not have been able to do. All the underlying code generated while making interactive changes is saved and can be printed out later, in order to make the exploratory data analysis reproducible. This is an excellent feature, particularly for those who want to share observations with colleagues that may not be local.  The only negative for this package is that, being based on the Shiny framework, to allow a colleague to explore the data requires that the colleague either have R, iSEE, and all its dependencies installed, or that you have a server running all necessary packages that you can point the colleague to. This limits sharing with people who are not R savvy, but is a function of how Shiny works, rather than the iSEE package. This is a high quality package, and given the generalizability of the SummarizedExperiment package, is applicable to a whole range of different data types. Given the ease of use, self documenting features, and applicability to multiple data types, this package will likely become very popular for exploratory data analysis.  Is the rationale for developing the new software tool clearly explained? Yes  Is the description of the software tool technically sound? Yes  Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others? Yes  Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool? Yes  Are the conclusions about the tool and its performance adequately supported by the findings presented in the article? Yes",506,0,1,0.755,0.1682376396,0.918002069,5,26.03,0.1585,f1000,0.0,0,5,4,0,factual,3,4,80,neutral,4,positive,5,low,3,5,5,5,factual,5,5,95,polite,5,positive,5,none,4.0,5.0,5.0,4.0,factual,5.0,5.0,90.0,polite,5.0,positive,4.0,none,3,5,5,3,factual,5,5,90,polite,5,positive,5,none,3,4,4,4,factual,4,4,92,polite,5,positive,5,low
108,Reviewer-i457,Learning to Reach Goals via Diffusion,"Diffusion models are a powerful class of generative models capable of mapping random noise in high-dimensional spaces to a target manifold through iterative denoising. In this work, we present a novel perspective on goal-conditioned reinforcement learning by framing it within the context of diffusion modeling. Analogous to the diffusion process, where Gaussian noise is used to create random trajectories that walk away from the data manifold, we construct trajectories that move away from potential goal states. We then learn a goal-conditioned policy analogous to the score function. This approach, which we call Merlin, can reach predefined or novel goals from an arbitrary initial state without learning a separate value function. We consider three choices for the noise model to replace Gaussian noise in diffusion - reverse play from the buffer, reverse dynamics model, and a novel non-parametric approach. We theoretically justify our approach and validate it on offline goal-reaching tasks. Empirical results are competitive with state-of-the-art methods, which suggests this perspective on diffusion for RL is a simple, scalable, and effective direction for sequential decision-making.","This presents a method for sequential decision making with diffusion. It frames sequential decision making as the reverse process in diffusion. In this case the initial state is “noise” and the final state is the result of denoising. For a particular goal state the policy will “denoise” the initial state. An additional contribution of this work is their “trajectory stitching method”. If there are states that are nearby to one another in two different trajectories then the dataset can be augmented by concatenation of trajectory segments (making sure to relabel the goal state for the swapped trajectories). Interesting dataset augmentation technique that might improve performance on some control tasks. The trajectory stitching method is only usable if distance between two states can be defined. What if states are observed via images? Additionally what if distance between states is not indicative of their relation to one another in a sequential process. What if there are discontinuities in states?

Transition from 3.2 to 4 is abrupt. No additional information on issues with offline reinforcement learning.

GCSL seems to be a very important concept which is used as a baseline algorithm in this paper. Yet there is no description of it in related work. How is GCSL different from GCRL?

Figure 7 is referenced in the main text but appears in the appendix. is the method applicable with partially observable states e.g., images?",230,0,0,0.7707,0.1163095238,0.8710092306,47,49.2569,0.4095,iclr,0.0206185567010309,3,4,3,3,factual,3,3,80,neutral,3,negative,4,low,3,4,3,4,partially factual,4,4,72,polite,5,neutral,4,moderate,2.0,4.0,4.0,3.0,partially factual,4.0,4.0,70.0,polite,4.0,neutral,3.0,low,2,3,3,2,factual,3,3,60,neutral,4,neutral,4,moderate,3,4,3,3,partially factual,3,4,75,polite,4,neutral,4,low
52,Reviewer-eZuw,Decompose Novel into Known: Part Concept Learning For 3D Novel Class Discovery,"In this work, we address 3D novel class discovery (NCD) that discovers novel classes from an unlabeled dataset by leveraging the knowledge of disjoint known classes. The key challenge of 3D NCD is that learned features by known class recognition are heavily biased and hinder generalization to novel classes. Since geometric parts are more generalizable across different classes, we propose to decompose novel into known parts, coined DNIK, to mitigate the above problems. DNIK learns a part concept bank encoding rich part geometric patterns from known classes so that novel 3D shapes can be represented as part concept compositions to facilitate cross-category generalization. Moreover, we formulate three constraints on part concepts to ensure diverse part concepts without collapsing. A part relation encoding module (PRE) is also developed to leverage part-wise spatial relations for better recognition. We construct three 3D NCD tasks for evaluation and extensive experiments show that our method achieves significantly superior results than SOTA baselines (+11.7%, +14.1%, and +16.3% improvements on average for three tasks, respectively). Code and data will be released.","- This paper proposes a novel part-based algorithm for 3D novel class discovery (NCD). Authors propose Decompose Novel Into Known parts (DNIK) that leverages knowledge about parts of known objects to discover novel classes.
- Authors identify that the main problem with learning 3D features for object discovery is that the features are heavily biased towards the known classes. This work shows that this can be prevented by using the well known part-based modeling approach. 
- DNIK is trained to learn a part concept bank that can be used to compose different known and novel objects. Three different regularizations are proposed to prevent the collapse of this part bank.
- Extensive experiments show the deficiencies of existing 2D NCD literature and the effectiveness of DNIK to overcome these issues. - This paper builds on an age old, part-based models in visual recognition and shows impressive improvements over single holistic representations currently in use in the 2D category discovery methods. As shown in the experiments this has significant merits for identifying and grouping new classes. 
- The paper writing was smooth and was very easy to follow. An experienced engineer would be able to reproduce the work with the given details.
- Authors support all the claims made in the paper with experiments on real world datasets or on toy problems. Sec 3.1 and Fig. 4.a were particularly interesting to understand what the authors were trying to convey.
- The effectiveness of the method was shown with the impressive experimental results. - While the problem tackled by the authors is relevant and important, the setup adopted by the authors is outdated. Generalized category discovery, as done in \[1\]\[2\] is a more realistic setting and it is not clear why the current method is not suited for this setup or the authors advice against it? It is my strong suggestion to the authors to answer this question and compare with the relevant work (cited below) to justify this work among existing literature.
- The toy example in Sec. 3.1 is not fair for the following reason. In L86, the setup states that the classes in known and unknown sets share some similarities, but in the example authors choose {table, sofa, stool} as known and {chair, bench, bathtub, plant} as unknown objects. In this case, bathtub and plant do not share any commonalities with the known objects. It looks like the authors intentionally exaggerate the problem to make their point. While this is acceptable, it is not clear how much of a serious issue is the ""overfitting to the known classes"" problem. 
- Author propose to use supervised contrastive loss to learn more parts from the known shapes. The motivation and explanation doesn't justify why this would be the case. In L204 authors pool the features along the last dimension which basically is a ""shape"" feature as opposed to a ""part"" feature. It is not clear how the contrastive loss helps learn more part features when the loss is being applied on the ""shape"" features.
- Table 4 demonstrates the performance improvement for each of the proposed components but experiments to demonstrate that show that the regularizations on the part features actually operate as the authors claim is missing. What happens when diversity loss is missing? Do all the part features in the bank collapse to fewer representations? This can be quantified by cosine similarity between the part features. Similar analysis on the remaining two regularization terms is warranted.

\[1\] Sagar Vaze, Kai Han, Andrea Vedaldi, Andrew Zisserman, Generalized Category Discovery, CVPR 2022.
\[2\] Sai Saketh Rambhatla, Rama Chellappa, Abhinav Shrivastava, The pursuit of knowledge: Discovering and localizing novel categories using dual memory, ICCV 2021. - Can Fig. 5b, 5c be combined in to one plot? Two separate plots makes it hard to understand what values of K, Q are being used for each of these. 
- Legend for Fig. 6 is missing.  Authors have addressed the limitations adequately. ",656,4,2,0.7643000000000001,0.1391305916,0.9319424629,220,50.7302,0.0437,neurips,0.0,4,5,4,5,factual,4,5,95,polite,5,neutral,5,none,5,5,5,5,factual,5,5,95,polite,5,neutral,5,low,2.0,5.0,4.0,4.0,factual,3.0,4.0,80.0,polite,5.0,neutral,5.0,low,4,5,4,4,factual,4,4,85,polite,5,positive,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
52,Reviewer-dey2,Decompose Novel into Known: Part Concept Learning For 3D Novel Class Discovery,"In this work, we address 3D novel class discovery (NCD) that discovers novel classes from an unlabeled dataset by leveraging the knowledge of disjoint known classes. The key challenge of 3D NCD is that learned features by known class recognition are heavily biased and hinder generalization to novel classes. Since geometric parts are more generalizable across different classes, we propose to decompose novel into known parts, coined DNIK, to mitigate the above problems. DNIK learns a part concept bank encoding rich part geometric patterns from known classes so that novel 3D shapes can be represented as part concept compositions to facilitate cross-category generalization. Moreover, we formulate three constraints on part concepts to ensure diverse part concepts without collapsing. A part relation encoding module (PRE) is also developed to leverage part-wise spatial relations for better recognition. We construct three 3D NCD tasks for evaluation and extensive experiments show that our method achieves significantly superior results than SOTA baselines (+11.7%, +14.1%, and +16.3% improvements on average for three tasks, respectively). Code and data will be released.","In this work, they address 3D novel class discovery (NCD) that discovers novel classes from an unlabeled dataset by leveraging the knowledge of disjoint known classes. The key challenge of 3D NCD is that learned features by known class recognition are heavily biased and hinder generalization to novel classes. Since geometric parts are more generalizable across different classes, the authors propose to decompose novel into known parts, coined DNIK, to mitigate the above problems.  1. The paper is well written and motivation (separate instances into repeatable parts) is pretty good. 
2. The model design is reasonable and the improvement is satisfied. 
3. The experimental analysis is sufficient.  1. This paper does not consider hierarchical part representation. 
2. why does Part Relation Encoder work for novel classes ? 
3. Does the improved representation works for some scene level tasks, such as novel class segmentation for point cloud ?  see the weakness  yes",151,0,6,0.7591,0.1863636364,0.9325822592,220,42.9518,0.0945,neurips,0.0,2,4,3,2,partially factual,3,2,65,polite,3,neutral,3,moderate,3,4,4,4,partially factual,4,4,75,polite,5,neutral,5,moderate,3.0,4.0,4.0,4.0,factual,4.0,5.0,80.0,polite,4.0,positive,4.0,none,2,3,3,2,factual,3,3,60,neutral,4,positive,4,moderate,3,4,4,4,partially factual,4,3,85,polite,5,positive,4,low
164,Reviewer-hRCv,Sample Complexity of Goal-Conditioned Hierarchical Reinforcement Learning,"Hierarchical Reinforcement Learning (HRL) algorithms can perform planning at multiple levels of abstraction. Empirical results have shown that state or temporal abstractions might significantly improve the sample efficiency of algorithms. Yet, we still do not have a complete understanding of the basis of those efficiency gains nor any theoretically grounded design rules. In this paper, we derive a lower bound on the sample complexity for the considered class of goal-conditioned HRL algorithms. The proposed lower bound empowers us to quantify the benefits of hierarchical decomposition and leads to the design of a simple Q-learning-type algorithm that leverages hierarchical decompositions. We empirically validate our theoretical findings by investigating the sample complexity of the proposed hierarchical algorithm on a spectrum of tasks (hierarchical $n$-rooms, Gymnasium's Taxi). The hierarchical $n$-rooms tasks were designed to allow us to dial their complexity over multiple orders of magnitude. Our theory and algorithmic findings provide a step towards answering the foundational question of quantifying the improvement hierarchical decomposition offers over monolithic solutions in reinforcement learning.","The paper takes an important step toward quantifying the benefits achieved due to hierarchical decomposition of an MDP by deriving lower bound on sample complexity of goal-conditioned HRL algorithms. The paper also proposes a novel hierarchical Q-learning algorithm that exploits goal-based hierarchical decomposition of an MDP into a high-level and a low-level sub-MDPs and jointly learns their policies. The authors evaluate hierarchical policies for different decompositions on original MDPs to validate when decomposition provides benefits and whether it aligns with the derived bound. 

The paper is well motivated and clearly written. The ideas of the paper to quantify benefits of hierarchical decomposition are novel. The derived theoretical guarantees on the lower bound are sound. I suggest clarifying that the derived bounds only apply to tabular setting of RL i.e. discrete state space problems in the Introduction. The theoretical findings are  backed by empirical results on maze environments of different sizes with convincing insights. The empirical evaluation would benefit from diversification of domains and tasks not restricted to navigation, and an investigation of bounds when using bad and good decompositions for the same environment.  (I) The paper provides strong theoretical guarantees on the lower bound of the number of episodes given a decomposition needed to learn an epsilon-accurate hierarchical policy, which also serves as a lower bound to learn an epsilon-accurate optimal policy. 

(II) The paper also identifies properties relating to state and temporal abstractions and the size of the high-level action space from the derived bound that can improve sample efficiency.
 (I) The assumptions regarding the scope of the derived bounds restricted to a tabular setting need to be clarified in the Introduction. 

(II) All experiments are on maze environments of different sizes. While the current analysis is convincing for navigation tasks, it will be interesting to see if the benefits of decomposition and the derived bounds align for more diverse domains and tasks that not restricted to just navigation e.g. officeworld \[2\], taxiworld \[3\] etc.

(III) It is not clear how the bounds will identify when a decomposition is bad enough and would degrade the performance compared to non-hierarchical algorithms. 

Minor errors:
(I) Line 48: proposes -> propose (I) How are the ideas of the Stationary Hierarchical Q-learning to overcome non-stationarity of the high-level policy related to the ideas in \[1\]? 

(II) Can you elaborate what it means to separate the original state space evenly between the two level of hierarchy? 

(III) Does the method apply only to dense reward functions?

(IV) Would the bounds identify when a decomposition for an environment would degrade performance of the proposed algorithm compared to Qlearning? 

References:

\[1\] Levy, A., Konidaris, G., Platt, R. and Saenko, K., 2017. Learning multi-level hierarchies with hindsight. arXiv preprint arXiv:1712.00948.

\[2\] Rodrigo Toro Icarte, Toryn Klassen, Richard Valenzano, and Sheila McIlraith. Using reward machines for high-level task specification and decomposition in reinforcement learning. In International Conference on Machine Learning, pages 2107–2116. PMLR, 2018.

\[3\] Thomas Dietterich. State abstraction in maxq hierarchical reinforcement learning. Advances in Neural Information Processing Systems, 12, 1999. (Included in the weaknesses)",508,6,5,0.7992,0.0943627451,0.8967522979,217,29.7299,0.2852,neurips,0.0114942528735632,4,4,4,4,factual,4,3,75,polite,3,neutral,4,low,5,5,5,5,factual,5,5,95,polite,5,positive,5,low,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,4,4,4,4,factual,4,4,85,polite,5,positive,5,low,3,4,4,4,factual,4,4,85,polite,5,positive,5,low
22,Reviewer-rgZH,CO2: Efficient Distributed Training with Full Communication-Computation Overlap,"The fundamental success of large language models hinges upon the efficacious implementation of large-scale distributed training techniques. Nevertheless, building a vast, high-performance cluster featuring high-speed communication interconnectivity is prohibitively costly, and accessible only to prominent entities. In this work, we aim to lower this barrier and democratize large-scale training with limited bandwidth clusters. We propose a new approach called CO2 that introduces local-updating and asynchronous communication to the distributed data-parallel training, thereby facilitating the full overlap of COmmunication with COmputation. CO2 is able to attain a high scalability even on extensive multi-node clusters constrained by very limited communication bandwidth. We further propose the staleness gap penalty and outer momentum clipping techniques together with CO2 to bolster its convergence and training stability. Besides, CO2 exhibits seamless integration with well-established ZeRO-series optimizers which mitigate memory consumption of model states with large model training. We also provide a mathematical proof of convergence, accompanied by the establishment of a stringent upper bound. Furthermore, we validate our findings through an extensive set of practical experiments encompassing a wide range of tasks in the fields of computer vision and natural language processing. These experiments serve to demonstrate the capabilities of CO2 in terms of convergence, generalization, and scalability when deployed across configurations comprising up to 128 A100 GPUs. The outcomes emphasize the outstanding capacity of CO2 to hugely improve scalability, no matter on clusters with 800Gbps RDMA or 80Gbps TCP/IP inter-node connections.","The paper proposes an approach called CO2 to improve throughput of distributed model training by overlapping computation and communication. Building on prior work that perform multiple training iterations with local updates before each global model synchronization, CO2 enables further throughput improvement by making the global synchronization asynchronous and overlapped with the next round of local updates. CO2 proposes two techniques for addressing the convergence issues of the asynchrony: (i) staleness penalty gap, and (ii) outer momentum clipping. The paper presents theoretical analyses of the convergence guarantees of these two techniques. The evaluation results show that CO2 can achieve convergence results comparable to baselines that are fully synchronous (e.g, Adam) and better than those using local updates (e.g, LocalSGD). The experimental results also show the throughput and scalability of CO2 are better than Adam. The paper is tackling an important problem since communication is a major bottleneck for scaling model sizes and training hardware, and so approaches for reducing communication overheads are very relevant to the community. 

The idea of overlapping communication with computation is reasonable given the cost-effectiveness. I also liked the fact that the paper attempts to quantify and fix the resulting staleness update problem. 

The evaluation considers a diverse and important set of workloads and hardware environments, which helps to understand the generality of CO2. I observe some critical problems in the draft that raise the question of whether CO2 can simultaneously achieve good convergence and high throughput. 

1. The convergence and throughput trade-off of inner loop step count ($\tau$) is not clearly reported in evaluation. In particular, the convergence results in Tables 1 & 2 should include the corresponding $\tau$ and throughput. I was unable to determine whether the good convergence results are achieved with $\tau$ that also provides throughput benefits. 

2. The paper is silent on the memory overheads of CO2 relative to baselines, even though Algorithm 2 suggests that multiple copies of the model is required to support asynchronous communication. 

3. Equation 3 assumes learning rate decay in the inner loop which is not true for learning rate schedules, such as cyclic, which involve learning rate increases. 

4. It is unclear to me whether CO2 can achieve expected throughput benefits in scenarios with parallelism techniques (e.g., tensor slicing, sequence parallelism, and zero stage 3) that introduce communication to forward/backward passes. It seems these (synchronous) communication operations would interfere with the overlapped communication and hurt overall throughput. Evaluating such scenarios could help to better understand the generality of CO2. See weaknesses.",415,0,5,0.7924,0.0957478632,0.8365457058,63,26.0033,0.2025,iclr,0.0,4,4,4,3,factual,3,4,80,polite,4,neutral,4,none,4,5,4,4,factual,4,5,85,polite,5,neutral,5,low,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,4,4,4,4,factual,4,4,85,polite,5,positive,5,low,3,4,4,4,factual,4,4,85,polite,5,neutral,5,low
22,Reviewer-8oQm,CO2: Efficient Distributed Training with Full Communication-Computation Overlap,"The fundamental success of large language models hinges upon the efficacious implementation of large-scale distributed training techniques. Nevertheless, building a vast, high-performance cluster featuring high-speed communication interconnectivity is prohibitively costly, and accessible only to prominent entities. In this work, we aim to lower this barrier and democratize large-scale training with limited bandwidth clusters. We propose a new approach called CO2 that introduces local-updating and asynchronous communication to the distributed data-parallel training, thereby facilitating the full overlap of COmmunication with COmputation. CO2 is able to attain a high scalability even on extensive multi-node clusters constrained by very limited communication bandwidth. We further propose the staleness gap penalty and outer momentum clipping techniques together with CO2 to bolster its convergence and training stability. Besides, CO2 exhibits seamless integration with well-established ZeRO-series optimizers which mitigate memory consumption of model states with large model training. We also provide a mathematical proof of convergence, accompanied by the establishment of a stringent upper bound. Furthermore, we validate our findings through an extensive set of practical experiments encompassing a wide range of tasks in the fields of computer vision and natural language processing. These experiments serve to demonstrate the capabilities of CO2 in terms of convergence, generalization, and scalability when deployed across configurations comprising up to 128 A100 GPUs. The outcomes emphasize the outstanding capacity of CO2 to hugely improve scalability, no matter on clusters with 800Gbps RDMA or 80Gbps TCP/IP inter-node connections.","This paper proposed a novel distributed training method: CO2, which can overlap communication and computation in distributed training. This technique is particularly useful when there are a large number of GPU nodes and the inter-connection between nodes are very slow. Compared to previous works, this paper introduces (1) penalty on stale momentum (2) momentum clipping. Empirical ablations show these two techniques are crucial to improve the training convergence performance. The authors also conducted extensive empirical studies, including experiments on image classification, large language model training, to demonstrate the effectiveness of the proposed method. - The paper has extensive empirical studies across different learning tasks as well as different network environments.
- The authors also provided a convergence analysis for the proposed method. - The idea of overlapping communication and computation is not new, as mentioned in the paper. The key contribution of this paper would be introducing the staleness penalty and momentum clipping mechanisms. They also present solid experimental resutls.
- The comparison with previous works are not enough. For example, totally overlapping communication and computation has already been achieved. like Wang et al, 2020. Overlap-Local SGD. The authors should include more discussions on the differences. or even include this method as a baseline.
- It is not very clear the convergence analysis was performed on which algorithm. Does the analysis consider staleness penalty and momentum clipping? Also, the convergence analysis looks like following previous works. It'd be better to cite few at the very beginning of the analyses. See the above section.",253,0,3,0.8169000000000001,0.0210642691,0.8847193122,51,29.1425,0.0513,iclr,0.0,2,3,2,2,partially factual,3,4,50,polite,4,neutral,3,moderate,4,4,4,4,partially factual,4,4,80,polite,5,neutral,5,moderate,2.0,4.0,4.0,3.0,factual,4.0,4.0,80.0,polite,5.0,neutral,3.0,none,3,4,4,3,factual,4,4,75,polite,5,neutral,4,low,2,4,3,4,partially factual,3,3,75,polite,4,neutral,4,low
12,Reviewer-mZPw,Any-to-Any Generation via Composable Diffusion,"We present Composable Diffusion (CoDi), a novel generative model capable of generating any combination of output modalities, such as language, image, video, or audio, from any combination of input modalities. Unlike existing generative AI systems, CoDi can generate multiple modalities in parallel and its input is not limited to a subset of modalities like text or image. Despite the absence of training datasets for many combinations of modalities, we propose to align modalities in both the input and output space. This allows CoDi to freely condition on any input combination and generate any group of modalities, even if they are not present in the training data. CoDi employs a novel composable generation strategy which involves building a shared multimodal space by bridging alignment in the diffusion process, enabling the synchronized generation of intertwined modalities, such as temporally aligned video and audio. Highly customizable and flexible, CoDi achieves strong joint-modality generation quality, and outperforms or is on par with the unimodal state-of-the-art for single-modality synthesis.","This paper presents a method that can generate any combination of output modalities, including language, audio, image, or video, from any combination of input modalities. The idea here is to align four modalities in a shared feature space first, and then learn to generate one or more modalities based on the shared feature space. This design enables many combinations of modalities despite the lack of training datasets. Since the feature space is shared, it also flexible to extend to other modalities. * The idea of any-to-any generation is interesting, and it enables many different tasks in one model.
* The framework is flexible and customizable to many other potential modalities, such as semantic maps, heat map, depth map and so on.
* The performance of the proposed method achieves comparable or better results than previous SOTA methods.
 * The method part is not clear. The relation among image diffusion model, video diffusion model, vision encoder and vision unet is confusing. Since 4 diffusion models are introduced and only 3 types of encoders and unet are shown in Figure 2, It s not clear whether image and video models share the parameters or not.
* The evaluation of Table 3 is not sufficient. Only the text-video faithfulness (CLIPSIM) is evaluated, while the video quality (FVD) is not evaluated.
* The proposed framework enables many different tasks. However, it does not outperform previous SOTA methods in many tasks, such as text-to-video generation, text-to-image generation, image captioning and video captioning.
 * From Table 8, using both text and audio as input achieves higher FID compared to using each single modality as input. Could you explain why model achieves worse performance with more information as input?
* From table 2 and table 3, CoDi does not outperform previous SOTA results. Do you think a model that can do all tasks need to sacrifice its performance on each specific task?
* During training, the text encoder weights are frozen after training with images, would it result to a suboptimal problem when training with other modalities?
* In Sec 3.3, image diffusion model and video diffusion model are introduced separately. However, in Figure 2, only vision UNet and Vision Encoder are shown. Does it mean image diffusion model share parameters with video diffusion model during training?
* In table 4, why CoDi can outperform other diffusion-based method in image captioning? The authors adequately address the limitations and potential negative sosietal impact.",405,0,0,0.7395,0.0743082368,0.906255722,215,37.9574,0.3617,neurips,0.0,3,4,4,4,partially factual,3,3,73,polite,4,neutral,4,none,4,4,4,4,partially factual,4,4,75,polite,5,neutral,4,moderate,2.0,4.0,4.0,3.0,partially factual,4.0,4.0,70.0,polite,4.0,neutral,3.0,low,3,4,4,3,factual,4,4,75,polite,5,neutral,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
0,Reviewer-i38b,$\nu$-ensembles: Improving deep ensemble calibration in the small data regime,"We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.","The paper proposes a very neat method for improving the diversity of deep ensembles: It assigns random labels to a set of unlabelled data and lets each ensemble component fit different random labels such that these ensemble components can be diverse. The paper further provides theoretical guarantees for the resulting ensembles' behavior on test samples. The empirical results further show that the method acquires significantly better calibration on small training dataset regime, without sacrificing accuracy. Importantly, the method only introduces little extra training overhead while outperforming baseline approaches that are way more complicated. Overall, I think the proposed idea is novel, interesting, easy-to-use, and could be of great impact. - The proposed method is easy! It is much easier and efficient to implement than other methods for enhancing ensemble diversity, such as Stein-based methods.

- The proposed method comes with theoretical guarantees: Although the method sounds like some heuristic, the author provides PAC-Bayes bounds for its performance on test data.

- The empirical performance improvement is significant: The results show that the proposed method improves the calibration error to a great extent for both in-distribution test data and out-of-distribution data (i.e. corrupted data), without hurting the accuracy. - The method ""Sample y randomly without replacement"", however, when the number of ensemble is larger than the number of classes, it is unclear to me how the method should be applied.

- Since the method assumes having access to a validation dataset, a baseline worth considering would be temperature scaling.

- The presentation of the results can be improved: There is no legend for the lines in Figure. 2; The usage of bold font is not consistent and confusing in Table. 1 Why the method becomes less effective when we have access to more data?

If I understand correctly, the method assigns random labels to **in-distribution** data, this sounds weird to me, as it implies that the ensemble would have high uncertainty on these in-distribution samples. I think one can also consider introducing OOD samples into training and assigning random labels to them for each ensemble member.",345,0,0,0.7883,0.0617635659,0.9469445348,47,33.8655,0.1932,iclr,0.01,3,4,3,3,factual,3,4,65,neutral,4,neutral,3,moderate,4,4,4,4,partially factual,5,5,85,polite,5,positive,5,moderate,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,4,3,factual,4,4,80,polite,5,positive,4,low,3,4,4,4,partially factual,4,3,85,polite,5,positive,4,low
0,Reviewer-3iBP,$\nu$-ensembles: Improving deep ensemble calibration in the small data regime,"We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.","The paper introduces a method to enhance the calibration of deep ensembles, particularly in situations where there is a small amount of labeled data and some unlabeled data. For each point in the unlabeled dataset, the ensemble members are trained with different randomly selected labels. The authors provide a theoretical justification for this approach, drawing on PAC-Bayes bounds to argue that it leads to lower negative log-likelihood and higher ensemble diversity on test samples. Empirically, they demonstrate that ν-ensembles outperform standard ensembles in terms of diversity and calibration, especially when the training dataset is small or moderate in size. - The paper gives a method to improve calibration error for deep ensembles using unlabeled data. The use of unlabeled data to improve calibration error of deep ensembles has not been explored much before as most of the works have focused on joint training approaches which can be memory and computationally expensive.
- The paper is overall well written and easy to understand. 
- The paper presents supports their method with both theoretical and experiments. - One major weakness of the paper is that their method only improves calibration error not accuracy but they have not compared to any other calibration technique like temperature sampling. 
- The other issue is that the method appears very similar to the Agree to disagree work mentioned in the paper where they also use unlabeled data to maximize diversity and the idea seem incremental. Can the authors please explain in detail how exactly Agree to disagree maximizes diversity on the unlabeled set?
- Another limitation is that this method only improves calibration in the small data regime. 
- Another limitation is that there are only two datasets used in the paper - CIFAR-10 and CIFAR-100. It would be nice to have additional datasets. - The paper says that the labels for unlabeled data points are chosen without replacement. What happens if we sample with replacement? One should expect the same empirical results to hold but maybe the theoretical argument will not hold?
- I understand the text written at bottom of the Figure 1 but I don’t understand the figure. What are the 3 columns in the figure?
- One part that is not clear to me is when we are forcing the models to make random predictions on unlabeled data which is from the same distribution, why we are not hurting the accuracy or the cross entropy loss of the model? When training data is small and unlabeled data set is bigger, can the authors share their regularization parameters and if they had to give small weights on the regularization term?
- The colors used in figure 2 and 3 are very similar and it is hard to distinguish different lines. 
- There are other works which also use this idea of diversifying using unlabeled datapoint for other problems. For example, DIVERSIFY AND DISAMBIGUATE: OUT-OF-DISTRIBUTION ROBUSTNESS VIA DISAGREEMENT. Can the authors please compare to this work also?
- Did the authors try using the unlabeled data from different distributions like random Gaussian noise. One benefit would be that fitting random labels on this dataset will not interfere with the learning on the original distribution.",530,0,0,0.7822,-0.0265522876,0.9537856579,47,40.043,0.1256,iclr,0.0,4,4,4,4,factual,4,4,90,polite,4,negative,4,low,4,4,4,4,partially factual,4,5,75,polite,5,neutral,5,moderate,2.0,4.0,4.0,3.0,factual,3.0,4.0,80.0,polite,5.0,positive,5.0,none,4,4,4,4,factual,4,4,80,polite,5,neutral,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
92,Reviewer-L5U9,Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks,"We present a new representation learning framework, Intensity Profile Projection, for continuous-time dynamic network data. Given triples $(i,j,t)$, each representing a time-stamped ($t$) interaction between two entities ($i,j$), our procedure returns a continuous-time trajectory for each node, representing its behaviour over time. The framework consists of three stages: estimating pairwise intensity functions, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and constructing evolving node representations via the learned projection. The trajectories satisfy two properties, known as structural and temporal coherence, which we see as fundamental for reliable inference. Moreoever, we develop estimation theory providing tight control on the error of any estimated trajectory, indicating that the representations could even be used in quite noise-sensitive follow-on analyses. The theory also elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce the level of smoothing as the signal-to-noise ratio increases on account of the algorithm `borrowing strength' across the network.","The paper presents a framework called Intensity Profile Projection (IPP) for continuous-time representation learning in dynamic networks. The authors aim to address the challenge of capturing temporal dynamics and evolving relationships in dynamic networks with both high statistical precision and interpretability. The model leverages the concept of intensity profiles, which encode the temporal changes and interactions between nodes in a network. The model provides a uniform error bound for learned node representations and preserves a novel ""temporal coherence"" property compared to existing baselines. Empirical results on real-world dynamic network datasets demonstrate that IPP outperforms existing methods in various tasks such, highlighting its ability to capture continuous-time representations and uncover temporal patterns in dynamic networks. 1. The paper introduces the Intensity Profile Projection (IPP) framework, which offers a unique and innovative approach to continuous-time representation learning for dynamic networks. It introduces the concept of intensity profiles and effectively utilizes them to capture temporal dynamics. 

2. Theoretical analysis towards the model shows that the model can achieve high statistical precision and preserve interpretability in terms of """"temporal coherence"".

3. The paper is in general easy to follow. 1. Lack of comparison with state-of-the-art methods: Although the paper claims improved performance over existing methods, it does not provide a comprehensive comparison with some existing continuous models such as GraphODEs\[1,2,3,4\] which combines neuralODE with GNNs to model network evolution over time.

2. Scalability: The scalability of the IPP framework is not extensively discussed. It would be valuable to address the computational requirements and scalability limitations of the proposed approach, especially when dealing with large-scale dynamic networks.

3. The related work section is too short to provide a comprehensive background of the research topic.


\[1\] Huang, Zijie, Yizhou Sun, and Wei Wang. ""Learning continuous system dynamics from irregularly-sampled partial observations."" Advances in Neural Information Processing Systems 33 (2020): 16177-16187.

\[2\] Song Wen, Hao Wang, and Dimitris Metaxas. 2022. Social ODE: Multi-agent Trajectory Forecasting with Neural Ordinary Differential Equations. In Computer Vision–ECCV 2022: 17th European Conference.

\[3\]Zijie Huang, Yizhou Sun, and Wei Wang. Coupled graph ode for learning interacting system dynamics. In
401 ACM SIGKDD Conference on Knowledge Discovery and Data Mining, page 705–715, 2021.

\[4\] Zang, Chengxi, and Fei Wang. ""Neural dynamics on complex networks."" In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 892-902. 2020. 1. What would be the time complexity of the proposed method?
2. How would the model performance be affected by different network topology? The authors have discussed the limitations of their work.",420,6,11,0.8181,0.0620555556,0.9237517715,215,25.273,0.0751,neurips,0.0,4,4,4,5,factual,4,4,78,neutral,5,neutral,4,low,4,5,4,4,partially factual,5,5,85,polite,5,neutral,5,low,2.0,4.0,4.0,3.0,factual,4.0,4.0,80.0,polite,4.0,neutral,3.0,low,3,4,4,3,factual,4,4,75,polite,5,neutral,4,low,3,4,3,4,partially factual,3,4,75,polite,4,neutral,4,low
128,Reviewer-TLX1,OSRT: An Online Sparse Approximation Model for Scattered Data,"Online learning is a crucial technique for dealing with large and evolving datasets in various domains, such as real-time data analysis, online advertising, or financial modeling. In this paper, we propose a novel predictive statistical model called the Online Sparse Residual Tree (OSRT) for handling streaming multivariate scattered data. OSRT is based on online tree decomposition and online adaptive radial basis function (RBF) exploration. OSRT dynamically expands its network depth as more data arrives, and incorporates a sparse and appropriate RBF refinement at each child node to minimize the residual error from its parent node. OSRT also uses an incremental method to explore the central node of the RBF function, ensuring both sparsity and accuracy of the model. When the network reaches its maximum depth, the OSRT model updates the RBF approximation of its final layer based on the most recent data. This ensures that the model captures the latest trends in the evolving data. We evaluate our algorithm on several datasets, and compare it with existing online RBF methods. From the results, it is shown that OSRT achieves higher efficiency and accuracy.","This paper proposes a method, Online Sparse Residual Tree (OSRT) for
handling streaming multivariate scattered data. The proposed
method is built on the sparse residual tree (SRT) method proposed in \[Xu & Luo, 2022\] and extended to deal with
evolving data efficiently in an online fashion.

The proposed OSRT model dynamically updates the tree structure by adding or deleting neurons and by splitting nodes as a new training sample arrives.
Experiments demonstrate that the ORST method has superior performance to other online algorithms. - With the proposed online extension, the SRT framework can now learn streaming data in an online fashion to predict future data.
- The experiments demonstrate the proposed method outperforms the state-of-the-art base-line methods in the literature. - There are some imprecise parts which make it difficult to evaluate the feasibility of the proposed method. For example, in Section 2.2, on page 5, the sentence ""then we set the."" is incomplete. Algorithm 1 is not fully explained in the text. For example, FindLeaf() in step 3 is not defined in the text. The step 9 seems to contradict what they say in the text. I supporse if the condition is NOT satisfied then it should do splitting. On page 5, the authors state that ""We have mentioned ... as $N_{max} = 1.2 N_{\chi}$,"" but they never mentioned it earlier.
- The SRT, which is the previous work, is treated as if originally proposed in this paper. The authors should clearly split Section 2 into two separate sections, one for explaining the previous SRT as background and the other for the proposed online extensions. 
- The details of the hyperparameter settings used in the experiments are missing completely. The hyperparameters include the maximum tree depth $d_{max}$, the factor $\theta_s$, the stack size $N_l$ and the error threshod $\Delta_1$. Changing their values may influence their performance and setting them to appropriate values may be non-trivial. However, none of their concrete values nor
their robustness to the performance in the experiments is reported. Because OSRT is an extension of SRT, I would like to know the performance difference
between the original SRT and its online version OSRT. The ORST is an online algorithm and evaluates each
sample only once according to Algorithm 1 on page 7. Therefore 
some performance degradation is expected against SRT, while OSRT is more
computationally efficient. The extent of the performance degradation is important
information to understand the potential of the proposed method and should be reported.

Minor comments:

In Section 2 on page 2, the Gaussian kernel is defined as $\theta_j(x)$ that includes $c_j$ as its center vector but a different
symbol $\phi_j(x)$ is used in the following equation. 
On page 4, $\phi_{\delta_l}(X_{li} -\chi_j)$ is used, where the definition of $\phi_{\delta_l}(x)$ does not include $c_j$ and the suffix of $\phi_{\delta_l}$ is the shape parameter, while the suffix of $\phi_j$ is the node index.

On page 4, $\sum_{i=1}^{t_q}$ should be $\sum_{i=1}^{q}$.

In Section 2.1, $\prec t_q$ is defined but $t_q$ is not defined at all and is still used in a couple of places.

In Equation (8), the notation $r_l(x)$ is misleading. It should be $r_l(X_l)$ as  used
later in $Q^T_{q+1}r_l(X_l)$.

In Section 2.3 on page 6, the definition of $S_m$ is unclear. $S_m$ is supposed to be a vertex of Voronoi diagram.

The right hand side of Equiation (1) : $\sum_{i=1}^{N_{\chi}} \alpha_i \phi_{\delta_l}(x)$ is confusing because 
$\sum_{i=1}^{N_{\chi}} \alpha_i \phi_{\delta_l}(x) = \phi_{\delta_l}(x)\sum_{i=1}^{N_{\chi}} \alpha_i $",568,0,0,0.7098,0.067958153,0.9277796745,49,56.0736,0.2552,iclr,0.0,5,5,5,5,factual,4,4,90,polite,4,negative,5,none,5,4,4,5,partially factual,4,5,85,polite,5,neutral,5,moderate,2.0,4.0,4.0,3.0,partially factual,4.0,3.0,60.0,polite,5.0,neutral,5.0,moderate,4,4,4,4,factual,4,4,85,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
128,Reviewer-nWJS,OSRT: An Online Sparse Approximation Model for Scattered Data,"Online learning is a crucial technique for dealing with large and evolving datasets in various domains, such as real-time data analysis, online advertising, or financial modeling. In this paper, we propose a novel predictive statistical model called the Online Sparse Residual Tree (OSRT) for handling streaming multivariate scattered data. OSRT is based on online tree decomposition and online adaptive radial basis function (RBF) exploration. OSRT dynamically expands its network depth as more data arrives, and incorporates a sparse and appropriate RBF refinement at each child node to minimize the residual error from its parent node. OSRT also uses an incremental method to explore the central node of the RBF function, ensuring both sparsity and accuracy of the model. When the network reaches its maximum depth, the OSRT model updates the RBF approximation of its final layer based on the most recent data. This ensures that the model captures the latest trends in the evolving data. We evaluate our algorithm on several datasets, and compare it with existing online RBF methods. From the results, it is shown that OSRT achieves higher efficiency and accuracy.","This paper presents a predictive statistical model OSRT for handling streaming multivariate scattered data. The OSRT model can dynamically expand its network depth with the arrival of data. A RBS refinement is also incorporated into the OSRT model to minimize its residual error. Moreover, the paper proposes an incremental method to explore the central node of the RBF function, ensuring the sparsity and accuracy of the model. Theoretical analysis and Empirical results are provided to demonstrate the effectiveness of the proposed OSRT mode. S1. The paper focuses on online regression analysis, which is an important problem especially considering the growing necessity to process large-scale data in the era of Big Data.

S2. The paper proposes several approaches to minimize the residual error. The effectiveness of the proposed method is theoretically proved and empirically demonstrated. My main concern is the presentation of the paper. 

1. There is no formal problem definition in the introduction, which makes it almost impossible for non-experts to understand the paper. 

2. The introduction part is too short and not very informative. The authors should at least illustrate some of the backgrounds of online regression analysis and highlight existing challenges. 

3. The authors did not clearly state the technical contributions of the work. The related work part is also messy, which makes it very hard for me to identify the contributions of the paper. 

4. the author did not present any intuition for the proofs, which makes it hard to verify the correctness. 

5. the current manuscript contains numerous typos, unclear sentences, and undefined notations. For instance: 

- Page 1: For example, The partition

- Page 1: with more and more data is generated

- Page 1: have deriving

- Page 1: too large a network may bring in ...

- Page 1: takes the growing strategy first, it adds

- Page 2: It separate

- Page 2: represented blow

- Page 2: Where

- Page 3: Where

- Page 3: Most regression trees grown by 

- Page 3: $r_{l+1, j}$ combined into

- Page 3: the notation $\varphi$ requires clarifications

- Page 3: $i \neq j$ Then -> $i \neq j$. Then

- Equation (4): $\mathbb{I}$ and $1_{\Omega_{L_i}}$

- Page 4: then the problem (??)


In general, I think the paper is promising. However, the presentation of the paper does not meet the high standards of ICLR. Please refer to the Weaknesses part for details.",399,0,5,0.7301000000000001,0.0372081413,0.9088370204,49,43.15,0.1508,iclr,0.0,3,4,5,3,factual,3,4,79,polite,4,negative,4,moderate,5,5,5,5,factual,5,5,90,neutral,5,negative,5,low,1.0,3.0,3.0,2.0,partially factual,3.0,2.0,60.0,polite,4.0,neutral,4.0,low,4,3,4,4,factual,4,4,75,polite,5,neutral,4,low,3,3,4,4,factual,4,4,78,polite,5,neutral,3,low
49,Reviewer-Yt1v,CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers,"Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \textbf{Cross}-\textbf{G}uided \textbf{E}nsemble of \textbf{T}okens (\textbf{\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \textit{CrossGET} has two key innovations: 1) \textit{Cross-Guided Matching and Ensemble}. \textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \textit{CrossGET} framework. The code and models will be made public.","The paper proposes CrossGET to accelerate VLM by token merging. Specifically, this work introduces complete-graph matching to partition tokens and merge/reduce tokens based on similarities. The experimental results on common vision-language tasks demonstrate some effectiveness of the proposed method. The paper is well-organized and the presentation is good. The motivation of accelerating VLMs is clear. 1. The major issue is novelty. CrossGET is incremental over ToMe by replacing ToMe's matching algorithm, adding learnable tokens and adapt unimodal ToMe to the multimodal setting.
2. As shown in Table 1, the newly proposed matching algorithm has marginal improvements.
3. CrossGET is proposed to accelerate heavy VLMs. However, majority of experiments are carried out on relatively light-weighted BLIP. There's only a small section for the truly heavy BLIP2, which is a stronger VLM that really needs acceleration.
4. CrossGET requires fine-tuning of VLMs. (1) In most cases, when models need fine-tuning, they are relatively small (acceleration is not demanding). (2) Huge VLMs that are really heavy can be used as zero-shot in different tasks or different datasets of a same task. In this sense, CrossGET which does not apply to pre-training stage is a bottleneck.
5. The paper fails to compare or adapt relevant works \[1\]\[2\].

\[1\] DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification, NeurIPS 2021

\[2\] Not all patches are what you need: Expediting vision transformers via token reorganizations. ICLR 2022

**Final recommendation**: I agree the paper is improved by additional experiments and extensive analysis, and thus I raise my rating to 5. When CrossGET is applying to Flamingo or BLIP2 which uses frozen LLMs, it reduces to accelerating only vision encoders? Then, there will be a bunch of alternative approaches in accelerating ViTs?",283,4,5,0.8172,0.0279545455,0.9102016687,74,38.8176,0.049,iclr,0.0,4,4,3,4,factual,3,4,86,polite,5,positive,4,low,5,5,4,5,factual,4,5,85,polite,5,neutral,5,none,2.0,4.0,4.0,3.0,factual,4.0,4.0,70.0,polite,4.0,neutral,3.0,low,3,4,4,3,factual,4,4,75,neutral,5,neutral,4,low,4,4,3,4,partially factual,3,3,75,polite,4,neutral,4,low
79,Reviewer-At7H,Farzi Data: Autoregressive Data Distillation,"We study data distillation for auto-regressive machine learning tasks, where the input and output have a strict left-to-right causal structure. More specifically, we propose Farzi, which summarizes an event sequence dataset into a small number of synthetic sequences — Farzi Data — which are optimized to maintain (if not improve) model performance compared to training on the full dataset. Under the hood, FARZI conducts memory-efficient data distillation by (i) deriving efficient reverse-mode differentiation of the Adam optimizer by leveraging Hessian-Vector Products; and (ii) factorizing the high-dimensional discrete event-space into a latent-space which provably promotes implicit regularization. Empirically, for sequential recommendation and language modeling tasks, we are able to achieve 98 − 120% of downstream full-data performance when training state-of-the-art models on Farzi Data of size as little as 0.1% of the original dataset. Notably, being able to train better models with significantly less data sheds light on the design of future large auto-regressive models, and opens up new opportunities to further scale up model and data sizes.","This paper proposes FARZI, a data distillation method for auto-regressive ML tasks/event-sequence datasets. The method summarizes a large dataset into a set of synthetic sequences in latent space which can be decoded later. They show that model performance is upheld/enhanced when compared to training on the complete dataset on the downstream tasks of sequential recommendation and language modeling. For data distillation, the paper shows Adam to be better than SGD as inner loop optimizer, and derives an efficient reverse mode differentiation of Adam such that its memory complexity is independent of the number of inner loop steps. - Originality and Significance: The latent parametrization that makes FARZI optimization friendly, and the proposed trick that enables reverse mode differentiation of Adam such that its memory complexity is independent of the number of inner loop steps are great contributions and of practical value.
- Quality and Clarity: The paper is well written with extensive experiments whose details and evaluations are that are clearly described. The results are impressive. The method is able to achieve better performance on downstream tasks compared with using the full dataset. - It is not clear whether this method will be practical and scale for larger language models and larger datasets. It would be great if the authors can elaborate on this.
- There is not a clear analysis of the total time gains of this method in comparison with training from scratch. Providing some values would make the case for this method more compelling. Listed in weakness section.",251,0,0,0.7685000000000001,0.2299744898,0.9208657742,47,39.2431,0.0945,iclr,0.0,1,2,2,1,unfactual,4,3,55,neutral,1,neutral,1,high,4,5,4,4,factual,4,4,85,polite,5,positive,5,moderate,2.0,5.0,4.0,3.0,factual,4.0,4.0,80.0,polite,4.0,neutral,3.0,none,3,4,4,4,factual,4,4,85,polite,5,positive,5,low,3,4,4,4,factual,4,4,85,polite,5,positive,5,low
40,Reviewer-PzSz,Contextual Bandits and Imitation Learning with Preference-Based Active Queries,"We consider the problem of contextual bandits and imitation learning, where the learner lacks direct knowledge of the executed action's reward. Instead, the learner can actively request the expert at each round to compare two actions and receive noisy preference feedback. The learner's objective is two-fold: to minimize regret associated with the executed actions, while simultaneously, minimizing the number of comparison queries made to the expert. In this paper, we assume that the learner has access to a function class that can represent the expert's preference model under appropriate link functions and present an algorithm that leverages an online regression oracle with respect to this function class. For the contextual bandit setting, our algorithm achieves a regret bound that combines the best of both worlds, scaling as $O(\min\\{\sqrt{T}, d/\Delta\\})$, where $T$ represents the number of interactions, $d$ represents the eluder dimension of the function class, and $\Delta$ represents the minimum preference of the optimal action over any suboptimal action under all contexts. Our algorithm does not require the knowledge of $\Delta$, and the obtained regret bound is comparable to what can be achieved in the standard contextual bandits setting where the learner observes reward signals at each round. Additionally, our algorithm makes only $O(\min\\{T, d^2/\Delta^2\\})$ queries to the expert. We then extend our algorithm to the imitation learning setting, where the agent engages with an unknown environment in episodes of length $H$, and provide similar guarantees regarding regret and query complexity. Interestingly, with preference-based feedback, our imitation learning algorithm can learn a policy outperforming a sub-optimal expert, matching the result from interactive imitation learning algorithms [Ross and Bagnell, 2014] that require access to the expert's actions and also reward signals.","This paper studies the contextual bandit and imitation learning problem with preference-based feedback. The authors propose an oracle-based contextual bandit algorithm, which attains both worst-case and instance-dependent regret bounds. Besides, the algorithm has an instance-dependent guarantee on the querying numbers of the preference-based information. Furthermore, the proposed bandit algorithm is extended to the imitation learning setting with provable guarantees. - the proposed method has strong theoretical guarantees on the regret (both worst-case and instance-dependent bound) and query complexity. Although the oracle-based algorithm proposed shares similar techniques with MinMaxDB \[Saha and Krishnamurthy, 2022\] and AdaCB \[Foster et al., 2020\], the authors provide enough discussion to highlight the difference.
- lower bounds are provided to justify the upper bounds on regret, and query complexity is tight up to logarithmic factors
- the paper is well-structured and written - about the practical implementation of the proposed method: one of my main concerns about the paper is from the practical side. Similar to the oracle-based algorithm for the standard contextual bandit problem (e.g., SquareCB \[Foster et al. 2022\]), the proposed method is established on an online regression solver with regret guarantees. However, I'm not sure to what extent such an online regression solver can be obtained with the preference-based feedback model. For instance, as shown in example 1, $f(x, a,b) = r(a,x)-r(x,b)$, the function $f(\cdot)$ is not convex even $r:\mathcal{X}\times\mathcal{A}\rightarrow\[0,1\]$ is a convex function, and the algorithm developed for online convex optimization is not applicable. I think it would be beneficial if the authors could provide some concrete examples (for example, the reward function has a linear structure?) that the online regression oracle is available. 

-  about the instance-dependent bound: the proposed instance-dependent regret bound as an $O(\Upsilon^2)$ dependence on the regret of the oracle and an  $O(\Upsilon^3)$ on the query complexity. There seems still some room for improvement. In the finite function space case, AdaCB attains an $O(\log \vert\mathcal{F}\vert/\Delta)$ bound for a standard contextual bandit problem, but the result obtained in this paper implies an $O(\log^2 \vert\mathcal{F}\vert/\Delta)$ regret bound. 


 - could you provide concrete examples of the online regression oracle for the preference-based feedback model? It would be even better if the author could provide more detailed discussions on to which extent such an online regression solver can be established.

- could you provide more discussion on the tightness of the instance-dependent bound, especially on the dependence of $\Upsilon$?

- The expert policy $\pi_e$ is not formally defined. Does $\pi_e$ refer to the policy that can maximize the value function? I am confused by the claim, ""our algorithm not only competes with the expert policy but can also surpass it to some extent"" in line 343. What is the formal definition of ""surpass."" Do you mean the regret would go negative due to the term $Adv_T$? However, it is unclear to me when the negative term is large enough to cancel the $O(\sqrt{T}, A/\Delta)$ term. The paper has discussed the limitation and potential future work in the conclusion. Another issue is that it imposes a realizable assumption for $f^\star$. It is unclear whether extending the analysis for standard contextual bandit (Section 5 in \[Foster et al., ICML 2020\]) to the contextual dueling bandit setting is possible.",533,1,0,0.7521,0.0431166056,0.9522576332,215,40.3366,0.5388000000000001,neurips,0.0,5,5,5,5,factual,5,5,100,polite,5,neutral,5,none,5,5,5,5,factual,5,5,95,polite,5,neutral,5,low,2.0,4.0,4.0,3.0,factual,3.0,4.0,80.0,polite,5.0,neutral,5.0,none,4,4,4,4,factual,4,4,85,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
110,Joyce-van-de-Leemput,Longitudinal RNA sequencing of the deep transcriptome during neurogenesis of cortical glutamatergic neurons from murine ESCs,"Using paired-end RNA sequencing, we have quantified the deep transcriptional changes that occur during differentiation of murine embryonic stem cells into a highly enriched population of glutamatergic cortical neurons. These data provide a detailed and nuanced account of longitudinal changes in the transcriptome during neurogenesis and neuronal maturation, starting from mouse embryonic stem cells and progressing through neuroepithelial stem cell induction, radial glial cell formation, neurogenesis, neuronal maturation and cortical patterning. Understanding the transcriptional mechanisms underlying the differentiation of stem cells into mature, glutamatergic neurons of cortical identity has myriad applications, including the elucidation of mechanisms of cortical patterning; identification of neurogenic processes; modeling of disease states; detailing of the host cell response to neurotoxic stimuli; and determination of potential therapeutic targets. In future work we anticipate correlating changes in longitudinal gene expression to other cell parameters, including neuronal function as well as characterizations of the proteome and metabolome. In this data article, we describe the methods used to produce the data and present the raw sequence read data in FASTQ files, sequencing run statistics and a summary flatfile of raw counts for 22,164 genes across 31 samples, representing 3-5 biological replicates at each timepoint. We propose that this data will be a valuable contribution to diverse research efforts in bioinformatics, stem cell research and developmental neuroscience studies.","Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The depth and temporal nature of the dataset presented in this paper will be beneficial to any researcher interested in cortical development in general, and potentially lead to many new insights and avenues to pursue. A point of note, in my experience differences in passage number of the cells used for differentiation can affect gene expression levels throughout. The authors state “ESCs were differentiated into neurons between 5-30 passages after adaptation to suspension culture.”, I wonder if that is why the DIV21 samples cluster in between the DIV16 and DIV28 when performing a PCA analysis on the transcript read counts (obtained from Data File 2)? Related question, how raw are the transcript read counts in Data File 2, as I thought raw counts would have to be integers whereas the counts given have decimal points? Finally, with regard to the previous Ref Report (Ragsdale and Albertin; 12 March 2013), have you considered comparative analysis using the Allen Brain Atlas/ Mouse Brain expression data for the thalamic and cortical areas and see which region your samples resemble most?",244,0,0,0.8079000000000001,0.069039294,0.8534755111000001,96,19.13,0.1969,f1000,0.0196078431372549,3,3,3,4,partially factual,3,4,70,neutral,4,neutral,4,moderate,4,4,4,4,partially factual,5,5,80,polite,5,neutral,5,moderate,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,3,3,factual,4,4,70,polite,4,positive,4,low,3,4,4,4,partially factual,4,4,85,polite,5,positive,5,low
129,Reviewer-mok7,"On quantum backpropagation, information reuse, and cheating measurement collapse","The success of modern deep learning hinges on the ability to train neural networks at scale. Through clever reuse of intermediate information, backpropagation facilitates training through gradient computation at a total cost roughly proportional to running the function, rather than incurring an additional factor proportional to the number of parameters -- which can now be in the trillions.  Naively, one expects that quantum measurement collapse entirely rules out the reuse of quantum information as in backpropagation. But recent developments in shadow tomography, which assumes access to multiple copies of a quantum state, have challenged that notion.  Here, we investigate whether parameterized quantum models can train as efficiently as classical neural networks. We show that achieving backpropagation scaling is impossible without access to multiple copies of a state.  With this added ability, we introduce an algorithm with foundations in shadow tomography that matches backpropagation scaling in quantum resources while reducing classical auxiliary computational costs to open problems in shadow tomography. These results highlight the nuance of reusing quantum information for practical purposes and clarify the unique difficulties in training large quantum models, which could alter the course of quantum machine learning.","The paper studies the scaling of computing the gradient of a quantum neural network. While in the classical case we can use backpropagation, which gives the same linear scaling for computing the gradient and the forward pass, in the quantum case, we would naively have to run a circuit for each component of the gradient, leading to a squared complexity in the number of parameters, which prevents studying quantum models with large number $M$ of parameters.
The authors formulate this problem in the language of shadow tomography and apply ideas from that field to the problem at hand.
This shows that while an $M\log M$ scaling is possible using polylog copies of the input state. This comes at a drawback of classical cost that scales as $2^n$ with $n$ the number of qubits. Resolving this exponential scaling would resolve some open problems in shadow tomography. - Relevant problem in quantum ML.
- Connection with shadow tomography and application to scaling of gradient computation is new and can lead to new ways to think about the problem
- Rigorous statements supporting scaling 
- Well written paper - The paper relies on quantum information concepts that are not necessarily familiar with the ML audience at the conference.
- When talking about memory requirements of backprop in classical neural networks, one needs to store activations for reverse mode autodiff. This leads to memory that scales with the number of layers, while in the quantum case by analogy the number of qubits does not scale with the number of layers. The authors could comment about this.
- I was confused by Prop. 3: is the proof considering the case of a number of parameters $4^n$? I am not sure what we learn from this example since it does not seem to be part of the quantum neural networks we would like to train.
- The classical scaling as $2^n$ required for the proposed algorithm restricts a lot the class of problem for which this protocol can be useful. 
 - Can you add a related work section to highlight the novelty with respect to previous work?
- Can you explain what is rotate/threshold check in figure 1? Can you add more intuition around proposition 7 to see how gentle measurements are used, e.g. what is alpha in this case? What is the role of $\sigma$? 
- Can you comment on what problems could benefit from the proposed protocol, namely small $n$ and large $M$?
- Can you explain why approximations to $\sigma$ using for example tensor networks could be more robust than just simulating the quantum neural network with tensor network? - As the authors say several time, the main limitation is that their algorithm come with a classical exponential scaling that limits its applicability. ",460,0,0,0.7696000000000001,0.0542147667,0.8965290785000001,216,52.7329,0.3398,neurips,0.0096153846153845,4,4,4,4,factual,3,4,85,neutral,4,neutral,4,low,4,4,4,4,partially factual,4,4,85,polite,5,neutral,4,moderate,2.0,4.0,4.0,4.0,factual,3.0,4.0,80.0,polite,5.0,neutral,5.0,none,4,4,4,4,factual,4,4,85,polite,5,neutral,5,low,3,4,4,4,factual,4,4,85,polite,5,neutral,5,low
37,Barend-L.-van-Drooge,Comparison of the oxidative potential of primary (POA) and secondary (SOA) organic aerosols derived from α-pinene and gasoline engine exhaust precursors,"Background: Primary (POA) and secondary (SOA) organic aerosols, deriving from both anthropogenic and biogenic sources, represent a major fraction of ambient particulate matter (PM) and play an important role in the etiology of respiratory and cardiovascular diseases, largely through systemic inflammation and cellular oxidative stress. The relative contributions of these species to the inhalation burden, however, are rather poorly characterized. In this study, we measured the in vitro oxidative stress response of alveolar macrophages exposed to primary and secondary PM derived from both anthropogenic and biogenic sources. Methods: POA and SOA were generated within an oxidation flow reactor (OFR) fed by pure, aerosolized α-pinene or gasoline engine exhaust, as representative emissions of biogenic and anthropogenic sources, respectively. The OFR utilized an ultraviolet (UV) lamp to achieve an equivalent atmospheric aging process of several days. Results: Anthropogenic SOA produced the greatest oxidative response (1900 ± 255 µg-Zymosan/mg-PM), followed by biogenic (α-pinene) SOA (1321 ± 542 µg-Zymosan/mg-PM), while anthropogenic POA produced the smallest response (51.4 ± 64.3 µg-Zymosan/mg-PM). Conclusions: These findings emphasize the importance of monitoring and controlling anthropogenic emissions in the urban atmosphere, while also taking into consideration spatial and seasonal differences in SOA composition. Local concentrations of biogenic and anthropogenic species contributing to the oxidative potential of ambient PM may vary widely, depending on the given region and time of year, due to factors such as surrounding vegetation, proximity to urban areas, and hours of daylight.","Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The work of Lovett et al. presents interesting data on the possible inflammatory effects of SOA from traffic as well as biogenic (pinene) origin. The method setup is well designed, although the variables, such as conditions of relative humidity and temperature, could have been studied in different values. On the other hand, the results show that the biogenic SOA have similar high inflammatory effect in the test compared to traffic SOA, which is an important fact, and indicates that effects have been observed in real-world data. However, the study could have been more complete and higher quality if the researchers would have made an effort to detect and quantify the molecular chemical compounds that are present in the SOA fractions.  The work is suitable for indexing.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",269,0,1,0.7683,0.1806060606,0.8230857849000001,120,33.54,0.0999,f1000,0.0204081632653061,3,4,3,2,factual,3,2,40,polite,3,positive,4,moderate,4,4,4,4,factual,4,4,85,polite,5,positive,5,moderate,2.0,4.0,4.0,3.0,factual,4.0,5.0,80.0,polite,4.0,positive,3.0,none,3,4,3,3,factual,4,4,75,polite,5,positive,4,low,3,4,3,4,factual,4,4,85,polite,5,positive,4,low
35,Reviewer-sqng,Cognitive Steering in Deep Neural Networks via Long-Range Modulatory Feedback Connections,"Given the rich visual information available in each glance, humans can internally direct their visual attention to enhance goal-relevant information---a capacity often absent in standard vision models.  Here we introduce cognitively and biologically-inspired long-range modulatory pathways to enable `cognitive steering’ in vision models.  First, we show that models equipped with these feedback pathways naturally show improved image recognition, adversarial robustness, and increased brain alignment, relative to baseline models. Further,  these feedback projections from the final layer of the vision backbone provide a meaningful steering interface, where goals can be specified as vectors in the output space.  We show that there are effective ways to steer the model that dramatically improve recognition of categories in composite images of multiple categories, succeeding where baseline feed-forward models without flexible steering fail. And, our multiplicative modulatory motif prevents rampant hallucination of the top-down goal category, dissociating what the model is looking for, from what it is looking at. Thus, these long-range modulatory pathways enable new behavioral capacities for goal-directed visual encoding, offering a flexible communication interface between cognitive and visual systems.","This work introduces a recurrent modulation module that can be added to visual models so that the top layer can project to and influence the earlier layers. The authors find that the model with the feedback projection layers outperforms the baseline feedforward model in both the categorization performance and adversarial robustness. The model is further analyzed to test whether the feedback modulation can be controlled to meaningfully steer the representations. The authors find that the top-layer steering yields significant performance increase when mixed targets are presenting in the same image in a side-to-side or overlaying fashion. The paper is well-written and easy to read. The significant improvement of the feedback-augmented model compared to the baseline model is also interesting. The steering analysis is done on both side-to-side and overlaying settings. The idea of adding feedback modulation from top layers to earlier layers is not new. The authors should more clearly discuss the difference between their work and other models.

The performance and robustness evaluation also needs to be more careful. The feedback connection adds more computation and trainable parameters. But the performance is still compared to the baseline model with less computation and trainable parameters. The authors should compare their model to a larger or deeper architecture.

Although the steering analysis shows that the model can reach higher performance, this analysis is kind of circular as the target signal is explicitly used to generate the modulation signal, which makes the performance improvement unsurprising. This steering property of the new model has its potential, as the proposed visual model is now available to be tested in attention experiments just as how humans can be asked to attend to different parts or features in their input. But more tests and experiments to compare models to humans are needed to illustrate this potential. See weakness. Yes.",303,0,2,0.7442000000000001,0.2003176931,0.8941668272000001,216,36.8412,0.0513,neurips,0.031578947368421,2,4,4,2,partially factual,4,3,65,polite,4,neutral,4,moderate,4,5,4,4,factual,4,4,85,polite,5,neutral,5,none,2.0,4.0,4.0,3.0,factual,4.0,4.0,70.0,polite,4.0,neutral,3.0,low,3,5,4,3,factual,4,4,80,polite,5,neutral,4,low,4,5,3,4,partially factual,3,3,78,polite,4,neutral,4,low
80,Reviewer-hEF2,FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things,"There is a significant relevance of federated learning (FL) in the realm of Artificial Intelligence of Things (AIoT). However, most of existing FL works are not conducted on datasets collected from authentic IoT devices that capture unique modalities and inherent challenges of IoT data. In this work, we introduce FedAIoT, a FL benchmark for AIoT to fill this critical gap. FedAIoT includes eight well-chosen datatsets collected from a wide range of IoT devices. These datasets cover unique IoT modalities and target representative applications of AIoT. In addition, FedAIoT includes a unified end-to-end FL framework for AIoT that simplifies benchmarking the performance of the datasets. Our benchmark results shed light on the opportunities and challenges of FL for AIoT. We hope that FedAIoT could serve as an invaluable resource for researchers and practitioners to foster advancements in the important field of FL for AIoT.","In this paper, the author(s) propose a federated learning benchmark dedicated to artificial intelligence of things. In particular, the benchmark includes eight extant datasets collected from IoT devices and applications. The proposed benchmark also contains an end-to-end framework, which consists of five main modules: non-IID data partitioning, data preprocessing, IoT-friendly models, FL hyperparameters, and IoT-factor emulator. Importance of contribution: The solution is proposed to resolve the lack of a proper benchmark for IoT-specific federated learning. The author(s) validate the feasibility of this benchmark.

Soundness: The author(s) explain the benchmark in detail, and conduct evaluation on the different modules in the framework. 

Quality of presentation: The paper is well-organized, and the language is technical yet understandable for readers with domain knowledge.

Comparison with related works: The author(s) introduce extant studies on federated learning benchmarks for computer vision, natural language processing, medical imaging, etc., and clarify the research gap between this study and related work. The methodology can be elaborated for better clarity of the overall research step. - Figure 1 is not explicitly referred to in the manuscript.
- The author(s) can consider elaborating the methodology of how to collect and choose the datasets. What are the metrics to select and finalise the eight datasets?
- The author(s) can specify the definition of small, medium and large datasets.
- A proof-reading is needed as there are some typos. For instance, Section 3.1: “… FedAIoT.These datasets …”, a space is needed.",239,0,0,0.7615000000000001,0.0212585034,0.9212706089,49,29.1699,0.068,iclr,0.0,1,4,2,1,partially factual,3,2,20,polite,3,positive,2,moderate,5,5,4,5,5,4,4,85,polite,5,positive,5,moderate,2.0,5.0,4.0,3.0,factual,3.0,4.0,80.0,polite,4.0,neutral,5.0,none,4,4,4,4,factual,4,4,80,polite,5,positive,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
123,Reviewer-EGJf,Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation,"Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.","**Summary:** 
This paper presents an open-source toolkit based on LoRa. I believe this work might be more appropriate for the ""benchmarking and datasets"" track. Positioned here, it's challenging for me to evaluate the innovation this paper offers. **Remarks:** 
While the improvements and variants on LoRa are relatively straightforward, the theoretical part of the paper seems sound. **Recommendation:** 
I would advise the authors to provide clear insights through experiments and offer some specific suggestions. I cannot evaluate this paper because I believe it is proper for a benchmarking and dataset track, not the main track.",94,0,0,0.7561,0.2401515152,0.7697365284000001,75,42.4333,0.2025,iclr,0.0374999999999999,3,4,3,2,partially factual,3,2,30,polite,2,negative,4,moderate,4,5,3,3,partially factual,3,3,55,polite,3,neutral,3,moderate,2.0,4.0,3.0,3.0,partially factual,3.0,4.0,60.0,polite,4.0,neutral,4.0,low,1,3,2,2,partially factual,3,2,40,polite,2,neutral,2,moderate,2,4,3,3,partially factual,3,3,65,polite,4,neutral,4,low
138,Reviewer-z7DA,Parameter-Efficient Tuning Helps Language Model Alignment,"Aligning large language models (LLMs) with human preferences is essential for safe and useful LLMs. Previous works mainly adopt reinforcement learning (RLHF) and direct preference optimization (DPO) with human feedback for alignment. Nevertheless, they have certain drawbacks. One such limitation is that they can only align models with one preference at the training time (e.g., they cannot learn to generate concise responses when the preference data prefers detailed responses), or have certain constraints for the data format (e.g., DPO only supports pairwise preference data). To this end, prior works incorporate controllable generations for alignment to make language models learn multiple preferences and provide outputs with different preferences during inference if asked. Controllable generation also offers more flexibility with regard to data format (e.g., it supports pointwise preference data). Specifically, it uses different control tokens for different preferences during training and inference, making LLMs behave differently when required. Current controllable generation methods either use a special token or hand-crafted prompts as control tokens, and optimize them together with LLMs. As control tokens are typically much lighter than LLMs, this optimization strategy may not effectively optimize control tokens. To this end, we first use parameter-efficient tuning (e.g., prompting tuning and low-rank adaptation) to optimize control tokens and then fine-tune models for controllable generations, similar to prior works. Our approach, alignMEnt with parameter-Efficient Tuning (MEET), improves the quality of control tokens, thus improving controllable generation quality consistently by an apparent margin on two well-recognized datasets compared with prior works.","The paper proposes MEET, a method to train a LLM to generate ""good"" and ""bad"" answers to a given question / task by conditioning the model computation with an adapter (LoRA or Soft Prompt). To do so, they adopt a two-step training procedure. First, they train a ""good control adapter"" and a ""bad control adapter"" on good answers and bad answers respectively while keeping the base LM fixed, then they fine-tune both the control adapters and the base model. The authors show that this two step procedure is important to achieve gains over the Chain of Hindsight baseline (basically a baseline where control adapters is just a handcrafted prompt ""A good/bad conversation is:"") and DPO on two datasets OpenAI Summary and HH-RLHF from Anthropic. - The paper is well-written, the details of the experimental setting are clear.
- The two-stage training procedure is interesting and its importance is validated by the ablation study.
- Results seem to suggest that the two-step optimization method delivers gains w.r.t. DPO. - It feels like the authors are a bit confused on where the novelty of their paper really lies, they seem to suggest that it is in using adapters to control generation, but imho, the interesting bit is more on the two-step training procedure that guarantees information is captured by the adapters and thus they are not ""information-starved"" by the full LM fine-tuning (easy to fix)

- The more problematic bit is that authors' confusion seems to have affected the overall experimental methodology; for example, the authors seem to tie their method to the specific loss function used (i.e. MLE) and compare to DPO, while their method can be used on top of DPO. Moreover, the baselines numbers are a bit concerning and some important baselines are missing (overall harder to fix) About novelty:

The paper proposes to learn ""attributes"" conditional models with adapters, which have been proposed in https://arxiv.org/pdf/2302.08453.pdf for diffusion models for example. So, here, the novelty might reside in 1/ applying this general idea to textual generation tasks and 2/ the two-stage training approach proposed to train these adapters. The current stance of the paper is that the main novelty is to apply LoRA adapters for generation instead of hard prompts. I feel like 2/ is a more interesting and impactful contribution but currently it is a bit understated in the paper, so it feels like it should be the central focus of the paper. I feel like the paper can be an interesting set of experiments showing that the two-stage approach prevent adapters from being ""information-starved"" from full model fine-tuning.

About experiments:

Confusion about the contributions seem to appear in Section 3, where the authors tie their method to MLE loss (1) and (2) and compare in the experiments with a DPO baseline. This is a bit surprising to me given that their method can be deployed on top of DPO, i.e. Eq (1) and (2) can use DPO instead of MLE (to train each good and bad expert), so I am not sure why DPO would be a baseline in the experiments. On the contrary, I would have expected to see two versions of their method in the experiments: with Eq. (1) and (2) using DPO (MEET-DPO) and Eq. (1) and (2) using MLE (MEET-MLE).

From all experiments, one straightforward baseline is missing in addition to CoH: SFT -- which just trains on positive data.

Similarly, for MEET-MLE, what is the impact of integrating negative data? i.e. what is the gap between MEET-SFT, which just trains the controllable adapter of positive data and MEET-MLE, which trains on both positive and negative data with Eq. 2?

In the first dataset, DPO underperforms CoH on OpenAI/Summary dataset. The fact that DPO underperforms CoH on this dataset is a bit suspicious. Did you tune the \beta parameter for DPO on both datasets ?

How do you do cross-validation in these two datasets? Are you searching for the best HPs for each method on the validation set?

Taken together, your results currently show that DPO is useless in these two datasets and severely underperform MLE training with MEET. I am not sure this result can be published without further ablations and baselines as I suggest above, especially it appears to me that MEET can be further improved with DPO training.

Please, do not consider my score as final, I am willing to increase the score substantially if the authors can give answers to my questions.",743,1,2,0.7414000000000001,0.0964416896,0.8564590812,47,50.4638,0.087,iclr,0.0,4,4,4,4,factual,5,4,90,polite,4,positive,4,low,5,5,5,5,partially factual,4,5,85,polite,5,neutral,5,low,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,neutral,3.0,low,3,4,4,4,factual,4,4,80,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
17,Reviewer-k6s5,Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models,"Large Language Models (LLMs) with a billion or more parameters are prime targets for network pruning, which aims to reduce a portion of the network weights without compromising performance. Prior approaches such as Weights Magnitude, SparseGPT, and Wanda, either concentrated solely on weights or integrated weights with activations for sparsity. However, they overlooked the informative gradients derived from pretrained large language models. In this paper, we present a novel sparsity-centric pruning method for pretrained LLMs, termed **G**radient-**b**ased **L**anguage **M**odel **P**runer (**GBLM-Pruner**). Distinctively, GBLM-Pruner operates in a training-free manner by harnessing normalized gradients, and substantially outperforms competitive counterparts like SparseGPT and Wanda in multiple benchmarks. Intriguing, after incorporating gradients, the unstructured pruning method tends to reveal some structural patterns post-pruning, which mirrors the geometric interdependence inherent in the LLMs' parameter structure. Additionally, GBLM-Pruner functions without any subsequent retraining or weight updates to maintain its simplicity as other counterparts. Extensive evaluations on LLaMA-1 and LLaMA-2 across various language benchmarks and perplexity show that GBLM-Pruner surpasses magnitude pruning, Wanda (*weights+activations*), and SparseGPT (*weights+activations+weight update*) by significant margins. Our code and models will be publicly available.","This study introduces GBLM-Pruner, a new post-training pruning technique designed for large language models, which leverages gradient information. The authors provide both theoretical rationale and empirical assessments that demonstrate GBLM-Pruner outperforms other prominent baselines, such as Wanda and SparseGPT. - The paper is well-organized, effectively presenting the method with clear descriptions and comprehensive empirical evaluations.
- Both theoretical explanations and empirical results are presented to validate the theoretical explanations and empirical results.
- The paper includes plenty of ablation studies, encompassing diverse sparsity levels, different pruning metrics, assessments of dependency on calibration samples, and visualizations that highlight the specifics of sparse patterns. - The improvements achieved by GBLM-Pruner, as compared to other baselines like SparseGPT and Wanda, appear to be relatively modest. For instance, in Table 2, under 50% unstructured sparsity, GBLM-Pruner (l1) yields perplexity reductions of only 0.06, 0.09, and 0.05 compared to Wanda on LLaMA-2-7B/13B/70B, respectively. Additionally, in Figure 2, the curves for Wanda and GBLM-Pruner exhibit significant overlap.
  
- I'm unclear about the rationale behind experimenting with the pruning metrics listed in Line 7/8. It seems that some of these metrics may not provide meaningful insights.

- It's essential to understand the memory and time requirements during the pruning process of GBLM-Pruner. Obtaining gradient information can impose a significant memory cost, and it may not be feasible to conduct this process in a layer-wise manner. Storing intermediate features for the backward process could further impact memory usage. Thus, it would be valuable to compare these memory and time requirements with those of other baseline methods for a more comprehensive assessment of GBLM-Pruner's practicality. None",267,0,1,0.812,0.1120610871,0.9594182372,56,23.6709,0.1262,iclr,0.0,2,3,3,3,partially factual,3,3,55,polite,4,neutral,3,low,4,5,4,4,factual,4,4,88,polite,5,neutral,5,low,2.0,4.0,4.0,3.0,factual,3.0,4.0,80.0,polite,5.0,neutral,5.0,none,3,4,4,3,factual,4,4,80,polite,5,neutral,4,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,3,low
51,Reviewer-QSAL,Data Market Design through Deep Learning,"The  _data market design_ problem is a problem in economic theory to find a set of signaling schemes (statistical experiments) to maximize expected revenue to the information seller, where each experiment reveals some of the information known to a seller and has a corresponding price. Each buyer has their own decision to make in a world environment, and their subjective expected value for the information associated with a particular experiment comes from the improvement in this decision and depends on their prior and value for different outcomes. In a setting with multiple buyers, a buyer's expected value for an experiment may also depend on the information sold to others. We introduce the application of deep learning for the design of revenue-optimal data markets, looking to expand the frontiers of what can be understood and achieved. Relative to earlier work on deep learning for auction design, we must learn signaling schemes rather than allocation rules and handle  _obedience constraints_  &mdash; these arising from modeling the downstream actions of buyers &mdash; in addition to incentive constraints on bids.  Our experiments demonstrate that this new deep learning framework can almost precisely replicate all known solutions from theory, expand to more complex settings, and be used to establish the optimality of new designs for data markets and make conjectures in regard to the structure of optimal designs.","This paper introduces a deep learning framework for the automated design of data markets, a novel and timely application in the field of economics. The authors address the data market design problem, which involves designing a set of signaling schemes to maximize expected revenue. The paper extends previous work on deep learning for auction design by learning signaling schemes and handling obedience constraints that arise from the actions of agents. - Innovative Application: The paper introduces a novel application of deep learning to the data market design problem, expanding the scope of machine learning in the field of economics.

- The paper is well-written overall. -Incremental work: It seems that the core contribution, the proposed neural network architecture, is a simple extension of existing model called RochetNet, by slightly modifying the loss function.

-Lack of comparison with baselines: mechanism design for information acquisition is a long standing problem. I was surprised to see no baseline comparison in the experiments, and no discussion on how/why existing approaches may not work in the methodology.  What are some baseline methods to compare with? For example, how does the standard rochetnet perform on the proposed market settings? Yes.",194,0,1,0.799,0.0097222222,0.957269609,215,33.5689,0.1249,neurips,0.0,2,4,2,2,partially factual,3,3,60,polite,4,neutral,3,moderate,3,4,3,3,partially factual,4,4,65,polite,5,neutral,4,moderate,2.0,4.0,4.0,3.0,factual,4.0,4.0,70.0,polite,5.0,positive,3.0,none,2,4,3,2,factual,3,3,60,neutral,4,neutral,4,low,2,4,3,4,partially factual,3,3,75,polite,5,neutral,4,low
23,Bertil-Blok,Case Report: A case of neurogenic bladder in the setting of Behçet's disease after an initial diagnosis of multiple sclerosis,"Behçet’s disease (BD) is an autoimmune vasculitis with an unclear etiology presenting with a classic triad of symptoms including oral and genital ulcers as well as iridocyclitis. A subset of BD patients exhibit neurological symptoms including psychiatric disturbances, balance problems, and voiding dysfunction, and the symptoms of BD can mimic other neurological diseases, including multiple sclerosis (MS).  Differentiating between potential diagnoses is challenging due to the lack of specific tests for these disorders and the overlap between clinical symptoms and radiological findings. We describe the case of a 52 year old woman initially diagnosed with and treated for MS.  From the urologic standpoint, she was treated for neurogenic detrusor overactivity with detrusor-sphincter-dyssynergia utilizing ileocecal augmentation cystoplasty with a continent stoma for intermittent catheterization. The patient was later diagnosed with BD in light of additional clinical findings.","Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The manuscript 'Case Report: A case of neurogenic bladder in the setting of Behçet's disease after an initial diagnosis of multiple sclerosis' is an interesting paper. However, I have some comments addressed below. The case report is a readable report on an interesting topic. However, the authors do not report on any vaginal child delivery nor do they mention the BMI of the patient. Both are risk factors for stress urinary incontinence. It is very possible that before the MMK a mixed urinary incontinence was present and in retrospect it is always easy to say that the previous physicians did not do a good job. The blaming distracts from the main important message that patients with a neurogenic bladder are different from patients without a neurogenic bladder. Both referring physicians and physicians who provided the irreversible surgical treatment were responsible for the patient. This means that also the general practitioner and neurologist should be informed and know to whom they send their patients to. On a regular basis we observe maltreatment because the referring physician did not care to refer his or her patient  specifically to an expert in the field. Some attention should be given to treatment with botulinum toxin and midurethral tapes, which were also around when the bladder augmentation was given.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Yes  Is the case presented with sufficient detail to be useful for other practitioners? Yes",350,0,1,0.7703,0.1161290323,0.8287411332,788,32.33,0.157,f1000,0.0,4,4,3,3,factual,3,3,70,polite,4,neutral,4,low,4,4,4,4,partially factual,3,3,65,polite,5,neutral,5,moderate,3.0,5.0,5.0,4.0,factual,4.0,4.0,80.0,polite,5.0,neutral,4.0,none,3,4,3,3,factual,3,3,65,neutral,4,neutral,3,low,2,4,3,3,partially factual,3,3,70,polite,4,neutral,4,low
172,Reviewer-icwN,Structured Neural Networks for Density Estimation and Causal Inference,"Injecting structure into neural networks enables learning functions that satisfy invariances with respect to subsets of inputs. For instance, when learning generative models using neural networks, it is advantageous to encode the conditional independence structure of observed variables, often in the form of Bayesian networks. We propose the Structured Neural Network (StrNN), which injects structure through masking pathways in a neural network. The masks are designed via a novel relationship we explore between neural network architectures and binary matrix factorization, to ensure that the desired independencies are respected. We devise and study practical algorithms for this otherwise NP-hard design problem based on novel objectives that control the model architecture. We demonstrate the utility of StrNN in three applications: (1) binary and Gaussian density estimation with StrNN, (2) real-valued density estimation with Structured Autoregressive Flows (StrAFs) and Structured Continuous Normalizing Flows (StrCNF), and (3) interventional and counterfactual analysis with StrAFs for causal inference. Our work opens up new avenues for learning neural networks that enable data-efficient generative modeling and the use of normalizing flows for causal effect estimation.","The authors propose a novel method for constructing structured neural networks (strNN) that are able to respect causal independencies between variables. Formal constraints for weight mask creation are discussed and evaluated empirically for an exact method and a greedy algorithm. The conditioned strNN are furthermore leveraged for conditioning autoregressive flow models. Practical application successfully is demonstrated over multiple synthetic datasets with comparisons between several baseline models, with and without the use of adjacency information. To the best of my knowledge related work is discussed sufficiently in the context of causal density estimation. 1. The authors propose a novel method for constructing structured models via weight masking that integrates seamlessly with existing neural architectures while respecting the strict independence assumptions of causal models. Preconditions and assumptions for application of the approach, specifically knowledge about the causal graph structure, are clearly stated.

2. To tackle the infeasibility of exact mask creation on larger graphs a greedy algorithm is proposed and its practical application is demonstrated.

3. The authors additionally include experiments on binary MNIST data, for which the underlying causal structure is unknown. By imposing a causal graph structure which promotes the usage of spatially local information, the authors improve performance for non-synthetic data over baselines. The example shown in Figure 1 decomposes the network into two separate networks. However, constructing the displayed a network would not require a complicated mask decomposition, but could be trivially solved by constructing two independent networks with constrained layer width. Only by inspecting the example provided in the appendix it is revealed that the presence of split-structures leads to shared weights between the outputs. 1. As causal mechanisms are often assumed to be independent in causal literature, I would like to ask the authors about the benefits or downsides of allowing for such shared weights within the network.

2. Furthermore, I would like to ask the authors to discuss possible simplifications for specific causal structures, e.g. in the case of independent causal mechanisms as seen in Figure 1.

Overall the idea is pretty good with a clever way of enforcing the causal independencies. However, all of this is assuming that the networks can leverage shared information between different mechanisms. If that is not the case then you could just train an independent density estimator for every single edge and (from a purely causal perspective) the problem becomes trivial to solve. No concerns here",397,0,6,0.8015,0.1236507937,0.8783051968000001,215,27.0767,0.1898,neurips,0.0,3,3,3,3,factual,4,4,70,polite,4,positive,4,low,4,4,4,4,partially factual,4,4,85,polite,5,positive,5,low,3.0,4.0,4.0,4.0,factual,4.0,5.0,80.0,polite,4.0,positive,5.0,none,3,4,4,3,factual,4,4,80,polite,5,positive,5,low,3,4,4,4,partially factual,4,3,85,polite,5,positive,4,low
172,Reviewer-Wq9i,Structured Neural Networks for Density Estimation and Causal Inference,"Injecting structure into neural networks enables learning functions that satisfy invariances with respect to subsets of inputs. For instance, when learning generative models using neural networks, it is advantageous to encode the conditional independence structure of observed variables, often in the form of Bayesian networks. We propose the Structured Neural Network (StrNN), which injects structure through masking pathways in a neural network. The masks are designed via a novel relationship we explore between neural network architectures and binary matrix factorization, to ensure that the desired independencies are respected. We devise and study practical algorithms for this otherwise NP-hard design problem based on novel objectives that control the model architecture. We demonstrate the utility of StrNN in three applications: (1) binary and Gaussian density estimation with StrNN, (2) real-valued density estimation with Structured Autoregressive Flows (StrAFs) and Structured Continuous Normalizing Flows (StrCNF), and (3) interventional and counterfactual analysis with StrAFs for causal inference. Our work opens up new avenues for learning neural networks that enable data-efficient generative modeling and the use of normalizing flows for causal effect estimation.","In this paper, the authors present a neural network architecture that can fulfill the bayesian DAG conditional independencies needed for normalized density estimation.
In this work, the authors start from a binary lower adjacency matrix that encodes the independencies of a bayesian network DAG. Then they introduce a factorization of the global adjacency matrix into L adjacency matrices, which can be used as masks on each layer. This construction allows neural networks to be trained for a normalized density estimation task.
The authors introduce an heuristic to exactly factorize the adjacency matrix for the different layers using two objective functions.
With this building block the authors proceed to create a normalizing flow architecture that respects the independency restrictions end-to-end.  The authors then compare their approach empirically on different task against MADE, a neural density estimator that allows general dependencies for a given random variable ordering.  I found the paper insightful, and the results show that the approach is beneficial. The paper is technically sound and easy to read. The results showing an improvement in data efficiency for a given negative likelihood are also very interesting.

The introduction of the normalizing flow approach and the comparison in the causal setting are also nice additions that can have impact in the broader community.

The experiment on the sample quality shows the benefit of restricting the dependencies in the network as it cuts paths for noise in other random variables (and feature transformations) to propagate through the network. The major weakness of this paper is the limited empirical section in comparison to other papers in this domain. This can cause readers to wonder if the benefits of the new approach as density estimators are not significant for other datasets.
A broader comparison on other datasets would make the paper more robust. 

Also and I'm considering this as a minor weakness in my review, is that the method although insightful does not provide a way to obtain the global adjacency matrix.

 As I was reading the paper, my first thought would be that you would explore the possibility of discovering the dependencies for a given order. 
Here one can start with a dense adjacency matrix, train the network, clip nodes in the layers according to Lottery Ticket Hypothesis, and propagate the masks forward, i.e., multiplying all the masks to get the adjacency matrix. As you are clipping, the adjacency matrix is guaranteed to either be the same or introduce independencies. 
At that point, you can even use your factorization algorithm again to obtain a network with more/other nodes active while still respecting the new independencies. 
I'm wondering if you explored similar ideas during your research?
 The main limitations of the approaches presented are inherited from the restrictions on ordered models, e.g., marginalization and map queries are intractable for the general case. This is not mentioned in the paper. 

There are no potential negative societal impact to this work.",484,0,0,0.7857000000000001,0.0355132962,0.8869557381000001,215,36.2197,0.1669,neurips,0.0,4,4,4,4,factual,4,4,90,polite,4,positive,4,low,4,4,4,4,factual,4,4,85,polite,5,positive,5,moderate,3.0,5.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,5.0,none,3,4,4,4,factual,4,4,85,polite,5,positive,5,low,3,4,4,4,partially factual,4,4,85,polite,5,positive,5,low
101,Reviewer-ST3b,LLM Censorship: The Problem and its Limitations,"Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.","This paper investigates the theoretical limitations of the current external censorship mechanisms in LLMs from the view of computing theory. Given these inherent limitations, the authors argue that LLM censorship should be addressed more as a security problem than a machine learning problem. - Trendy topic
- A novel perspective to study LLM censorship - Implications can be extended
- Readability can be improved In this paper, the authors first focus on the semantic censorship mechanisms, proving that the current mechanisms cannot reliably detect if LLM output is ""semantically impermissible."" They further show that such limitations are inherent and can extend beyond semantic censorship mechanisms by designing Mosaic prompts.

Overall, the authors study a trendy topic and offer a novel perspective to understand LLM censorship. However, I have the following concerns.

- The authors prove the impossibility of semantic censorship using string transformation by showing how the transformed string might break the ""invariance of semantic censorship."" Here, I have some doubts regarding the invariance property. In my opinion, the semantics of a string often change after the transformation. Thus, it is reasonable for the transformed string to bypass semantic censorship mechanisms. Moreover, LLMs do not necessarily output harmful texts with the transformed string. Why does the invariance property hold? Is this property an important goal considered by LLM censorship developers when designing their mechanisms?

- Implications can be extended. It appears to me that the current implication discussion stops at showing LLM censorship is more of a security problem than a machine learning problem. What are the direct implications for model developers when building censorship? Are there any defensive measures against the Mosaic prompts? The authors only briefly mention that there are standard approaches, such as access controls and user monitoring, to build censorship from the security view. However, there is no further analysis showing that these approaches can indeed overcome the theoretical limitations of current external censorship mechanisms and surpass them in censorship performances.

- Readability can be improved. Many sentences are too long and difficult to read. For example, ""Thus, we can understand censorship as a method of determining permissibility of a string and censorship mechanisms can be described as a function, f(x), restricting the string x to the set of permissible strings P by transforming it to another string x' ∈ P if necessary, e.g. x' ='I am unable to answer.'""",394,0,0,0.787,0.0838709677,0.8256777525000001,47,29.8058,0.1199,iclr,0.0196078431372549,2,4,2,2,factual,3,4,60,neutral,3,neutral,2,moderate,4,3,4,4,partially factual,4,4,75,polite,5,neutral,4,moderate,2.0,3.0,4.0,3.0,factual,4.0,4.0,70.0,polite,5.0,neutral,3.0,low,3,3,4,4,factual,4,4,80,polite,5,neutral,4,low,2,3,3,4,partially factual,3,3,70,polite,5,neutral,4,low
101,Reviewer-xHLz,LLM Censorship: The Problem and its Limitations,"Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.","This paper explores some of the theoretical limitations of LLM censorship, the problem of identifying permissible inputs and outputs to language models. In particular, the paper focuses on the limitations of semantic censorship, or filtering of strings based on their meaning. First, the paper shows that determining whether a “program” output by an LLM is permissible is an undecidable problem. Then, the paper discusses the impossibility of semantic censorship by showing that strings can undergo transformations which preserve their semantic meaning but are otherwise unintelligible except to a user who knows how to invert the transformation. Finally, the paper introduces Mosaic Prompts, a way of breaking up an impermissible prompt into permissible pieces. This paper’s primary strength is that it identifies an important issue to focus on that has been unexplored in the literature - what are the theoretical limits on the ability to filter LLM inputs or outputs based on their semantic meaning? The paper is a good exposition of this problem and the theoretical settings it considers highlight some important limitations for the task. The figures and tables also do a good job of clarifying some of the concepts in the text. Overall, the authors’ assertion that syntactic censorship is likely to be more successful than semantic censorship is well-taken from this work. This paper’s primary weakness is the number of assumptions and limitations that come into the different theoretical treatments that the paper covers. First, the paper itself admits that the treatment of Rice’s theorem for programs on Turing Machines is not generally applicable to the bounded inputs and outputs case of LLMs. Second, in the section 2.2 on the invertible transform, I believe there may be a flaw in the reasoning of the proof. Under assumption 1, the authors assume that the model is capable of following instructions such that it can produce the transformation $g$. This assumption is explicitly stated. It seems that the proof also requires that the LLM (or corresponding companion LLM that is doing censorship) is unable to compute the inverse transformation $g^{-1}$. If it were, then it could check the semantics of the un-transformed string for permissibility. This assumption weakens the power of the impossibility result in my opinion. Finally, while I think that the Mosaic Prompt approach is interesting, I do think the paper underestimates the LLM’s ability to attend to previous prompts. While in the mosaic approach the model is likely to answer early prompts, it is conceivable that once enough of the pieces of the impermissible prompt are present, one would be able to detect the impermissibility of the conversation overall. Does the impossibility result in Section 2.2 require an assumption that $g^-1$ is not computable by the permissibility model?

Is the problem space simplified at all by considering the compositionality of strings? For example, if there is an impermissible substring within a larger string, does that make the larger string automatically impermissible as well?

Does something like “fuzzy” permissibility fit into this framework at all? For example, many prompts and outputs would be considered “borderline” or have some level of “toxicity” if sent to a human rater, rather than a bright-line permissible vs. not rule. Does that make the problem any easier or harder?",537,0,0,0.7747,0.1567073171,0.8508368134000001,47,36.7413,0.0657,iclr,0.01,2,5,4,3,factual,4,4,80,polite,4,neutral,4,none,3,5,4,5,5,5,5,85,polite,5,neutral,5,low,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,neutral,3.0,none,3,4,4,3,factual,4,4,80,polite,5,positive,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
25,Ravi-Dadlani,Case Report: Sciatic nerve schwannoma - a rare cause of sciatica,Herein we report a rare case of a sciatic nerve schwannoma causing sciatica in a 69-year-old female. Sciatic nerve schwannoma is a rare entity. It should always be considered as a possible cause of sciatica in patients that present with symptoms of sciatica with no prolapsed disc in the lumbar spine and a negative crossed straight leg raise test. Timely diagnosis and complete excision of the lesion leads to complete resolution of the symptoms of such patients.,"Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I congratulate the authors on an interesting case report. It is a well written report but I would like to suggest a few additional points.  Since several such case reports have been published earlier, it would be interesting if the authors could add a 'review of literature'. A single tabulated format with some interesting characteristic, such as  the exact location of the tumor along the course of the sciatic nerve. It would also be interesting to see a small table with other 'sciatica mimicks'. Personally I have seen lumbosacral plexus tumors presenting with sciatica.  The article may be accepted for indexing with these minor additions.",172,0,0,0.7861,0.0818681319,0.7953575253,1,32.73,0.1213,f1000,0.0099009900990099,4,3,4,3,unfactual,3,3,70,neutral,4,positive,1,low,5,5,4,5,factual,5,5,95,polite,5,positive,5,none,3.0,4.0,4.0,4.0,factual,4.0,5.0,80.0,polite,4.0,positive,3.0,none,4,5,3,4,factual,4,4,80,polite,5,positive,4,low,3,4,3,4,factual,4,4,85,polite,5,positive,4,low
157,Reviewer-Zg7q,Regularization properties of adversarially-trained linear regression,"State-of-the-art machine learning models can be vulnerable to very small input perturbations that are adversarially constructed. Adversarial training is an effective approach to defend against it. Formulated as a min-max problem, it searches for the best solution when the training data were corrupted by the worst-case attacks. Linear models are among the simple models where vulnerabilities can be observed and are the focus of our study. In this case, adversarial training leads to a convex optimization problem which can be formulated as the minimization of a finite sum. We provide a comparative analysis between the solution of adversarial training in linear regression and other regularization methods. Our main findings are that: (A) Adversarial training yields the  minimum-norm  interpolating solution in the overparameterized regime (more parameters than data), as long as the maximum disturbance radius is smaller than a threshold. And, conversely, the minimum-norm interpolator is the solution to adversarial training with a given radius. (B) Adversarial training can be equivalent to parameter shrinking methods (ridge regression and Lasso). This happens in the underparametrized region, for an appropriate choice of adversarial radius and zero-mean symmetrically distributed covariates. (C) For $\ell_\infty$-adversarial training---as in square-root Lasso---the choice of adversarial radius for optimal bounds does not depend on the additive noise variance. We confirm our theoretical findings with numerical examples.","This paper studies the connection between adversarial training and regularization methods in linear regression problem. Simulation studies are provided to justify the correctness of their theoretical observations. The authors conducts a comprehensive study on the relationship between adversarial training and regularization methods in linear regression setup. The writing is clear and easy to understand. My major concern towards this paper is the limit of its contribution. While the analysis is comprehensive, it is only restricted to linear models. Considering that the adversarial training is more commonly used in neural networks rather than linear models in reality, the contribution is limited. The authors are encouraged to add more discussions on neural networks.

In addition, the following paper considers the connection between regularization and adversarial robustness:

Jakubovitz, Daniel, and Raja Giryes. ""Improving dnn robustness to adversarial attacks using jacobian regularization."" Proceedings of the European Conference on Computer Vision (ECCV). 2018.

Please cite this paper and compare it to the submission from intuition aspect. Is it possible to extend the analysis to two-layer neural networks? NA",173,0,2,0.7644000000000001,0.1020337302,0.8797743320000001,221,19.2375,0.2191,neurips,0.0,1,3,2,1,partially factual,2,2,40,polite,2,positive,3,high,5,5,4,5,factual,5,5,95,polite,5,neutral,5,low,2.0,5.0,4.0,3.0,factual,4.0,4.0,80.0,polite,4.0,neutral,3.0,none,3,4,3,3,factual,4,4,70,polite,4,neutral,3,low,3,4,3,4,factual,4,4,85,polite,5,neutral,4,low
157,Reviewer-6WVQ,Regularization properties of adversarially-trained linear regression,"State-of-the-art machine learning models can be vulnerable to very small input perturbations that are adversarially constructed. Adversarial training is an effective approach to defend against it. Formulated as a min-max problem, it searches for the best solution when the training data were corrupted by the worst-case attacks. Linear models are among the simple models where vulnerabilities can be observed and are the focus of our study. In this case, adversarial training leads to a convex optimization problem which can be formulated as the minimization of a finite sum. We provide a comparative analysis between the solution of adversarial training in linear regression and other regularization methods. Our main findings are that: (A) Adversarial training yields the  minimum-norm  interpolating solution in the overparameterized regime (more parameters than data), as long as the maximum disturbance radius is smaller than a threshold. And, conversely, the minimum-norm interpolator is the solution to adversarial training with a given radius. (B) Adversarial training can be equivalent to parameter shrinking methods (ridge regression and Lasso). This happens in the underparametrized region, for an appropriate choice of adversarial radius and zero-mean symmetrically distributed covariates. (C) For $\ell_\infty$-adversarial training---as in square-root Lasso---the choice of adversarial radius for optimal bounds does not depend on the additive noise variance. We confirm our theoretical findings with numerical examples.","The paper studies adversarial training (AT) for linear regression for which the inner maximization problems has a closed form solution. They then attempt at relating the solutions to solutions of other optimization problems:

- They show that the minimum norm interpolator also minimizes the adversarial loss (iff the adversarial perturbation is sufficiently small)
- They show that adversarial training (under certain conditions) minimizes something closely related to the LASSO and ridge regression objective for $\ell_\infty$ and $\ell_2$ attacks respectively.
- They show that similarly to square-root LASSO, adversarial training does not need knowledge of the variance and they argue that this makes adversarial training a viable alternative.
 - It seems interesting to attempt connecting AT to sparse solutions
- The initial setup and the statements of the theorems are presented in a clean way
- Existing literature is well-covered
 - My main concern is that the theoretical claims are rather weak:
    - Concerning Thm. 1, l. 122 ""minimum-norm interpolators as the outcome of adversarial training"" seems a bit of a stretch, since it is not *consistently* the outcome of adversarial training (we might be able to find a minimizer of $R^{adv}$ that is *not* a min norm interpolator). AT would imply minimum-norm interpolator if the minimizer of $R^{adv}$ was unique, but this cannot be the case since LASSO is not unique in general.
    - Prop. 2 is concerning minimum norm interpolator (so not necessarily obtainable with AT!). What makes this statement interesting for adversarial training if we need to obtain the solution through other means?
    - Prop. 4 seems to not directly relate AT to LASSO/ridge regression. Whats is the conclusion of Prop. 4? 
    - Thm. 2 exists to show that AT can replace sqrt-root LASSO. You are comparison with Lasso though – doesn't the bound have a bias in comparison with sqrt-root LASSO (eq. 10 of \[29\]). The main feature of AT seems to be the claim that $\delta^*$ is invariant to rescaling of $\varepsilon$. Can you explicitly make $\delta^*$ in Thm. 2 independent of $\varepsilon$? (currently this is not the case in theorem statement)

Comments:

- Prop. 5 maybe pick a different variable than $p$ (already used for dimensionality)
- l. 144 should have been $\delta$ instead of $\delta_{train}$?
- Maybe write ""a solution"" in l. 144 instead of ""the"".
- l. 179: Please describe the dataset in the appendix or provide a more direct pointer to \[18\].
 - Thm. 1: $\bar \delta$ depends on the $\ell_\infty$-norm regardless of the choice of norm in the adversarial training? This seems potentially loose – could you comment on it?
- Prop. 2: Do you still rely on full row rank in Prop. 2? 
- l. 158-159: Isn't the claim in \[17\] about $\ell_2$ minimum norm while your Prop. 7 is a claim about choice of norm in the adversarial training? 
- Figure 3: Could you label the plot to explain the colors? I don't understan how to interpret the plot.
- Figure 4 / l. 179: what is ""regularization paths""? 
- What assumption breaks in Prop. 4 since it is no longer able to predict similarly after $\delta$ is made sufficiently small (as demonstrated in Fig. 4)?
 N/A",528,3,6,0.739,0.0506906288,0.9212126732,221,49.9975,0.7282000000000001,neurips,0.0,4,4,4,4,factual,4,4,80,polite,5,positive,5,low,5,5,4,5,factual,5,5,85,polite,5,negative,5,moderate,2.0,4.0,4.0,3.0,partially factual,4.0,3.0,60.0,polite,5.0,neutral,5.0,low,4,4,4,4,factual,4,4,85,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
157,Reviewer-CYXN,Regularization properties of adversarially-trained linear regression,"State-of-the-art machine learning models can be vulnerable to very small input perturbations that are adversarially constructed. Adversarial training is an effective approach to defend against it. Formulated as a min-max problem, it searches for the best solution when the training data were corrupted by the worst-case attacks. Linear models are among the simple models where vulnerabilities can be observed and are the focus of our study. In this case, adversarial training leads to a convex optimization problem which can be formulated as the minimization of a finite sum. We provide a comparative analysis between the solution of adversarial training in linear regression and other regularization methods. Our main findings are that: (A) Adversarial training yields the  minimum-norm  interpolating solution in the overparameterized regime (more parameters than data), as long as the maximum disturbance radius is smaller than a threshold. And, conversely, the minimum-norm interpolator is the solution to adversarial training with a given radius. (B) Adversarial training can be equivalent to parameter shrinking methods (ridge regression and Lasso). This happens in the underparametrized region, for an appropriate choice of adversarial radius and zero-mean symmetrically distributed covariates. (C) For $\ell_\infty$-adversarial training---as in square-root Lasso---the choice of adversarial radius for optimal bounds does not depend on the additive noise variance. We confirm our theoretical findings with numerical examples.","This paper investigates adversarial training of linear regression. The authors compared the solution of adversarial training and other regularization frameworks (minimum-norm interpolating, ridge regression, Lasso and square-root Lasso), and established close relations between adversarial training and other methods under certain conditions depending on the disturbance radius and over/under-parameterization. The authors also consider extending the result to more general loss function for linear model. 1.	The paper provides valuable insights on the relation between adversarial training and other regularization frameworks for linear regression, which contributes to the area of robust learning. The analysis is sound.
2.	The paper provides good background knowledge and details in their work. 
3.	The paper is well-organized and easy to follow overall.
 1.	In the abstract, the authors claim that adversarial training can be equivalent to parameter shrinkage methods (like ridge regression and Lasso). However, from Proposition 4, it seems the two frameworks are not equivalent, since the regularization term in the equation of Proposition 4 equals $\delta^2\left\| \beta\right\|^2 + c\delta\left\| \beta\right\|$ for some constant $c$. I am curious about how the quadratic term can affect the solution, or how close the adversarial training solution is from the parameter shrinkage solution.

2.	In the numerical experiment, the authors have not mentioned how the adversarial training is carried out in these datasets. From the code in the supplementary materials, it seems the adversarial samples are generated by the PGD attack. Please consider including more details in the paper. Also, does PGD generate sufficiently strong attacks for linear regression?
 Here are some additional questions/comments:

1.	$\sigma_1$ and $\sigma_n$ in line 126 are undefined.

2.	The authors claim in line 151 and Remark 2 that the model becomes robust as feature dimension $p$ grows, which seems not precise to me. The authors suggest that the threshold $\bar{\delta}$ increases faster, but this only guarantees that the optimal solution of adversarial training and minimum-norm interpolator agree, which does not necessarily mean more robustness. Does the risk $\mathcal{R}^{\text{adv}}$ decrease as feature dimension $p$ grows? 

3.	The paper investigates the situation where the sample features $x_i$’s are disturbed in linear regression. In applications, it is also very common that the target $y_i$’s are disturbed.  
 The authors have adequately addressed the limitations.",368,0,7,0.7637,0.1577767857,0.9543603063,221,30.1542,0.1719,neurips,0.0120481927710843,4,5,4,4,factual,4,4,85,polite,4,positive,4,low,4,5,5,5,partially factual,5,5,85,polite,5,neutral,5,low,2.0,4.0,4.0,3.0,factual,3.0,4.0,80.0,polite,5.0,neutral,5.0,none,4,4,4,4,factual,5,5,85,polite,5,neutral,5,low,3,5,4,4,partially factual,4,4,85,polite,5,positive,5,low
10,Reviewer-7Q1Z,An interpretable error correction method for enhancing code-to-code translation,"Transformer-based machine translation models currently dominate the field of model-based program translation. However, these models fail to provide interpretative support for the generated program translations. Moreover, researchers frequently invest substantial time and computational resources in retraining models, yet the improvement in translation accuracy is quite limited. 
To address these issues, we introduce a novel approach, $k\text{NN-ECD}$, which combines $k$-nearest-neighbor search with a key-value error correction datastore to overwrite the wrong translations of TransCoder-ST. This provides a decision-making basis for interpreting the corrected translations. Building upon this, we further propose $k\text{NN-ECS}_{m}$, a methodology that employs a distributed structure with $m$ sub-datastores connected in series,  utilizing $m$ diverse experts for multi-round error correction. Additionally, we put forward a unified name rule, encouraging the datastore to focus more on code logic and structure rather than diverse rare identifiers. Our experimental results show that our approach improves the translation accuracy from 68.9\% to 89.9\% of TransCoder-ST (for translation from Java to Python). This error correction method augments program translation, overcoming the inherent limitations of Transformer-based code translation models, such as resource-intensive retraining requirements and uninterpretable outcomes.","This paper focuses on improving Java $\rightarrow$ Python translation using error correction, rather than retraining the underlying translation model. They devise two error correction techniques (kNN-ECD and kNN-ECS) based on kNN-MT, which entails retrieving from datastores. To build this datastore, they first collect 82,665 Java functions and generate high-quality unit tests for them using EvoSuite. Then, they use TransCoder-ST to translate the Java functions paired with the unit tests to Python. From these they extract pairs of the form (failed Python function, successful Python function), which are then used to build (a) datastore(s). The datastore is organized based on two components: (1) (key, value) pairs and (2) (key, value) $\rightarrow$ token. The query to this datastore is formed by using the last decoder hidden states corresponding to the full source input (i.e., failed Python function) and partial target (i.e., possible correction generated so far). To reduce noise caused by diverse rare identifiers during retrieval, they apply the unified name rule. In kNN-ECD, only one round of correction is performed. In kNN-ECS_{m}, they perform $m$ rounds of correction, with m smaller datasets (after segmenting the large datastore into $m$ parts). Results show that kNN-ECS outperforms kNN-ECD as well as a vanilla TransCoder-ST with no error correction. - The proposed approach successfully corrects errors to a certain extent, without retraining the model or re-sampling the model many times, which is usually done in self-repair.
- The idea of multi-round error correction and the analysis done with this, varying the number of rounds, and analyzing the performance for each of these, is quite interesting and may inspire future work. - Evaluation is based on translated unit tests generated by the same model that the authors are trying to correct translation errors for. Therefore, the unit tests that are generated could be wrong, and so the evaluation is unreliable. Evaluation should be performed based on a separate, high-quality set of unit tests. Possibly datasets like HumanEval-X would be better alternatives here.
- The experiments and results are fairly limited. First, the authors focus on only Java $\rightarrow$ Python and fail to consider other languages or even the reverse direction of Python $\rightarrow$ Java. Next, Table 1 seems to be missing many baselines and other models to which their approach should be compared. Namely, the only baseline is the pure TransCoder-ST model, which is only the starting point of their approach. The authors discuss that the main advantage of their approach is that no retraining is required, so it would be important to see how their approach performs relative to a retraining-based one. For this, they could have simply fine-tuned TransCoder-ST on the error correction pairs they collected for building their datastore. Next, latency is not measured, even though the authors discuss latency in related work. It seems that retrieving from a large datastore or retrieving multiple times from smaller datastores could take a long time, so it would be important to understand how the overall latency compares to other approaches. Finally, the authors do not report results on state-of-the-art code models, so it is difficult to assess the true value of their approach.
- The authors present the unified name rule as a novelty; however, I do not find this to be that novel, given the work the authors discussed in the ""Related Work"" section.
- There are multiple aspects of the paper that are not clear.  Please see the ""Questions"" section. 1) Based on what is written in the paper, 10 Python functions with unit test cases are generated for each Java function. So, you have $(func_1, tests_1), (func_2, tests_2), (func_3, tests_3)... (func_{10}, tests_{10})$. Success is measured by executing the tests in some Python environment, where $func_i$ is considered a success if it passes all tests in $tests_i$. By this definition, suppose $func_1$ fails $tests_1$ and $func_2$ passes $tests_2$.  The paper states ""we combined the first failed Python function with the first successful Python function to form an error correction language pair."" Based on this, it seems that $(func_1, func_2)$ would be considered an error correction pair. However, there is no guarantee that $tests_1 = tests_2$, meaning that the two functions could be executed against different test suites. Therefore, $func_2$ may not actually correspond to a correction of $func_1$. Could this please be clarified? 
2) The ""interpretable decision-making"" idea is not clear to me. It seems that you are suggesting that the reasoning for predicting a specific token at a timestep $t$ can be attributed to the source and partial target function predicted so far. This is also the case for transformer-based decoders, so it is not clear to me how your approach can be considered more interpretable than a transformer as they claim.
3) In 3.2, you state that the hidden representations from the last layer of the decoder are used to build the (key,value) and query. My understanding is that the (key ,value) and query correspond to (failed Python function, partial Python function). It is not clear to me how there would be a decoder state corresponding to the failed Python function since that is passed into the encoder (Figure 1). Or is (failed Python function, partial Python function) meant to actually only represent the representation of the partial Python function generated so far, as labeled as ""Key"" in Figure 1? 
4) You claim that the improvement of ECS over ECD is ""primarily attributed to its distributed structure, which includes diverse datastore variants."" However, you do not seem to have multi-round experiments with ECD in which you repeatedly perform retrieval/correction on the same large datastore up to $m$ times. Therefore, isn't it possible that the advantage is actually from doing iterative code correction rather than the distributed nature of it?",949,0,0,0.7745000000000001,0.0229609929,0.8705494404,60,49.7816,0.2416,iclr,0.0,2,4,4,3,partially factual,4,4,82,neutral,4,negative,4,low,4,5,4,4,factual,4,4,85,polite,5,neutral,5,low,2.0,4.0,4.0,3.0,partially factual,4.0,3.0,60.0,polite,5.0,neutral,5.0,low,4,5,5,4,factual,5,5,90,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
145,Reviewer-AWzJ,Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning,"Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.","This work considers training an agent without online interaction or abundant offline data but only with the reward function of the target environment. Borrowing the idea of rehearsal from the cognitive mechanism, this work proposes policy rehearsal. In detail, this work hopes to train an array of models to imitate the target model. Theoretical analyses indicate that the target environment performance gap between the policy trained in these imitated models and the optimal policy can be bounded by three terms, which are further summarized as diversity and eligibility. Based on these two criteria, this work proposes two corresponding reward functions for training imitated models and then uses these models to train the policy. Also, the proposed ReDM can easily combined with offline datasets. Extensive results show the effectiveness of ReDM. - The ideas about the setting are novel and important, minimizing interaction with the environment as much as possible is an important problem in the RL community. Also, introducing rehearsal into RL is novel and enlightening.

- The writing of Sec 3.2 is clear and solid, I have roughly read all the proofs, which are written quite clearly.

- The proposed ReDM utilizes two novel terms for learning an imitated model, which is interesting and helpful.

Currently, my evaluation of this paper is really Boardline. If authors can address my concerns in Weaknesses and Questions, or point out what I have misunderstood, I'd like to update my scores accordingly. Also, I will keep active in the following discussion stage. - The connection between diversity and controlling $\epsilon_e, \epsilon_a$ is unclear. For example, if all environments are the same, i.e., there is no diversity, it is obvious that $\epsilon_a=0$ is minimal. There also needs more explanation about why $\epsilon_e$ can be controlled via diversity.

- Based on the previous points, one of my major concerns is why the proposed methods can help optimize the gap calculated in Thm 3.3. The authors have summarized the three errors in Thm 3.3 as diversity and eligibility, which indeed provides insights for analyzing this problem. But I think a more direct connection, like whether the objective in Sec 3.3 can be proven to directly control the three errors in Thm 3.3, will make the analyses more solid.

- In experiments, providing the results directly trained in the target environments as the reference will better show the results.

- Lack of some related works, like utilizing model-based methods for improving generalization \[1-3\], and finding diverse skills for unsupervised RL \[4-6\] as this work hopes to find diverse models.

\[1\] Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning

\[2\] Task Aware Dreamer for Task Generalization in Reinforcement Learning

\[3\] The Benefits of Model-Based Generalization in Reinforcement Learning

\[4\] Diversity is All You Need: Learning Skills without a Reward Function

\[5\] Effective diversity in population based reinforcement learning - In my opinion, the considered setting is that the agent can only get the reward function of the target task but has no knowledge about the dynamic of the target task. Is it right? Given the offline data, it is understandable that the agent can learn the dynamic to some degree. But without an offline dataset, it seems that there is no idea for the agent to learn the dynamic of the target task. 

- Based on the previous question, I'm confused about the setting of Experiment 4.1 "" ReDM With no Interaction Data"". As there are no data about the environment and the agent can not interact with the environment, how does the agent to learn about the environment?

- As Unsupervised RL considers training an agent in the environment without reward, in my opinion, the setting in this work is like training an agent and models in the environment with reward but without dynamic. As the dynamic of the target environment will vary a lot, whether finetuning the agent (as well as the model) in the target environment with few steps will be more reasonable?

- About $r_e$ for Eligibility. The proposed method is to randomly sample N trajectories and estimate the biggest return. Is this inefficient as the state space and action space are continuous in experiments? Also, what is the choice of N in experiments?

- I'm curious about the performance of ReDM in the D4RL setting (Sec. 4.3) but without any Interaction Data.",720,5,0,0.7541,0.0956459436,0.9084495306,57,42.3274,0.0512,iclr,0.009090909090909,4,4,4,4,factual,3,4,80,polite,4,neutral,4,none,4,4,4,4,partially factual,4,4,88,polite,5,neutral,5,moderate,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,3.0,none,4,4,4,4,factual,4,4,85,polite,5,neutral,5,low,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
196,Reviewer-AkjD,ZeroP: Zero-Shot Quantization via Proxy Data,"Zero-shot quantization (ZSQ) is a promising approach for achieving low-bit constraint networks without relying on the original data (OD). However, due to the high cost and privacy concerns associated with OD, it is often scarce, leading to the unsatisfactory performance of ZSQ. Most ZSQ methods rely solely on synthetic data (SD) to mitigate this issue. In this paper, we propose a novel ZSQ framework, named ZeroP, that leverages publicly available data - proxy data (PD) - as a substitute for the OD. We first explore the impact of PD on the performance of current ZSQ methods over 16 different computer vision datasets and introduce a simple and effective PD selection method based on batch-normalization statistics(BNS) to select the optimal PD. We then apply ZeroP to three state-of-the-art pure-SD (using only SD) methods, achieving 7% to 16% improvements in accuracy for MobileNetV1 on ImageNet-1K in a 4-bit setting. Furthermore, we demonstrate the effectiveness of ZeroP on extensive models and datasets. For example, ZeroP achieves a top-1 accuracy of 72.17% for ResNet-50 on ImageNet-1K in a 4-bit setting, outperforming the SOTA pure-SD method by 3.9%. Overall, our results indicate that ZeroP offers a promising solution for achieving high-performance low-bit networks without relying on original training data and opens up new avenues for using publicly available data for data-free tasks.","The paper presents ZeroP, a novel approach for the Zero-Shot Quantization (ZSQ) task. The approach aims to investigate the potential gain of Proxy Data (PD) across 16 commonly used CV datasets. In addition, the paper introduces the BNS distance as a simple yet effective metric for selecting suitable PD for a specific task. - The paper introduces the BNS distance metric which provides a simple yet effective means to select suitable Proxy Data for a given task.
- The paper conducts thorough experiments showing that ZeroP outperforms existing pure-SD methods by a significant margin across diverse datasets.
- The work is relevant given the need for efficient methods in the ZSQ space without relying on original data. - The approach, while novel in certain aspects, leans heavily on established methodologies such as pure-SD. The introduction and utilization of Proxy Data, although effective, do not drastically deviate from methods previously explored in the domain of data-free tasks.
- The paper mainly focuses on 4-bit and 5-bit quantization, leaving questions about the performance and relevance of other bit quantizations. - The focus on 4-bit and 5-bit quantizations was evident, but it raises the question: what about other bit depths? Were experiments conducted with other bit quantizations, and if so, what were the results? Elaborating on this could provide a broader understanding of the system's applicability.",223,0,0,0.7581,0.1654220779,0.9028347731,54,34.8749,0.0999,iclr,0.0206185567010309,5,4,4,4,factual,5,5,70,polite,5,neutral,5,none,4,5,4,4,factual,5,5,85,polite,5,neutral,5,low,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,5.0,positive,3.0,none,3,4,4,3,factual,4,4,80,polite,5,positive,4,low,2,4,3,3,factual,3,4,78,polite,5,positive,4,low
196,Reviewer-qH2g,ZeroP: Zero-Shot Quantization via Proxy Data,"Zero-shot quantization (ZSQ) is a promising approach for achieving low-bit constraint networks without relying on the original data (OD). However, due to the high cost and privacy concerns associated with OD, it is often scarce, leading to the unsatisfactory performance of ZSQ. Most ZSQ methods rely solely on synthetic data (SD) to mitigate this issue. In this paper, we propose a novel ZSQ framework, named ZeroP, that leverages publicly available data - proxy data (PD) - as a substitute for the OD. We first explore the impact of PD on the performance of current ZSQ methods over 16 different computer vision datasets and introduce a simple and effective PD selection method based on batch-normalization statistics(BNS) to select the optimal PD. We then apply ZeroP to three state-of-the-art pure-SD (using only SD) methods, achieving 7% to 16% improvements in accuracy for MobileNetV1 on ImageNet-1K in a 4-bit setting. Furthermore, we demonstrate the effectiveness of ZeroP on extensive models and datasets. For example, ZeroP achieves a top-1 accuracy of 72.17% for ResNet-50 on ImageNet-1K in a 4-bit setting, outperforming the SOTA pure-SD method by 3.9%. Overall, our results indicate that ZeroP offers a promising solution for achieving high-performance low-bit networks without relying on original training data and opens up new avenues for using publicly available data for data-free tasks.","A simple but intuitive method that uses proxy data for ZSQ. To find the most suitable proxy data, a BNS-based distance is used where a small BNS distance indicates a higher relation between proxy data and original data. This method is simple but effective. It does provide a SOTA performance. Comprehensive and impressive experiment results.
This paper is valuable. The novelty of this paper appears constrained, particularly when considered with an earlier work that seemingly shares a similar idea.

\[1\] ""Is In-Domain Data Really Needed? A Pilot Study on Cross-Domain Calibration for Network Quantization,"" CVPR2021Workshop.

Note that \[1\] is an accepted paper, not a preprint paper. However, I can't find any reference to \[1\] within this manuscript. While it's not feasible to reference every related work, the conceptual overlap with \[1\] is pronounced. \[1\] primarily targets PTQ, but it does not involve real data and can be regarded as a ZSQ method.  And the only different point is the select metric.

I think this paper is valuable. However, more experiments for comparison are needed. See weaknesses",176,5,1,0.8331000000000001,0.2364035088,0.7975381613,54,44.2552,0.0529,iclr,0.021978021978022,0,5,2,0,partially factual,4,4,30,neutral,3,negative,3,none,3,4,4,3,partially factual,4,4,75,polite,5,positive,5,moderate,3.0,4.0,4.0,4.0,factual,4.0,4.0,80.0,polite,4.0,positive,3.0,none,2,4,3,3,factual,3,3,65,polite,4,positive,4,low,2,4,3,4,partially factual,3,3,75,polite,5,positive,4,low
8,Reviewer-oy34,AdaPlanner: Adaptive Planning from Feedback with Language Models,"Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the agent to plan and refine with fewer task demonstrations. Our experiments in the ALFWorld and MiniWoB++ environments demonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and 4.11% while utilizing 2x and 600x fewer samples, respectively. The implementation of AdaPlanner is available at https://github.com/haotiansun14/AdaPlanner.","Briefly summarize the paper and its contributions. This is not the place to critique the paper; the authors should generally agree with a well-written summary.

The paper proposes AdaPlanner, an LLM-based adaptive planner for text-based sequential decision-making tasks. The planner is adaptive in the sense that it can refine the generated plan/policy based on feedback. 

The contributions made in this paper include the following
1. interacting with the environment with LLM in the loop
2. a code-style prompt is engineered for LLMs to output a policy 
3. refining the LLM policy for the current task based on feedback
4. prompt tuning for new tasks based on previous interaction (termed skill discovery)

The proposed AdaPlanner is evaluated on two text-based sequential decision-making environments ALFWorld and MiniWoB++. Their experiments indicate that with feedback, LLMs can adapt the plan.
 
* The paper is well written.
* The paper focuses on extremely relevant and signifcant problems. 
 * I find the paper lacks significant details. Please see the next section for the list of questions.
* The paper employs sloppy mathematical notations.
* The paper lacks the rigor of scientific evaluation. 
* Paper misses all references to LLM-based approaches for planning with PDDL. The one that I find most relevant for code generation is ""Generalized Planning in PDDL Domains with Pretrained Large Language Models, Tom Silver, Soham Dan, Kavitha Srinivas, Joshua B. Tenenbaum, Leslie Pack Kaelbling, Michael Katz”
 
**Major**

1. How is the programmatic response from LLM converted to action responses? Did the conversion require manual intervention? For instance, Figure 2 has an indentation error which would result in a wrong plan. Were such indentation errors evaluated manually? Can authors provide a list of errors made by LLMs? 
1. In line 167, what does an alignment between ‘anticipated plan’ and environment mean? How does the AdaPlanner observe the alignment? 
1. Can authors provide details about the size of the task used in the prompt (for samples) vs the size of the task that was successfully solved by AdaPlanner? To establish the claim of sample efficiency, it is important to understand if the planner is able to efficiently plan for tasks that are significantly different from the prompts.
1. The X-axis in Figure 3 indicates `# Samples per task`. Is this the number of samples provided for each trajectory? Or sum?  
1. What was the length of plans or length of trajectories generated by AdaPlanner vs other approaches? To claim the effectiveness of the AdaPlanner, it is important to compare the length of successful trajectories.
1. For skill discovery, how is the solution converted to the skill? How are skills represented? How large is the skill memory?  Were the discovered skills included in the count of samples used for training as they are training samples for the next set of trajectories?
1. It is not clear how skills are filtered and what criteria are used for the evaluation and ranking of skills.
1. What is the connection between skill discovery and prompt tuning?
1. The success rate of ""With SD"" in Figure 4d looks significantly reduced from  Figure 4a. Were different settings used for theses experiments?
1. At various places, the paper mentions ""environment feedback"". In my opinion, this is a misnomer. The feedback is not from the environment. The environment just provides the next observation, the feedback is generated by the agent itself. And the use of observation to refine a plan or next action is quite standard practice in RL. I would highly recommend dropping the term feedback from the title. 
1. The use of term plan and policy is a little confusing. A plan is a sequence of actions. A policy is a mapping from states to actions. By this definition, the `solution()` function is as a policy. In preliminaries, the planning policy ($\rho$) is conditioned on a previous plan $P_t$. However, the appendix describes the refinement prompt using the assertion error (instead of `solution()`). Isn't the assertion error providing information about the policy (the `solution()` function)? So I am confused by the terminologies. Is the $\rho$ refined conditioned on the policy or the plan? The usage of these terms is also confusing in the Preliminary section. Request authors to precisely define the mathematical notations and highlight what they represent in the examples.

**Minor**

12. In line 387, there are extra curly braces.
12. The notation $\rho$ is used in line 73 but introduced much later.
12. As the context $c_t$ is defined as a sequence of action and observations from time step $0$ to $t$, it is not clear what $c_{>t}$ means (in line 116).  
12. Open-Loop system in Figure 1 should have an arrow going from env to planner with $o_1$.
12. Statement in Line 144 ""To generate a plan .."" looks like a repetition of Line 141 ""To generate an initial plan...""
12. In line 116, if $h_t$ is obtained from $c_t$ then would it not be captured in $c_{>t}$? An example of $h_t$ would help better understand the proposed update.
12. In line 73, as $\rho$ is defined using $\Delta(A^{T})$. But the length $T$ is not fixed. 
12. In line 73 $\rho$ is defined where a plan is conditioned only on observation and goal. However, later it is conditioned on the context, plan, and goal. 



 
* The evaluations are restricted to text-based sequential decision-making problems and task where the inadmissible actions do not cause drastic changes in the environment. On the contrary, inadmissible actions are like no-ops. Further, the paper does not present analysis of plan length. Hence, the analysis is limited to zero risk environments. 
* The claim made in the abstract about skill discovery mechanism enabling agent to plan with fewer task demonstration is not substantiated in the evaluations. Evaluation in Fig. 4d only established improvement in success rate, not sample efficiency. ",965,0,17,0.7161000000000001,0.0723501082,0.8610098362,215,54.1142,0.1104,neurips,0.0,5,4,5,5,factual,3,4,90,neutral,4,neutral,4,none,5,5,5,5,5,5,5,95,polite,5,neutral,5,none,4.0,4.0,3.0,3.0,partially factual,3.0,2.0,60.0,polite,4.0,neutral,4.0,low,5,5,5,5,factual,5,5,95,polite,5,neutral,5,none,3,4,4,4,partially factual,4,4,85,polite,5,neutral,5,low
