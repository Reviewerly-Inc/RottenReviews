{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a09ad5a1-2c02-4bc1-a60a-64238c6452ec",
       "rows": [
        [
         "0",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_eS3u",
         "1698243150596",
         "1699636093263",
         "6",
         "2",
         "3",
         "2",
         "3",
         "This work proposes LSTNet, a self-supervised method to establish reliable 3D dense correspondences irrespective of the input point clouds’ rotational orientation.\n\nSpecifically, LSTNet learns to formulate SO(3)-invariant local shape transform for each point in a dynamic, input-dependent manner. Each point-wise local shape transform can map the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor, which is passed to the decoder to reconstruct the shape and pose of the input point cloud. \n\nThe proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish dense point-wise correspondences via nearest point pairs between cross-reconstructed point clouds. The self- and cross-reconstruction training strategy is simple yet effective. \n\nLSTNet demonstrates state-of-the-art performance on 3D semantic matching when evaluated on the KeypointNet dataset and part segmentation label transfer when evaluated on the ShapeNet dataset. The performance of aligned shape pairs under the setting of I/I shows that other methods, such as CPAE, are much better than LSTNet. The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.\n\nLack of limitations.",
         "191",
         "0",
         "0",
         "0.7074",
         "0.09",
         "0.9708871841000001",
         "52",
         "16",
         "28.0536",
         "14.6186",
         "17.913",
         "16.0443",
         "17.8357",
         "0.1213",
         "78",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_jP4i",
         "1698652503617",
         "1699636093190",
         "5",
         "4",
         "3",
         "3",
         "2",
         "1) This paper proposes a self-supervised method to find semantically corresponding points for a point cloud pair;\n\n2）The main idea is to decouple a point cloud feature learning process into a SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms;\n\n3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method. 1) This paper is generally well-written;\n\n2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant\npoint-wise local shape transforms seems to be novel;\n\n3) Experimental results are good. 1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset. \n\n2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation. \n\n3) The running time and GPU memory cost is blurry for me;\n\n4) Please compare the proposed method with more recent papers, e.g., \\[SC3K: Self-supervised and Coherent 3D Keypoints Estimation\nfrom Rotated, Noisy, and Decimated Point Cloud Data\\]. Please refer to the weaknesses.",
         "215",
         "0",
         "0",
         "0.7009",
         "0.1601851852",
         "0.8842770457",
         "52",
         "11",
         "32.339",
         "14.0899",
         "17.5302",
         "15.9032",
         "16.5285",
         "0.1719",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_wiS9",
         "1698706547448",
         "1699636093122",
         "3",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces LSTNet, which leverages an SO(3)-equivariant encoder-decoder architecture(Vector Neuron Networks, VNNs) and proposes a novel function called local shape transform to further transform the learned features. The proposed method is validated on both the 3D keypoint transfer and part segmentation label transformer tasks. 1. The idea of cross-reconstruction for generating inter-object correspondences in a self-supervised way is interesting;\n\n2. The overall writing is good and the methodology part is well-organized and easy to follow. 1. The novelty of this work seems insufficient for ICLR. The whole pipeline heavily relies on VNNs and the main contribution I personally consider is the local shape transform and the self-supervised mechanism for correspondences.\n\n2. Regarding the local shape transform:\n   2.1. From 3.1.1, the SO(3)-invariant output is $\\mathbf{V}\\mathbf{U}^T \\in \\mathbb{R}^{C \\times C}$, while in 3.1.2, the obtained SO(3)-invariant features $\\mathbf{V} \\in \\mathbb{R}^{C^\\prime \\times 3 \\times N}$ have a different shape;\n\n   2.2 The authors claimed that the local shape transform transforms the global features to local ones. Regarding this, I have two questions. \n\n      2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer. \n\n      2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the \"global\" features by such a mechanism, the features turn to \"local\"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so)\n\n3. Regarding the experiments:\n    3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments;\n\n     3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.\n\n    3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., \\[1\\], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.\n\n   3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?\n\n4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration \\[2, 3, 4, 5\\] should also be discussed.\n---------------------------------------------\n\\[1\\]. Zohaib et al. SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data, ICCV 2023;\n\n\\[2\\]. Dent et al. PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors, ECCV 2018\n\n\\[3\\]. Ao et al. SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration, CVPR 2021\n\n\\[4\\]. Wang et al. You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors, ACM MM 2022\n\n\\[5\\]. Yu et al. Rotation-Invariant Transformer for Point Cloud Matching, CVPR 2023 See weaknesses.",
         "570",
         "7",
         "10",
         "0.7698",
         "0.0953869048",
         "0.8982679844",
         "52",
         "10",
         "49.1847",
         "9.5403",
         "12.0174",
         "11.8969",
         "11.5244",
         "0.050300000000000004",
         "77",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_a6Ps",
         "1698768293694",
         "1699636092942",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper attempts to register point cloud properties to their templates without precise correspondences and exact shape matching. To achieve this, the authors trained a local shape transform (LST) network that produces SO(3) invariant correspondences. The training is self-supervised. The experimental results on ShapeNet look nice. - Valid motivation. Unlike the abused topic, vanilla point cloud registration, the motivation stands and could potentially benefit practical usages.\n- The SO(3)-invariant network design intrinsically ensures robustness against rotations.\n- The joint usage of a global descriptor and a local descriptor makes sense and may help with classification and recognition directly.\n- The self-supervision scheme looks plausible by self and cross-reconstruction. My major concern is with the experimental setup. While the experiments on ShapeNet is common in the community and shows good result, I am in general doubtful whether such an approach could be really applied to the real world. \nIn motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. \\[Scan2CAD, CVPR 2019\\]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases. \n\nThe authors also take groundtruth keypoints and semantic segmentations from datasets for the experiments. In the real-world, however, obtaining such accurate high-level semantic information already requires a deep understanding of the point cloud, and its segmentation backbone may already be SO(3) invariant. This impairs the strength that the authors proposed. Following my points in the \"weaknesses\" section, I am curious about several relevant problems in the practical setup (i.e., scan to model). \n1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity? \n2. Will the network still be functional if the density distributions are different across input and output? \n3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?\n4. Would non-gt and/or biased key points and semantic parts be transferred properly?\n\nIt would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.",
         "412",
         "0",
         "5",
         "0.7920",
         "0.1400193798",
         "0.9250699282",
         "52",
         "10",
         "43.5803",
         "10.8007",
         "13.4756",
         "13.141",
         "11.9551",
         "0.129",
         "85",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "4",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_Frem",
         "1699350072271",
         "1699636092872",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a method of learning dense 3D correspondence between shapes in a self-supervised manner. Specifically, it is built on an existing SO(3)-equivariant representation. The input point clouds are independently encoded to SO(3)-equivariant global shape descriptor Z and dynamic SO(3)-invariant point-wise local shape transforms. Then the network is trained via penalizing errors in self- and cross- reconstructions via the decoder. The experiment validates the effectiveness of the proposed method. 1. The paper is in general well organized and easy to follow. \n2. The proposed method is straightforward and shown to be effective on the test data. 1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method. \n2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.\n3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?\n4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design. Please refer to the Weaknees part.",
         "290",
         "0",
         "7",
         "0.6900",
         "0.1242424242",
         "0.9471604824000001",
         "52",
         "3",
         "43.0465",
         "10.8574",
         "13.8",
         "13.106",
         "11.3839",
         "0.1864",
         "81",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "5",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_xDut",
         "1698437142685",
         "1699636121514",
         "8",
         "5",
         "4",
         "4",
         "3",
         "This paper is about multilingual federated prompt tuning for low-resource languages, bringing together federated learning and prompt-tuning techniques. This approach leverages parameter-efficient fine-tuning which preserves user privacy, and additionally, the authors introduce language distance in order to highlight the strengths of the proposed paradigm. The results show that the technique is parameter efficient and computationally beneficial, reducing by 99% the number of trainable parameters while increasing the performance on downstream tasks (XNLI, NC) of ~7% accuracy. This paper makes a contribution to the federated learning field showing how federated learning can be used to enhance the performance of language models while preserving user privacy. The experiments are well-designed and the results are convincing - added to extensive analyses in order to leverage the capabilities of the proposed paradigm, but also its limitations. Although the paper is generally well-structured, the title mentions `low-resource` languages. However, the two tasks leveraged are primarily on high-resource languages, rather than low-resourced language. I would suggest to the authors to include more tasks - there are many low-resource language datasets (for instance on African languages MasakhaNEWS, Masakhaner (1.0 and 2.0 - which have been cited by the way but not used), MasakhaPOS; Indic languages: https://github.com/AI4Bharat/indicnlp_catalog; etc) and tasks.\n\nThis is rather a highly recommended suggestion, that does not take away the contribution of the paper. Including them would strengthen the paper and be more in accordance with the title. The Aggregation formula is a bit confusing. Did you mean h_{global, t+1} = \\sum_{k=1}^{m} h_{k, t}? Because the `t+1` on the last term does not make sense to me.",
         "262",
         "1",
         "0",
         "0.7963",
         "0.1664583333",
         "0.9397115707",
         "52",
         "13",
         "34.7123",
         "12.4236",
         "15.2872",
         "14.0992",
         "14.6228",
         "0.25730000000000003",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_E7Lk",
         "1698484432194",
         "1700794322411",
         "1",
         "5",
         "1",
         "2",
         "2",
         "The paper introduces a finetuning paradigm that combines federated learning (FL) with prompt tuning for multilingual finetuning on certain, with the goal to preserve the privacy of the local data used for the finetuning job. The results show better performance in certain classification tasks, such as New Classification and XNLI. - Federated learning have recently gained good traction, the paper is a good application of it in the tasks of finetuning LLM. The paper chooses to use prompt tuning instead of full tuning to save costs, as well as to avoid overfitting on small data.\n- The method produces better performance on the 2 classification tasks compared to baselines - The proposed is a very trivial combination of federated learning and prompt tuning, which both are established methodology in their own realm. There is no novelty, such as modification or adjustment to the method that may have give a better results. In other words, people with an objective to do federated learning for privacy purpose can easily come up with prompt tuning as a solution to reduce costs.\n- Though it may have implicitly inferred by the concept of FL, the paper did not mention why and how federated learning helps with privacy and in which case one should use FL for their application.\n- The purpose of the task of multilingual finetuning in this case, is not warranted use case of privacy preservation.\n- There is no reported evidence that privacy is actually preserved. Such as whether the final model memorize the local data.\n- There are better parameter-efficient finetuning methods, such as LORA/QLora, that the authors should conduct experiments on and do comparision with prompt tuning.\n- The results show prompt tuning are much worse than full-federated tuning, thus casting doubt if the cost-saving is worth it.\n- Other generative and knowledge-based tasks, such as QA, translations and summarizations should be performed.\n\n**I have read the author responses and I advocate for a strong reject, below are reasons:**\n\n* I mentioned the paper has fundamental problems with originality, novelty, where the paper uses an unrelated existing and non-novel method designed for a different problem (fed-learning) to solve a low-resource \"privacy\" problem that does not make sense or exist yet, in which the method itself much worse than standard training. \n* Instead of addressing the scientific issue, the authors distracted away by pressing that they are helping the low-resource communities, or improving inequality as a societal issue. These multiple responses are lengthy, wordy, unnecessary, and filled with many \"politically correct\" (I don't know better word) things to avoid the scientific issue. Agree that we should help those under-represented communities, but after reading these, I shouldn't feel like rejecting the paper is an action against those communities.\n* The problem of \"a low-resource community who wants to shut down their internet and border\" is unfounded. We train LLM on public data we can find. If they wants to protect their secret data, they can download a public pre-trained model and fine-tune on their own. \n* The real problem is how to improve low-resource with the limited data we have, which the paper fails to suggest a better solution than trivial.\n* Less communication doens't mean more privacy, because we transfer model weights, not the data. And less parameters doesn't mean less private information be leaked. This misconception leads to wrong approach.\n* The author claims to be the first to target the low-resource problem and many other things, but there have been many works in previous years about this. Please be careful with this kind of \"we are first\" statements.\n* Overall, none of the responses has helped resolve the issues stated in the review. - Citation formet incorrect, \\citep{} be used to produce something like (Abc, et al., 2023) and not Abc, et al., 2023 everywhere.\n- Many grammatical errors, such as \"Throughout the fine-tuning...\"\"",
         "646",
         "0",
         "0",
         "0.8297",
         "0.1105421563",
         "0.9287629724",
         "65",
         "26",
         "45.2282",
         "11.9836",
         "14.6",
         "13.5927",
         "13.0802",
         "0.0978",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "7",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_AG4r",
         "1698731849876",
         "1700723834276",
         "3",
         "4",
         "4",
         "1",
         "3",
         "The paper proposes a Multilingual Federated Prompt Tuning paradigm, where lightweight multilingual prompts are encoded and on regional devices in different languages and aggregated by averaging the prompt embeddings. The goal is fine-tuning multilingual large language models on resource-constraint devices in a privacy-preserving way. The paper evaluates this approach via the XNLI task, ablated into data efficiency, \"language distance\", and communication cost, against \"monolingual\" training (baseline). The innovation lies in that the paper somehow mashes federated learning, multi-lingual (low resource) language models, and Parameter-Efficient Fine-Tuning in one paper. The fact that they managed to come up with a storyline for a system that bolsters the benefit of each approach is commendable. - poor presentation: the citations are not separable enough from the main text, e.g., without any parenthesis, rendering the submission unreadable. Against the tradition and ease of reading, abbreviations are not defined in advance, e.g., NLI, PFL, PLM.\n- claims unverifiable: no code release.\n- conflating existing metrics with innovation: language distance is not a new concept.\n- conceptual weakness: the contrived baseline was bound to give the proposed approach an edge due to lack of federated learning. Also, what the paper refers to as prompts are just classifier model input, which are different from decoders-style LLM prompts as commonly acknowledged. Finally, the approach has absolutely nothing to do with privacy which the abstract and the main body consistently bolsters. \n- evaluation weakness: only two tasks (new classification and XNLI) was used in evaluation. In section 5.4.1 \n\n>  In both the NC and XNLI tasks, despite the total number of\nparameters exceeding 278 million, the trainable parameters are only around 1.2 million, accounting\nfor less than 0.5% of the total.\n\nCould the authors clarify which part of the model is being fine-tuned?",
         "293",
         "0",
         "0",
         "0.8387",
         "-0.0202793239",
         "0.8988320827",
         "64",
         "23",
         "35.1555",
         "11.9208",
         "14.2417",
         "13.3484",
         "12.5904",
         "0.0999",
         "77",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "8",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_LsRx",
         "1698767055794",
         "1700887244625",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The paper applies federated learning on multilingual scenarios to efficiently parameter-efficient prompt fine-tuning in a manner that preserves user privacy. The idea is to utilize a single global encoder that accumulates the information via federated prompt averaging. Thus, it learns the language patterns without knowing about the user information. They evaluated the experiment on NC and XNLI datasets and found performance improvement over the baseline. - The method is very practical since it is simple and efficient, and it is an appropriate method for training multilingual model.\n- Good analysis on the data efficiency and distance measurement, showing the effectiveness of the proposed method. - In terms of novelty, the proposed idea is not new, and it is only a further investigation of the multilingual setting.\n- Lack of clarity. The paper does not provide enough information about how the prompts are constructed or look like and hyperparameters for all settings. I suggest adding the information to the paper or appendix. Questions:\n- Do you have any findings on why multilingual centralized learning is far worse than federated learning in Table 2?\n- How did you tune the training and parameter averaging?\n\nSuggestions:\n- Figure number is missing on Page 2\n\n\"As depicted in Figure , \"\n\n- Missing Figure/Table \n\n\"This translates to over 99% reduction in the communication overhead shown in 3\"\n\n- Typo\n\n\"Finetuning accuracy across different lanugages on the NC task.\"",
         "234",
         "0",
         "0",
         "0.7573",
         "0.0373593074",
         "0.9010972977",
         "66",
         "24",
         "31.2256",
         "13.1655",
         "15.1127",
         "14.332699999999999",
         "12.1462",
         "0.25730000000000003",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "9",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_agCZ",
         "1698322956814",
         "1699636820093",
         "5",
         "3",
         "2",
         "2",
         "2",
         "To tackle Multi-Domain Text Classification (MDTC) task, one mainstream of proposed techniques is to extract the features via the shared and private extractors to capture the domain-invariant and domain-specific knowledge, respectively. However, as the number of domains increases, the count of their private extractors will also rapidly surge.  \nThe author proposed a novel approach Stochastic Adversarial Network (SAN) to avoid the unaffordable explosion of parameters when encountering the newly emerged domains. Specifically, the author modeled the domain-specific feature extractors as a multivariate Gaussian distribution. Furthermore, some tricks, such as domain label smoothing and robust pseudo-label regularization techniques, are utilized to improve the overall performance.\nExtensive experiments on two benchmarks demonstrate the superiority of the proposed method compared with the state-of-the-art baselines. 1.\tThis paper proposes a novel approach, called Stochastic Adversarial Network, to reduce the computational cost while meeting a large amount of domains.\n2.\tThis paper originally employs Gaussian distribution to generate private extractors in order to circumvent the extensive parameters found in previous works. \n3.\tThis paper conducts numerous experiments to show the effectiveness of the proposed scheme. Moreover, the parameter sensitivity and ablation study demonstrate the rationale of parameter selection and the necessity of each modules, respectively. 1.\tThe motivation is trivial. It is hard to say that the model size is the bottleneck of the training process according to Table.1 and 9. 342.91M is absolutely fine in current period. Further, inference process may gain nothing in the aspect of computational acceleration as we only choose one private extractor from the Domain Discriminator D. \n2.\tThe baselines are outdated and improvements on two benchmarks are limited. According to Table 2,3 and 4, it can hardly convince me that the proposed model exactly outperforms the SOTA models. It is worth noting that the author points out this limitation in Appendix E. \n3.\tThe writing and organization need to be improved. \na)\tThe emphasis in writing has been misplaced. As the author highlights the role of multivariate Gaussian distribution in Abstract, you are supposed to tell more story of it instead of the regularization term, which is the idea of others.\nb)\tThe effectiveness is not the focus of this article, efficiency is. Therefore, moving D. 5 to the main body of the article perhaps make your contribution more prominent. \nc)\tSome tools can be utilized effectively to optimize sentence structure and composition. 1.\tThe aim of equation (3) is to ensure that the shared Feature Extractor F_s exactly extract the domain-invariant features. Thus the author maximum this loss to let the discriminator D be confused about the features coming from F_s. Here is the question: discriminator D may lack of capabilities to recognize the difference among domains as this loss function does not involve any domain knowledge.\nThere may exists another adversarial network in equation (3), i.e. domain-specific extractor enhances the capabilities of discriminator D and domain-invariant extractor still confuse the discriminator D. \n2.\tAs a classic NLP task, this method inevitably needs to be compared with chatgpt. Currently, chatgpt has shown remarkable zero-shot capabilities. Therefore, you need to convince the reviewers why your method should be used instead of chatgpt or highlight the scenarios in which your method has significant advantages.",
         "534",
         "0",
         "5",
         "0.7784",
         "0.09682159950000001",
         "0.9668992162000001",
         "48",
         "15",
         "31.5082",
         "12.8846",
         "15.6113",
         "14.3361",
         "13.4832",
         "0.20270000000000002",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "10",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_NpVu",
         "1698685251472",
         "1699636819980",
         "1",
         "4",
         "1",
         "3",
         "1",
         "The paper presents a new model for MDTC, built on the previous shared-private feature extraction architecture. The innovation includes 1) modelling the parameter of domain-specific feature extractors as a Gaussian random variable, and for each domain, the parameter is drawn from the distribution. This is why the model is called stochastic adversarial network, or SAN, 2)  domain label smoothing 3) pseudo labelling regularization.  The authors show some empirical successes on some datasets. The paper demonstrates that the authors are well aware of the challenges in MDTC and are familiar with various tools in deep learning (such as reparametrization trick, label smoothing, pseudo labelling etc). I have some concerns about this work.\n\n1. Assuming the design of proposed model is sensible (in fact I have doubts on this; see 2), the work heuristically puts together a bunch of well-known techniques to improve performance. Works of primarily such a nature, although potentially valuable in practice, do not possess enough novelty that justifies a publication in ICLR. \n\n2. I have doubts on the proposed approach in the \"stochastic\" part. Let us track the parameter $W_1$ of the domain-specific feature extractor for domain 1. In the beginning it is drawn from the prescribed Gaussian, say, its value is $W_1^{(0)}$, and after the first iteration, the Gaussian parameter gets updated (using the reparametrization trick)  -- well, whether Gaussian parameter is updated or not is not critical here. Then in the next iteration, $W_1$  is drawn again, let us call it $W_1^{(1)}$. If this understanding is correct, then $W_1^{(0)}$ and $W_1^{(1)}$ can be very different. That is, along the training process, $W_1$ will randomly hop everywhere as long as the Gaussian variance is not vanishing. How would such a scheme work at all? Bringing the parameter $W_2$ of the second domain-specific extractor into the picture would show an even more absurd picture: at each iteration $t$, $W_1^{(t)}$ and  $W_2^{(t)}$ are random variables following the same Gaussian distribution. How would $W_1$ and $W_2$ track their respective domain specific features?  If this structure were to work, it would have to be the case where the Gaussian variance is very small (which might be the case as shown in Figure 3 of the appendix). In that case, all domain-specific extractors are more or less the same, i.e, all equal to the Gaussian mean, only subject to some tiny *domain-nonspecific* random perturbation. That would defeat the entire purpose of having domain specific feature extractors. -- I could misunderstood the paper and I am willing to hear the authors' defence on this. In your defence, please also show the initial and final values of the Gaussian mean vector $\\mu$ (say, in terms of its L1-norm divided by its dimension), I would like compare it with $\\sigma$. See weakness 2.\n\nAdditional question: The authors say that the conventional shared-private adversarial scheme will have \"exponential increase\" in model parameters as new domains emerge? Why is it exponential?",
         "484",
         "0",
         "3",
         "0.7855",
         "-0.0365584416",
         "0.847129941",
         "48",
         "11",
         "47.077",
         "11.2985",
         "14.3863",
         "13.7578",
         "12.8684",
         "0.1563",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "11",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_bAwA",
         "1698806204960",
         "1699636819830",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper tackles the multi-domain text classification (MDTC) problem, and tries to minimize the amount the learning parameters by introducing a stochastic feature extractor (domain feature). The model is effective in handling the benchmark datasets and outperform the other baseline models. Additional multi-source UDA experiment is also conducted as a simple model extension. The proposed model performs strong in the benchmark dataset, with minimized learning parameters. The design of using both shared/private feature extractor is interesting and effective in merging the domain in the latent space. The proposed method is straightforward and easy to understand. 1. Though the proposal seems to be effective and achieving strong performance, the model itself still uses a relative old adversarial backbone, with the discriminator approach for removing the domain invariant feature. The two-feature-extractor approach is interesting, but that is mainly to deal with parameter increase in the MDTC problem. It would be great to see other design improvement in the model.\n2. The performance gain in using the proposed model is marginal on the Amazon review/FDU-MTL datasets. Also, it would be great to have some analysis on adjusting the setting between the two feature extractors. 1. This might be somewhat irrelevant, but would the model perform well in multi domain classification in other domain type(s), e.g., images?",
         "213",
         "0",
         "3",
         "0.7456",
         "0.26833333330000003",
         "0.9479958415",
         "48",
         "9",
         "35.1089",
         "12.7719",
         "15.5507",
         "14.5546",
         "14.2456",
         "0.1041",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "12",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_skmj",
         "1698632081062",
         "1701140370231",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper studies multi-modal generalization in neural networks such as transformer-based models and recurrent networks. To do so, the authors propose Genertic COG, a modular benchmark with multi-modal splits to test for 3 types of generalization: 1) distractor (generalization to different noise distribution), 2) systemic compositional (generalization to new permutation of task structures) and 3) productive compositional (generalization to tasks of greater complexity) generalization. Experiments conducted by the authors showed that while cross-attention based transformers (e.g. CrossAttn and Perceiver) outperform other models and perform well on distractor and systemic compositional generalization, they fail at productive generalization when the depth of the task tree goes to out-of-distribution (>3). Representational analysis is done to show that cross-attention based transformers (e.g. CrossAttn and Perceiver) superior performance on distractor generalization might be due to their ability to better retain task-relevant (e.g. stimulus and response) information at the penultimate layer. +The paper studies a timely and critical question about the generalization capability of multimodal transformer-based models\n\n+The proposed benchmark dataset uncovers a limitation of current multimodal transformer-based models: productive generalization which can facilitate the development of more generalizable transformers/LLMs. \n\n+The paper is generally well-written and easy to follow -While the paper’s studies show that certain designs (e.g. cross-attention) seem to confer multi-modal generalization, there are still some key questions that can be more thoroughly studied to uncover the reasons why this is the case.\n\n-Similarly, important discussions such as why the (cross-attention) transformers might fail at productive generalization is lacking. What is the key architectural difference between dual stream transformer and transformers with cross attn that can explain their generalization performance? Is it only the lack of a cross attention between the different modalities?\n\nPossible typo:\n“Finally, we included a Perceiver-like model (Jaegle et al., 2021), an architecture designed to generically process multimodal inputs (Fig. 2f).”:  (Fig. 2f) > (Fig. 2e).\n\n\n==Post-Rebuttal==\nI appreciate the authors' response and decided to keep my score.",
         "318",
         "1",
         "3",
         "0.8097",
         "0.0690708101",
         "0.8793090582",
         "69",
         "29",
         "14.3228",
         "16.1836",
         "19.2815",
         "17.1951",
         "18.7062",
         "0.6926",
         "76",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "13",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_a4Su",
         "1699400405601",
         "1699636123172",
         "3",
         "3",
         "1",
         "2",
         "2",
         "This paper proposes a new benchmark for assessing various forms of generalization in a multimodal setting named gCOG. The dataset includes several different splits intended to measure different aspects of generalization. The paper also compares several different model architectures on the dataset. * The paper introduces a new dataset, gCOG. While the dataset is conceptually similar to those from prior work, such as gSCAN, it supports different types of contexts and instruction types, including more compositional instructions. I'm aware of some prior work (e.g. \\[1\\], \\[2\\]) that studied compositional generalization in natural language tasks and found that gains on one synthetic task did not always transfer to other tasks, so increasing the diversity of such benchmarks for assessing compositional generalization and related challenges in the multimodal setting could be a potentially valuable contribution.\n\n\\[1\\] https://arxiv.org/abs/2007.08970\n\\[2\\] https://aclanthology.org/2021.acl-long.75/ * I'm concerned about the strength of the baselines used in the paper (see my related questions below). While the primary contribution of the paper is the dataset, it is also important to establish strong baselines for this new dataset and to ensure that the conclusions from the empirical results are valid. The appendix states that only a *single Transformer layer* with a *single attention head* was used. This is almost certainly not an optimal depth and number of attention heads. Relatedly, it looks like some models are potentially underfit, according to the figures. With >5M training examples and a relatively simple input space, I would have expected a reasonably sized Transformer model to achieve low training loss and reasonable IID generalization. If these models could have been applied to similar tasks such as gSCAN (even using symbolic tokens to represent the scene context), where they could be compared with comparable baselines from prior work, this would have helped establish that these are indeed reasonably strong baselines that have been well tuned.\n* The qualitative difference between gCOG and datasets from prior work such as gSCAN was not very clearly described. For example, one of the key claims seemed to be gCOG \"employs generic feature sets that are not tied to any specific modality\". However, it seems like it is a useful property for a multimodal dataset to have a clear relation to real-world multimodal tasks. Indeed, the authors provide interpretations of their tasks in the form of natural language instructions and visual scenes (e.g. in Figure 1), and these are very useful for understanding the task. Representing this dataset using familiar modalities (e.g. vision, natural language) could enable future work to study different research questions, e.g. the impact of pre-training. The ability to alternatively represent the task input as a sequence of tokens is also reasonable for studying certain research questions, but this also seems possible for datasets from prior work. For example, I understand that gSCAN includes both symbolic descriptions as well as visual renderings. Anyways, I think clarifying the motivation for this dataset (e.g. increasing diversity of available benchmarks, focusing on different generalization challenges, etc.) separately from how inputs are represented for the experiments in this paper (e.g. token sequence vs. images and natural language) would be useful.\n* Some of the main empirical conclusions (e.g. that generalization to greater \"depth\" is challenging for models such as Transformers) are generally known from prior work.\n\nnits:\n* Introduction paragraph 1 - \"on a carefully controlled generic multimodal reasoning tasks\" -> \"on carefully...\" or \"...task\"\n* Appendix A.2.1 - Maybe reference Tables 8 and 9 where you discuss different positional embeddings.\n* Consider discussing \\[3\\] in related work. \\[3\\] demonstrated the importance of cross-modal attention for gSCAN, and similarly studied the relative difficulty of various aspects of generalization, including distractors.\n\n\\[3\\] https://aclanthology.org/2021.emnlp-main.166/ * Why not try more layers and attention heads, e.g. following a standard hyperparameter setting for model size such as those of BERT-Base? Or even BERT-Small?\n* In Figure 2 (F) why does the single-stream Transformer have almost double the parameters of the double stream Transformer? For the other Transformers, do the encoder blocks used for the task vector and stimulus vector share parameters? \n* What optimizer and hyperparameters (e.g. learning rate) were used for training? How were these chosen? I didn't see these details in Appendix A.2. \n* Position embeddings - Since you are representing 10x10 grids as 1D sequences, 1D relative positions may not capture this structure well. On the other hand, absolute position embeddings seem potentially problematic in the case of the SSTrfmr model, since they will not be consistently assigned to the same grid position if the text sequence is first and has varying length. Mitigating this may be important to provide for a fairer comparison with the SSTrfmr model.\n* To what do you attribute the periodic loss spikes during training that are shown in Figure 4 (E)?\n* I found the usage of \"cross-attention\" a bit confusing. For example, the single stream Transformer features cross-modal attention as an implicit consequence of self-attention over the concatenated sequence. I thought this would commonly be referred to as an instance of \"cross-attention\" between modalities. \n* Does the dataset also contain visual renderings and natural language instructions to enable future work to study these tasks using familiar modalities?",
         "860",
         "10",
         "1",
         "0.8184",
         "0.076096273",
         "0.8955636024",
         "52",
         "2",
         "37.0807",
         "11.9609",
         "15.3107",
         "14.4483",
         "12.808",
         "0.1278",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "14",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_DJb6",
         "1699470958350",
         "1699636122858",
         "8",
         "4",
         "3",
         "3",
         "3",
         "The paper introduces a new multimodal question answering benchmark for out-of-distribution generalization, specifically covering task compositionality, robustness to distractors and combinatorial generalization. It uses this benchmark to evaluate various models and analyze their performance. - **Topic**: The paper studies an important topic which in my opinion is underexplored in current deep learning research. Especially given the tendency these days to scale training up to vast amounts of data, I believe it is particularly important to design carefully controlled benchmarks that can: evaluate the model’s performance from a critical and cautious standpoint, point to their fundamental limitations (e.g. systematic generalization), and support further research about ways to overcome these.  \n- **Evaluation**: The paper offers both extensive extrinsic evaluation, with performance comparison of various models on the different generalization skills, as well as intrinsic analysis of their internal representations’ degree of alignment to the stimuli.\n- **Clarity**: The writing quality is good and the paper is clear and easy to follow. The paper is well-organized, claims and findings are clearly stated, and useful figures and diagrams are provided.\n- **Related Works**: It does a good job in providing the relevant context, motivation and related works. \n- **Contribution**: The empirical findings of the paper on the benefits and limitations of different inductive biases such as recurrent and attention-based are important and may be of broad interest to the community. - **Pre-trained models** The paper focuses on models trained from scratch rather than pre-trained. This could be a strength and a weakness. On the one hand, it allows for isolating the contribution of the architectural choices from other factors of optimization, and training data. On the other hand, it has been observed that by training models at large enough scales enables the emergence of generalization capabilities, which we don’t see in smaller scales. I think it will be critical to also analyze the performance of pretrained models on the benchmark, in order to strengthen the paper.\n- **Visual Simplicity**: The visual side of the benchmark is quite rudimentary, featuring colorful letters. Extending it to a larger range of visual tokens/objects, that could have more than one property (color), and a broader set of elements and variations (than 26 letters), could be a straightforward extension that could help make it a bit more challenging visually. - **COG task**: It will be useful to discuss the COG task (rather than just mentioning it) before describing the new gCOG one, so that it will be clearer to the reader what are new contributions of the new benchmark compared to COG and the degree of their importance. In the overview diagram I would also recommend showing a sample also from COG to make the differences clearer. \n- **Grid size / generalization**: It could be interesting to vary the size of the grid in training/evaluation and study its impact on model’s performance. \n- **Terminology**: I recommend changing the phrase “Distractor generalization” to one that better conveys it’s about changing the answer distribution. Maybe e.g. answer distribution shift. I also recommend changing the name “Systematic compositional generalization” to “combinatorial generalization”, to emphasize that the main point is the generalization to permutation, and also to better contrast it with the following “Productive generalization” (which could also be systematic).\n- **Figures**: Would be good to increase the size of the plots in Figure 3b. It will also be good the increase the distance and visual separation between the sub-figures in each figure throughout the paper. \n- In the introduction: “multimodal question-answer” -> “answering”.\n- “This design allowed us” -> “This design allow us”.",
         "591",
         "0",
         "2",
         "0.7407",
         "0.1749524183",
         "0.9485415220000001",
         "52",
         "1",
         "28.5253",
         "14.5712",
         "17.3533",
         "15.8558",
         "15.5336",
         "0.25520000000000004",
         "90",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "15",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2",
         "0.8079",
         "0.1061594203",
         "0.8954392672",
         "49",
         "12",
         "30.6084",
         "13.0004",
         "15.6607",
         "14.5546",
         "14.526299999999999",
         "0.0364",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "16",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head \\[1\\], \\[2\\], \\[3\\]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works \\[1\\]\\[2\\] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n\\[1\\], Frozen clip models are efficient video learners, ECCV-2022\n\n\\[2\\], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n\\[3\\]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0",
         "0.7694",
         "0.0820393375",
         "0.8567712307",
         "49",
         "11",
         "39.7853",
         "10.703",
         "12.5661",
         "12.2047",
         "12.4388",
         "0.07200000000000001",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "17",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7",
         "0.8374",
         "0.0525974026",
         "0.9221839309000001",
         "49",
         "8",
         "20.0915",
         "14.8293",
         "18.2521",
         "15.9032",
         "16.8967",
         "0.19390000000000002",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "18",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0",
         "0.7506",
         "0.3529761905",
         "0.8587207794",
         "49",
         "2",
         "56.3637",
         "9.621",
         "12.2299",
         "12.231",
         "10.3101",
         "0.4364",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "19",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_5Cgw",
         "1697885084973",
         "1699636148336",
         "3",
         "5",
         "3",
         "2",
         "2",
         "The study puts forward a VAE-based approach to acquire disentangled representations without the need for supervision. In this framework, it assumes that diverse data samples exhibit variations across multiple factors, making it particularly well-suited for real-world datasets. The newly proposed technique, referred to as CFASL, introduces a range of unsupervised loss components that serve to instill \"inductive biases.\" These include parallel and perpendicular loss terms, in addition to a sparsity loss designed to encourage alignment along factor axes. The outcomes of this study illustrate the method's superior performance when compared to various other unsupervised disentanglement VAEs, both under single-factor and multi-factor alteration scenarios, across multiple widely used benchmark datasets. 1. The paper represents a significant stride in enhancing the practicality of disentanglement techniques within the realm of real image domains. It grapples with a formidable challenge where we cannot presume access to images that solely vary in a singular factor, thereby intensifying the complexity of extracting disentangled representations.\n\n2. The quantitative findings not only exhibit enhancements in the primary focus of this study, which is the alteration of multiple factors, but also in the scenario involving changes in a single factor. 1. The proposed approach incorporates a diverse array of loss terms within its training objectives, with each term potentially making a distinct contribution. However, this diversity comes at the expense of imposing significant assumptions on the underlying image distribution. While I acknowledge that these assumptions may be justified within the context of the datasets considered in this paper, it's worth noting that some metrics, such as DCI, do not unequivocally demonstrate superiority in the ablation study presented in Table 2.\n\nNevertheless, I believe that the paper could benefit from a more comprehensive exploration of the limitations stemming from these strong assumptions. It would be valuable for the authors to provide concrete examples where these assumptions result in unintended or adverse outcomes. Even for an unsupervised setting, it remains crucial to take into account the nature of transformations within the image domain. A more explicit discussion of these assumption-related limitations would substantially bolster the significance of the claims advanced in this paper, in my view.\n\n2. The qualitative results exhibit low image quality. While this is common across unsupervised disentanglement methods, it is really challenging to get convinced that better disentanglement is achieved. It would be valuable for the author to consider domain-specific metrics for the evaluation phase e.g. face identity loss, facial expression classification, head pose regression, etc. to assess whether only a specific attribute is altered during the single factor change experiments. 1. Following the weaknesses mentioned above, could the authors provide concrete examples (other datasets) where the assumptions induced by the loss terms result in unintended or adverse outcomes compared to the baseline beta-VAE?\n\n2. Could the authors please provide the ablation study results of the different loss terms for all datasets considered in the paper (and not only 3D-Cars)?",
         "483",
         "0",
         "7",
         "0.8442",
         "0.138866012",
         "0.8097960949",
         "51",
         "20",
         "20.0803",
         "15.9126",
         "18.6369",
         "16.6917",
         "17.3977",
         "0.15430000000000002",
         "88",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "20",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_oACj",
         "1698758328711",
         "1699636148260",
         "5",
         "3",
         "3",
         "1",
         "2",
         "The authors introduce a new VAE architecture which operates on pairs of inputs and utilizes a set of regularization terms to induce structured disentanglement of the latent space with respect to observed symmetry transformations between examples in these pairs. The authors show that their model indeed achieves higher disentanglement scores than relevant baselines on a variety of datasets with a variety of different metrics. Specifically, the authors target the 'multi-factor change' regime, and demonstrate improved performance in this setting with their newly introduced metric. - The related work is well covered, and the authors position their method well in the literature.\n- The proposed combination of losses appears novel to the best of my knowledge, and the use of parallelism and orthogonality losses specifically on latent transformations is an interesting and exciting idea. \n- The study of disentanglement with respect to multiple simultaneously changing factors is important and interesting, and the authors make a notable contribution to this direction.\n- The results appear promising, and indicate that the model is performing well with respect to the baselines. \n- The methodology and extended results in the appendix appear sound. The calculation of P-values in the appendix is very important and appreciated. Furthermore, the use of an ablation study to validate their proposed model is a welcome addition. Weaknesses summarized:\n- The paper is challenging to read as the english is quite poor and the logical flow of the work is unorganized.\n- The method itself is composed of a wide variety of loss terms and the intuition or reasoning for why these terms are necessary is not provided. (Specifically for the parallel and perpendicular losses).\n\nIn more detail:\n\nWeakness 1:\nThere are many typos and poor grammar throughout the paper, with many sentences simply not making much sense. I include a few examples below, but there are many many more and the authors should have someone proof read this work more carefully:\n- In the abstract: \"We propose ... (CFASL) on VAEs for the extension to \\[a\\] general multi-factor change condition without constraint.\" \n- \"To implement  group equivariant VAE, Winter et al. (2022); Nasiri & Bepler (2022) achieve the translation and  rotation equivariant VAE\"\n- \"For the equivariant encoder and decoder, we differently propose the single forward process by the  encoder and decoder objective functions compared to previous work (Yang et al., 2022).\"\n- \"Differently, we induce disentanglement learning  with group equivariant VAE for inductive bias.\"\n- 'The unsupervised learning work (Winter et al., 2022) achieves class invariant and group equivariant  function in less constraint condition.'\n\nWeakness 2: \nNaming is extremely unclear. For example, what are 'sections' referred to in Section 3.2? How do these differ from factors? \n\nWeakness 3: \nDespite appealing to a precise probabilistic generative model as its primary value and distinction from prior work, the model itself could be made significantly more elegant in the context of generative models. For example, the 'factor prediction' mechanism could be integrated as a component of the generative model and inferred with another approximate posterior, as done in prior work (Song et al 2023).\n\nWeakness 4:\nThe discussion of learning the Lie algebra is quite rushed and the intuition for why the large set of different loss terms should be incorporated is largely missing.\n\n\\[1\\] (Song et al. 2023) https://arxiv.org/pdf/2309.13167.pdf Question 1:\nThe point that prior work with autoencoders does not extend to VAE's does not make much sense to me. Specifically the quote: \"Furthermore, the methods on autoencoder are not directly applicable to VAEs, because  of the large difference to VAE in probabilistic interpretation\". Can the authors provide further details to reinforce this claim?\n\nQuestion 2:\nGiven there are so many loss terms for this model, it is likely that it will be computationally expensive to estimate the correct weightings for each of these terms in a hyperparamter search. Can the authors speak to how this was done in their case and how expensive it was? \n\nQuestion 3:\nOne of the main selling points for this paper was the ability to extend disentanglement methods to 'multi-factor' change. However, for the experiments, the authors consider datasets which guarantee commutativity of transformations. Theoretically then, is there a reason why we should expect the other baseline models to not be able to handle this multi factor change? For example, it seems the axis aligned disentangled representations of the beta-vae should be able to compose multiple transformations simply by jointly changing multiple latent dimensions. Is this not the case?",
         "744",
         "6",
         "1",
         "0.7790",
         "0.16209867760000002",
         "0.887704134",
         "51",
         "10",
         "39.4602",
         "12.5279",
         "15.1911",
         "14.4792",
         "13.6498",
         "0.09770000000000001",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "21",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_A4b1",
         "1698803382759",
         "1699636148172",
         "5",
         "3",
         "2",
         "2",
         "2",
         "Following the Variational Auto Encoder (VAE) framework, this paper proposes an extension of the single factor (change condition) disentanglement learning method, which they call as Composite Factor-Aligned Symmetry Learning (CFASL). The main idea and/or the assumption is certain scenarios such as the composite/complex symmetries (where certain mathematical transformational relationships exist) can be better captured by utilizing explicit symmetrical relationship information, if provided as additional input to the VAE learning framework. \n\nAs a part of the learning scheme, to facilitate this required piece of information, the proposed method explicitly inputs pairwise symmetrical relationship (and corresponding transformation) information. The expectation is the model, if learned in this fashion, should generate better representative samples from within those transformational subspace/domains. \n\nTo better explain and evaluate the scenario, some new metrics such as m-FVMk (extension of a common metric for a single factor change condition evaluation) have been proposed. They have compared their method with some state-of-the-art methods and on nine benchmark datasets; reported results are found to be promising. The following items seem to have some originality: (i) learning from explicit pairwise transformations, (ii) a network architecture to learn the codebook of symmetries for (i),  (iii) some associated metrics supporting (i) and (ii), and (iv) imposing group equivariant encoder-decoder into the learning framework. \n\nOverall, the paper is well written.  Mathematical derivations of different components seem to be sufficient. The proposed method has been tested on a number of benchmarks (both quantitative and qualitative analysis), and reported results are found to be promising. In addition, the ablation study of different loss functions may have added some extra points. \n\nIn terms of quality, I would rate the work as \"moderate\". In this work, one of the important missing part is the proper probabilistic derivation of the methodology, the core of the VAE framework. Or it may be due to the way the paper/work has been presented. To me, it's not sufficient to connect to the VAE world. It is suggested the authors clarify this important aspect with necessary derivations.  \n\nFor certain items/results, the authors claim statistical significance performance (section 5.2, and appendix D); however, without sufficient details of their significance tests. It is suggested authors include details of these statistical tests. \n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, we may require additional details for a fair companion of their results. \n\nThe paper/research may have some significance, and it would be beneficial if the source code could be released. It is suggested the authors clarify the probabilistic derivation of the approach and make a proper connection to the VAE basics. \n\nIt is suggested authors include details of these statistical tests.\n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, I suggest authors provide further details and release code if possible.",
         "461",
         "0",
         "0",
         "0.7849",
         "0.0855008418",
         "0.9382466078",
         "51",
         "9",
         "30.801",
         "13.7351",
         "16.5337",
         "15.4148",
         "15.7803",
         "0.08660000000000001",
         "84",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "22",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_DbMo",
         "1698968978898",
         "1699636148102",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The manuscript aims to improve existing methods of unsupervised disentangled representations learning.  Inspired by the symmetry group action approach from (Higgins et al 2018,2022), authors suggest several additions for the conventional beta-VAE  method, resulting  in the form of seven supplementary loss terms. The article is devoted to important subject of disentanglement learning. Authors report improvements over some of existing methods on four simple datasets 1) Only simple datasets are considered, the method is not tested on standard complex datasets like MPI 3D. \n\n2) Reported improvements of CFASL in all measured metrics are essentially always situated within standard deviations of some other methods. \n\n3) Reconstruction loss is not reported in 3 out of 4 datasets. Upon visual inspection of reported samples, the reconstruction quality is not satisfactory. \n\n4) As reported on Figure 4, on 3DShapes dataset, there is no consistent improvement in FVM metric even at the expense of deteriorating reconstruction quality . \n\n5) There is no theoretic justifications for introduction of so many, seven in total,  additional loss terms. \n\n6) Description of Lie group action is not clear, how the action by psi_i is defined? how the dimensions of Lie groups are chosen?\n\n7) The described group action by matrix multiplications do not preserve the normal distribution, so the group equivariant term is not compatible with the  standard KL term from beta-VAE loss. \n\n8) There is no comparison with most recent disentanglement methods like DAVA, TCWAE.\n\n9) Related work section does not mention many works from vast literature on disentanglement learning, eg Disentangling Adversarial Variational Autoencoder (ICLR 2023). Why is the reconstruction quality not reported in three out of four datasets?\n\nWhy the method was not tested on standard more complex datasets like MPI3D?",
         "284",
         "0",
         "0",
         "0.7452",
         "0.070014881",
         "0.8747272491",
         "51",
         "7",
         "34.0313",
         "12.9067",
         "16.1209",
         "14.7317",
         "13.6173",
         "0.0751",
         "89",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "23",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_mr2r",
         "1698569976113",
         "1699636242675",
         "3",
         "4",
         "2",
         "2",
         "1",
         "The article offers a Gaussian Mixture-based differential entropy/mutual entropy estimation approach. Furthermore, it provides numerical experiments to test the expected behavior of the estimator and its application to self-supervised learning. The article addresses an important problem of mutual information estimation. It provides relevant numerical experiments to test the validity of the proposed approach. - The main approach proposed by the authors seem to be already appeared in the literature in some references not cited by the authors (please see the questions part).\n\n- There seems to be a major issue about the expressions provided for the proposed approach (please see the questions part).\n\n- The presentation requires improvement. ### I. INTRODUCTION \n\n**3rd paragraph:** \n\n- \"identify matrix\":  identity matrix?\n\n- \"The mutual information can be consequently estimated by the entropy decomposition.\": This sentence follows identity matrix addition sentence. I guess it might be better to clarify causality here. At this point, it is not clear what is meant by \"entropy decomposition\", whether it is a trivial procedure and what enables it (mixture of Gaussians modelling?).\n\n### 2.1 BACKGROUND\n\n**Paragraph before (4)**\n\n- After equation (1): instead of \"for a multi-variable Gaussian variable\" use Gaussian (random) vector ?\n\n- In the notation $$X=\\[x_1,x_2, \\ldots x_n\\]$$ $x_i$'s appear as column vectors, however, they are actuallly row vectors as $X\\in\\mathbb{R}^{n\\times d}$\n\n- (5) should be\n\n$$\\mathbf{H}_D(X)=\\sum_{i=1}^k \\frac{1}{2} \\log \\left(\\lambda_i+\\beta\\right)+(d-k)\\log(\\beta)+C_d$$\n\n- After (5): \"Therefore, LogDet can estimate the entropy of multivariate Gaussian variables by approximating the differential entropy.\". This is not a surprise/or contribution as the authors  simply defined (5) using (2) by replacing the true covariance with $\\beta I$ perturbed sample correlation (covariance?) matrix. This is sort of obvious. \n\n### 2.1.1 LOGDET ENTROPY ESTIMATOR FOR NON-GAUSSIAN VARIABLE\n\n- Title : ... NON-GAUSSIAN VECTOR\n\n- Replace variable->vector\n\n- There already exists GMM based entropy/mutual information approximation based works such as \n\n\\[a\\]. Lan T, Erdogmus D, Ozertem U, Huang Y. Estimating mutual information using gaussian mixture model for feature ranking and selection. InThe 2006 IEEE international joint conference on neural network proceedings 2006 Jul 16 (pp. 5034-5039). IEEE.\n\n\\[b\\]. Huber MF, Bailey T, Durrant-Whyte H, Hanebeck UD. On entropy approximation for Gaussian mixture random vectors. In2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems 2008 Aug 20 (pp. 181-188). IEEE.\n\nYou need to refer to existing literature and clearly state what is novel in your approach relative to them.\n\n\n- Theorem 2 and Theorem 3 of \\[b\\] above already covers the lower and upper bounds of mixture of Gaussians. It looks like they are same as what is provided in this section. \n\n- There seems to be a major issue about the upper bound expression. The first expression for the upper bound (at the bottom of page 3), contains covariances ($\\Sigma_i$'s ) obtained from the GMM fitting algorithm, whereas the second line contains the overall sample covariance of actual data, instead of conditional covariance estimates. How do you equate these lines? The second line in fact equals to\n\n$$\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)+\\sum_{i=1}^K \\pi_i \\cdot\\left(-\\log \\pi_i+C_d\\right)$$\n\nas $\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)$ is independent of the summation index $i$. This does not make sense as you disregard covariance parameters of the GMM. \n\n- How do you make the upper bound objective co\n\n### 2.2 THE ISSUE OF MODEL SELECTION\n\n- Title: Model Selection is to generic for the discussion in this section. \"The Issue of Model Order Selection\" could be a better title.\n\n\n\n\n### 3. APPLICATION IN SELF-SUPERVISED LEARNING\n\nThe logdet-mutual information based SSL appears to be proposed in the following reference:\n\n\\[c\\]. Ozsoy S, Hamdan S, Arik S, Yuret D, Erdogan A. Self-supervised learning with an information maximization criterion. Advances in Neural Information Processing Systems. 2022 Dec 6;35:35240-53.\n\nThe authors should also clarify the relative novelty relative to \\[c\\]. Especially, the impact of GMM order selection as the approach in \\[c\\] appears to be for $K=1$. There is also claim in \\[c\\] that the use of $K=1$  defines correlative information maximizing which targets a linear (identity in their modified setting) between the representations of augmented versions of inputs. For $K>1$ does  maximizing mutual information between augmentation representation lead to nonlinear mappings between them? Is such organization of representation space desirable for classification tasks, for example?\n\nOr are you just using (18) with order $1$, which seems to be just the approach in \\[c\\]. \n\n### 4. RELATED WORKS & 5 SIMULATION STUDIES\n\nAll the references we mentioned above and the relevant references that cite them should be included in this discussion, and simulation results \n\n- 5.2 : ofBelghazi...-> of Belghazi\n- Figure 2: Two small figures and caption could be more informative.\n- 5.4 SSL: What is K for EMP-MILE? Is upper bound employed in EMP-MILE?  what if you directly use MILE?\nHow is backprop used in coordination with the GMM algorithm? As GMM parameters are algorithmically obtained from network output, how does backprop do backward mapping from probabilities $\\pi_i$'s (and there should be covariance estimates $\\hat{\\Sigma}_i$'s, as discussed above)",
         "825",
         "0",
         "11",
         "0.7898",
         "0.0758333333",
         "0.9194312096",
         "50",
         "12",
         "32.871",
         "12.3962",
         "15.7154",
         "14.1987",
         "13.0703",
         "0.1107",
         "100",
         "0",
         "2",
         "1",
         "0"
        ],
        [
         "24",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_fvqj",
         "1698878886574",
         "1699636242588",
         "3",
         "5",
         "2",
         "1",
         "2",
         "This paper proposes a new approach to estimating the mutual information between a pair of random vectors, by extending the closed-form expression that is available to Gaussian variables to non-Gaussian variables. This is done by estimating Gaussian mixture approximations of the involved densities and then using bounds on the differential entropy of Gaussian mixtures. Estimating mutual information between high-dimensional non-Gaussian variables is an important problem with many applications. The proposed method extends Gaussian (which the authors refer to log-det) estimators to be applicable beyond Gaussian variables via the use of Gaussian mixture approximations, coupled with bounds on the differential entropy of mixtures. Unfortunately. the paper contains several critical flaws, namely a quite sloppy notation, that lead me to recommend its rejection. \n\nThe authors mixture, in a very confusing way, random variables and data matrices, typically using the same notation for both, $X$. For example, in Equations (1), (2), and (10), $X$ is a $d$-dimensional random variable, whereas in Equation (4), $X \\in \\mathbb{R}^{n\\times d}$ is a data matrix. Even worse, in the final equation of page 3, the two different definitions are used together and it is not even clear where the second equality means; it is simply wrong because $X^T X/n$ does not coincide with $\\Sigma_i$.\n\nUnlike what the authors claim, Equation (5) is not equivalent to Equation (5); the two differ by $\\frac{d-k}{2}\\log \\beta$.  \n\nAdding a matrix proportional to identity ($\\beta I$ in the paper) to the sample covariance was not proposed in a 2021 paper. It is a very classical method that can be found in any classical text on covariance matrix estimation, many decades ago.\n\nThe inequality in Equation (8) was not shown by Zhouyin and Liu in 2021. It is a classical result of information theory, that can be found, for example, in the famous Cover and Thomas book. By the way, the citation to this book is wrong in the paper; one of the authors (J. Thomas) is missing. \n\nThe two bounds for the differential entropy of mixtures that the authors claim to have introduced are in fact not new. The upper bound is in fact a well-known corollary of the log sum inequality (see the Cover and Thomas book). The lower bound was proved in 2008 by Huber et al. at https://doi.org/10.1109/MFI.2008.4648062 I have no questions.",
         "383",
         "1",
         "1",
         "0.7288",
         "-0.053505050500000005",
         "0.8470067382",
         "50",
         "8",
         "39.4844",
         "12.7598",
         "16.0005",
         "14.7779",
         "13.3057",
         "0.21480000000000002",
         "85",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "25",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_F4Ta",
         "1698980874812",
         "1699636242491",
         "6",
         "4",
         "3",
         "3",
         "2",
         "This work presents a mutual information (MI) estimator called MILE (LE=logdet estimator) which uses \nthe log det closed form formula of the entropy of Gaussians.\n\nTo accomodate MI to arbitrary densities, a Gaussian mixture model (GMM) is first fit to data and lower/upper bounds on the entropy of GMM is used to define MILE formula Eq 15. \n\nThen MILE is benchmarked with other MI  estimators and MILE can be used in loss functions in semi-supervised learning in experiments. - Simple MI estimator method based on  \n\nZhanghao Zhouyin and Ding Liu. Understanding neural networks with logarithm determinant entropy estimator. arXiv preprint arXiv:2105.03705, 2021\n\n(cited in the paper)\n\n- Very good experiments and comparisons with other MI estimators\n\n- Source codes provided in supplemental information  for reproducible research -The paper is sloppy in its writing, and one problem is to determine the number of components k of the GMM which\n loosen the lower upper bounds on the entropy. \n\n- Another problem is to deal with near singularity (det close to zero) by introducing a regularization term \\beta.\n\n- Give definition of MI and link with copulas, e.g.,\nMa, Jian, and Zengqi Sun. \"Mutual information is copula entropy.\" Tsinghua Science & Technology 16.1 (2011): 51-54.\nThis will relate to Eq. 8 as well.\n\n- Because MI estimation is an important and well-studied topic, I suggest to put Section 4 on related works after the introduction to that the contributions are better explained.\n\n- The lower/upper bounded of entropy of GMMs are not tight. There is a rich litterature which also compares the tightness of the various bounds.\n\nHuber, Marco F., et al. \"On entropy approximation for Gaussian mixture random vectors.\" 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems. IEEE, 2008.\n\nEven in 1D:\nNielsen, Frank, and Ke Sun. \"Guaranteed bounds on the Kullback–Leibler divergence of univariate mixtures.\" IEEE Signal Processing Letters 23.11 (2016): 1543-1546.\n\n- Notice that some distributions do not admit densities (some elliptical distributions for example)\n\n\n\n- Mention MI properties (i.e., tensorization) which defines the self-consistency test of estimators\n\n\n- small remarks:\n* data covariance = scatter matrix\n* after (3), define $\\Sigma_x$ as scatter matrix?\n*  page 3, first sentence need to be rephrased\n* some typos: \npage 7  hyperparamter -> hyperparameter\npage 9 self-supervied -> self-supervised    competitve -> competitive - Would using PCA beforehand be more appropriate in the case of near singularity?\n\n- Can we tackle robustness/variance with f-MI?\n\nMoon, Kevin, and Alfred Hero. \"Multivariate f-divergence estimation with confidence.\" Advances in neural information processing systems 27 (2014).\nEsposito, Amedeo Roberto, Michael Gastpar, and Ibrahim Issa. \"Robust Generalization via f− Mutual Information.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.",
         "447",
         "3",
         "7",
         "0.8255",
         "0.1368315018",
         "0.9330754280000001",
         "50",
         "7",
         "35.4092",
         "11.3442",
         "14.446",
         "12.9766",
         "10.7556",
         "0.08660000000000001",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "26",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_MHkc",
         "1699156174555",
         "1699636242410",
         "3",
         "4",
         "2",
         "3",
         "2",
         "this paper proposes to use the logdet function for the estimation of mutual information. \ntwo bounds are proposed for this purpose. the results show improvement in comparison \nto the editing methods. the proposed function itself is \"the Coding Length Function\". simple method with good results. In my opinion this paper reinvents \"Coding Length Function\".  \"...the difference is we put a scaling hyperparameter β on the identity matrix I..\" - that is not a difference. both affects SNR. The latter can be affected either way: by multiplying the noise covariance or by division of the data covariance. I do agree that the results are interesting, but the novelty is quite limited due the the above. \n\nplease elaborate on the limitations. \"So, we recommend β = 1e−3 in the following simulation studies\" why not beta=zero? \nFigure 1.b shows that beta=zero correctly estimates the true MI. \nThat raises a question why do you need beta > 0?\n\nHow do you define $\\pi_c$ in e.g., Eq17?\n\nBoth bounds are loose. How can you explain that such loose bounds lead to very small variance in MI?\n\nDo you calculate MILE in batches?",
         "187",
         "0",
         "1",
         "0.7572",
         "0.0981946625",
         "0.8652637601000001",
         "50",
         "5",
         "61.8294",
         "7.0412",
         "9.7432",
         "10.4262",
         "6.5339",
         "0.4252",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "27",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_oYZA",
         "1699327631740",
         "1699636242348",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The paper proposes uses bounds on the entropy and mutual information for a mixture of Gaussian random variables based on the log determinant calculations used in calculating the entropy for a single Gaussian. In the context of self-supervised learning, the Gaussian mixture is assumed to known based on the augmentation. In other cases the number of mixture components has to be selected. Empirical results are reported on a synthetic benchmark of correlated Gaussians with and without non-linear transformations. Results of self-consistency measures are reported on CIFAR10. The paper is a logical motivation. Differential entropy is easy to calculate for Gaussian distributions, and mixture of Gaussians are universal approximations given enough data, so why not use GMM for mutual information estimation. The insight of using the augmentations as defining the GMM is a useful, simplifying assumption. One main weakness is the lack of extensive comparisons of using this method for self-supervised learning versus other. The one example in the main body (Table 1) shows that at 300 epochs the method is better than some other methods but is inferior to EMP-SSL. At 1000 epochs the other methods outperform the listed, but no results for 1000 epochs are reported. \n\nThe second main weakness is the paper does not give a complete description of the method. The paper is lacking in clarity with some key point unaddressed. The notation is confusing since the random variables (Z,Z') are denoted the same as Z_c, which may be a data point in the empirical sample. There should more clarity on random variables as compared to  sample sets, starting back before equation 4. The confusion carries to last paragraph of Section 4 where $\\mathbf{X}$ is defined but then $X$ is used in the definition. \n\nThe use of one instance for one cluster is not clear to me upon reading it\n\"This is because we treat the augmented data from one instance as a cluster, and this data\naugmentation strategy automatically clusters the data.\" This should be re written.\n\n In equation 17 it is not clear how $\\zeta_c$ captures all instances in the batch. It has only a single $i$ index. Perhaps the $\\zeta_c$ should concatenate them all. In section 3.2, $\\zeta_c$ is a set which indexes the whole match, which makes more sense, but it should be a matrix not a set. In any case, how is the $H(Z)$ term estimated in section 3.1? By keeping $Z_c$ fixed and only augmenting the second the one covariance matrix will be rank-1 (before ridge). \n\nIt doesn't sound like the experiments for the 5.2 are run fairly \" our MILE estimator does not require extra training,\" In this problem the point is that the MI could be changing at each data instance. Thus, other methods do not use access to the change points. MILE should have to be run (which involves performing the GMM since there are no self-clusters as in SSL) at each point. Running an expectation maximization is as much or more training than the updates of network.  \t\n\nIn the SSL, the trade-off parameter having to be searched in the grid  \\[0.01,0.1,1.0,2.0\\] doesn't seem to be efficient compared to EMP-SSL. \n \nIn terms of unsubstantiated claims, the method is clearly biased (not only by the choice of number of components) but also on the non-linear transform cases. It is not clear how well the mutual information estimation would actually work on more complicated data. Thus, even if it is useful for self-supervised learning is not necessarily a more accurate estimate of differential entropy. \n\n**Minor:**\nThere are a number of typographical mistakes that are distracting.\n\nI don't understand what this means\n\"often dwarfing traditional parametric and non-parametric approaches in statistics\"\n\n\" base on the \" -> \"based on the \" \n\nI'm not familiar with this phrasing \"When X subjects to a Gaussian\" \n\n\"a ‘noise’ $\\hat{X}$ \" -> \"a noisy $\\hat{X}$\" \n\nThe paragraph before equation (4) are not clear. \" an expanding factor\" is not defined nor is it clear what is meant by \"enlarging the original covariance matrix\".\n\nExtra $=$ on equation 14.\n\n\"trading each\" -> \"treating each\" ? \n\n\" ground true data\" \n\n\"SMILE: moothed\" -> \"SMILE: smoothed\" \n\nIt should be a parenthetical reference for You et al. (2017) fo LARS optimizer. How is the $H(Z)$ term estimated in section 3.1? Is it also based on augmented data?\n\nIn the SSL, the trade-off parameter having to be searched in the grid  \\[0.01,0.1,1.0,2.0\\] doesn't seem to be efficient compared to EMP-SSL. Are there hyper-parameters for EMP-SSL?  \n\nWhy in Table 1 is 1000 epochs not tested?\n\nIs the GMM method run at each time point in Figure 2?",
         "766",
         "1",
         "2",
         "0.7605",
         "0.0532218443",
         "0.8940244317",
         "50",
         "3",
         "54.1694",
         "9.5215",
         "12.4683",
         "12.0691",
         "9.6868",
         "0.1494",
         "91",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "28",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_e4bh",
         "1698824679826",
         "1700667146725",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs) which build on the graph theoretical concept of graphexes to include sparse network structures between agents. This improves over prior work on Graphon Mean Field Games which only allows for modelling with dense graphs. The authors derive convergence properties for the finite game. In addition, a learning algorithm based on online mirror descent is provided for a particular class of GXMFGs that follow a core-periphery network structure. Finally, the theoretical claims are empirically validated over both synthetic and real-world networks. - This paper has a clear motivation to extend Graphon Mean Field Games to deal with sparse graphs which are frequently seen in practice. The hybrid graphex approach proposed in this work looks like a natural and intuitive solution.\n- The technical development is principled and the analysis is nontrivial.\n- The overall presentation and clarity is good. - Even though the authors explained in the paper, I didn't like the fact that the proposed GXMFGs have no baseline competitors to compare against. While I agree that one could argue on the contrary that the ability to work with sparse graphs is precisely the unique advantage of GXMGFs, I think that the authors should at least spend some efforts to discuss (if empirical comparison with LPGMFG is indeed unsuitable) how GXMFGs would compare with LPGMFG and GMFG in practice. In Figure 3a, it looks like the curves are diverging rather than converging as k increases? Are the curves coloured correctly?",
         "248",
         "0",
         "0",
         "0.8187",
         "0.0240079365",
         "0.9548254013",
         "61",
         "21",
         "47.3621",
         "11.3161",
         "14.0651",
         "13.2744",
         "12.8151",
         "0.1262",
         "95",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "29",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_hgJx",
         "1698838739665",
         "1699636550718",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs), a framework for addressing the challenge of learning agent behavior in large populations. GXMFGs leverage graphon theory and graphexes, which represent limiting objects in sparse graph sequences. This approach suits real-world networks with both dense cores and sparse peripheries. The paper presents a specialized learning algorithm for GXMFGs. \n\nKey contributions include:\n\n1. Introduction of GXMFGs, extending the scope of Mean Field Games.\n2. Provides theoretical guarantees to show that GXMFGs accurately approximates finite systems.\n3. Development of a learning algorithm tailored to GXMFGs.\n4. Empirical validation on synthetic and real-world networks, demonstrating GXMFGs' ability to model agent interactions and determine equilibria effectively. - Well-Written and Organized: The paper demonstrates strong writing and organization, enhancing its overall readability and accessibility.\n\n- Clear Motivation: The paper effectively conveys a clear and compelling motivation for addressing the problem it tackles.\n\n- Thorough Discussion of Prior Works: The paper provides a comprehensive and well-structured overview of prior works related to the research area.\n\n- The paper provides solid theoretical contributions complimented with supporting empirical studies strengthens the paper's arguments and findings. As the current paper falls outside the scope of my research interests, I am unable to identify any significant weaknesses in the paper. Consequently, my confidence in assessing the paper is limited. - Providing an intuitive explanation for assumptions 1(b) and 1(c) would greatly enhance the paper's overall readability and accessibility.\n\n- While the paper assumes finite state and action spaces, it may be beneficial to explore whether the proposed approach can be extended to scenarios with infinite action spaces. \n- Including the code for the simulations, would enhance reproducibility.",
         "275",
         "0",
         "4",
         "0.8110",
         "0.1125396825",
         "0.9475759268",
         "49",
         "9",
         "19.6817",
         "14.2129",
         "17.5973",
         "15.0211",
         "14.8225",
         "0.1213",
         "79",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "30",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_P6cQ",
         "1698854680058",
         "1699636550633",
         "6",
         "4",
         "3",
         "3",
         "3",
         "In this paper, the authors study a class of games with many players who are interacting through a sparse graph structure. More specifically, they are interested in the regime where the number of players tend to infinity. The main solution concept is an extension of the notion of Nash equilibrium. The authors propose a learning algorithm based on online mirror descent. They conclude the paper with examples and numerical simulations. Overall, the paper studies an interesting problem and is relatively clearly written. As far as I know, this is a new extension of MFG to sparse graphs. The algorithm is very inspired from existing ones but there is an adaptation to the problem under consideration (core vs periphery). The model is quite abstract at some places. For the theoretical results, they are mostly about the analysis of the game and I am not sure how relevant they are for this conference (although they are certainly interesting for a certain community). It might have been more interesting to focus more on the learning algorithm. \n\nThere are some typos which make it hard to check the correctness of some parts (see questions). 1. I am wondering if some assumptions are missing. For example below Lemma 1, should $f$ be at least measurable (and perhaps more?) with respect to $\\alpha$ for the integral to make sense?\n\n2. Assumption 2 as used for instance in Lemma 1 does not seem to make much sense (unless I missed something): What is $\\boldsymbol{\\pi}$? We do not know in advance the equilibrium policy and even if we did, we would still need to define the set of admissible deviations for the Nash equilibrium. Could you please clarify?\n\n3. Algorithm 1, line 14: Could you please explain or recall what is $Q^{k, \\mu^{\\tau_{\\mathrm{max}}}}$?\n\nSome typos: Should the state space be either $\\mathcal{X}$ or $X$ (see section 3 for instance)? Does $\\mathbb{G}^\\infty_{\\alpha,t}$ depend on $\\boldsymbol{\\mu}$ or not (see bottom of page 4)? Etc.",
         "324",
         "0",
         "4",
         "0.8025",
         "0.19302597400000002",
         "0.9195409417",
         "49",
         "9",
         "56.4417",
         "9.2197",
         "11.6035",
         "11.8555",
         "9.9651",
         "0.6631",
         "111",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "31",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_qFZD",
         "1698724264822",
         "1699636511957",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper introduces out-of-variable (OOV) generalization, which is an the ability to generalize in environments with variables that have never been jointly observed before. OOV is an issue in settings where different variables (e.g. diagnostic tests) are available for different environments (e.g. different patients). The paper investigates challenges for common approaches when faced with the OOV problem, and proposes an OOV predictor that leverage moments of the error distribution. The work contributes to theoretical understandings of OOV and offers a proof-of-concept for a predictor capable of non-trivial OOV transfer. - The paper formally studies a new perspective on generalization.\n- The methods employed in the paper are sound. - The paper does not demonstrate the practical applicability of the concept of OOV generalization, and the setting feels a bit contrived. Also it seems like OOV generalization can be thought of just a case of OOD generalization--if we think about all the variables together as the input, the OOV generalization is just a case of OOD generalization (e.g. covariate shift) where some inputs have clear signal from some features and other inputs have clear signal from other features. \n- It would be helpful to include more intuitive discussion throughout the paper providing more analysis on the sections. For example, more discussion on the assumptions of the settings/theorems would be helpful, and it's not clear exactly under what assumptions the proposed predictor is appropriate. Please see weaknesses above.",
         "236",
         "0",
         "2",
         "0.7220",
         "0.11756198350000001",
         "0.8290046453000001",
         "49",
         "10",
         "31.9194",
         "13.2407",
         "15.9316",
         "14.8796",
         "13.7972",
         "0.1839",
         "85",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "32",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_s9Ga",
         "1698762596885",
         "1700684618252",
         "8",
         "4",
         "3",
         "4",
         "2",
         "This work investigates out-of-variable (OOV) generalization, which is a sub-problem to OOD generalization, and refers to scenarios where an agent needs to generalize to environments containing variables that were never jointly observed before. The paper shows that if the source and target environments contain some overlapping variables (and under certain conditions), information from the predictor in the source environment can improve predictions in the target environment. More specifically,  the moments of the residual distribution from the optimal classifier in the source environment can be used to calculate the generating function with respect to the unobserved variable in the target domain.\n\nBased on this observation, the paper proposes a practical algorithm for OOV prediction, evaluates its performance, and compares it against the marginal predictor and imputed predictor, as well as an Oracle predictor. The paper proposes a new and important problem-setting - OOV generalization, which can occur in real-world situations, on its own or alongside OOD aspects. The work also provides an extensive study of the identification problems of various variants of OOV scenarios, including theoretical proofs and examples. \n\nIn addition, the paper proposes a practical algorithm to solve several OOV scenarios that achieves non-trivial OOV transfer on synthetic data.\n\nThe ideas presented in the paper are novel and the conclusion that information from source domains can be used for prediction in the target domain in this setting is important, and can potentially have a broad impact on future research in the field. The main limitation of the paper is that the proposed approach was tested on only synthetic data, and was not validated using more challenging datasets. \n\nIn addition, the extension of OOV in multi-environments is mentioned mainly in the appendix and the algorithm was not tested empirically for that extension. I would like to ask the following questions:\n\n1. For future work, is there a more complicated/realistic dataset to validate the algorithm?\n2. Is it possible to compare the algorithm to state-of-the-art marginal or causal methods such as Mejia et al. (2021) or Janzing (2018)? To validate if Vapnik’s principle holds and whether the proposed approach indeed improves results due to solving a less general problem.\n3. Theorem 3 connects all moments of the residual distribution to the partial derivatives with respect to the unique variable of the target environment. If additional moments were to be calculated as part of the proposed algorithm, would it improve results (for the general function case)? \n4. In general, since the paper's main claim is that in the real world, it is likely to encounter both aspects of OOD and OOV - How simple is it to combine state-of-the-art  OOD methods with the proposed approach? I cannot imagine at the moment a straightforward way to do that.",
         "454",
         "2",
         "3",
         "0.7695",
         "0.1422634079",
         "0.9121482372",
         "61",
         "22",
         "27.7135",
         "15.3038",
         "18.6308",
         "16.8747",
         "15.9651",
         "0.1633",
         "97",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "33",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_woi7",
         "1698788842803",
         "1699636511769",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper describes the out-of-variable OOV problem, which in its simplest form, aims to learn a predictor Y = f_t(X2, X3) given an OOV predictor Y = f_s(X1, X2) and a dataset (X2, X3), but without any instance of (X2, X3, Y). The authors describe the setting in which this is possible and develops an algorithm. The key observation is that the third moment of the residue Y - f_s(X1,X2) contains information about X3 that is least polluted by the noise. - The key observation/discovery is clever, and the algorithm is straight-forward to use.\n- The writing is clear, clean, and well-referenced. The examples also made things concrete and easy to follow.\n- The rigor and simplicity of the work can act as a foundation to build OOV research. - The main weakness is the applicability of the method. The authors only showed results for proof-of-concept, not for real-world usage. \n- It is unclear how one could identify whether the assumptions are satisfied given a dataset.\n- It is unclear how bad the predictor would be if the assumptions are not satisfied.\n- It is not yet clear what realistic problem can be well modeled by OOV generalization. Intro:\n- It seems OOV fits very well the frame of missing-not-at-random and covariate-dependent missingness. Could the authors comment on that?\n\nSection 2:\n- Theorem 2 is slightly confusing for me at first glance because I thought PA_Y by definition includes all parents of Y (so x1,x2, x3 in the example) and not just those in the target environment (x2, x3). It may be helpful to clarify.\n\nSection 3:\nAs I am trying to get a sense of the restriction and applicability of the approach, I was wondering the following questions: \n- How does the method fair with the oracle as the magnitude of the noise increases? \n- What if the noise is not gaussian but more heavy tailed? \n- Does the performance degrade or improve with increasing number of variables? \n- I assume Theorem 3 does not apply to discrete variables because of the violation of differentiability; is that right?\n\nSection 4:\n- Can include missing-not-at-random imputation and covariate-missing imputation as two more baseline models (a search in Google scholar using the two key phrases yields some methods).\n- It would be really interesting if the authors could find some real-world datasets, create source and target environments by sub-setting the columns, and see how the method performs.\n- Figure 3: I don’t quite understand the figure. It would be helpful to define OOV loss, be explicit about the number of samples on the y-axis being (x2,x3,y) or (x1,x2,y) or something else. I also don’t understand why relative loss is zero means the method is on par with the oracle predictor. Why not just show how the fine-tuning error compares with oracle training, which seems easier to interpret? Anyway, I am overall a bit confused about the figure, so my questions may not make sense.",
         "493",
         "0",
         "0",
         "0.7642",
         "0.0947004608",
         "0.8592604399",
         "49",
         "9",
         "53.3705",
         "10.1765",
         "12.6762",
         "12.5225",
         "10.2004",
         "0.0743",
         "74",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "34",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_xwQY",
         "1699441328198",
         "1699636511667",
         "8",
         "3",
         "3",
         "3",
         "3",
         "The paper investigates out-of-variable generalization, namely the ability for a predictive model to generalize to target domains in which the agent has never seen the joint variables in the target domain in a single source domain before. Under certain assumptions as well as when these assumptions don't fully hold, the paper shows that the error residual distribution in an environment provides information on the unobserved causal parent variable in this environment, and they use this information to derive an algorithm that performs OOV generalization with source and target domains that have overlapping sets of causal factors. **Originality**\n- As far as I know, though the problem the paper addresses is well-known as a significant problem, the paper provides several theoretical results, mathematical derivations, and supports these with simple empirical results that are novel.\n\n**Quality**\n- The quality of the paper is high. It addresses a high-value problem in a principled fashion, shows how certain assumptions help obtain certain results and how and in which cases these assumptions can be bypasses while maintain approximately accurate results, and evaluates these cases in terms of loss accuracy as well as sample complexity of its approach versus baseline approaches.\n- The paper openly highlights limitations in its work, such as assumptions made for theorems to hold, and proposes prospective future work in multiple avenues. This refreshingly is (1) included at all and (2) doesn't seem like a mere afterthought.\n\n**Clarity**\n- The paper is mostly clear in its explanation of motivation, preliminaries, approach, baseline usage, results, and limitations.\n- The paper does a great job providing simple, clear real-world examples to elucidate the problem and applications of the various theorems included in multiple cases.\n\n**Significance**\n- The significance of the problem the paper addresses is high and the problem is ubiquitous. The approach is promising and can be applied in many real-world settings through Monte-Carlo sampling or similar methods. The paper shows that their approach can perform relatively well in \"few\"-shot settings though this depends on the number of variables involved and the complexity of the problem.\n\nFrom what I can tell, this is excellent work that I hope motivates further addressing this *out-of-variable* generalization problem by the research and applied AI community. My only reservation is my limited knowledge on the understanding of and state-of-the-art theoretical and applied approaches addressing this problem. - Referring to Figure 1, in the first paragraph in page 3, the claim \"it would seem all but impossible...(orange box)\" could be better explained.\n- In Figure 1, it is unclear whether \"With $Y$ not observed in the target domain\" is an assumption made or is somehow indicated in the diagram or earlier in the paper. Eventually I realized that it's an assumption made, but the illustration Figure 1a alone isn't enough to show this assumption. This ambiguity may clear for some or compound for some later in Section 3. - The abstract states \"merely considering differences in data distributions is inadequate for fully capturing differences between learning environments.\" Doesn't out-of-variable technically fall under out-of-distribution, so shouldn't this be adequate? Perhaps more specificity is needed here.\n- The abstract states \"Mathematically, out-of-variable generalization requires the efficient re-use of past marginal information...\" Why does it require efficient re-use? Could it work with \"non-efficient\" or inefficient re-use?\n- On page 2, should \"modal\" be \"model?\"\n- On page 6, do you mean \"parentheses\" instead of \"brackets\" between Eq (9) and Eq (10)?\n- Why is the joint predictor considered an oracle predictor if MomentLearn outperforms it?\n- Could you explain why MomentLearn is reliably more sample efficient than the oracle predictor for \"few\"-shot prediction?",
         "602",
         "0",
         "0",
         "0.7701",
         "0.10227124180000001",
         "0.9314678907",
         "49",
         "2",
         "29.5723",
         "14.1717",
         "17.226",
         "15.4091",
         "14.9494",
         "0.45280000000000004",
         "97",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "35",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_HgHQ",
         "1697165838375",
         "1699635934990",
         "3",
         "5",
         "2",
         "3",
         "2",
         "The paper proposes a simple yet efficient feature direction distillation loss. Experiments show that this significantly improves KD\nperformance. 1. Improving KD by feature norm and direction is reasonable and effectiveness.\n2. Experiments on standard benchmarks demonstrate that adopting $\\mathcal{L}_{dino}$ remarkably improves existing KD methods. 1. The contributions seem a little limited. \n2. There is lack of theoretical analysis of DINO loss. The paper is not good enough to be published on ICLR. 1. How to align the features between heterogeneous architectures?\n2. Could you please provide more theoretical analysis?\n3. What about extending it to a multi-layer version of feature distillation?\n4. How to apply the proposed method to existing KD methods, e.g. ReviewKD, DKD, DIST? Just add the DINO loss function to the total loss ? If so, I think adding other loss like contrastive distillation loss or RKD may also make a improvement.",
         "146",
         "0",
         "8",
         "0.8205",
         "0.07793367350000001",
         "0.8326533437",
         "56",
         "28",
         "43.4591",
         "9.7707",
         "12.1429",
         "11.6299",
         "9.46",
         "0.5162",
         "80",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "36",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_yLjx",
         "1697172920902",
         "1699635934905",
         "6",
         "5",
         "3",
         "3",
         "2",
         "Here is a summary of the key points from the paper:\n\n- The paper proposes a method to improve knowledge distillation (KD) by regularizing student features to align direction with teacher class-means and have sufficiently large norms. \n\n- Current KD methods like logit or feature distillation align student and teacher but don't directly optimize for student's task performance.\n\n- The paper shows regularizing direction using cosine similarity to teacher class means helps improve student accuracy. \n\n- It also finds student models tend to produce smaller-norm features, so encouraging larger norms improves performance. \n\n- A simple combined loss called dino-loss is proposed to simultaneously regularize student feature direction and norm using teacher class means.\n\n- Experiments on CIFAR and ImageNet classification, and COCO detection show dino-loss consistently improves various KD methods like KD, ReviewKD, DKD.\n\n- Dino-loss achieves new state-of-the-art results among KD techniques on classification and detection benchmarks.\n\n- The method is model-agnostic, simple to implement, adds minimal overhead, and benefits from larger teacher models.\n\nIn summary, the key contributions are a way to improve KD by regularizing student features for better alignment and norms, along with a simple and effective dino-loss to achieve this jointly. The results demonstrate consistent gains across tasks and benchmarks. The paper presents an original and significant approach to improve KD via thoughtful feature regularization. The method is intuitive and supported by quality experiments. The gains are demonstrated to be significant across tasks. The presentation and discussion are clear:\n- The method and dino-loss are clearly explained with illustrations and equations. Results are well-presented in tables and figures. Limitations are properly discussed.\n- Improving KD is an important practical problem. The consistent gains are significant. Sets new state-of-the-art results on ImageNet classification and COCO detection.\n- Model-agnostic nature allows wide applicability to various KD methods and models. Simple extension can benefit the community compared to more complex techniques. - The paper should address the lack of novelty by acknowledging that feature normalization techniques have already been widely employed in knowledge distillation. For example, PKD (NeurIPS-2023) specifically incorporates channel alignment for detectors, and SKD (Guo Jia) explores normalization techniques on predictions. and Feature Normalized Knowledge Distillation for\n/mage Classification ECCV2022 also presents feature norm. Furthermore, it is worth investigating whether the proposed method has already been considered in the distiller's search work, as exemplified by KD-Zero: Evolving Knowledge Distiller for Any Teacher-Student Pairs (NeurIPS-2023).\n\n- In addition, the paper should incorporate a thorough discussion of relevant KD-related studies, including Self-Regulated Feature Learning via Teacher-free Feature Distillation (ECCV2022), NORM: Knowledge Distillation via N-to-One Representation Matching (ICLR2023), Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer (NIPS2022), DisWOT: Student Architecture Search for Distillation Without Training (CVPR2023), and Automated Knowledge Distillation via Monte Carlo Tree Search (ICCV2023). These discussions will provide valuable insights into the existing literature, establish connections with previous research, and potentially highlight points of comparison and contrast. The only concern to me is the novelty of the work and I hope the authors could discuss some of the related work I mentioned in the revised version.",
         "510",
         "0",
         "1",
         "0.8228",
         "0.134258658",
         "0.9310495853",
         "56",
         "28",
         "21.6614",
         "14.6476",
         "16.1946",
         "15.0048",
         "16.804",
         "0.063",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "37",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_VRvE",
         "1698736302686",
         "1699635934723",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper studies Knowledge Distillation (KD). A simple loss term namely ND loss is proposed to enhance the distillation performance. It encourages the student to produce large-norm features and aligns the direction of student features and teacher class-means. The ND loss helps not only logit-based distillation methods but also feature-based distillation methods. 1. The proposed method is simple but effective. Encouraging the feature norm for the student is novel in the field of KD.\n2. Experimental results are strong. The authors also conduct experiments on object detection. The proposed loss can improve the existing methods on both image classification and object detection.\n3. The whole paper is organized and written well. It is not a novel thing that decoupling the feature into the magnitude and the direction. Previous works \\[1\\]\\[2\\] already studied this point. \\[1\\] uses the teacher classifier to project both teacher features and student features into the same space and then align them. \\[2\\] proposes a loss term to align two features’ direction. Compared to the existing works, this paper proposes enlarging feature norm and utilizing the class-mean feature. Authors should check more existing papers and discuss their differences.\n\\[1\\] Yang, Jing, et al. \"Knowledge distillation via softmax regression representation learning.\" International Conference on Learning Representations (ICLR), 2021.\n\n\\[2\\] Wang, Guo-Hua, Yifan Ge, and Jianxin Wu. \"Distilling knowledge by mimicking features.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 44.11 (2021): 8183-8195. None",
         "235",
         "7",
         "6",
         "0.7478",
         "0.1515151515",
         "0.9257477522",
         "56",
         "10",
         "45.6243",
         "9.4339",
         "10.8955",
         "11.0306",
         "10.9165",
         "0.0999",
         "85",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "38",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_AuzT",
         "1698788774762",
         "1699635934515",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper proposes to use teacher's class-mean to align student's direction and encourage the student to produce large-norms features, improving the performance of KD. The paper is generally well-written, and the methodology is well-motivated. 1. would expect comparisons and discussion to similarity-preserving KD e.g., \\[1\\], which is a large family in feature distillation methods and shows some relations to the proposed method.\n2. Meanwhile, comparisons/discussion to explainablity-based KD, e.g., \\[2\\] are needed to see whether those methods can be benefited from the proposed method.\n\n\\[1\\] Tung, Fred, and Greg Mori. “Similarity-Preserving Knowledge Distillation.” ICCV 2019.\n\n\\[2\\] Guo, Ziyao, et al. \"Class Attention Transfer Based Knowledge Distillation.\" CVPR 2023. Please see weakness.",
         "111",
         "4",
         "6",
         "0.7517",
         "0.1321428571",
         "0.8699356318",
         "56",
         "9",
         "39.5873",
         "10.2446",
         "10.8832",
         "11.2081",
         "12.4695",
         "0.1376",
         "72",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "39",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_AcYB",
         "1697637540901",
         "1700740134087",
         "5",
         "4",
         "3",
         "2",
         "2",
         "The authors introduce Neural Sinkhorn gradient flow, which is a Wasserstein Gradient Flow wrt to the Sinkhorn divergence. The authors show that the velocity field can be calculated using the Sinkhorn potentials. This allows training a neural network approximating the velocity field. Furthermore, a mean field limit is established. The algorithm is evaluated on a toy example, MNIST image generation and CIFAR10 image generation. The authors do a good job at explaining the underlying concepts of their algorithms. The maths is nicely done. The core idea is very neat and the cifar10 results seem to be good quantitatively wrt other gradient flow works. 1) The article is full with typos. Just to name a few: \"piror\", \"Sinkhron\", \"Experimrnts\", \"speedest descent\", question mark in the appendix and so on. Please fix those. \n\n2) the authors write \"We do not compare with extant neural WGF methods on MNIST because most of the neural WGF\nmethods only show generative power and trajectories on this dataset and lack the criteria to make\ncomparisons.\" There are several papers (also gradient flow based ones), which evaluate a FID on MNIST. Please provide it as well. \n\n3) Also many of the MNIST digits appear flipped. Did the authors use data augmentation there? Also there seems to some slight noise present the generated MNIST digits. \n\n4) Although the CIFAR10 value seems good, there are unfortunately no generated images provided. It is standard practice to sample many images in the appendix. \n\n5) It is unclear what the trajectories show. Does it show the particle flow or the trained Neural Sinkhorn Gradient Flow? \n\n6) The statement of theorem 2 is incorrect. I guess the authors do not want to sample the Euler scheme (eq 14) but the continuous gradient flow, otherwise the statement would need to depend on the step size $\\eta$. \n\n7) In the proof of Theorem 2: Please provide a proof (or reference) why the mean field limit exists. Or do you mean the gradient flow starting at $\\mu_0$ with target $\\mu$ (first two sentences).\n\n8) Later in that proof: why does there exists a weakly convergent subsequence of $\\mu_t^M$? Further, I cant find the definition of $U_{\\mu}$. \n\n9) The code is not runnable, as the model (or any checkpoints) are not provided.\n\n10) From how I understood it, the learning of the velocity field is batched, i.e., one trains for different sets of $(z_i,x_i)$. Since the Sinkhorn dynamic describes an interacting particle system I dont see how this should be possible. To be more precise, one particle $\\tilde{x}$ could be sent to $x_0$ in the first batch, but to a totally different particle $x_1$ in another one, depending on the drawn prior and target samples. Are the positions of the other particles also input to the neural network (i.e by putting them in the channels)? Please elaborate. See weaknesses section. Overall I really like the idea, but the weaknesses prevent me from giving a higher score. It seems like the paper was rushed and is currently not ready for publication. I am willing to raise my score, if the authors address these issues.",
         "516",
         "0",
         "3",
         "0.7790",
         "0.1480691057",
         "0.8920141459",
         "62",
         "35",
         "60.9059",
         "8.1376",
         "10.8579",
         "11.2611",
         "8.6721",
         "0.2179",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "40",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KKim",
         "1698338217824",
         "1700755549491",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces a novel way to train generative models. The authors want to approximate the gradient flow in the Wasserstein space.  They want to approximate the vector field which transports the source distribution to the real-data empirical distribution while minimizing the Sinkhorn divergence. The authors showed the analytical form of the vector field when one considers the Sinkhorn divergence and then they explain how to learn this vector field with a neural network through the simulation of a probability path. They showed that their procedures recover the true probability path when the number of iid samples goes to infinity. Finally, they validate their proposed method on several image-generative tasks. i) The motivation and the introduction are clear\n\nii) Regressing vector fields has been a recent and popular approach with many different applications in machine learning. The proposed approach is interesting and appears to be novel. The theoretical results also show that the proposed method has appealing properties. \n\niii) The authors also provided several experiments showing interesting results from their methods. The first thing I would like to highlight is that I have checked the provided code. I see several inconsistencies and weaknesses between the provided code and the paper:\n\n1. There are several differences in the empirical implementation between the paper and the code. In Appendix A, the authors state that they are computing the entropic potential through stochastic optimization algorithms \\[Genevay et al, 2016\\]. However, this is not what is done in practice according to the provided code. In practice, the authors compute the potential between mini-batches of samples, they sample a minibatch of cifar10 experiments, then sample a minibatch of the source Gaussian, and simulate the gradient flows between the two minibatches. This style of minibatch approximation induces a bias that should at least be mentioned in the main paper but also discussed. Indeed, the authors do not compute the true Sinkhorn divergence but a minibatch approximation of it; this approximation is slightly different than the one from \\[1,2\\] and that should be discussed. I understand the reason why the authors use this approach (decreasing the cost of this preprocessing step), but this is not what they say they do in Appendix A. In that regard, the paper is much closer to the minibatch optimal transport Flow Matching \\[Pooladian et al., Tong et al\\] and Appendix A deserves a major revision.\n\n2. With the provided code, there are several insights that should be discussed in the paper. In the provided cifar experiments, the number of Gaussian samples used is 50000 samples. This number is extremely low to approximate the semi-discrete OT. Therefore, a discussion regarding the statistical performance of the method is needed in my opinion.\n\n3. As your method requires the simulation of the probability path, I wonder about the training time between your method and the recent Flow Matching approaches which are simulation free.\n\n4. There are many typos in the paper (including in titles: ie ExperimRnts, Notaions) that lead to poor clarity...\n\n5. The experiments include two toy datasets (synthetic 2D and MNIST). I would like to know how the method performs on other big datasets (Flowers, CelebA) or on other tasks such as single-cell dynamics \\[4\\].\n\n6. The related work on optimal transport is incomplete. Several works used the sliced Wasserstein distance to perform gradient flows \\[3\\].\n\n\\[1\\] Learning Generative Models with Sinkhorn Divergences, Genevay et al, AISTATS 2018\n\\[2\\] Learning with minibatch Wasserstein, Fatras et al, AISTATS 2020\n\\[3\\] Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions\n\\[4\\] TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics 1. \\[Pooladian et al., Tong et al.\\] proved that when the minibatch increases, they get closer to the true optimal transport cost (W_2^2). The interest of their method is that they can rely on minibatches and learn the vector field from an unlimited number of minibatches. Could you follow a similar approach and simulate the gradient flow during training? While it would be an expensive step in training, it might improve the metrics on the different generative model experiments.\n\n2. What is the performance of your method concerning the number of simulation steps (ie Euler integration and its learning rate)?\n\n3. What is the time of the preprocessing step concerning the training time?\n\n4. Could you compare your method with OT-CFM \\[Pooladian et al., Tong et al.\\] on the synthetic data? I am curious to compare the differences.\n\nIn my opinion, the mentioned weaknesses have to be revised and this paper should go under a major revision. I deeply think that the experimental section should better highlight what is done in practice and the theoretical section should mention the different biases (statistical and minibatch). Therefore, I recommend rejecting the current manuscript as it does not meet the ICLR acceptance bar.\n\n\n----- EDIT POST REBUTTAL -----\n\nI thank the authors for their answers. I have read the updated manuscript. While it is now better than before, I suggest they add a limitation section where they describe the different biases in their algorithm. I understand the motivations of the paper. Overall, I think that the manuscript deserves another round of reviews but I have decided to move my score to 5 as they have given good answers.",
         "873",
         "7",
         "8",
         "0.7648",
         "0.0723611111",
         "0.8572189808",
         "62",
         "27",
         "47.6358",
         "10.776299999999999",
         "13.8642",
         "13.3974",
         "11.9247",
         "0.9374",
         "105",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "41",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_Kh9H",
         "1698606606187",
         "1699636333063",
         "6",
         "4",
         "3",
         "2",
         "2",
         "Through a series of approximations (and at times, really, relaxations) the authors show that the Sinkhorn gradient flow from one measure to another can be learned.  They do this by first reducing their relaxed problem to a vector field matching problem, and then proposing a neural network-based Algorithm for matching the Sinkhorn-Wasserstein flow's vector field by a neural network (though no convergence/approximation guarantees are proven).\nThe problem is interesting, and its solution is sufficiently novel to merit publication. The problem is natural to study, the results are mathematically correct, and the experiments are convincing. While the paper is mathematically correct, it does not provide theoretical justification for one of its main components, namely showing that approximate vector field matching yields approximate solutions for all time $t$.  I feel that without this guarantee, there is a gap in the theoretical viability of this model.  Nevertheless, this is a minor point since the length of a conference paper does not allow one to treat every such point.\n\nThere are minor typos throughout. \n* E.g. euclidean instead of Euclidean\n* $lim$ instead of $\\lim$ atop page 15 in the appendix\n* The positive scalar $\\delta$ is not defined in the proof of Theorem $1$\n* In the statement of Lemma 3: \"teh\" should read \"the\"\n\nSome references are obscure\n* For The fact that $\\mu + t\\delta \\mu$ converges weakly to $\\mu$, perhaps it is worth simply noting that due to linearity of integration (wrt to the measure term). Can it be shown that approximate vector field matching yields approximate solutions for all time $t$?",
         "262",
         "0",
         "1",
         "0.7647",
         "0.0019972452",
         "0.8472071886",
         "49",
         "11",
         "40.0713",
         "14.0299",
         "16.0213",
         "14.5546",
         "15.9806",
         "0.0613",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "42",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KkYD",
         "1698745650108",
         "1700818697559",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper under consideration deals with the standard generative modelling setup (image generation from noise). To solve this problem, the authors propose to model the gradient flow w.r.t. the Sinkhorn divergence. The paper utilizes an explicit (forward) Euler discretization scheme, i.e., given a distribution $\\mu_t$ at the current time step $t$, the proposed method aims at finding the subsequent distribution $\\mu_{t + 1}$ following the gradient of the Sinkhorn divergence at point $\\mu_t$. The authors validate their methodology on toy 2D setups as well as standard image benchmarks (MNIST and CIFAR10).\n\n**Post-rebuttal update:** I thank the authors for the detailed answer. The majority of my concerns are properly addressed. I rise my score. However, I still tend to reject the paper. Also I agree with reviewer KKim that minibatch OT approximation should be discussed more thorougly. Thank you. To the best of my knowledge, the framework of the gradient flow w.r.t. Sinkhorn divergence for pure generative modelling has not yet been considered. This indicates that the paper is indeed bringing something novel to the ML community. At the same time, the idea of the Sinkhorn gradient flow has already arisen in previous research. In particular, \\[A\\] solves Sinkhorn barycenter problems by adjusting a generative distribution towards the barycenter distribution with the help of a procedure called “functional gradient descent” which is actually the discretization of the gradient flow w.r.t. the sum of Sinkhorn divergences to the target distributions. At the same time, it is worth mentioning, that \\[A\\] just simulates particles and does not build a generative model.\nRegarding the other strengths of the paper, I would like to note the well-organized Experiments section.\n\n\\[A\\] Sinkhorn Barycenter via Functional Gradient Descent, NeurIPS’2020 - Some theoretical results from the paper are known. For example, the statement of Theorem 1 could be found in \\[B\\] (eq. 26) or \\[C\\] (eq. 8). \n- The quality of the code provided is not good. There is no README/or other instruction to run the code. There are imports of non-existing classes. So, there is no possibility of checking (at least, qualitatively) the provided experimental results.\n\nFrom my point, the main weakness of the proposed paper is the limited methodological contribution. The authors simulate the particles of data following Sinkhorn divergence - as I already mentioned, this is not a super fresh idea. To make a generative model from these simulated trajectories, the authors simply solve the regression task to learn the local pushforward maps. And that is it. Combined with the fact, that the practical performance of the proposed approach is far from being SOTA in the generative modelling, the overall contribution of the paper seems for me to be limited. - My main question (and, probably, one of the main of my concerns) is regarding the proposed methodology. The authors propose to compute certain $\\mathcal{W}_{\\varepsilon}$ potentials (on discrete support of available samples) and then somehow take the gradients of these potentials w.r.t. the corresponding samples (eq. (13)). From the paper it is not clear how to compute the gradients, because the obtained potentials look like vectors of sample size shape, which are obtained through the iterations of the Sinkhorn algorithm. As I understand, in practice, the authors utilize SampleLoss from the geomloss package (\\[B\\]).  The outcome of this observation is that \\[B\\] should be properly cited when deriving the algorithm (section 4.2). I recommend authors explicitly use SampleLoss in the algorithm's listing. It will contribute to the clearness of what's going on. \n- The vector field of the Sinkhorn gradient flow is estimated by empirical samples. It is not clear how well this sample estimate approximates the true vector field. This point should be clarified. Note, that Theorem 2 works only for mean-field limit. \n- In the Introduction section, the authors consider a taxonomy of divergences used for gradient flow modelling, namely, \"divergences \\[...\\] with the same support\" and \"divergences \\[...\\]  with possible different support\". As I understand, the first class is about $f-$ divergences and the second class is about the other types (like Sinkhorn, MMD etc.). I have a question regarding the provided examples of works which deal with the former or the latter type of divergences. The fact is that the works \\[D\\], \\[E\\], \\[F\\], \\[G\\] deal with KL-divergence (or f-divergence) minimization. That is why I wonder why did the authors classify them as the second class.\n- A good work regarding poor expressiveness of ICNNs is \\[H\\].\n- What is the “ground” set ($\\S$ 3.1, first line).\n- Table 1. What are the differences between 1-RF, 2-RF and 3-RF methods?\n\n\\[B\\] Interpolating between Optimal Transport and MMD using Sinkhorn Divergences, AISTATS’2019\n\n\\[C\\] Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm, NeurIPS’2019\n\n\\[D\\] Large-scale wasserstein gradient flows. NeurIPS'2021\n\n\\[E\\] Optimizing functionals on the space of probabilities with input convex neural networks. TMLR\n\n\\[F\\]  Proximal optimal tranport modeling of population dynamics. AISTATS\n\n\\[G\\] Variational wasserstein gradient flow. ICML\n\n\\[H\\] Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. NeurIPS’2021.",
         "827",
         "0",
         "8",
         "0.7673",
         "0.0867376775",
         "0.8458420038000001",
         "63",
         "23",
         "48.4494",
         "9.8761",
         "12.9425",
         "12.5739",
         "10.9848",
         "0.5343",
         "74",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "43",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_MEFG",
         "1699146383667",
         "1699636332903",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces the idea of learning a time-dependent velocity field of the Sinkhorn Wasserstein gradient flow from samples from the target distribution to calculate the empirical velocity field approximations. The paper supports its claim by showing that the mean-field limit of this process recovers the true Sinkhorn Wasserstein gradient flow. They also validated the process with some empirical studies. The paper is well written and easy to follow. The proofs and arguments in the appendix are well-typed out and clear.  There are some nice diagrams in the empirical section to supports the claim the authors are making. I think the experiments could be more extensive. One thing about this method is to investigate the number of samples needed. effectively learn the velocity field. This is one important experiment missing as is remains unclear how sample-efficient the proposed method is. It would also make the paper more completing if the method is applied to generative models that output discrete random variable like binary mnist or even language modelling. One possible question is what happens if we change the source distribution to be closer to the target distribution like it was from a generator how would the method perform there. Another question is to better understand the sample complexity of the method as the current method may not be sample efficient due to the empirical distribution being approximated using the samples.",
         "230",
         "0",
         "0",
         "0.7569",
         "0.1872807018",
         "0.8377009034",
         "49",
         "5",
         "39.9077",
         "12.0883",
         "13.8595",
         "13.639",
         "12.502",
         "0.216",
         "99",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "44",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_JSi7",
         "1698680587788",
         "1699636955419",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This article discusses a method to improve the application of SLM in the medical field, utilizing LLM's medical proficiency to boost SLM performance in medical tasks under privacy-restricted scenarios which has important social significance. The method was tested on MedQA, HEADQA, MedMCQA, and MMLU-professional medicine datasets, showing some improvements over existing methods. Additionally, the authors compared results across different sizes of training sets. see summary 1). Imprecise example of Privacy Protection.\nThe example in Figure 1 indicates that personal privacy issues are only present in the first sentence, and the key words \"man\" and \"admitted\" in that sentence have almost no impact on the subsequent content. Could it then be possible to simply delete the first sentence to achieve privacy protection, as extracting key words here does not seem to play a significant role.\n\n2). Privacy Protection as an Innovation Point\nRegarding the extraction of key words for privacy protection, the paper uses a medical NER model proposed by Neumann et al in 2019. We suggest further improvement of this model, for example, considering age as a crucial keyword for certain diseases and extracting it as necessary to better enrich the innovative aspects of the paper.\n\n3). Ambiguity of Symbols in Annotations\nAnnotation 13 on page 8 only appears in the content of the article but is not explained.\n\n4) The overall innovation of the methodology needs improvement, as the majority of the content relies on existing methods, such as the medical NER (Named Entity Recognition) model. please see the weaknesses.",
         "251",
         "0",
         "3",
         "0.8122",
         "0.0869868637",
         "0.8446011543",
         "48",
         "11",
         "30.5608",
         "14.193",
         "18.2471",
         "16.5267",
         "14.5487",
         "0.1839",
         "83",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "45",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_gXvF",
         "1698819472631",
         "1699636955275",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This paper tried to improve the performance of small medical language models by introducing knowledge from large language models, which keeps the privacy of clinical text when using large language models.  The proposed method uses keywords instead of full raw text to generate initial evidence from LLM and feed the evidence to small language model. Privacy-preserving is an essential and common need when using LLM in clinical text. This paper tried to solve this problem by using keywords instead of raw text, the idea is novel and experiments demonstrated the effectiveness of this approach. 1. As this research utilized a named entity recognition model to extract keywords, it is possible that the NER model can extract privacy information such as patient names. Is there any filtering or postprocessing step to avoid that? In addition, it is not guaranteed that NER system will never extract sensitive patient information; for example, if the NER system incorrectly extracts a patient's address as a symptom, then the address may be leaked to LLM. Although it is very rare, it is still necessary to comment on this. \n2. As the LLM already provides a preliminary decision, I am curious about the performance if we only feed the preliminary decision from LLM to SLM. It is worth knowing which part of the LLM-generated information improves the SLM most. \n3. The related work section need to discuss more LLM application in the clinical area, especially the knowledge-enhanced LLM in clinical settings. For example, paper \"Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.\" also utilized external knowledge for clinical questions. \n4. By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem? By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem?",
         "326",
         "0",
         "4",
         "0.7696",
         "0.0399925075",
         "0.9072911739",
         "48",
         "9",
         "42.8243",
         "12.0502",
         "14.7872",
         "13.9505",
         "12.5318",
         "0.181",
         "108",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "46",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_TtE2",
         "1698819599156",
         "1700663756238",
         "6",
         "4",
         "2",
         "2",
         "3",
         "The paper studied medical QA problems by incorporating large language models (LLMs) to assist small-language models (SLMs). To protect the private information in the data, the authors propose to first extract keywords and then use the keywords to query LLMs for intermediate content which can be used for SLMs to enhance prediction accuracy. 1. (originality) The proposed method is novel by extracting keywords and privately incorporating LLM for SLM-based predictions.\n2. (clarity) Overall, the paper is fair in presentation. The demonstrations of synthetic medical data with private information and extracted keywords are helpful for understanding the concepts.\n3. (significance) Versus the compared baselines, the proposed methods significantly improve the prediction accuracy on three medical QA tasks.\n4. (quality) The authors thoroughly evaluate the performance of the proposed method. 1. (Clarity) There is no specific definition of the private information. From Figure 1, it seems that privacy definition is restricted to private identifiable information (PII). The authors should clarify the scope of privacy risks. Importantly, the proposed method cannot address general private information leakage that is considered by strict formulations like differential privacy.\n2. (Quality) The evaluation of privacy is not strict. \n  - Risks: It is possible that the keyword extraction includes private identifiable information (PII), for instance, names and dates as shown in Figure 1. There is no theoretical guarantee for privacy protection or empirical evaluation of the leakage rates of such PII.\n  - Metric: The authors used the privacy budget for quantifying privacy risks:  the ratio of the number of words provided to the LLM to the total words in the original question. However, I doubt if the metric can imply some privacy risks. There essentially lacks an intuitive explanation of the relationship between the privacy budget and privacy risks.\n3. (Motivation) As the authors said, SLM presents a large gap compared to LLMs and thus there is no clear motivation to use SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. In the paper, there is no referred evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks. Thus, I strongly doubt if the motivation of the paper can hold. * There is no clear motivation to see SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. Is there any evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks?",
         "426",
         "0",
         "7",
         "0.7723",
         "0.0983912484",
         "0.9060524702",
         "59",
         "21",
         "36.5456",
         "12.5405",
         "15.7498",
         "14.4949",
         "13.1327",
         "0.1262",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "47",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_EBQC",
         "1699202302455",
         "1701315616812",
         "6",
         "3",
         "3",
         "3",
         "3",
         "In situations where text data is subject to privacy protection constraints, this paper designs a small-scale language model to perform diagnoses of diseases. Utilizing the rich prior medical knowledge in LLM, the approach involves generating a medical knowledge-intensive context using privacy-protected text. This generated context, along with key terms extracted from the text and questions, is then input into the SLM, which is fine-tuned during training. Experiments across multiple datasets demonstrate that this fine-tuning process effectively enhances the accuracy of the diagnostic model. 1. This paper focuses on a very important research topic in the field of medicine: how to effectively extract more useful information from incomplete text under the conditions of privacy protection. The author has made full use of the domain knowledge in LLM to effectively fine-tune the SLM, which ensures that the lightweight models can achieve high accuracy.\n\n2. This paper presents rich and comprehensive experiments. Beyond basic decision-making tasks, it also explores solutions for few-shot experiments and out-of-distribution (OOD) model generalization using the methods discussed in this paper.\n\n3. This paper fully utilizes the rich domain knowledge in LLMs to expand the knowledge base of medical reports, achieving excellent diagnostic accuracy even while ensuring privacy protection. 1. The contribution of this paper to the algorithm and the significance of the clinical problems it addresses seem not to be very high.\n\n2. The main work of this paper appears more as an engineering problem, transferring domain knowledge from LLMs to SLMs. From the perspective of algorithmic contribution, there seems to be some room for improvement. 1. The experimental datasets in this paper are all question-and-answer test datasets, and whether the methods of this paper are applicable to medical report datasets requires additional experimentation. This is because in medical reports, how to generate high-quality questions using other LLM interfaces is a question worth studying.\n\n2. Large language models provide additional domain knowledge, but in the context of specific medical tasks, will the direct transfer of knowledge from LLMs to SLMs lead to incorrect information leakage into SLMs? How can we ensure that LLMs only enhance information relevant to the current medical issue without introducing additional errors or irrelevant information? This is a very important issue in the medical field, as it directly relates to patient diagnosis.",
         "378",
         "0",
         "7",
         "0.8087",
         "0.1651777003",
         "0.9162929654",
         "67",
         "24",
         "24.0186",
         "15.4331",
         "18.2063",
         "16.3464",
         "16.6892",
         "0.09870000000000001",
         "96",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "48",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E\\[x_t^\\top \\eta\\]>0$, where $E\\[\\cdot\\]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9",
         "0.7199",
         "0.1048061787",
         "0.9118013978",
         "49",
         "12",
         "45.2022",
         "10.9542",
         "14.0176",
         "13.1874",
         "11.7498",
         "0.1041",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "49",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9",
         "0.8034",
         "0.040322580600000005",
         "0.9313320518",
         "49",
         "9",
         "50.8505",
         "9.2389",
         "11.4157",
         "11.538",
         "10.4235",
         "0.1822",
         "96",
         "0",
         "0",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 28028
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_eS3u</td>\n",
       "      <td>1698243150596</td>\n",
       "      <td>1699636093263</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6186</td>\n",
       "      <td>17.9130</td>\n",
       "      <td>16.0443</td>\n",
       "      <td>17.8357</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_jP4i</td>\n",
       "      <td>1698652503617</td>\n",
       "      <td>1699636093190</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0899</td>\n",
       "      <td>17.5302</td>\n",
       "      <td>15.9032</td>\n",
       "      <td>16.5285</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_wiS9</td>\n",
       "      <td>1698706547448</td>\n",
       "      <td>1699636093122</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5403</td>\n",
       "      <td>12.0174</td>\n",
       "      <td>11.8969</td>\n",
       "      <td>11.5244</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_a6Ps</td>\n",
       "      <td>1698768293694</td>\n",
       "      <td>1699636092942</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8007</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>13.1410</td>\n",
       "      <td>11.9551</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_Frem</td>\n",
       "      <td>1699350072271</td>\n",
       "      <td>1699636092872</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8574</td>\n",
       "      <td>13.8000</td>\n",
       "      <td>13.1060</td>\n",
       "      <td>11.3839</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28023</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_vt7i</td>\n",
       "      <td>1698673110283</td>\n",
       "      <td>1699636153803</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0579</td>\n",
       "      <td>12.7786</td>\n",
       "      <td>12.5508</td>\n",
       "      <td>10.3710</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28024</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_oaZ7</td>\n",
       "      <td>1698928691830</td>\n",
       "      <td>1699636153728</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8753</td>\n",
       "      <td>13.4660</td>\n",
       "      <td>12.9318</td>\n",
       "      <td>11.0496</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_fMm6</td>\n",
       "      <td>1698618130371</td>\n",
       "      <td>1699636636496</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2763</td>\n",
       "      <td>15.9379</td>\n",
       "      <td>14.6494</td>\n",
       "      <td>14.6519</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28026</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_tZQw</td>\n",
       "      <td>1698807944071</td>\n",
       "      <td>1699636636378</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11.3380</td>\n",
       "      <td>13.3077</td>\n",
       "      <td>12.5694</td>\n",
       "      <td>11.8039</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28027</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_9qjF</td>\n",
       "      <td>1698910414535</td>\n",
       "      <td>1699636636278</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>16.9199</td>\n",
       "      <td>19.5537</td>\n",
       "      <td>17.1577</td>\n",
       "      <td>17.8347</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28028 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zzv4Bf50RW               1647             1695102158671   \n",
       "1        zzv4Bf50RW               1647             1695102158671   \n",
       "2        zzv4Bf50RW               1647             1695102158671   \n",
       "3        zzv4Bf50RW               1647             1695102158671   \n",
       "4        zzv4Bf50RW               1647             1695102158671   \n",
       "...             ...                ...                       ...   \n",
       "28023    014CgNPAGy               2200             1695179071455   \n",
       "28024    014CgNPAGy               2200             1695179071455   \n",
       "28025    0074qaufB6               5962             1695403263602   \n",
       "28026    0074qaufB6               5962             1695403263602   \n",
       "28027    0074qaufB6               5962             1695403263602   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "1      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "2      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "3      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "4      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "...                                                  ...   \n",
       "28023                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28024                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28025          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28026          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28027          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "1      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "2      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "3      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "4      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "...                                                  ...   \n",
       "28023  On the Role of Momentum in the Implicit Bias o...   \n",
       "28024  On the Role of Momentum in the Implicit Bias o...   \n",
       "28025  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28026  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28027  InfoNet: Missing Information Retrieval in Mult...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Establishing accurate dense 3D correspondences...  Reviewer_eS3u   \n",
       "1      Establishing accurate dense 3D correspondences...  Reviewer_jP4i   \n",
       "2      Establishing accurate dense 3D correspondences...  Reviewer_wiS9   \n",
       "3      Establishing accurate dense 3D correspondences...  Reviewer_a6Ps   \n",
       "4      Establishing accurate dense 3D correspondences...  Reviewer_Frem   \n",
       "...                                                  ...            ...   \n",
       "28023  Momentum is a widely adopted and crucial modif...  Reviewer_vt7i   \n",
       "28024  Momentum is a widely adopted and crucial modif...  Reviewer_oaZ7   \n",
       "28025  Faulty sensors in a multiple input stream setu...  Reviewer_fMm6   \n",
       "28026  Faulty sensors in a multiple input stream setu...  Reviewer_tZQw   \n",
       "28027  Faulty sensors in a multiple input stream setu...  Reviewer_9qjF   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1698243150596           1699636093263              6  ...   \n",
       "1      1698652503617           1699636093190              5  ...   \n",
       "2      1698706547448           1699636093122              3  ...   \n",
       "3      1698768293694           1699636092942              5  ...   \n",
       "4      1699350072271           1699636092872              5  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "28023  1698673110283           1699636153803              5  ...   \n",
       "28024  1698928691830           1699636153728              3  ...   \n",
       "28025  1698618130371           1699636636496              1  ...   \n",
       "28026  1698807944071           1699636636378              3  ...   \n",
       "28027  1698910414535           1699636636278              5  ...   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "0                   14.6186      17.9130     16.0443   \n",
       "1                   14.0899      17.5302     15.9032   \n",
       "2                    9.5403      12.0174     11.8969   \n",
       "3                   10.8007      13.4756     13.1410   \n",
       "4                   10.8574      13.8000     13.1060   \n",
       "...                     ...          ...         ...   \n",
       "28023               10.0579      12.7786     12.5508   \n",
       "28024               10.8753      13.4660     12.9318   \n",
       "28025               13.2763      15.9379     14.6494   \n",
       "28026               11.3380      13.3077     12.5694   \n",
       "28027               16.9199      19.5537     17.1577   \n",
       "\n",
       "       automated_readability_index politeness_score  hedge_C  hedge_D  \\\n",
       "0                          17.8357           0.1213       78        0   \n",
       "1                          16.5285           0.1719       73        0   \n",
       "2                          11.5244           0.0503       77        0   \n",
       "3                          11.9551           0.1290       85        0   \n",
       "4                          11.3839           0.1864       81        0   \n",
       "...                            ...              ...      ...      ...   \n",
       "28023                      10.3710           0.2111       90        0   \n",
       "28024                      11.0496           0.1100      100        1   \n",
       "28025                      14.6519           0.1507       98        0   \n",
       "28026                      11.8039           0.0720       99        0   \n",
       "28027                      17.8347           0.0917       74        0   \n",
       "\n",
       "       hedge_E hedge_I  hedge_N  \n",
       "0            0       0        0  \n",
       "1            0       0        0  \n",
       "2            0       0        0  \n",
       "3            2       0        0  \n",
       "4            0       0        0  \n",
       "...        ...     ...      ...  \n",
       "28023        0       0        0  \n",
       "28024        0       0        0  \n",
       "28025        1       0        0  \n",
       "28026        0       0        0  \n",
       "28027        0       0        0  \n",
       "\n",
       "[28028 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "input_file = '/home/ali/Review_Quality_Benchmark/data/processed/openreview_iclr2024_v8.json'\n",
    "\n",
    "df = pd.read_json(input_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6b274fee-b8d0-4f72-8161-e82e27760357",
       "rows": [
        [
         "15",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2",
         "0.8079",
         "0.1061594203",
         "0.8954392672",
         "49",
         "12",
         "30.6084",
         "13.0004",
         "15.6607",
         "14.5546",
         "14.526299999999999",
         "0.0364",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "16",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head \\[1\\], \\[2\\], \\[3\\]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works \\[1\\]\\[2\\] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n\\[1\\], Frozen clip models are efficient video learners, ECCV-2022\n\n\\[2\\], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n\\[3\\]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0",
         "0.7694",
         "0.0820393375",
         "0.8567712307",
         "49",
         "11",
         "39.7853",
         "10.703",
         "12.5661",
         "12.2047",
         "12.4388",
         "0.07200000000000001",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "17",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7",
         "0.8374",
         "0.0525974026",
         "0.9221839309000001",
         "49",
         "8",
         "20.0915",
         "14.8293",
         "18.2521",
         "15.9032",
         "16.8967",
         "0.19390000000000002",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "18",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0",
         "0.7506",
         "0.3529761905",
         "0.8587207794",
         "49",
         "2",
         "56.3637",
         "9.621",
         "12.2299",
         "12.231",
         "10.3101",
         "0.4364",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "48",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E\\[x_t^\\top \\eta\\]>0$, where $E\\[\\cdot\\]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9",
         "0.7199",
         "0.1048061787",
         "0.9118013978",
         "49",
         "12",
         "45.2022",
         "10.9542",
         "14.0176",
         "13.1874",
         "11.7498",
         "0.1041",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "49",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9",
         "0.8034",
         "0.040322580600000005",
         "0.9313320518",
         "49",
         "9",
         "50.8505",
         "9.2389",
         "11.4157",
         "11.538",
         "10.4235",
         "0.1822",
         "96",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "50",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_g3du",
         "1698930603674",
         "1700722619651",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper unifies the ``linear demand'' and the ``linear valuation'' by proposing a new demand model where each item has a feature-dependent price elasticity. The authors devise an effective online optimization algorithm that can achieve a nearly optimal regret bound. Some numerical simulations are conducted to empirically show the effectiveness of the proposed approach. S1. A new demand model for the contextual pricing problem.\n\nS2. The proposed algorithm has a regret bound close to the theoretical lower bound.\n\nS3. Numerical simulations are conducted. W1. Although the proposed demand model extends existing models by considering the feature-dependent price elasticity, the proposed model and online algorithm still rely on linear forms of elasticity and valuation. Remember ICLR is a deep learning conference. A potentially more suitable treatment may be substituting the linear functions with a neural tangent kernel and then devising online algorithms correspondingly.\n\nW2. What is the major technical challenge if we replace the uniform \\alpha with a feature-dependent price elasticity? The authors may want to discuss more the impact of introducing feature-dependent price elasticity terms on algorithm design as well as regret analysis. \n\nW3. As the authors mention in Ethic issues, personalized pricing may have fairness issues. Therefore, it is essential to discuss how to deal with the cases when we add some fairness regularization terms or fairness constraints to the optimization problem. \n\nW4. Still about personalized pricing. As the objective is purely the interest of the platform, I would like to see discussions or experimental results on how the personalized pricing algorithm affects customer well-being metrics such as consumer surplus. W2",
         "262",
         "0",
         "8",
         "0.7992",
         "0.1764419404",
         "0.8751015663",
         "62",
         "20",
         "25.3956",
         "14.0564",
         "15.689",
         "14.5546",
         "14.287",
         "0.11520000000000001",
         "91",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "51",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_DP3X",
         "1699005113456",
         "1699636362126",
         "3",
         "3",
         "2",
         "3",
         "2",
         "In this work, the authors face the problem of contextual dynamic pricing in a heteroscedastic environment. The authors face this applicative problem by proposing a new theoretical framework. They provide a lower bound on the expected regret for the setting. Then, the authors provide an algorithm, for which they discuss the upper bound, which matches the lower bound up to log factors. The authors also provide a numerical validation of the solution. The work faces a problem of interest from the applicative point of view. \n\nThe relevant literature is properly discussed. The presentation can be improved, in particular from the introductory part.\n\nThe main concern is about the theoretical analysis of this paper. Indeed, an important focus of this work is related to heteroscedasticity, which is its differential part w.r.t. existing literature. However, this phenomenon is not highlighted in the analysis. For example, in Thr 4.5, the authors retrieve a bound in which such a phenomenon is not highlighted, and the result presented is already present in the literature. Furthermore, the result presented is known for a setting that is simpler than the one presented in this paper, so it holds in this scenario. See weaknesses.",
         "196",
         "0",
         "2",
         "0.6975",
         "0.12310606060000001",
         "0.9069638848",
         "49",
         "7",
         "44.575",
         "10.52",
         "13.763300000000001",
         "13.141",
         "10.3936",
         "0.0483",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "82",
         "zmV50sislh",
         "6748",
         "1695437867951",
         "['~Qian_Chen10', '~Tianjian_Zhang1', '~Linxin_Yang1', '~Qingyu_Han2', '~Akang_Wang1', '~Ruoyu_Sun1', '~Xiaodong_Luo2', '~Tsung-Hui_Chang1']",
         "A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs",
         "Recently, machine learning techniques have been widely utilized for solving mixed-integer linear programs (MILPs). Notably, learning-based approaches that encode MILPs as bipartite graphs and then leverage graph neural networks (GNNs) to identify high-quality solutions have shown remarkable potential. Symmetry as an intrinsic property of many MILPs leads to multiple equivalent solutions, which incurs noticeable computational challenges and hence is treated with care in classic optimization algorithms. However, to the best of our knowledge, none of the learning-based methods take special care of symmetry within MILPs such that their computational performance might be jeopardized. To mitigate this issue, we propose a symmetry-aware learning approach that includes (i) position embeddings as node features to differentiate interchangeable variable nodes, and (ii) a novel loss function to alleviate ambiguity caused by equivalent solutions. We conduct extensive experiments on public datasets and the computational results demonstrate that our proposed approach significantly outperforms existing ones in both computational efficiency and solution quality.",
         "Reviewer_9XGv",
         "1698659346752",
         "1699636777123",
         "5",
         "4",
         "2",
         "3",
         "2",
         "This paper focuses on two issues---indistinguishable variable nodes and label ambiguity---in using GNNs to solve MILPs with symmetries.\nIt proposes to use position embeddings and designs a symmetry-aware loss to alleviate the aforementioned two issues, respectively.\nExperiments on four datasets demonstrate the effectiveness of the proposed method in terms of computational efficiency and solution quality. 1.\tThis paper is easy to follow. It’s worth mentioning that it formulates the issues in using GNNs to solve MILPs with symmetries clearly.\n2.\tThe proposed methods are simple yet effective. They can be combined with a series of GNN based approaches to improve their performance.\n3.\tExperiments on four benchmark datasets, as well as the extensive ablation studies, demonstrate the effectiveness of position embeddings and the symmetry-aware loss. 1.\tThe authors may want to provide more discussions on some related works.\n\n\ta) The authors mention that \\[1\\] and \\[2\\] “try to tackle the label ambiguity drawback by learning conditional distribution” (Section 2). Then, they claim that it “is not symmetry-aware” (Paragraph Baselines, Section 5.1). However, more explanations are necessary.\n\n\tb) The authors claim that “the random features used in \\[2\\] may cause severe generalization issue” (Section 2). They may want to conduct experiments to support this claim and to demonstrate the superiority of position embeddings over random features.\n\n\tc) The authors claim that “none of the existing learning-based approaches take special care of symmetry handling” (Section 2). However, these approaches identified the symmetry issues and proposed some tricks to deal with these issues. The authors may want to further explain what they mean by “take special care of symmetry handling”.\n\n\td) Since “works from mathematical perspectives suggest symmetry-handling algorithms” (Section 2), the authors may want to provide more details about the relationship between this work and those works from mathematical perspectives.\n\n2.\tThe position embedding technique, which is one of the core contributions of this paper, has been implemented in the code of \\[3\\] to tackle the strong symmetry.\nhttps://github.com/sribdcn/Predict-and-Search_MILP_method/blob/main/PredictAndSearch_GRB.py#L47.\nTherefore, the technical contribution is minor.\n3.\tThe symmetry-aware loss involves using Hungarian Algorithm to solve Problem (9), whose time complexity is $O(n^3)$. This may lead to a high training cost. Therefore, the authors may want to report the running time.\n4.\tThe authors may want to report the standard deviation of the results in Table 1.\n5.\tSome of the references, such as \\[2\\] and \\[3\\], are in the wrong form.\n\n\\[1\\] Vinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid Von Glehn, Pawel Lichocki, Ivan Lobov, Brendan O’Donoghue, Nicolas Sonnerat, Christian Tjandraatmadja, Pengming Wang, et al. Solving mixed-integer programs using neural networks. arXiv preprint arXiv:2012.13349, 2020.\n\n\\[2\\] Ziang Chen, Jialin Liu, Xinshang Wang, and Wotao Yin. On representing mixed-integer linear programs by graph neural networks. In The Eleventh International Conference on Learning Representations, 2023.\n\n\\[3\\] Qingyu Han, Linxin Yang, Qian Chen, Xiang Zhou, Dong Zhang, Akang Wang, Ruoyu Sun, and Xiaodong Luo. A gnn-guided predict-and-search framework for mixed-integer linear programming. In The Eleventh International Conference on Learning Representations, 2023. 1.\tWhy are the results of BKS, Gurobi and PS on the datasets WA and IP different from those reported in \\[3\\]?\n2.\tIt seems that with the position embedding, the permutation invariance does not hold any more. For example, if we exchange the positions of two different columns, we will obtain different graph embeddings as they will have invariant node features while variant position embeddings. Is that the case?\n3.\tHow to calculate $\\Phi$ for a given dataset?\n4.\tSince $\\Phi$ indicates the number of possible equivalent solutions, it measures the extend of the issue of label ambiguity. Is there any metric to measure the extend of the issue of indistinguishable variable nodes?",
         "610",
         "11",
         "16",
         "0.7926",
         "0.0799570106",
         "0.8030416369000001",
         "48",
         "11",
         "42.0889",
         "11.0849",
         "13.9512",
         "13.223",
         "13.0027",
         "0.0709",
         "78",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "83",
         "zmV50sislh",
         "6748",
         "1695437867951",
         "['~Qian_Chen10', '~Tianjian_Zhang1', '~Linxin_Yang1', '~Qingyu_Han2', '~Akang_Wang1', '~Ruoyu_Sun1', '~Xiaodong_Luo2', '~Tsung-Hui_Chang1']",
         "A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs",
         "Recently, machine learning techniques have been widely utilized for solving mixed-integer linear programs (MILPs). Notably, learning-based approaches that encode MILPs as bipartite graphs and then leverage graph neural networks (GNNs) to identify high-quality solutions have shown remarkable potential. Symmetry as an intrinsic property of many MILPs leads to multiple equivalent solutions, which incurs noticeable computational challenges and hence is treated with care in classic optimization algorithms. However, to the best of our knowledge, none of the learning-based methods take special care of symmetry within MILPs such that their computational performance might be jeopardized. To mitigate this issue, we propose a symmetry-aware learning approach that includes (i) position embeddings as node features to differentiate interchangeable variable nodes, and (ii) a novel loss function to alleviate ambiguity caused by equivalent solutions. We conduct extensive experiments on public datasets and the computational results demonstrate that our proposed approach significantly outperforms existing ones in both computational efficiency and solution quality.",
         "Reviewer_MwS2",
         "1698687887527",
         "1699636777000",
         "3",
         "3",
         "2",
         "2",
         "2",
         "The paper “ A symmetry -aware Learning Approach for solving Mixed-Integer Linear programs'' discusses  how to solve mixed-integer linear programs (MILPs), while taking into account the symmetry that may exist between variables leading to multiple optimal solutions.  It highlights the issue that MILPs often have symmetry, resulting in multiple equivalent solutions and causing challenges for traditional optimization methods. While machine learning-based approaches using graph neural networks (GNNs) have shown promise in solving MILPs, they haven't addressed the issue of symmetry. To tackle this problem, the paper proposes a \"symmetry-aware\" learning approach that incorporates position embeddings to distinguish interchangeable variables and introduces a novel loss function to handle the ambiguity caused by equivalent solutions. The authors conducted experiments on public datasets and found that their approach outperforms existing methods in terms of computational efficiency and solution quality. MILP has been used in various capacities in optimization aspects of ML and  recently, with the development of GNN, MILP can be solved as GNNs and this enables use of MILPs as a plug in module in many different deep learning models. In this respect, the paper studies a relevant problem. The premise of the paper is based on the weak assumption that symmetry incurs noticeable computational costs. This is not clearly demonstrated in the paper.\nThe improvements proposed by the paper, are not justified as sound theoretical choices. The position embedding seems to add  additional features(why necessarily this way) whereas the symmetry aware loss minimizes distortion to another permutation of the input. What it means in terms of optimization is not clear maybe a simple example of how this helps will illustrate the point better.\nExperimental results are ok, but does not backup the main premise of the the paper that symmetry is significant cost on computational resources. NA",
         "296",
         "0",
         "1",
         "0.8198",
         "0.1106666667",
         "0.957783103",
         "48",
         "10",
         "24.3528",
         "15.5",
         "19.1108",
         "16.9418",
         "16.7759",
         "0.0354",
         "88",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "84",
         "zmV50sislh",
         "6748",
         "1695437867951",
         "['~Qian_Chen10', '~Tianjian_Zhang1', '~Linxin_Yang1', '~Qingyu_Han2', '~Akang_Wang1', '~Ruoyu_Sun1', '~Xiaodong_Luo2', '~Tsung-Hui_Chang1']",
         "A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs",
         "Recently, machine learning techniques have been widely utilized for solving mixed-integer linear programs (MILPs). Notably, learning-based approaches that encode MILPs as bipartite graphs and then leverage graph neural networks (GNNs) to identify high-quality solutions have shown remarkable potential. Symmetry as an intrinsic property of many MILPs leads to multiple equivalent solutions, which incurs noticeable computational challenges and hence is treated with care in classic optimization algorithms. However, to the best of our knowledge, none of the learning-based methods take special care of symmetry within MILPs such that their computational performance might be jeopardized. To mitigate this issue, we propose a symmetry-aware learning approach that includes (i) position embeddings as node features to differentiate interchangeable variable nodes, and (ii) a novel loss function to alleviate ambiguity caused by equivalent solutions. We conduct extensive experiments on public datasets and the computational results demonstrate that our proposed approach significantly outperforms existing ones in both computational efficiency and solution quality.",
         "Reviewer_7CFb",
         "1698695520566",
         "1699636776805",
         "3",
         "3",
         "3",
         "2",
         "1",
         "The paper introduces a neural network MIP solver that is designed to handle symmetry in binary linear programming. The solver predicts initial solutions for MILP using neural networks. The authors highlight the significance of handling variable symmetry and suggest addressing this challenge through positional embedding and a custom-designed loss function. Experimental results show that this approach is superior to other neural solvers and the default Gurobi configuration. * The paper is written in a clear and easy to understand manner.\n* While the traditional optimization community has widely recognized the symmetry of variables, it has not been studied as much with neural networks. The authors provide valuable insights into the field of neural MILP solving, and their efforts should be greatly appreciated. - My primary concern is that this paper represents incremental work compared to a paper published in ICLR 2023 by Han et al., titled \"A GNN-Guided Predict-and-Search Framework for Mixed-Integer Linear Programming.\"\n  - The paper by Han et al. is cited and compared as a significant baseline in this paper. Both papers follow a similar process: a neural network predicts an initial solution, certain digits with higher confidence are fixed and treated as new constraints, and finally, Gurobi is used to solve the modified problem with additional constraints. The only technical addition in this paper appears to be the inclusion of positional embeddings in nodes.\n  - What makes this paper seem more incremental is my observation that positional embeddings are already implemented in the code accompanying Han et al. (ICLR 2023): \\[github link\\](https://github.com/sribdcn/Predict-and-Search_MILP_method/blob/b45ded73d261ef912ebb56934607d6424a88b387/PredictAndSearch_GRB.py#L48). My point is that publishing a new paper at a top ML conference by employing a technique that has already proven effective in a previous paper, without providing valuable insights, is questionable.\n  - The experimental improvement compared to Han et al. (ICLR 2023) also seems incremental in Table 1.\n- The authors might argue for the importance of symmetry in solving MIP, which I agree with. However, as an ICLR paper, it requires stronger motivation. \n  - An excellent example can be found in another paper published at ICLR 2023, where the breaking of symmetry is explored: Chen et al.'s \"On Representing Mixed-Integer Linear Programs by Graph Neural Networks.\" Chen et al. offer theoretical insights into solving symmetric MIPs using graph neural networks. They discovered that symmetry is a theoretical bottleneck of GNNs when solving MIPs, and then proposed to break symmetry by introducing random noise. \n  - It's worth noting that when breaking the symmetry of MIPs, positional embeddings and random noise are two sides of the same coin. The underlying technical motivation is to assign the symmetric nodes different features. Also, positional embeddings are random features concatenated to nodes, because positional embeddings are not permutation-invariant. If we randomly permute the nodes, the positional embeddings also change randomly. * Seeing that Han et al. (ICLR 2023) have already implemented positional embedding, can the authors explain where the performance improvement comes from?\n* Can the authors distinguish this paper, technically, from Han et al. (ICLR 2023)?",
         "499",
         "1",
         "3",
         "0.8001",
         "0.0524685632",
         "0.876499176",
         "48",
         "10",
         "34.4649",
         "12.2407",
         "14.5426",
         "13.8643",
         "13.294",
         "0.1932",
         "105",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "85",
         "zmV50sislh",
         "6748",
         "1695437867951",
         "['~Qian_Chen10', '~Tianjian_Zhang1', '~Linxin_Yang1', '~Qingyu_Han2', '~Akang_Wang1', '~Ruoyu_Sun1', '~Xiaodong_Luo2', '~Tsung-Hui_Chang1']",
         "A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs",
         "Recently, machine learning techniques have been widely utilized for solving mixed-integer linear programs (MILPs). Notably, learning-based approaches that encode MILPs as bipartite graphs and then leverage graph neural networks (GNNs) to identify high-quality solutions have shown remarkable potential. Symmetry as an intrinsic property of many MILPs leads to multiple equivalent solutions, which incurs noticeable computational challenges and hence is treated with care in classic optimization algorithms. However, to the best of our knowledge, none of the learning-based methods take special care of symmetry within MILPs such that their computational performance might be jeopardized. To mitigate this issue, we propose a symmetry-aware learning approach that includes (i) position embeddings as node features to differentiate interchangeable variable nodes, and (ii) a novel loss function to alleviate ambiguity caused by equivalent solutions. We conduct extensive experiments on public datasets and the computational results demonstrate that our proposed approach significantly outperforms existing ones in both computational efficiency and solution quality.",
         "Reviewer_Vpp5",
         "1699044161972",
         "1699636776523",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper studies GNNs for solving MILPs and considers the symmetric properties of MILPs (i.e., switching some variables does not essentially change the problem). The proposed methods include: 1) adding additional features (positional embedding) to differentiate variables that are symmetric; 2) defining the loss function for an orbit of the symmetry group, not just a point. The approach is tested on two datasets and compared with other methods. Some numerical advantages are reported by the authors. Symmetry is an important property in MILPs but is rarely considered in GNN-based methods for solving MILPs. It is good to introduce this topic to the community. The writing is clear. The ideas of adding differentiable features and using orbit loss (or symmetry-aware loss) make sense (they are standard in handling symmetry and have been used in other problems). The numerical results show that the approach is promising. 1. This paper only considers one very special type of symmetry group (a binary matrix and the symmetry group is the the permutation group on the columns). In general, the exact symmetry group of a MILP problem, and hence the symmetry-aware loss, may be very expensive to compute, which makes the proposed method in some sense impractical. I would suggest investigating algorithms based on only partial information about the symmetry group (e.g. the output of the Weisfeiler-Lehman test/color refinement).\n2. Line 6 in Algorithm 1 is expensive to implement, especially when the symmetric group is large. I think the authors should discuss how to solve this subproblem (probably approximately) fast, instead of just saying \"can be solved in parallel\". \n3. Positional embedding (or the related random feature technique) has frequently appeared in the previous literature, which makes the contribution of this paper in some sense incremental. None.",
         "291",
         "0",
         "4",
         "0.7831",
         "0.0324761905",
         "0.872069478",
         "48",
         "6",
         "43.2276",
         "11.4824",
         "15.2319",
         "14.1265",
         "12.702",
         "0.1695",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "108",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_wKPf",
         "1697902750791",
         "1699637014797",
         "5",
         "3",
         "4",
         "1",
         "2",
         "The authors proposed a novel embedding method to represent data points that have partial order relation. The author's idea is to map those data points to bit sequences, where the inequality of the values of two sequences corresponding to the original partial order relation. 1. The original idea of using bit sequences is novel as far as I know, simple, easy to understand, and intuitive to some extent.\n1. The authors successfully associate the proposed method with the existing order embedding, which helps the authors' understanding.\n1. The algorithm's explanation also maintains some intuition.\n1. The algorithm has strong advantage on the space computational complexity.\n1. Overall, the technical parts of the paper are well-written. Overall, the presentation of the paper needs essential refinement. The current version's presentation degrades the paper's quality although the research idea itself is nice and impressing to me.\n\n1. From the introduction, the ultimate motivation of the work is not very clear. For continuous space embedding case, we could use them for visualization or we could input the representations to another machine learning architecture, such as neural network. However, we have no clear idea how we can use the obtained binary embedding in applications. If we just want to do link prediction or reconstruction, we do not need to stick to embedding-based methods.\n\n1. As a starting motivation of the research, the paper criticizes hyperbolic embedding, pointing out that \"learning in hyperbolic space is challenging because optimization algorithms, like gradient descent and its variants, are not well studied for hyperbolic space.\" Indeed, the gradient descent methods on hyperbolic space have been well-studied theoretically, e.g., \\[A-E\\]. Although the convergence to the global optimum cannot be guaranteed, as not in Euclidean space, but they are not by far worse than the author's theoretical guarantee on the proposed algorithm. The author mentioned that the problem is a NP-complete problem as a decision problem, but it is not a practically positive result unless P=NP. In this sense, the current draft gives readers impression that the author has not solved the original motivation. If it is difficult to provide a theoretical guarantee of the proposed algorithm, the author should criticize the hyperbolic embedding in another way. \n\n1. This item is about another important motivation of the paper, \"logical operation.\" The explanation regarding the logical operation on the binary representations does not seem correct. The logical \"not\" operator does not seem to work like the semantic \"not.\" Assume that \"living thing\" is \\[0, 0\\], \"cat\" is \\[0, 1\\], and \"dog\" is \\[1, 0\\]. This does not self-contradict since a cat is a living thing and a dog is a living thing, too. Let's apply the logical \"not\" to the living thing. According to your explanation, \"not living thing\" is \\[1, 1\\]. Now, according to the rule, we conclude that \"a not living thing is a cat\", and \"a not living thing is a dog.\" This is obviously wrong. Hence, the proposed boolean representations are not intuitive as the authors claim.\n\n1. Citation does not include which year it is published, which makes it extremely difficult to see the flow of the existing methods.\n\n1. The page limitation is violated.\n\n1. As I discuss in the Questions section, the advantages of the proposed methods do not seem completely stated in the current draft.\n\n\\[A\\] Zhang, Hongyi, and Suvrit Sra. \"First-order methods for geodesically convex optimization.\" In Conference on Learning Theory, pp. 1617-1638. PMLR, 2016.\n\n\\[B\\] Zhang, Hongyi, Sashank J Reddi, and Suvrit Sra. \"Riemannian SVRG: Fast stochastic optimization on Riemannian manifolds.\" Advances in Neural Information Processing Systems 29 (2016).\n\n\\[C\\] Liu, Yuanyuan, Fanhua Shang, James Cheng, Hong Cheng, and Licheng Jiao. \"Accelerated first-order methods for geodesically convex optimization on Riemannian manifolds.\" Advances in Neural Information Processing Systems 30 (2017).\n\n\\[D\\] Zhou, Pan, Xiao-Tong Yuan, and Jiashi Feng. \"Faster first-order methods for stochastic non-convex optimization on Riemannian manifolds.\" In The 22nd International Conference on Artificial Intelligence and Statistics, pp. 138-147. PMLR, 2019.\n\n\\[E\\] Bécigneul, Gary, and Octavian-Eugen Ganea. \"Riemannian adaptive optimization methods.\" ICLR 2019. - Why did you not show the memory (RAM) to store the representation in the numerical experiments? I thought you could emphasize the advantage of the proposed method clearer this way, since the proposed method's type is boolean, and existing method's types are float or double.\n- Why did you not show the order of time complexity of the proposed algorithm? If I understand it correctly, each step's time and space complexity is linear to the dimension, which seems to be an advantage of the proposed algorithm.",
         "758",
         "6",
         "18",
         "0.7241",
         "0.09107399690000001",
         "0.8398560286000001",
         "47",
         "20",
         "43.4382",
         "10.9568",
         "14.5665",
         "13.7247",
         "11.6684",
         "0.2889",
         "99",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "109",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_EAos",
         "1698496730611",
         "1699637014689",
         "6",
         "4",
         "3",
         "4",
         "3",
         "The paper introduces a novel approach, BINDER, for order embedding using binary vectors. BINDER aims to represent concepts with hypernym-hyponym relationships in a binary vector space, allowing for embeddings of both seen and unseen concepts. Experimental results demonstrate BINDER's superiority over existing order embedding methodologies. 1) Conceptual Simplicity: BINDER offers a novel and conceptually simple approach to hierarchical representation learning by using binary vectors. This simplicity is an advantage because it makes the method more interpretable and easier to understand compared to complex, black-box models.\n\n2) Strong Performance in Reconstruction Task: BINDER consistently demonstrates excellent performance in the reconstruction task. This indicates its robust ability to learn embeddings that satisfy order constraints, which is a critical aspect of hierarchical representation learning.\n\n3) Transitive Closure: BINDER's ability to predict hypernymy relations without relying heavily on transitive closure in the training data is a significant strength. This property suggests that the model can generalize effectively to unseen concepts and is not overly dependent on the availability of transitive edges.\n\n4) Originality of Approach: BINDER introduces a unique approach to order embedding using binary vectors. This originality stems from its different perspective on hierarchical representation learning and adds to the diversity of methods in this field.\n\n5) Potential for Extensions: The paper hints at possible extensions, such as incorporating node similarity expressions and considering sibling similarity. These extensions have the potential to enhance BINDER's capabilities and could pave the way for future research. 1) Generalization to Unseen Concepts: While BINDER claims to generate embeddings for unseen concepts by using logical functions over existing concepts, it would be beneficial to provide more detailed explanations and examples of how this generalization is achieved. A concrete illustration of how BINDER generates embeddings for unseen concepts could strengthen the paper.\n\n2) Experimental Rigor: The paper mentions that BINDER is a randomized algorithm but provides results from the best run out of five. It would be helpful to include more detailed information on the variability observed in these runs, such as mean and standard deviation. A discussion of the algorithm's sensitivity to random initialization would also be insightful.\n\n3) Hyperparameter Sensitivity: The paper discusses hyperparameters like the learning rate and bias but does not delve into their sensitivity analysis. A study on how these hyperparameters affect BINDER's performance and convergence would provide a better understanding of its behavior.\n\n4) Comparative Discussion: While BINDER's strengths are well-discussed, it would be beneficial to have a comparative discussion with competing methods, highlighting where BINDER outperforms them in more depth. This would provide additional context for readers.\n\n5) The complexity. It seems that the model requires very high dimensionalty but there is no such discussion. The worst case is that the concepts are fully disjoint, then you need N dimension, which makes the model not scalable. 1) Why does the accuracy (acc) decrease when the number of transitive edges increases? How can this phenomenon be explained?\n\n2) In equation (1), you specify that a $\\neq$ b, meaning when a = b, it should be considered a negative example. However, in Section 2.3, the negative pairs (n) involving reflexivity constraints, where a is-a a, are excluded. Does this mean that reflexivity constraints are neither treated as positive nor negative examples? I understand that in the experiments and method, you've avoided dealing with the self-relation, but in practice, it might occur. How do you plan to handle cases where the reflexivity constraint is present?\n\n3) In Section 2.3 (Training Algorithm), it might enhance clarity and conciseness by describing the sampling process as selecting $r$ from $W \\setminus \\{a, b\\}$. This would align well with the earlier statement that the number of negative examples is $n^2 - n - |P|$.\n\n4) In Table 3 (Reconstruction Results Acc(\\%) (dim)) and similar cases, what is the purpose of including \"(dim)\" in the table header?\n\n5) One notable advantage of BINDER is its ability to generate embeddings for unseen concepts using logical functions over existing concepts, a feature not present in its competitors.\n\n6) Could the finite permutation space of binary vectors result in a loss of expressivity, limiting the model's ability to capture complex relationships?",
         "688",
         "0",
         "1",
         "0.8389",
         "0.1037961973",
         "0.9189862013000001",
         "47",
         "13",
         "26.4766",
         "13.9298",
         "17.1862",
         "15.3679",
         "14.5235",
         "0.195",
         "78",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "110",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_JqKj",
         "1698792625602",
         "1699637014554",
         "3",
         "4",
         "2",
         "2",
         "3",
         "This work proposes BINDER, an approach for order-based representation. BINDER uses binary bits as representation vectors, via a scalable optimization procedure. Authors evaluate experiments on both prediction and reconstruction tasks. Overall, the paper is well-organized, and the authors provide a detailed description of their contributions. 1. The Introduction section is also missing an important recent work on two-view knowledge graph embeddings, which jointly embed both the ontological and instance view spaces: \n\\[KDD 2022\\] Dual-Geometric Space Embedding Model for Two-View Knowledge Graphs. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22). Association for Computing Machinery, New York, NY, USA, 676–686. https://doi.org/10.1145/3534678.3539350\n\n2. It would be helpful if the authors could create an illustration of an example knowledge graph following their problem formulation. \n\n3. Further, the model fails to include important baseline models such as standard knowledge graph embedding model in the hyperbolic space e.g., RefH/RotH/AttH, hyperbolic GCN (HGCN), and the product space (M2GNN). \n\n4. Moreover, the size of the datasets also seem to be relatively small-scale with number of nodes and edges on the scale of thousands as opposed to million node/billion edge graphs indicative of real world KGs e.g., DBPedia & YAGO. Why is only the hyperbolic space being considered? Entities can form cyclic relations as well, which is better modeled in the spherical space.  Perhaps the authors need to more clearly denote the distinction between entities and concepts.",
         "236",
         "1",
         "4",
         "0.8234",
         "0.062440191400000004",
         "0.8767731190000001",
         "47",
         "9",
         "37.8775",
         "12.1462",
         "14.7143",
         "14.0326",
         "14.6042",
         "0.07200000000000001",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "111",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_VtjX",
         "1699042810956",
         "1699637014430",
         "1",
         "5",
         "3",
         "3",
         "1",
         "In this work the authors develop a method for creating bit-vector representations of entities such that an order relation on bit-vectors captures some hierarchical structure. More specifically, the authors focus on representing hypernym ($\\texttt{is-a}$) relationships between entities. For a given set of entities $W$ and some set of $\\texttt{is-a}$ relationships expressed as pairs $P \\subseteq W \\times W$, the authors propose to represent each entity $a \\in W$ by a bit-vector $\\mathbf a \\in \\\\{0,1\\\\}^d$ for some $d$, such that\n\n$$\\mathbf b_j = 1 \\implies \\mathbf a_j = 1 \\quad \\iff \\quad (a,b) \\in P \\setminus \\Delta_W,$$\n\nwhere $\\Delta_W = \\\\{(a,a) \\mid a \\in W\\\\}$ is the identity relation on $W$.\n\nThe authors formulate a loss function for a bit-vector representation of entities which is a linear combination of a \"positive loss\", which counts the number of times $(a,b) \\in P$ and $a\\ne b$, but there is some $j$ for which $\\mathbf b_j = 1$ and $\\mathbf a_j = 0$, and a \"negative loss\", which counts the number of times $(a,b) \\in N \\subseteq W \\times W \\setminus (P \\cup \\Delta_W)$ are such that $\\mathbf b_j = 1 \\implies \\mathbf a_j = 1$. Since the representation is discrete we cannot take gradients of this loss function, so the authors propose an algorithm which randomly flips bits with a probability which is correlated with the amount of improvement in the loss function as a consequence of flipping that bit.\n\nThey evaluate their model on 5 hypernym datasets. They evaluate in both a reconstruction setting as well as a setting where edges from the transitive closure are removed during training and expected to be recovered during evaluation. They claim their model generally outperforms  baselines including order embeddings, Poincare embeddings, and hyperbolic entailment cones. The authors do an admirable job presenting the background and motivation for this work. Their proposed model is explained clearly, and the randomized algorithm they propose is somewhat novel. Unfortunately, there a many fundamental problems with this work.\n\nFirst, it is unclear to me what problem or task the proposed model is actually solving. What do we gain by representing entities with bit vectors capturing their hypernym relationships? In general, the motivation to embed entities in this setting is one of the following:\n1. Space Efficiency: The new representation requires fewer bits to store than some naive approach (eg. adjacency list of the transitive reduction)\n2. Computational Efficiency: There is some operation which can be performed on the embedded representation more efficiently than on some other representation\n3. Generalization: The embedding allows one to infer missing edges between existing nodes or make predictions of graph edges from unseen nodes (based on input node features)\n4. Transference to Other Tasks: The embedding captures the graph relationships which can then be plugged into other architectures for use in tasks which benefit from the knowledge of the graph structure (eg. MLP for classification)\n\nThe authors discuss space efficiency in Appendix F.3, however comparisons here are only made to other baselines, and the numbers quoted are far and above what would be required (eg. the authors claim that baselines with more than 100 dimensions take more than 10 hours to run, but this is far longer than the numbers reported in \\[0\\] and my personal experience suggests, where it is possible to train a model to represent WordNet reasonably well in 10-20 minutes). Comparing bit vectors to floating point models which were not quantized is disingenuous at best. The authors do claim their embedding is useful for is generalization, however the evaluation performed only assesses generalization to the transitive closure, which is trivial to perform symbolically on the set $P$ which would result in perfect accuracy on this evaluation. There are also issues with this evaluation separately, which are addressed below, but fundamentally this task is not truly a test of generalization in any useful sense.\n\nThe authors do claim that Binder embeddings have some unique capabilities unavailable to other models. Specifically, they claim that Binder embeddings have a well-defined complement, union, or intersection, however this is not true, or at least not any more true here than in any other embedding method. The authors even state that if \"we have a concept 'living-thing' for which we have a binary vector representation, \\[...\\] if we want to obtain a representation for 'not living things' we can obtain that simply by reversing the bits of the 'living thing' vector', however this is not true. To see this, consider a \"living thing\" vector as $\\[0,1,1\\]$, then based on the authors' embedding definition the set of living things is $\\{\\[0,1,1\\],\\[1,1,1\\]\\}$. By their claim, the representation of \"not living thing\" should therefore be $\\[1,0,0\\]$. This would mean that the set of living things includes the bit vectors $\\\\{\\[0,1,1\\],\\[1,1,1\\]\\\\}$ and the set of not living things is $\\\\{\\[1,0,0\\],\\[1,1,0\\],\\[1,0,1\\],\\[1,1,1\\]\\\\}$. Note that this means that the bit vector $\\[1,1,1\\]$ is both living and not living. Moreover, it also means the space is not decomposed into just \"living thing\" and \"not living thing\" - for example, the vector $\\[0,1,0\\]$ is neither living or not living. Therefore this definition of complement is not correct. Not only that, there is *no* bit vector which captures the full complement of being a living thing, because to not be a living thing, according to their definition, we simply need to have a zero in the first or second position, and there is no way to express this \"or\" condition with a single vector. A similar argument shows Binder embeddings are not closed under union.\n\nSecondly, even if there is some benefit to representing entities by bit-vectors, it is straightforward to provide a deterministic algorithm which takes a set $P$ and produces a bit-vector embedding which perfectly satisfies the constraint above using a topological sort. With some additional care in the construction process, it even seems possible to create a bit-vector with minimal size which perfectly satisfies the constraint. Therefore, the use of a randomized algorithm here does not seem to have any benefit.\n\nThirdly, there are a number of problems with the experiments. For some reason, the authors chose to report a reweighted accuracy statistic as opposed to the more conventional F1 metric when dealing with data imbalances. In addition, the authors evaluate on a test set with negatives which were created by random perturbation, however this approach can lead to a very coarse evaluation, and has issues with test set bias. For the test set accompanying Order Embeddings paper, for example, you can get almost 0.90 F1 by simply treating any node in the training data which has a child as though it is a parent to every other node in the training set. It was for this reason that more comprehensive evaluations advocate for using the full adjacency matrix \\[0\\]. In addition, the other models present in that paper all serve as reasonable baselines, and the \\[associated code\\](https://github.com/iesl/geometric-graph-embedding) has implementations readily available.\n\nFinally, a number of the characterizations or claims made in the introduction are incorrect. The authors claim optimization algorithms are not well studied for hyperbolic space, however this is not the case - Riemannian gradient descent is well understood (\\[1\\], \\[2\\], \\[3\\]). Moreover, there are approaches to parameterizing and training on hyperbolic space which have been shown empirically to work well with standard gradient descent techniques such as SGD or Adam \\[4\\]. The authors claim box embeddings have more degrees of freedom than point embeddings, but this is not true - a box embedding in $d$-dimensional space does have $2d$ parameters per box, but it is for this reason that experiments using box embeddings compare $d$-dimensional boxes to $2d$-dimensional vectors, so they have exactly the same number of free parameters. The claim that bit vectors are more interpretable is not supported by any experiments, and there is no clear reason to expect that the randomized algorithm leads to interpretable properties in each dimension. The interpretability hinted at for the bit vectors is equivalent to the level of interpretability that order, probabilistic order, or box embeddings provide.\n\n\\[0\\] Boratko, Michael, et al. \"Capacity and bias of learned geometric embeddings for directed graphs.\" Advances in Neural Information Processing Systems 34 (2021): 16423-16436.\n\\[1\\] Bonnabel, Silvere. \"Stochastic gradient descent on Riemannian manifolds.\" IEEE Transactions on Automatic Control 58.9 (2013): 2217-2229.\n\\[2\\] Bécigneul, Gary, and Octavian-Eugen Ganea. \"Riemannian adaptive optimization methods.\" arXiv preprint arXiv:1810.00760 (2018).\n\\[3\\] Hu, Jiang, et al. \"A brief introduction to manifold optimization.\" Journal of the Operations Research Society of China 8 (2020): 199-248.\n\\[4\\] Law, Marc, et al. \"Lorentzian distance learning for hyperbolic representations.\" International Conference on Machine Learning. PMLR, 2019. The section on the weaknesses highlights my concerns with this work. \n\n1. Can you clarify the specific problem or task that your proposed model is designed to solve? How does the use of bit vectors capturing hypernym relationships contribute to solving this problem?\n\n2. Regarding space efficiency, how does the bit vector representation compare to a sparse adjacency list? If it is not more compact, does it offer any benefits beyond the sparse adjacency list?\n\n3. In terms of generalization, the current evaluation focus on the transitive closure. When training on this data in the 0% case, does your negative set include edges from the transitive closure? Regardless, if we know the relation is transitive, what benefit do we gain by training on the transitive reduction and being able to \"generalize\" to the transitive closure which is not also achievable by simply taking the transitive closure of the training data?\n\n4. You mention unique capabilities of Binder embeddings, such as well-defined complement, union, or intersection operations. Given the issues highlighted with these operations, how do you respond to the concerns about the correctness of these claims?\n\n5. Could you elaborate on why a randomized algorithm is used for generating bit-vector embeddings when a deterministic algorithm could suffice?\n\n6. Why was a reweighted accuracy statistic chosen over the conventional F1 metric in your experiments, especially in the context of data imbalances?\n\n7. Please correct or respond to my assertions above regarding the inaccuracies in characterizing other baselines. (For example, the assertion that optimization algorithms in hyperbolic space are not well-studied,  or that box embeddings have more degrees of freedom than point embeddings.) After correcting these claims, please address what specific benefits this embedding provides beyond those provided by the baselines.\n\n8. The interpretability of bit vectors is claimed to be superior in your paper. Can you provide empirical evidence or a theoretical framework that supports this claim, in a setting where equivalent effort is also given to order, probabilistic order, or box embeddings?\n\n9. Would you consider evaluating the representational capacity of your model on the full adjacency matrix? This may be computationally prohibitive; if so, it is reasonable to select a subgraph (eg. Animal subgraph from WordNet) and evaluate the full adjacency matrix on that subgraph.\n\n---\n\nI apologize if my review seems harsh. I would like to commend the authors for the clear and structured presentation of their approach. The manuscript is well-written, and the methodology is articulated with a level of detail that reflects a thorough understanding of the subject matter. It is evident that considerable effort has gone into developing and describing the proposed model.\n\nOne of the main challenges in this area of research seems to be a legacy of ambiguity in motivations and intentions from previous works, like a bad game of \"telephone\". Previous evaluations designed to highlight specific aspects of a model may be misconstrued to be a task in and of themselves, and this problem can compound on itself in subsequent work. It is also possible that I misunderstood the author's motivations and approach, and if so then I humbly apologize and ask the authors to clarify things for me.",
         "1957",
         "28",
         "16",
         "0.7801",
         "0.0865779046",
         "0.8620133996",
         "47",
         "6",
         "39.3787",
         "12.7481",
         "15.7533",
         "14.598700000000001",
         "13.9316",
         "0.8969",
         "74",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "112",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_psGs",
         "1699176535017",
         "1699637014327",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper proposes a method called Binder, which is a hierarchical concept representation method through order embedding of binary vectors. The paper explores the importance of order-based representation in natural language understanding and generation, and discusses the strengths and weaknesses of existing approaches. It also describes the geometric constraints imposed by order-based representation and how they capture semantic relationships between concepts. The paper concludes by discussing potential applications of Binder's approach to hierarchical concept representation in practical natural language processing tasks. 1. The paper proposes BINDER, a novel order embedding approach which embeds the entities at the vertex of a d-dimensional hypercube, which is simple, elegant, compact and explainable.\n\n2. The paper proposes an optimization algorithm for BINDER, which is simple, efficient, and effective, and can be seen as a proxy of gradient descent for the combinatorial space.\n\n3. The experimental results show that BINDER achieves great performance on link prediction and reconstruction tasks. 1. For reconstruction task, OE achieves better performance than BINDER with fewer dimension. Thus, BINDER does not show superiority over OE.\n2. BINDER may still suffer from the limitation of optimization, leading to inferior performance.\n3. It is better to report the mean results, rather than the best results. 1. You claim that “In BINDER’s embedding, an ‘1’ in some representation dimension denotes “having a latent property”. How to verify it through experiments?\n\n2. What are the differences between the proposed optimization method and randomized local search algorithm? What is the novelty of the proposed optimization method?\n\n3. How to ensure the convergence of the proposed optimization algorithms?\n\n4. Why BINDER is better than OE in WordNet Nouns dataset?\n\n5. How is the dimension (in parenthesis) in Table 3 set? Why is the dimension of OE smaller than that of BINDER?\n\n6. Can you provide the experimental results of box embedding?",
         "305",
         "0",
         "12",
         "0.7586",
         "0.2639705882",
         "0.9477813244000001",
         "47",
         "5",
         "31.3097",
         "12.6808",
         "15.9361",
         "14.1918",
         "13.1578",
         "0.1544",
         "95",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "157",
         "zdboax4dlK",
         "1381",
         "1695049614035",
         "['~Amirhossein_Farzam1', '~Allen_Tannenbaum2', '~Guillermo_Sapiro1']",
         "Ricci Curvature, Robustness, and Causal Inference on Networked Data",
         "In the complex landscape of networked data, understanding the causal effects of interventions is a critical challenge with implications across various domains. Graph Neural Networks (GNNs) have emerged as a powerful tool for capturing complex dependencies, yet the potential of geometric deep learning for GNN-based network causal inference remains underexplored. This work makes three key contributions to bridge this gap. First, we establish a theoretical connection between graph curvature and causal inference, revealing that negative curvatures pose challenges in identifying causal effects. Second, based on this theoretical insight, we present computational results using Ricci curvature to predict the reliability of causal effect estimations, empirically demonstrating that positive curvature regions yield more accurate estimations. Lastly, we propose a method using Ricci flow to improve treatment effect estimation on networked data, showing superior performance by reducing error through flattening the edges in the network. Our findings open new avenues for leveraging geometry in causal effect estimation, offering insights and tools that enhance the performance of GNNs in causal inference tasks.",
         "Reviewer_fMiq",
         "1698709496083",
         "1699636065930",
         "5",
         "4",
         "2",
         "2",
         "3",
         "The authors explore networked data via graph-neutral networks. Using graph Ricci curvature, they predicted the reliability of causal effect estimations on networked data. Their empirical findings confirmed that positive curvature regions yield more accurate results. The main review will take place in this section owing to the flow in which the review was conducted.\n\n### Abstract\n\n- The first sentence is interesting and whilst I know this is the abstract, it would be helpful to know _why_ the author(s) think it is critical challenge to understand the causal effect in networked data - who cares and why?\n\n\n### Introduction\n\n- What do you mean by \"the endogeneity\"  - this is a fairly non-standard way to use that way (at least to this reviewer, hence please do tell your usage of the term)\n- \"identifying causal effects is particularly challenging on a network of units with non-trivial dependencies\" - why is this? What gives rise to the difficulty?\n- A graphic may be helpful at the end of page one to illustrate the concepts that you discuss (e.g. graph curvature) for readers less familiar with this topic.\n\n\n### CAUSALITY, INVARIANCE, AND ROBUSTNESS\n\n- What is meant by \"unit\" in the first sentence of this paragraph?\n- Do you assume the presence of unobserved confounders? If so, please spell that out.\n- Why is your outcome denoted $\\mathbf{Y}$? That gives the impression that you are dealing with a multi-objective (more than one outcome) setting - are you? Perhaps best to spell out the domain of the features and the outcome(s) either way to avoid any confusion.\n- I find definition 2 and the paragraph following, very vague and ambiguous. It is not clear what you are describing. What is $\\mathbf{C}$? The way the bottom part of page 3 is phrased, make it difficult for a reader to extract meaning from a language that is rather too formal (without providing all the background, since that, I assume, lives in (Buhlmann, 2020)).\n- Whilst I appreciate that (Rothenhausler et al., 2021) uses the term \"anchor\" for a very common graph concept, it may be better to stick with the common tongue when it comes to graph formalism, where $A$ in figure 1 is either a leaf node or a root node depending on the perspective of the modeller. These terms predate the former's by a few decades and so may make this part of the section of the paper a bit more accessible by using the more common nomenclature. \n- You should adopt the standard graphical norms when it comes to causal inference. If H is a hidden confounder then it is standard to dash the edges (H,X) and (H,Y). The way you have drawn figure 1 makes it appear as if H is observed.\n- H is hidden (latent or unobserved) yet you are including it in equation 2? Please explain how that works.\n- You use 'source' and 'anchor' to refer to variable $A$ but never the standard 'root/leaf'? Consider picking one of these four terms.\n\n### CURVATURE, ROBUSTNESS, AND ENTROPY\n\n- The start of section 3 could do with an illustration of the concepts involved with Ricci curvature (e.g. figure four from the top: https://www.researchgate.net/publication/334371953_Community_Detection_on_Networks_with_Ricci_Flow/figures?lo=1)\n- Use $S(\\cdot)$ and not $S(.)$ for the Boltzmann entropy.\n\n### Entropic causal inference\n\n- Move the review of entropic causal inference to the preliminaries - the introduction of it the way you have done it now, breaks the flow of the paper.\n- This does make any sense: $Y = f(X,E)$ - what is $f$? What is $X$ the same as before? What is $E$ noise terms? What is the causal modelling framework you are using? Is $f$ an SEM? You seem to suggest that $E$ are exogenous variables which d-separeted (?) I assume that's what your symbol means since you haven't defined it, from the outcome variable $Y$ but then you introduce something you call 'alternative exogenous variables' - what's that?\n- Equation 9 presently does not point toward anything since it is not clear how the connection is made between it and what you say it is pointing to, which is not clear since section four is lacking a lot of detail for this to be a convincing argument.\n- What I find curious further about this section if that if equation 9 is a powerful result you build on, it would be helpful if you placed it in a lemme/theorem/proposition to indicate its importance to the paper.\n\n### Curvature and causal inference\n\n- Paragraph 2 in this section could use a figure for your stated causal relationship.\n- This may be a very silly question but you say: \"we expect a higher entropy of the exogenous variables when the curvature is larger\" - how can you expect anything at all about the exogenous variables since you cannot measure them? They are latent and so unknown to the modeller. Hence, what use is theorem 2 (being the devil's advocate here)\n- Suggestion: place this within a remark: \"This ultimately suggests that more positive Ricci curvatures are expected to correspond to lower errors in estimating the causal effect\"\n\n### RELATED WORK\n\n- What are you evaluation metrics actually measuring w.r.t. your contribution in this paper? What is the relation to Ricci curvature w.r.t. these metrics?\n- To confirm, none of your networks have unobserved confounders? See the Strengths section for relevant comments. See the Strengths section for relevant comments.",
         "905",
         "2",
         "0",
         "0.7875",
         "0.10808124350000001",
         "0.8884601593",
         "53",
         "10",
         "57.6228",
         "9.3546",
         "11.8793",
         "11.7711",
         "9.7607",
         "0.8362",
         "94",
         "1",
         "0",
         "0",
         "1"
        ],
        [
         "158",
         "zdboax4dlK",
         "1381",
         "1695049614035",
         "['~Amirhossein_Farzam1', '~Allen_Tannenbaum2', '~Guillermo_Sapiro1']",
         "Ricci Curvature, Robustness, and Causal Inference on Networked Data",
         "In the complex landscape of networked data, understanding the causal effects of interventions is a critical challenge with implications across various domains. Graph Neural Networks (GNNs) have emerged as a powerful tool for capturing complex dependencies, yet the potential of geometric deep learning for GNN-based network causal inference remains underexplored. This work makes three key contributions to bridge this gap. First, we establish a theoretical connection between graph curvature and causal inference, revealing that negative curvatures pose challenges in identifying causal effects. Second, based on this theoretical insight, we present computational results using Ricci curvature to predict the reliability of causal effect estimations, empirically demonstrating that positive curvature regions yield more accurate estimations. Lastly, we propose a method using Ricci flow to improve treatment effect estimation on networked data, showing superior performance by reducing error through flattening the edges in the network. Our findings open new avenues for leveraging geometry in causal effect estimation, offering insights and tools that enhance the performance of GNNs in causal inference tasks.",
         "Reviewer_poe6",
         "1698777490509",
         "1699636065859",
         "3",
         "5",
         "2",
         "1",
         "1",
         "This paper claims to address the challenge of understanding causal effects in networked data using Graph Neural Networks (GNNs). They claim to utilize the link between graph curvature and causal inference, finding that negative curvatures complicate identifying causal effects to predict the reliability of causal effect estimations, showing that positive curvature regions lead to more accurate results. The exploration of curvature is intriguing.\nCausal inference on network data is an interesting problem to investigate. - The contribution of this paper is relatively moderate, as it amalgamates ideas from other sources, resulting in a contribution that is at best modest.\n- The paper is poorly written. \n- This paper seems to essentially be using causal discovery to improve causal inference. This is not properly explained. \n- Sounds like this paper violates the SUTVA assumption in casual inference on networks. - This paper seems to essentially be using causal discovery to improve causal inference.  Could the author please elaborate on that? \n- How do you justify violating the SUTVA assumption in casual inference on networks?\n- Implementing Ricci flow adjustments involves complex computations, especially on large-scale networks, which can be computationally intensive and time-consuming. This complexity may limit its applicability to real-time or resource-constrained scenarios. How do the authors justify the complexity and computational costs?\n- How interpretable are the results? What is behind the improved estimations (beyond statistical metrics)? \n- Ricci flow adjustments' effectiveness varies based on the unique structure of real-world networks, which are diverse and dynamic. Generalizing this method across different scenarios is challenging due to the complex nature of network connections. Moreover, the method's reliance on parameters like edge weights and curvature values makes it highly sensitive to even minor fluctuations. Selecting appropriate parameter values demands careful tuning and a deep understanding of the network, posing significant challenges in achieving optimal performance. Could the authors elaborate on these issues?",
         "311",
         "0",
         "0",
         "0.7886",
         "0.0841597796",
         "0.9391565323000001",
         "53",
         "9",
         "23.982",
         "13.3246",
         "16.6167",
         "14.424",
         "13.4968",
         "0.2298",
         "86",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "159",
         "zdboax4dlK",
         "1381",
         "1695049614035",
         "['~Amirhossein_Farzam1', '~Allen_Tannenbaum2', '~Guillermo_Sapiro1']",
         "Ricci Curvature, Robustness, and Causal Inference on Networked Data",
         "In the complex landscape of networked data, understanding the causal effects of interventions is a critical challenge with implications across various domains. Graph Neural Networks (GNNs) have emerged as a powerful tool for capturing complex dependencies, yet the potential of geometric deep learning for GNN-based network causal inference remains underexplored. This work makes three key contributions to bridge this gap. First, we establish a theoretical connection between graph curvature and causal inference, revealing that negative curvatures pose challenges in identifying causal effects. Second, based on this theoretical insight, we present computational results using Ricci curvature to predict the reliability of causal effect estimations, empirically demonstrating that positive curvature regions yield more accurate estimations. Lastly, we propose a method using Ricci flow to improve treatment effect estimation on networked data, showing superior performance by reducing error through flattening the edges in the network. Our findings open new avenues for leveraging geometry in causal effect estimation, offering insights and tools that enhance the performance of GNNs in causal inference tasks.",
         "Reviewer_UoX4",
         "1699241264461",
         "1699636065800",
         "3",
         "3",
         "2",
         "2",
         "3",
         "This manuscript bridges the Ollivier Ricci curvature with causal inference and shows that positive curvatures 'help' with the causal inference while negative ones do not. The connection is built on a causal model that regards the problem as a worst-case risk minimization. The main spot of the theoretical analysis is to show that if the ricci curvature is negative, then higher entropy is needed to fit the causal model. Numerical results align with the theoretical analysis. Further experiments show that integrating ricci flow with GNNs can improve the performance. 1. The paper discusses the background and related work quite carefully, and is in general well-written.\n2. I like this discovery. Building connections between geometry of the network and the causal inference should shed light on more future work, in addition to more understanding of this topic, especially given the fast development.\n3. I acknowledge the theoretical analysis as the main contribution, it is good that the experimental results corroborate with the theoretical analysis. 1. It seems that the background is discussed too much (until page 5) and the main entree is too short (only one page), which possibly indicates that this work relies a lot on previous work. Further, the large body of discussion triggers confusion, I would expect a clear logical argument, for example, the causal model has some property, leads to robustness, further goes to entropy, and lands in Ricci curvature. The above may be wrong, but readers need the correct version instead of a stack of notions.\n\n2. As for the proposed method integrating ricci flow and GNN, I could not find anything else except one paragraph in section 5.1. So if I am not misunderstanding, the proposed algorithm is: First run Ricci flow and attain the edge weights, then use existing frameworks of GNN-based causal inference. This is OK but the contribution is quite limited. Have the authors think about how to further take advantage of this property and design new GNN frameworks? Such as \\[1\\] and many others. Further, it would be good to at least present the pseudo code/descriptions by steps of the proposed method.\n\n\\[1\\] Curvature Graph Networks. 1. I unfortunately do not understand the formalization part very well. Could you explain what are the roles of system robustness and distributional robustness in the causal model? (Especially the risk minimization). In section 3.2 you said \"we utilize the correlation between Boltzmann entropy and Ricci curvature to formally establish this anticipated connection\" but later in section 4, Shannon entropy is discussed and Theorem 2 also uses Shannon entropy. This is confusing, could you please make it clear?\n\n2. I am fine with the most proof of Theorem 3.2 but not the second assumption. If I understand correctly, $X$ is the feature and $Y$ is the label, then the difference of two datasets may not just lie on the features. I wonder if the assumption that $H(Y|X;E)$ remains similar is OK in a causality task, but nothing more.\n\n3. What does it mean by a \"wrong causal model\"?\n\n4. This is not a major issue, but have you experienced computational issues when the networks are large? The computation of ricci flow takes $\\tilde{O}(mn^3)$ if I remember correctly, which can be larger than the time for GNN. Then if we think about applications, this is a hurdle.",
         "551",
         "2",
         "10",
         "0.8052",
         "0.1119542957",
         "0.8874665499000001",
         "53",
         "4",
         "50.9348",
         "10.3029",
         "13.5027",
         "13.0737",
         "10.819",
         "0.5519000000000001",
         "87",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "163",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_irmp",
         "1697978211527",
         "1699636429994",
         "6",
         "4",
         "4",
         "2",
         "3",
         "The author proposed physically-intuitive embedding method for partial order hierarchy. The method uses shadow cones, which generalize existing hyperbolic entailment cones. The author also constructed the algorithm to optimize the shadow cones. 1. The paper provides novel multiple variants of the existing hyperbolic entailment cone method. The techniques provided for handling shadow cones are significant technical contributions in the area.\n1. The physics-inspired explanation, with plenty of intuitive figures, of the proposed method helps readers understand the proposed method's concept and algorithm. The explanation also provides another explanation of why existing hyperbolic entailment cones cannot be defined for a point around the center of the Poincare ball.\n1. Table 1 summarizes the proposed 4 methods well. Overall, the paper is well-written as a technical report but has room for improvement in terms of scientific discussion or presentation.\n1. Although the light-source-shadow-based explanation is quite helpful in understanding WHAT the proposed methods are doing, but does not explain at all WHY they do so. Specifically, we do not see what the shape and size of the light source and the size of embedding in the umbral cases imply in the context of partial order or semantics. Also, readers do not see how we select one of the 4 proposed methods depending on the situation.\n1. Overall, the paper is written as a technical extension of the hyperbolic entailment cone method, but the current draft does not position the proposed method well in the context of the whole partial order embedding area. It is not an unacceptable way, but limits the readers. The authors might want to compare it with other methods such as Order embedding, Gaussian embedding, Box embedding, etc.\n1. The title of the paper lacks essential keywords and confuses readers. It should include the word \"shadow cone.\" Also, if possible, the words \"hierarchy\" or \"partial order\" could be included. Readers might think the phrase \"dark side\" indicates the surface of a hemisphere, rather than a shadow cone. Also, from the word \"moon,\" readers feel the impression that the embedding has a volume. However, this is not the case for the penumbral cone embedding. I am aware that we have many styles on which we title a paper, but, at least, we need to avoid confusing readers. 1. Why the experimental results by Entailment Cone and Penumbral-Poincaré-ball are different while they are equivalent according to Theorem 3.2?\n1. What do the shape and size of the light source and the size of embedding in the umbral cases imply in the context of partial order or semantics?\n1. How do we select one of the 4 proposed methods depending on the situation?",
         "441",
         "0",
         "9",
         "0.7558",
         "0.026785714300000003",
         "0.9128438830000001",
         "49",
         "19",
         "45.6284",
         "11.2774",
         "14.1308",
         "13.5382",
         "11.9012",
         "0.1615",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "164",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_JBVb",
         "1698155132625",
         "1699636429907",
         "8",
         "3",
         "3",
         "3",
         "3",
         "This paper considers the problem of learning representations to model hierarchical relationships using hyperbolic space. The authors introduce several formulations of *shadow cones*, a novel and unifying framework of physics inspired representations. Entailment relations are defined by the containment of shadows of the object representations given a fixed light source and boundary if hyperbolic space. The authors present two different shadow formulations each in two different hyperbolic spaces. A smooth loss function is introduced to train shadow cones in a stable manner, avoiding some of the training issues presented in prior work. The effectiveness of the presented method is shown on standard open source datasets. * The proposed approach is novel and well-motivated, avoiding many of the issues in prior work\n* The proposed representation formulation encapsulates previous approaches\n* The paper is well written and includes many intuitive figures and diagrams to illustrate the proposed approach\n* The empirical results demonstrate the efficacy of the proposed methodology on standard datasets for this task * The paper uses quite a bit of space introducing all four formulations of shadow cones, leaving less space for additional empirical results\n* At the end of Section 4, the authors make claims about ease of training, but do not justify claims beyond just a statement by fiat. \n* The proposed approaches are only compared against a single baseline -- even though this is the supposed state of the art in hyperbolic representations it would be beneficial to see comparisons with other methods.\n* The empirical results are all demonstrated on the same singular type of task. It would benefit the paper to see experiments on different types of tasks such as collaborative filtering. * What advantages might this method have over a different representation learning paradigm such as box embeddings (e.g. \\[1\\])?\n* Why is there such a big discrepancy in the results between Penumbral-Poincaré-ball and Entailment cones in Table 2? These formulations are mathematically equivalent, but perform quite differently in some cases. Is this attributable to the loss function or training procedure in some way?\n* What is the relationship between convexity and performance? The non-convex method seems to perform better. Why is this the case?\n* What are the potential challenges to learning representations in the half-space formulation?\n\n\\[1\\] Dasgupta S, Boratko M, Zhang D, Vilnis L, Li X, McCallum A. Improving local identifiability in probabilistic box embeddings. Advances in Neural Information Processing Systems, 2020",
         "403",
         "2",
         "1",
         "0.7695",
         "0.0638305322",
         "0.875056684",
         "49",
         "17",
         "30.9327",
         "13.5585",
         "16.2491",
         "14.9556",
         "13.825",
         "0.0751",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "165",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_s6e6",
         "1698490763984",
         "1699636429797",
         "6",
         "3",
         "2",
         "3",
         "2",
         "Hyperbolic space have been shown to be particularly well suited to encode the latent structure of complex objects such as trees or graphs. In particular, using random graphs with an hyperbolic latent space are known to exhibit properties often found in real world networks such a the small world phenomenon or the scale free property. \n\nIn this paper, the authors introduce the so-called shadow cones framework: a methodology that allows to define a partial order embedding of hierarchical data. The authors show that such framework can be particularly efficient to learn a latent embeddings of nodes for trees or more generally for DAGs. Their method extends to the concept of entailment cones previously introduced by Ganea. On three different datasets, the authors show that using their method to learn the hierarchical structure of partially observed DAGs can allow to infer unseen edges better than previous approaches. - Hyperbolic spaces have been shown to be very promising latent space to model graph data. This paper is focused on DAGs and proposes a new framework to learn embedding for hierarchical data. \n\n- The authors did an excellent job in ensuring the comprehensibility of their method, notably by incorporating highly insightful illustrations.\n\n- As a by product, the paper provides a comprehensive overview of various approaches to incorporate 'shadows' for embedding points in hyperbolic space, employing the concepts of umbral and penumbral cones. This lucid exposition elucidates the source of the limitations observed in prior methods, particularly with regard to the $\\epsilon$ hole problem. - I think the authors should better stress the concrete applications of their method. For example, are there applications related to structure learning?  \n\n- In my opinion, the authors should include in their comparison methods that do not rely on hyperbolic spaces (but rather on Euclidean ones for example or with manifold with positive curvature). I thank the authors for their nice submission.\n\nApart for my questions presented in the previous section (i.e. use of the method for applications and comparison with methods not using hyperbolic spaces), I would be interested to know if the method could be used in more general settings. In particular:\n\n- How the method could be used for real world graphs that are not (exactly) DAGs?\n\n- How the method could be used for multiclass hierarchical problems?\n\nHere are some typos and additional comments: \n\n- In the loss function (cf. Eq(1)), if think N and P are not properly defined in the text.\n\n- At the end of the first paragraph of the introduction of Section 3, I think there is an error. Should the last sentence rather be \"Specifically, $v$ is in the shadow cone of $u$ iff $v \\subset$ the shadow of $u$.\" ?\n\n- After Theorem 4.2, I think the first \"their\" should be removed from the sentence \"which is\ndesigned to draw child nodes v closer to their the cones of their patent nodes\".",
         "484",
         "0",
         "0",
         "0.7727",
         "0.1312085976",
         "0.8662823439",
         "49",
         "13",
         "48.6583",
         "11.1727",
         "13.9105",
         "13.2198",
         "11.9401",
         "0.8146",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "166",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_SzVy",
         "1698609725308",
         "1699636429703",
         "6",
         "3",
         "2",
         "3",
         "2",
         "This paper proposes the use of (light) cones to learn embeddings of posets in hyperbolic space. Specifically, the paper looks at two models depending whether the data or the light source has mass. The paper proves a variety of consistency results such the fact that inclusion of the cones form a poset. The idea of using cones is quite interesting to me. The paper shows that it results in a loss at least at the optimal point that does preserve the partial order structure. Further, it does so in a way that gives coordinates from which we can extract the partial order. Hence I think this is quite interesting and quite novel. I think of these are strong strengths. \n\nThe paper is mostly easy to follow however there are a few details I would like added. Please see weaknesses and questions 1) The first weakness for me is the context for the work. I think some more discussion to related concepts such as DAG learning, which is learning DAGs from data \\[1,2,3\\], other hyperbolic hierarchical learning like hyperbolic tree learning, which is about learning trees to represent hyperbolic data or embed in hyperbolic apace \\[4,5\\], graph embeddings in hyperbolic space \\[6,7,8\\], and hyperbolic link prediction \\[9\\] would be great. \n\n2) I think the experimental setup could be further expanded upon. First, I think it should be clarified that we can do the link prediction without the embedding step (this would have a 100% accuracy) and then mention that you do the embedding step to understand the how well the embedding performs. As part of the experiment, it would be good to have a baseline for Euclidean poset embedding. However, I admit I do not know of one. Maybe on of the DAG learning papers has a baseline that could be used. \n\n3) Building on the above it would be good to show that such embeddings can be used other non-trivial down stream tasks and that such embeddings provide an advantage. \n\n\\[1\\] X. Zheng, B. Aragam, P.K. Ravikumar, and E.P. Xing. Dags with no tears: Continuous optimization for structure learning. In Advances in Neural Information Processing Systems 31, 2018.\\\n\\[2\\] Yu, Y., Gao, T., Yin, N., & Ji, Q. (2021, July). DAGs with no curl: An efficient DAG structure learning approach. In International Conference on Machine Learning (pp. 12156-12166). PMLR.\\\n\\[3\\] Lachapelle, S., Brouillard, P., Deleu, T., & Lacoste-Julien, S. (2019). Gradient-based neural dag learning. arXiv preprint arXiv:1906.02226.\n\n\\[4\\] Ittai Abraham, Mahesh Balakrishnan, Fabian Kuhn, Dahlia Malkhi, Venugopalan Ramasub- ramanian, and Kunal Talwar. Reconstructing Approximate Tree Metrics. In Proceedings of the Twenty-sixth Annual ACM Symposium on Principles of Distributed Computing, PODC ’07, pages 43–52, New York, NY, USA, 2007. ACM.\\\n\\[5\\] Sonthalia, R., & Gilbert, A. (2020). Tree! i am no tree! i am a low dimensional hyperbolic embedding. Advances in Neural Information Processing Systems, 33, 845-856.\n\n\\[6\\] Chamberlain, B. P., Clough, J., & Deisenroth, M. P. (2017). Neural embeddings of graphs in hyperbolic space. arXiv preprint arXiv:1705.10359.\\\n\\[7\\] T. Blasius, T. Friedrich, A. Krohmer, and S. Laue. Efficient Embedding of Scale-Free Graphs in the Hyperbolic Plane. IEEE/ACM Transactions on Networking, 26(2):920–933, April 2018.\\\n\\[8\\] Kevin Verbeek and Subhash Suri. Metric Embedding, Hyperbolic Space, and Social Networks. Computational Geometry, 59:1 – 12, 2016.\n\n\\[9\\] Zhe Pan and Peng Wang. 2021. Hyperbolic Hierarchy-Aware Knowledge Graph Embedding for Link Prediction. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 2941–2948, Punta Cana, Dominican Republic. Association for Computational Linguistics. I have a few questions. \n\n1) In the loss function $P$ and $N$ haven't been defined. \n\n2) For the cones I do not understand the boundary computation. Could the authors please expand on that? I did not see anything in the appendix either. \n\n3) Why do we need the ball around $y$ to be in the shadow for $y$ to be in the umbral cone, but only need the point $y$ to be in the shadows for the penumbral cone? I see that the umbral method seems to perform the best. I imagine based on how the loss in formulated this pushes the point to the interior of the cone rather than leaving it on the boundary where we might have numerical issues. \n\n4) Could the authors provide intuition for why umbral cones are not geodetically convex? I believe in this regard calling them cones might be a bit confusing, because cones in Euclidean space are not only convex, but contains these geodesic rays. I would have thought the same is true for the hyperbolic ones. Hence was surprised when I saw this result.",
         "761",
         "16",
         "15",
         "0.7842",
         "0.14448892330000002",
         "0.809056282",
         "49",
         "11",
         "60.774",
         "8.0207",
         "10.9281",
         "11.2081",
         "8.9529",
         "0.364",
         "107",
         "1",
         "0",
         "1",
         "0"
        ],
        [
         "167",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_Arvf",
         "1698749524713",
         "1701125357640",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a physically intuitive partial order embedding framework \"shadow cones\" that generalizes the well-known \"hyperbolic entailment cones\". Also, this framework generalizes to two different hyperbolic models, the Poincaré disk and Poincaré half-space. The experiments shows that the generalized \"shadow cones\" outperform the \"hyperbolic entailment cones\" baseline. 1. The paper is well-motivated and has a good connection to existing research.\n2. It considers two hyperbolic models, the Poincaré disk and the Poincaré half-space.\n3. The theoretical analysis provides nice properties of the proposed models. 1. Compared with the novel and interesting motivation, the description, especially the figures, lacks explanation, almost all the symbols in the figures are not mentioned in the captions or corresponding text.\n2. The experiment is not very supportive of the claim. For example, In the experiment, Poincaré ball based cones performed worse than Poincaré half-space based cones. While in the important baseline \"hyperbolic entailment cones\", the Poincaré ball is used, if the proposed cone generalizes \"hyperbolic entailment cone\", it should be as good as the \"hyperbolic entailment cone\".\n3. The use of different definitions for light source in the Penumbral cone and the Umbral cone is somewhat inconsistent. Please see the weaknesses.",
         "197",
         "0",
         "6",
         "0.7006",
         "0.1862637363",
         "0.9387722611",
         "66",
         "27",
         "40.7264",
         "11.6572",
         "14.8915",
         "14.1918",
         "14.5363",
         "0.1376",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "168",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_6mLv",
         "1698994582440",
         "1700643652951",
         "6",
         "3",
         "3",
         "2",
         "3",
         "The authors introduce the \"shadow cones\" framework for constructing entailment cones in hyperbolic space. Unlike prior work that utilized nested cones in the Poincaré ball, shadow cones model partial orders based on subset relations between shadows created by a light source and opaque objects.  This framework extends beyond the Poincaré ball, allowing for more diverse formulations and hyperbolic space models. Shadow cones offer advantages over existing constructions, particularly in terms of optimization properties. Experimental results demonstrate the consistent and significant outperformance of shadow cones compared to existing entailment cone constructions across datasets of varying sizes and hierarchical structures. 1. The introduction of shadow cones presents an innovative approach to defining entailment relations in hyperbolic space. Drawing inspiration from physical phenomena adds an intuitive and captivating aspect to the concept.\n\n2.  The authors provide a comprehensive mathematical formulation for shadow cones, enhancing the rigor of their work and enabling further exploration and development by other researchers in the field.\n\n3.  The experimental results across four datasets demonstrate the superior performance of the proposal compared to the current state-of-the-art methods. 1. While the authors tested their framework on four datasets, it would be beneficial to see how the framework performs on a wider variety of datasets, including those from different domains or those with different characteristics (like KG, recommender system datasets and so on). This would provide a more comprehensive evaluation of the framework's performance and versatility.\n\n2.The work builds on the entailment cone but a few partial order methods have been proposed and a thorough comparison or discussion is needed.\n\n3. Captions for the figures are brief and ambiguous, hindering their readability. \n\n\n\\[1\\]Capacity and Bias of Learned Geometric Embeddings for Directed Graphs.\n\\[2\\]Modeling Transitivity and Cyclicity in Directed Graphs via Binary Code Box Embeddings see weakness",
         "295",
         "2",
         "5",
         "0.8035",
         "0.1550724638",
         "0.9411929846",
         "61",
         "19",
         "21.6882",
         "15.12",
         "18.8497",
         "16.5672",
         "16.9667",
         "0.0945",
         "96",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "195",
         "zUHgYRRAWl",
         "4337",
         "1695345226979",
         "['~Chenghui_Zhou1', '~Barnabas_Poczos1']",
         "Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage VAE",
         "Variational autoencoder (VAE) is a popular method for drug discovery and various architectures and pipelines have been proposed to improve its performance. However, VAE approaches are known to suffer from poor manifold recovery when the data lie on a low-dimensional manifold embedded in a higher dimensional ambient space [Dai and Wipf, 2019]. The consequences of it in drug discovery are somewhat under-explored. In this paper, we explore applying a multi-stage VAE approach, that can improve manifold recovery on a synthetic dataset, to the field of drug discovery. We experimentally evaluate our multi-stage VAE approach using the ChEMBL dataset and demonstrate its ability to improve the property statistics of generated molecules substantially from pre-existing methods without incorporating property predictors into the training pipeline. We further fine-tune our models on two curated and much smaller molecule datasets that target different proteins. Our experiments show an increase in the number of active molecules generated by the multi-stage VAE in comparison to their one-stage equivalent. For each of the two tasks, our baselines include methods that use learned property predictors to incorporate target metrics directly into the training objective and we discuss complications that arise with this methodology.",
         "Reviewer_DTvh",
         "1698432721685",
         "1699636403897",
         "1",
         "5",
         "1",
         "1",
         "1",
         "The authors propose a new method for training VAEs for drug discovery tasks. Unfortunately, I must vote to reject without further review as the authors blatantly violated the ICLR submission template. Violations include:\n\n* Obviously significantly reducing the margin size to fit within the page limit.\n* Removing the \"Under review as a conference paper at ICLR 2024\" header.\n* Not including a references section in their submission. Rejecting without further review. Rejecting without further review. Rejecting without further review.",
         "80",
         "0",
         "0",
         "0.7838",
         "-0.0098484848",
         "0.8092228174",
         "49",
         "13",
         "34.4578",
         "10.8443",
         "12.6812",
         "11.4568",
         "10.1706",
         "0.07390000000000001",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "196",
         "zUHgYRRAWl",
         "4337",
         "1695345226979",
         "['~Chenghui_Zhou1', '~Barnabas_Poczos1']",
         "Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage VAE",
         "Variational autoencoder (VAE) is a popular method for drug discovery and various architectures and pipelines have been proposed to improve its performance. However, VAE approaches are known to suffer from poor manifold recovery when the data lie on a low-dimensional manifold embedded in a higher dimensional ambient space [Dai and Wipf, 2019]. The consequences of it in drug discovery are somewhat under-explored. In this paper, we explore applying a multi-stage VAE approach, that can improve manifold recovery on a synthetic dataset, to the field of drug discovery. We experimentally evaluate our multi-stage VAE approach using the ChEMBL dataset and demonstrate its ability to improve the property statistics of generated molecules substantially from pre-existing methods without incorporating property predictors into the training pipeline. We further fine-tune our models on two curated and much smaller molecule datasets that target different proteins. Our experiments show an increase in the number of active molecules generated by the multi-stage VAE in comparison to their one-stage equivalent. For each of the two tasks, our baselines include methods that use learned property predictors to incorporate target metrics directly into the training objective and we discuss complications that arise with this methodology.",
         "Reviewer_uwWu",
         "1698666834458",
         "1699636403824",
         "3",
         "4",
         "1",
         "2",
         "1",
         "The article \"Objective-agnostic enhancement...\" describes the use of multi-layer VAE models for the prediction and generation of small molecules for drug discovery problems. The use of multi-layer VAE models is proposed in view of their better generative statistics, approximation of the true, for a given dataset, immersion in high-dimensional space.\n\nThe article is very simple, offering basically nothing new. The level of workmanship is low, additionally parts of the paper are clearly missing.\n\nI believe that the proposed article is not ready, does not contain any novelties, and as such should not be accepted. 1. Correct posing of a problem, with correct references to related work.\n2. The authors undertake the issue of finding better low-dimension space immersion in high-dimensional space. On the other hand, it is not proved that their solution is the right one. 1. The authors note that typically, high-dimensional data can be projected onto a low-dimensional space immersed in a high-dimensional space. To demonstrate this, they conduct a very simple experiment on synthetic data. This experiment does not show much, only the authors claim that for one of the later layers a space with the correct dimensionality for the data is obtained. This experiment is clearly spurious and can be removed.\n2. The authors propose to build a VAE model with many hidden layers iteratively. In each step, developing the projection of the most recently obtained hidden layer into a new VAE model. The obtained model would get the variances on the diagonal reach the values {0, 1}, which would show the selection/reduction of individual dimensions projection. \nIt seems that the analogy with synthetic experiment is insufficient for a direct application of this approach.\n3. Several models with randomly selected numbers of hidden layers are used in the experiments.\n4. In the comparisons, each model has a different dimensionality of hidden layers for the same data.\n5. There is no bibliography in the work. I suspect that this is a simple editorial error (references in the work are marked as links), but such an error in a work for a major conference is unacceptable. Similarly, there is no appendix to which there is a reference in the main text. 1. Is the synthetic experiment really needed? I would remove it if I were you. In place of it, I would give some better mathematical discussion.\n2. Is the analogy between the scheme presented in the synthetic data experiment to the problem of molecule generation really valid? Could you, please, better justify the analogy?\n3. Why just that number of layers are used in the models? Why are there 3 layers for HGNN and MoLeR? The \"MoLeR + prop\" model is completely unclear? Why does the RNN model only have two layers? The LatentGAN model seems to have only one hidden layer, right? Or maybe some of the nodels are for comparison? This is not clear from the text of the work.\n4. If one of the goals was to show that multi-layer models, along with variance optimization, allow for better matching of the implicit dimensions, does using different dimensions allow this to be shown for different models? There is no description of the individual statistics used in the work.\n5. Was variance optimization used for all models? This is not clear from the text.\n6. The standard in the editorial composition of scientific works is to place descriptions of tables above them, not below.",
         "568",
         "0",
         "13",
         "0.7239",
         "0.0615771877",
         "0.8907097578000001",
         "49",
         "11",
         "48.9896",
         "10.038",
         "12.8701",
         "12.413",
         "9.5053",
         "0.2922",
         "88",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "197",
         "zUHgYRRAWl",
         "4337",
         "1695345226979",
         "['~Chenghui_Zhou1', '~Barnabas_Poczos1']",
         "Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage VAE",
         "Variational autoencoder (VAE) is a popular method for drug discovery and various architectures and pipelines have been proposed to improve its performance. However, VAE approaches are known to suffer from poor manifold recovery when the data lie on a low-dimensional manifold embedded in a higher dimensional ambient space [Dai and Wipf, 2019]. The consequences of it in drug discovery are somewhat under-explored. In this paper, we explore applying a multi-stage VAE approach, that can improve manifold recovery on a synthetic dataset, to the field of drug discovery. We experimentally evaluate our multi-stage VAE approach using the ChEMBL dataset and demonstrate its ability to improve the property statistics of generated molecules substantially from pre-existing methods without incorporating property predictors into the training pipeline. We further fine-tune our models on two curated and much smaller molecule datasets that target different proteins. Our experiments show an increase in the number of active molecules generated by the multi-stage VAE in comparison to their one-stage equivalent. For each of the two tasks, our baselines include methods that use learned property predictors to incorporate target metrics directly into the training objective and we discuss complications that arise with this methodology.",
         "Reviewer_un1d",
         "1698911651980",
         "1699636403750",
         "1",
         "4",
         "2",
         "2",
         "2",
         "A multi-stage VAE model that help generate molecules with conditional properties. Proposed a novel multi-stage model. No reference section. \nNo under review header.\nI believe this paper is not ready to be reviewed. N/A",
         "34",
         "0",
         "3",
         "0.8889",
         "-0.1",
         "0.80578053",
         "49",
         "8",
         "48.1506",
         "8.2326",
         "10.9553",
         "9.8885",
         "7.4594000000000005",
         "0.2086",
         "33",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "227",
         "zQXX3ZV2HE",
         "2189",
         "1695178042065",
         "['~Liang_Muxue1', '~Chuan_Wang1', '~Siyuan_Liang1', '~Aishan_Liu1', '~Zeming_Liu1', '~Liang_Yang2', '~Xiaochun_Cao3']",
         "Adversarial Instance Attacks for Interactions between Human and Object",
         "Adversarial attacks can easily deceive deep neural networks (DNNs); however, they are also valuable for evaluating the robustness of DNNs. Existing attacks on object detection primarily focus on attacking the recognition of objects, while whether the attacks remain effective on more complex scene understanding tasks (e.g., extracting the interaction between objects) remains largely unexplored. In this paper, we, for the first time, propose Adversarial Instance Attacks, a novel black-box attacking framework for scene interactions without interfering with object detections. To achieve the goal, we first introduce an Interaction Area Sampling module that identifies vulnerable anchors (area) for adversarial instances positioning. Secondly, we design an Object Category Search module and build an interaction co-occurrence knowledge graph to explore categories with higher obfuscation scores toward specific object-interaction pairs. Finally, our framework generates perturbations that serve as adversarial instances with high co-occurrence obfuscation towards specific interactions in vulnerable areas and deceive HOI models. Extensive experiments conducted against multiple models demonstrate effectiveness in attacking interactions of HOI. Our approach surpasses existing methods by significant margins, achieving an improvement of at least +10.36%}.",
         "Reviewer_FvgA",
         "1698417808331",
         "1699636152756",
         "3",
         "4",
         "3",
         "2",
         "2",
         "The paper proposes a approach called Adversarial Instance Attacks (AIA) to attack the interaction predictions between humans and objects in the context of Human Object Interaction (HOI) tasks. The authors argue that existing adversarial attacks on object detection do not effectively extend to interactions, as interactions are more complex and require considering spatial and semantic relationships. AIA is designed to generate adversarial instances that distract the model's attention away from the original interaction, without disrupting the detection of human and object bounding boxes or their categories. The proposed AIA framework comprises three main modules: Interaction Area Sampling (IAS), Object Category Search (OCS), and Adversarial Instance Generation (AIG). The authors claim that AIA outperforms other attack methods in attacking interactions. Innovative Approach: The paper introduces a novel approach to attacking interactions in HOI tasks, addressing a gap in the existing literature.\n\nExperimental Results: The paper presents a thorough evaluation of the proposed AIA framework and compares it with other attack methods on various target and surrogate models. The results indicate that AIA is effective in attacking interactions.\n\nDiscussion on Perturbation Bounds: The paper provides an insightful analysis of the impact of different perturbation bounds on the success of attacks, shedding light on how noise affects interaction recognition. Lack of Clarity: The paper is challenging to follow due to its complex technical language and insufficient contextual explanations. It assumes a high level of familiarity with the subject matter, making it less accessible to a broad audience.\n\nAmbiguity in Terminology: Some terms and acronyms are not adequately defined or clarified, such as \"Adversarial Instance Attacks,\" \"Adversarial Interaction Attack,\" and \"HOTR.\"\n\nMissing Visual Aids: Given the complexity of the proposed framework, the paper would benefit from visual aids, diagrams, or flowcharts to help readers understand the different modules and their interactions.\n\nEvaluation Metrics: The paper could benefit from a more detailed discussion of the evaluation metrics used and how they relate to the effectiveness of the attacks. 1. Could you provide more clarity on the specific datasets used in the experiments and how they were collected or prepared?\n\n2. Can you elaborate on the definition of \"L\" in the context of perturbation bounds? What does it represent, and how is it determined?\n\n3. How does the AIA framework perform against state-of-the-art HOI models, and are there specific models it is more effective against?\n\n4. What kind of perturbations or attacks are used in the experiments? Is there a specific method for generating these adversarial instances?",
         "411",
         "0",
         "4",
         "0.7982",
         "0.13815040650000002",
         "0.8926494718",
         "51",
         "14",
         "23.7753",
         "15.0483",
         "18.0497",
         "16.2186",
         "16.108",
         "0.3442",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "228",
         "zQXX3ZV2HE",
         "2189",
         "1695178042065",
         "['~Liang_Muxue1', '~Chuan_Wang1', '~Siyuan_Liang1', '~Aishan_Liu1', '~Zeming_Liu1', '~Liang_Yang2', '~Xiaochun_Cao3']",
         "Adversarial Instance Attacks for Interactions between Human and Object",
         "Adversarial attacks can easily deceive deep neural networks (DNNs); however, they are also valuable for evaluating the robustness of DNNs. Existing attacks on object detection primarily focus on attacking the recognition of objects, while whether the attacks remain effective on more complex scene understanding tasks (e.g., extracting the interaction between objects) remains largely unexplored. In this paper, we, for the first time, propose Adversarial Instance Attacks, a novel black-box attacking framework for scene interactions without interfering with object detections. To achieve the goal, we first introduce an Interaction Area Sampling module that identifies vulnerable anchors (area) for adversarial instances positioning. Secondly, we design an Object Category Search module and build an interaction co-occurrence knowledge graph to explore categories with higher obfuscation scores toward specific object-interaction pairs. Finally, our framework generates perturbations that serve as adversarial instances with high co-occurrence obfuscation towards specific interactions in vulnerable areas and deceive HOI models. Extensive experiments conducted against multiple models demonstrate effectiveness in attacking interactions of HOI. Our approach surpasses existing methods by significant margins, achieving an improvement of at least +10.36%}.",
         "Reviewer_fSia",
         "1698647640926",
         "1699636152669",
         "1",
         "2",
         "2",
         "1",
         "2",
         "The authors have introduced an adversarial attack problem that targets interactions between humans and objects. They evaluate this problem within the context of the Human Object Interaction (HOI) task, as proposed by Gkioxari et al. in 2018. Furthermore, the authors have successfully demonstrated an attacking framework for this novel problem The paper proposes to tackle a new problem for adversarial attack for interactions between human and objects, based on the Human Object Interaction (HOI) task (Gkioxari et al., 2018), which is a new contribution to the field and might be interested to the adversarial attack community. However, the motivation is not clear when it is a difficult problem compared to existing attack problems. And the evaluation and writing quality are poor. Deficient Writing Quality: The paper exhibits evident signs of hasty preparation, accompanied by numerous errors. To illustrate a few examples, some of which are highlighted in bold text:\n\n* The reviewer could not understand “on the interaction between scene contents and **realize**’ based on” \n\n* The math notations of {$ h_i^b, o_i^b, o_i^l, a_i $} are incorrect and confusing. It does not make sense to use a set { } for both coordinates and categories. And defining $a_i$ as the categories of the object is wrong.\n\n* directly adding noise to the union area not only **drop the precise** of interaction perception but also **bring** .... \n\nThe motivation is unclear. The arguments within the sentences lack proper support. For instance, the sentence \"a direct strategy to disturb the interaction is adding noises on the union area of human and object, following the feature extraction procedure in HOI. However, directly adding noise to the union area not only drop the precise of interaction perception but also bring interference in locating and classifying human and objects\" lacks clarity and substantiation.\n\nUnderstanding the paper's concept is challenging, primarily due to its poor writing quality. For example, the exact process for generating \"N^q candidate interaction areas\" is not explained and appears disconnected from the subsequent content. Upon reviewing Section 3.3, the reviewer found it to be incomplete, offering only a feature extraction process without any content related to sampling. The method for obtaining the extracted candidate predicate areas $A$ is also unclear.\n\nThe rationale behind distance calculation remains unclear, as does the definition of the midpoint function $f_{mid}()$.\n\n\"To address this issue, we employ random assignment to connect perplexing object categories to candidate predicate areas in order to generate the attack instances.\" However, the explanation for this random assignment is unclear.\n\nIn summary, while the paper may address an important problem of black-box adversarial attacks in scene interactions, its writing quality falls significantly below the standards of ICLR. Significant revisions are required. Therefore, the reviewer recommends clear rejection.\"\n\n\nThe equation (6) seems to contradict to the original claim of the paper  \"our goal is to bring confusion on the\ninteraction of a pair of human and an object, without contaminating their detection results including\nthe human bounding box, object bounding box, and object category\", as the object bounding boxes seem to be changed. Please provide more clarifications to it. Please refer to the above comments.",
         "522",
         "1",
         "1",
         "0.7922",
         "0.033107672500000004",
         "0.8696472049",
         "51",
         "11",
         "33.1415",
         "13.0399",
         "16.2725",
         "14.9895",
         "13.4814",
         "0.0988",
         "90",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "229",
         "zQXX3ZV2HE",
         "2189",
         "1695178042065",
         "['~Liang_Muxue1', '~Chuan_Wang1', '~Siyuan_Liang1', '~Aishan_Liu1', '~Zeming_Liu1', '~Liang_Yang2', '~Xiaochun_Cao3']",
         "Adversarial Instance Attacks for Interactions between Human and Object",
         "Adversarial attacks can easily deceive deep neural networks (DNNs); however, they are also valuable for evaluating the robustness of DNNs. Existing attacks on object detection primarily focus on attacking the recognition of objects, while whether the attacks remain effective on more complex scene understanding tasks (e.g., extracting the interaction between objects) remains largely unexplored. In this paper, we, for the first time, propose Adversarial Instance Attacks, a novel black-box attacking framework for scene interactions without interfering with object detections. To achieve the goal, we first introduce an Interaction Area Sampling module that identifies vulnerable anchors (area) for adversarial instances positioning. Secondly, we design an Object Category Search module and build an interaction co-occurrence knowledge graph to explore categories with higher obfuscation scores toward specific object-interaction pairs. Finally, our framework generates perturbations that serve as adversarial instances with high co-occurrence obfuscation towards specific interactions in vulnerable areas and deceive HOI models. Extensive experiments conducted against multiple models demonstrate effectiveness in attacking interactions of HOI. Our approach surpasses existing methods by significant margins, achieving an improvement of at least +10.36%}.",
         "Reviewer_62sG",
         "1698744806152",
         "1699636152594",
         "3",
         "4",
         "3",
         "2",
         "2",
         "In this paper, the authors propose a black-box attack method against Human Object Interaction (HOI). The proposed method of Adversarial Instance Attacks (AIA) consists of an Interaction Area Sampling (IAS) module for finding the vulnerable areas, an Object Category Search (OCS) module for assigning the confusing category, and an Adversarial Instance Generation (AIG) module for attacking effects. The experiment validations on the V-COCO datasets are given to demonstrate its effectiveness on various models. 1. The proposed attack method is conducted in a new area, Human Object Interaction.\n2. Choosing the fragility of one image to attack is an interesting and reasonable idea for Human Object Interaction. 1. For the experiments, the comparisons between I-FGSM and PGD on detectors and the proposed method are unfair. The authors use the transfer results by I-FGSM and PGD to attack HOI, where the adversarial examples based on the architecture of detectors (e.g., Faster RCNN and YOLO ) are generated. Thus, these methods have a weak transferability across the different tasks. However, the proposed method has more knowledge about the attacked task instead of only detectors.\n2. The tasks of HOI highly rely on the results of detections. The existing attacks for detection can be directly employed in this task, leading to awful results. From the proposed method, the attacks aim to fool the interactions between the human and object, instead of the human and the object itself. If so, wrong detection results and boxes easily lead to wrong interactions. Thus, those attacks against object detection, especially for fooling the detection boxes should be involved in comparisons. Besides, why only attacking the interaction in HOI is worthy of investigating?\n3. Expect for the illustration in Figure 1, more visualizations with various methods (e.g., PGD and I-FGSM) should be involved to demonstrate its imperceptibility and effectiveness.\n4. There are some minor problems.\n- In the caption of Figure 1, ‘remaining0’ seems a typo.\n- Some formats of references are wrong and inconsistent. 1. The comparison between I-FGSM and PGD on detectors and the proposed method for HOI is unfair as the prior knowledge is different. \n2. Discuss the motivation for only attacking the interaction in HOI, and give some attack results on only attacking the detectors.\n3. Give more visual comparisons between various methods.",
         "378",
         "0",
         "9",
         "0.7396",
         "-0.036809991800000004",
         "0.9304254651",
         "51",
         "10",
         "38.47",
         "11.7752",
         "13.61",
         "13.1604",
         "11.7891",
         "0.1213",
         "81",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "230",
         "zQXX3ZV2HE",
         "2189",
         "1695178042065",
         "['~Liang_Muxue1', '~Chuan_Wang1', '~Siyuan_Liang1', '~Aishan_Liu1', '~Zeming_Liu1', '~Liang_Yang2', '~Xiaochun_Cao3']",
         "Adversarial Instance Attacks for Interactions between Human and Object",
         "Adversarial attacks can easily deceive deep neural networks (DNNs); however, they are also valuable for evaluating the robustness of DNNs. Existing attacks on object detection primarily focus on attacking the recognition of objects, while whether the attacks remain effective on more complex scene understanding tasks (e.g., extracting the interaction between objects) remains largely unexplored. In this paper, we, for the first time, propose Adversarial Instance Attacks, a novel black-box attacking framework for scene interactions without interfering with object detections. To achieve the goal, we first introduce an Interaction Area Sampling module that identifies vulnerable anchors (area) for adversarial instances positioning. Secondly, we design an Object Category Search module and build an interaction co-occurrence knowledge graph to explore categories with higher obfuscation scores toward specific object-interaction pairs. Finally, our framework generates perturbations that serve as adversarial instances with high co-occurrence obfuscation towards specific interactions in vulnerable areas and deceive HOI models. Extensive experiments conducted against multiple models demonstrate effectiveness in attacking interactions of HOI. Our approach surpasses existing methods by significant margins, achieving an improvement of at least +10.36%}.",
         "Reviewer_L4HX",
         "1698933201485",
         "1699636152505",
         "5",
         "3",
         "3",
         "3",
         "2",
         "This paper proposed a new concept for adversarial attack on Human Object Interaction (HOI). Different from adversarial attack on object classification or detection, there was less work focused on HOI attack. In this paper, the main idea is to find a proper region in an image, where an invisible object is inserted and which will mislead the HOI classifier. To this end, three modules are proposed, i.e., Interaction Area Sampling module, Object Category Search module, and Adversarial Instance Generation module. + A novel adversarial attack is defined for human object interaction recognition task. HOI recognition task is a high-level task with respect to object classification or detection tasks. It motivation of this paper makes sense which is to insert an inviable object to mislead the HOI classifier. - My main concern is that the proposed attack is somewhat an untargeted attack for an HOI recognition system, where we cannot choose the target HOI category, instead, the target HOI category is determined by the method via finding the most confusing interaction. I am not sure the whether such attack will happen in real applications or not.\n- The proposed method is straightforward, which is combination of existing techniques such as Targeted adversarial Objectness Gradient attacks (TOG) in Adversarial Instance Generation module. Can we conduct a targeted adversarial attack for HOI recognition, which is that we can explicitly choose the target HOI category we want the attack achieves.",
         "236",
         "0",
         "0",
         "0.7818",
         "0.0552020202",
         "0.8878258467000001",
         "51",
         "8",
         "31.3614",
         "13.7087",
         "15.492",
         "14.435",
         "13.5447",
         "0.2084",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "258",
         "zLwCT9srfo",
         "7961",
         "1695491975818",
         "['~Julia_Gusak1', '~Xunyi_Zhao1', '~Théotime_Le_Hellard1', '~Zhe_LI20', '~Lionel_Eyraud-Dubois1', '~Olivier_Beaumont1']",
         "H-Rockmate: Hierarchical Approach for Efficient Re-materialization of Large Neural Networks",
         "Training modern neural networks poses a significant memory challenge, as storing intermediate results during the forward and backward passes demands substantial memory resources. To address this issue while maintaining model accuracy, re-materialization techniques have been introduced to recompute selected intermediate results rather than storing them, thereby adhering to peak memory constraints. The main algorithmic problem is to compute a re-materialization schedule that minimizes the computational overhead within a given memory budget. Our H-Rockmate framework builds upon an existing Rockmate solution and overcomes its limitation to work with sequential block structures by proposing a hierarchical approach. The framework performs an automatic decomposition of the data-flow graph into a hierarchy of small-scale subgraphs, and finds a re-materialization schedule for the whole graph by recursively solving optimization problems for each subgraph. H-Rockmate allows users to transform their PyTorch models into nn.Modules that execute forward and backward passes efficiently within the specified memory budget. This framework can handle neural networks with diverse data-flow graph structures, including U-Nets and encoder-decoder Transformers. H-Rockmate outperforms existing re-materialization approaches in terms of average training iteration time and peak memory trade-offs, demonstrating superior memory efficiency in training modern neural networks.",
         "Reviewer_u563",
         "1697419993497",
         "1701667998218",
         "6",
         "4",
         "3",
         "2",
         "3",
         "The authors proposed a hierachical (or devide and conquer) approach to make re-compute/materialize decision by:\n  1. partition the graph into subgraphs hierachically\n  2. apply a modified ILP solver (H-ILP) on solved subraphs recursively\n  3. additionally, the base solver for the leaf subgraphs of the (hierachical) tree is modularized to swap between different algos\n\nto address the issue of existing approaches which (are either ILP based thus) don't scale to large graph or fail to optimize more general graph with long skip connections like Unet. + The hierachical + ILP solution proposed by the authors is intuitive and practical in the sense that:\n  1. the search space of ILP based approach is too large to scale to graph with thousands of computational ops/nodes, a good graph partition can trim down the search space efficiently\n  2. non-ILP based approach has a hard time dealing with networks with long skip connections like UNET or ENCODER/DECODER architecutre.\n\n+ the base solver for the bottom/leaf subgraph is modularized, thus can swap to different algos as a graph/solver runtime tradeoff\n\n+ solid explanation/comparisons to related works/baselines, and the robustness to hierachy depth (figure 4) is a good indicator of its scalability to general/deep networks - The parition algorithms (especially the score function/cost model in equation 1) is a bit ad-hoc, I can grasp the intuition behind it, e.g., it tries to identify a subgraph with least IO and penalize on number of nodes in it so that it can minimize the memory required to checkpoint its IO while keeping the scale of each subgraph relatively small. However, graph partition is a long-studied problem and usually such a heuristic/greedy based algo don't scale very well in the sense that they are typically tailored for specific known targets and would fail overtime when target envolves, that being said, I would suggest:\n  1. try the partition algos on a densenet to see if it produces good result\n  2. alternatively make this partition algo also modularized as the solvers, what's more valuable/solid in this work is the intuitionn of hierachy (devide and conquer) and the H-ILP solver IMO\n\n- the presentation can be improved:\n  1. the 3.1 H-partition part contains a lot implementation details without much explanation where they come from, e.g., as is briefly mentioned above regarding equation (1), and additionally why do you need alpha and why is it 0.5, why did you choose 4 candidte groups in \"Formation of candidate groups\" rather than other numbers.\n   2. On the other hand, the caption of the most important figure 1 doesn't have enough details, what's the time vs memory plot? (I think they refer to options), what's direct solver (I only got base solvers for bottom subgraph and H-ILP hierachical solver), etc.\n   3. How does H-ROCKMATE beat the baselines in Unet/Encoder-Deccoders more concretely? An explanation or preferrably an illustrative exmaple would help readers understand the quality of it more intuitively. In addition to the questions in Weakness, here are a couple more questions:\n\n1. what does \"the higher level algorithm adapts the sub schedules\" conrectely mean in Correction terms for memory usage?\n\n2. would \"model = HRockmate(model, sample, memory_budget)\" work with Tensor Parallel packages like Megatron? as my guess of the implementation relies on model/graph tracing and Megatron can pose difficulties in such tracing due to collective communications.",
         "549",
         "0",
         "2",
         "0.8388",
         "0.020962909000000002",
         "0.7621635199",
         "71",
         "49",
         "40.7196",
         "13.434",
         "16.3634",
         "15.041",
         "15.1895",
         "0.1463",
         "76",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "259",
         "zLwCT9srfo",
         "7961",
         "1695491975818",
         "['~Julia_Gusak1', '~Xunyi_Zhao1', '~Théotime_Le_Hellard1', '~Zhe_LI20', '~Lionel_Eyraud-Dubois1', '~Olivier_Beaumont1']",
         "H-Rockmate: Hierarchical Approach for Efficient Re-materialization of Large Neural Networks",
         "Training modern neural networks poses a significant memory challenge, as storing intermediate results during the forward and backward passes demands substantial memory resources. To address this issue while maintaining model accuracy, re-materialization techniques have been introduced to recompute selected intermediate results rather than storing them, thereby adhering to peak memory constraints. The main algorithmic problem is to compute a re-materialization schedule that minimizes the computational overhead within a given memory budget. Our H-Rockmate framework builds upon an existing Rockmate solution and overcomes its limitation to work with sequential block structures by proposing a hierarchical approach. The framework performs an automatic decomposition of the data-flow graph into a hierarchy of small-scale subgraphs, and finds a re-materialization schedule for the whole graph by recursively solving optimization problems for each subgraph. H-Rockmate allows users to transform their PyTorch models into nn.Modules that execute forward and backward passes efficiently within the specified memory budget. This framework can handle neural networks with diverse data-flow graph structures, including U-Nets and encoder-decoder Transformers. H-Rockmate outperforms existing re-materialization approaches in terms of average training iteration time and peak memory trade-offs, demonstrating superior memory efficiency in training modern neural networks.",
         "Reviewer_piuX",
         "1698748954661",
         "1699636978684",
         "6",
         "3",
         "3",
         "4",
         "3",
         "This paper introduces H-Rockmate, which is a hierarchical approach to find a re-materialization strategy for large neural networks. It decomposes a dataflow graph into multi-level and find efficient solutions of each blocks in bottom level. A related ILP formulation is proposed to recombine low-level solutions. H-Rockmate can find similar performance as ROCKMATE in less time, making it more practical. 1.\tH-Rockmate proposes a hierarchical decomposition method for the computation graph. Thus the size of the ILP problem is smaller. Experiments show that efficiency and performance haven’t been compromised.\n2.\tOther re-materialization strategies can be integrated into their frameworks to achieve better performance.\n3.\tTheoretical analysis of their algorithm and ILP formulation is provided in the Appendix. 1.\tSince they claim H-Rockmate works for large neural networks, the sizes of neural networks used in experiments are the same as other works.\n2.\tThere are some typos in the Appendix, such as “line ??”. 1.\tIf H-Rockmate is applied to a billion-level neural networks like LLaMA, how will the peak memory and iteration time be? I think experiments with larger neural networks than GPT2 is necessary.\n2.\tCan you introduce what constraints are considered in your main part of the paper and introduce detailed expressions in Appendix？\n3.\tWhat if modeling on-chip global memory to get a better scheduling? Can your method support this?",
         "222",
         "0",
         "8",
         "0.8209",
         "0.1093984962",
         "0.9032994509000001",
         "47",
         "10",
         "42.3728",
         "10.7806",
         "14.2128",
         "13.0239",
         "11.36",
         "0.2429",
         "81",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "260",
         "zLwCT9srfo",
         "7961",
         "1695491975818",
         "['~Julia_Gusak1', '~Xunyi_Zhao1', '~Théotime_Le_Hellard1', '~Zhe_LI20', '~Lionel_Eyraud-Dubois1', '~Olivier_Beaumont1']",
         "H-Rockmate: Hierarchical Approach for Efficient Re-materialization of Large Neural Networks",
         "Training modern neural networks poses a significant memory challenge, as storing intermediate results during the forward and backward passes demands substantial memory resources. To address this issue while maintaining model accuracy, re-materialization techniques have been introduced to recompute selected intermediate results rather than storing them, thereby adhering to peak memory constraints. The main algorithmic problem is to compute a re-materialization schedule that minimizes the computational overhead within a given memory budget. Our H-Rockmate framework builds upon an existing Rockmate solution and overcomes its limitation to work with sequential block structures by proposing a hierarchical approach. The framework performs an automatic decomposition of the data-flow graph into a hierarchy of small-scale subgraphs, and finds a re-materialization schedule for the whole graph by recursively solving optimization problems for each subgraph. H-Rockmate allows users to transform their PyTorch models into nn.Modules that execute forward and backward passes efficiently within the specified memory budget. This framework can handle neural networks with diverse data-flow graph structures, including U-Nets and encoder-decoder Transformers. H-Rockmate outperforms existing re-materialization approaches in terms of average training iteration time and peak memory trade-offs, demonstrating superior memory efficiency in training modern neural networks.",
         "Reviewer_J4PJ",
         "1699177659177",
         "1699636978582",
         "3",
         "4",
         "3",
         "2",
         "2",
         "This paper tries to solve the problem of efficient scheduling of re-materialization of the training computation. Concretely, the paper proposes H-rockmate, a hierarchical solution to decompose the data-flow graph into a hierarchy of small-scale subgraphs and compute a re-materialization schedule that minimizes the computational overhead within a given memory budget. Empirical studies are conducted to evaluate the performance of the proposed method in terms of solver efficiency and end-to-end performance. - The summarization of this research area is clear and accurate; the related work section is well-organized.\n\n- The intuition behind the scheduling algorithm design is clear and straightforward.   \n\n- Based on the reported experimental results, the reduction of the solver execution time is significant. - The writing of the paper can be significantly improved. First of all, there is a lack of a formal definition for the scheduling problem itself -- the current introduction of the problem is interweaved with the problem statement in Section 3.1. Additionally, section 3.2 is too casual; there is a lack of enough formalization about the mathematical representation of the problem -- I notice plenty of important information is left in the appendix. I do not think this is an appropriate trade-off; the technique content should be self-explained within the scope of the paper.   \n\n- I am a little confused by the presented results in Figure 3; I was expecting that when the budget is very low, every algorithm should be able to find the scheduling of re-computing every activation, while when the budget is very high, every algorithm should be able to find the scheduling of no-recomputation, but still there is some difference between each line. This was confusing. Additionally, the important hyper-parameters, such as batch size, are not enumerated in Section 4. \n\n- Another trivial detail is that the font style differs from other submissions I reviewed; please check the instructions to ensure you are using the requested font style. See my comments in the Weakness section.",
         "325",
         "0",
         "0",
         "0.7376",
         "0.0940166667",
         "0.8504388928000001",
         "47",
         "5",
         "31.936700000000002",
         "13.7268",
         "16.1269",
         "15.3315",
         "13.9392",
         "0.4828",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "278",
         "zH6zBoktYO",
         "8000",
         "1695493297402",
         "['~Neel_Jain1', '~Khalid_Saifullah1', '~Yuxin_Wen2', '~John_Kirchenbauer1', '~Manli_Shu1', '~Aniruddha_Saha1', '~Micah_Goldblum1', '~Jonas_Geiping1', '~Tom_Goldstein1']",
         "Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models",
         "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set, which can lead to misleading evaluations. To alleviate the issues in traditional evaluation, we propose a complementary framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-sensitivity and human-supervised evaluations. The self-sensitivity paradigm complements current evaluation strategies that rely on labeled data.",
         "Reviewer_KAMN",
         "1698750843403",
         "1699636985472",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper presents a framework for self-supervised evaluation of Large Language Models (LLMs) by proposing a series of sensitivity (invariance) metrics that assess various aspects of language model behavior without the need for human-labeled datasets. These metrics evaluate the models based on their reaction to input transformations concerning knowledge via negations, toxicity, and word order. The authors claim that these self-supervised evaluation methods can complement traditional supervised benchmarks and provide efficient evaluation in real-world settings. - The proposed self-supervised evaluation framework addresses the significant challenge of evaluating LLMs without the extensive need for labeled datasets, which is a common bottleneck.\n\n- The authors provide empirical evidence that correlates the proposed self-supervised metrics with existing supervised benchmarks, lending credibility to their approach.\n\n- By analyzing how LLMs react to various textual transformations, the paper offers deeper insights into the behavior and limitations of these models, which can inform future research and model development. - The paper acknowledges model entropy as a factor that could influence sensitivity scores but does not explore it in detail. Understanding how the entropy of a model's output distribution affects evaluation metrics is crucial for interpreting results accurately.\n\n- The main methods proposed in this work—knowledge probing via negations, toxicity detection, and word order—seem to be presented as separate entities without a unifying theme or rationale that clearly ties them together. The paper could benefit from a more cohesive narrative that explains how these methods collectively advance the understanding and evaluation of LLMs.\n\n- The proposed methods, such as adding \"not\" after certain words for negation or appending trigger words for toxicity, may seem too basic or trivial. This simplicity could lead to questions about the depth and sophistication of the approach, as well as its ability to capture the nuances of language and behavior of LLMs. The straightforward nature of the methods may not generalize well to the complex and varied inputs that LLMs encounter in real-world applications. The paper might not demonstrate that the methods can handle different linguistic constructions, idiomatic expressions, or contextual nuances.\n\n- The motivation behind each method is not evidently articulated. While each method addresses a different aspect of language model behavior, the paper may not clearly explain why these particular aspects are chosen and how they complement each other in providing a comprehensive evaluation.\n\n- The methods may not be backed by a comprehensive set of experiments to validate their effectiveness across different models, domains, prompts, and languages. This could be seen as lacking in terms of the breadth and depth of experimental validation. - Could you explain the rationale behind the simplicity of the proposed methods? How do you ensure that such straightforward techniques can provide a robust evaluation of complex LLM behaviors?\n\n- To what extent did you consider more sophisticated prompt engineering in your evaluation framework? Could you elaborate on how different prompt designs might affect the outcomes of your proposed metrics? For example, how could changing the position of trigger words in toxicisy detection influence the outcome?\n\n- Can you discuss any additional experiments that might demonstrate the robustness of your evaluation methods across different languages, dialects, or domains?\n\n- How might the entropy of a model's output distribution or its propensity for memorization affect the outcomes of your self-supervised evaluation metrics?\n\n- What steps did you take to mitigate the impact of potential confounding factors, such as model overfitting or exposure to similar data during training, on your evaluation results?",
         "575",
         "0",
         "0",
         "0.8257",
         "0.0663548753",
         "0.9400341511",
         "47",
         "10",
         "20.8135",
         "15.7261",
         "18.6817",
         "16.7589",
         "16.8104",
         "0.3442",
         "95",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "279",
         "zH6zBoktYO",
         "8000",
         "1695493297402",
         "['~Neel_Jain1', '~Khalid_Saifullah1', '~Yuxin_Wen2', '~John_Kirchenbauer1', '~Manli_Shu1', '~Aniruddha_Saha1', '~Micah_Goldblum1', '~Jonas_Geiping1', '~Tom_Goldstein1']",
         "Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models",
         "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set, which can lead to misleading evaluations. To alleviate the issues in traditional evaluation, we propose a complementary framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-sensitivity and human-supervised evaluations. The self-sensitivity paradigm complements current evaluation strategies that rely on labeled data.",
         "Reviewer_tXds",
         "1698786794121",
         "1699636985358",
         "5",
         "3",
         "3",
         "3",
         "3",
         "The paper introduces a new self-supervised approach to the evaluation of LLMs, alleviating the need for small domain-specific datasets with human-curated labels as in traditional evaluations. The new evaluation method, on a higher level, is through analyzing invariances and sensitivities to transformations. The work provides detailed case studies on several self-supervised evaluation strategies for different aspects of LLMs, including those related to negations, toxicity detection, long-range dependency, and sensitivity to word order, etc. Strong correlations have been shown between the designed self-supervised evaluation metrics and human-supervised evaluations. - **Originality**: This paper offers a fresh approach to the evaluation of LLMs, moving away from dataset-bound evaluations to a sustainable assessment methodology.\n  \n- **Quality**: The transformations, like handling of negations, word order changes, and others, are impressive steps toward achieving a holistic evaluation of LLMs. \n  \n- **Clarity**: The paper is accessible to even readers that are unfamiliar with the domain. The delineation of their methods and results is commendable.\n  \n- **Significance**: The paper’s methodology, if thoroughly verified and broadly adopted, has the potential to revolutionize how LLM evaluations are conducted, making them more dynamic, comprehensive, and reflective of real-world applications. - **Terminological Ambiguity**: The usage of \"self-supervised\" is somewhat misleading. Given the context of this paper, an alternative term or a more precise explanation would be helpful.\n\n- **Metric Soundness**: While the paper puts forth several innovative metrics, further clarity and validation are needed. For example, the paper justifies its methods heavily by calculating the correlation between proposed scores and one specific existing task. Then I believe a natural question arises – if, for example, having high correlation with TriviaQA alone is enough to demonstrate the legitimacy of SSE, then why don’t we just use TriviaQA accuracy (and also HellaSwag) as the evaluation metric? I am therefore doubtful of the significance of the proposed metrics.\n \n \n- **Questionable Conclusion**: Following up on the comment on the correlation analysis, the paper tries to prove the usefulness of their metrics by showing correlation with existing task on some metrics (e.g. TriviaQA accuracy), but also tries to disprove other evaluation metrics by showing they correlate less nicely with their proposed metrics. For example, the paper concludes perplexity is not a robust evaluation metric because it does not have a very high correlation with SSE; the Cohere Command model is an outlier in their analysis which highlights a weakness of TriviaQA.\n\n- **Visualization**: The visualization in this paper is unfriendly to people with color vision deficiency if not anyone. I find it very hard to distinguish to the difference in the sizes and colors in the figures representing different models. - Can authors provide some examples of how they perform the transformations to evaluate long-range sensitivity.\n\n- How do you identify the neutral corpus?\n\n- “We further explore why correct normalization is important by cross-referencing the frequency with which perplexity goes down rather than up, see Figure 14 in Appendix A.5.” from the figure I see a nice negative correlation between “Percent PPL Drops” and TriviaQA accuracy. So how can this show correct normalization is import in SSE?\n\n- What data do the metric PPL use? Following this paper’s logic, I think the first step this paper should do is to evaluate the correlation between, for example, normalized PPL and TriviaQA accuracy (and other realistic tasks such as MMLU etc).\n\n- How well do toxicity scores by this paper correlate with those by Perspective API on instruction tuned models? From figure 6 left, it looks like there are no Xs. Same question for word order section and figure 4, 7. Without the results of instruction tuned models, it is hard to see if the scores correlate better on vanilla models than instruction tuned models. And therefore hard to assess the significance of the metrics.\n\n- It is still hard for me to understand how to use this paper in real-world applications. How adaptable are these proposed metrics? Would the methodology need alterations to assess LLMs in more dynamic, real-world scenarios?\n\n- Given the terminological ambiguity around \"self-supervised,\" can authors elaborate on this terminology or propose an alternative name to prevent misconceptions?",
         "684",
         "0",
         "0",
         "0.7944",
         "0.0862385928",
         "0.8980768919000001",
         "47",
         "9",
         "24.8802",
         "14.3988",
         "16.8833",
         "15.4333",
         "14.4001",
         "0.1651",
         "85",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "280",
         "zH6zBoktYO",
         "8000",
         "1695493297402",
         "['~Neel_Jain1', '~Khalid_Saifullah1', '~Yuxin_Wen2', '~John_Kirchenbauer1', '~Manli_Shu1', '~Aniruddha_Saha1', '~Micah_Goldblum1', '~Jonas_Geiping1', '~Tom_Goldstein1']",
         "Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models",
         "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set, which can lead to misleading evaluations. To alleviate the issues in traditional evaluation, we propose a complementary framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-sensitivity and human-supervised evaluations. The self-sensitivity paradigm complements current evaluation strategies that rely on labeled data.",
         "Reviewer_cArL",
         "1698793273308",
         "1699636985240",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper presents a self-supervised method for evaluating LLMs without relying on domain-specific, human-annotated datasets. The authors detail a structured approach for self-supervised evaluation, focusing on LLM invariances and sensitivities. Preliminary tests indicate a correlation between their proposed metrics and established ones that depend on human annotations. - Originality: The paper unveils a fresh evaluation technique for Large Language Models that minimizes human intervention. This addresses the shortcomings of conventional methods and provides an alternative measure of a model's capabilities.\n- Their approach can be adapted to different data domains by simply varying the unlabeled text in evaluations. Such as the clinical setting, where they show their method has a good correlation with MMLU (clinical). - Weak evidence for the robustness of this method: In my opinion, using the correlation to TriviaQA's accuracies to prove their usefulness seems to be a bit of weak evidence, especially when only ~10+ models are considered in the experiments. The correlation results can be simply affected by noises/outliners. For example, you mentioned that \"The Pearson correlation between TriviaQA and Normalized sensitivity score is 0.76 for vanilla models and 0.73 for instruction models after removing the Cohere Command outlier\". It proves that the evaluation method is a little bit brittle. When I have a new model that wants to be tested, how can I know my model is not another outlier?\n- I would suggest the authors increase the number of models to 100+, so as to reduce the effects of noise when computing the correlations. If there are not enough LLMs to be tested, one of the strategies you can use is to do early exiting from the models \\[1\\] so that you can get different outputs from different layers of the model, representing different levels of understanding of the data, and thus increase the number of total data points to be compared.\n\n\\[1\\] Eliciting Latent Predictions from Transformers with the Tuned Lens\nNora Belrose, Zach Furman, Logan Smith, Danny Halawi, Igor Ostrovsky, Lev McKinney, Stella Biderman, Jacob Steinhardt https://arxiv.org/abs/2303.08112 - In figure 3, 4, 6, and 7, why the models used for comparison is changing all the time? In figure 3 there are 28 data points but in figure 7 there are only 11 data points. What's your standard of selecting these models to be evaluated? I think it's better to include all the models throughout the experiments to reduce the effects of noise/outliers. The experiment results presented make me feel that some of the results are hidden so the correlation may not be that good if we add them back to the figure.",
         "431",
         "3",
         "0",
         "0.7772",
         "0.0634541847",
         "0.9203519225000001",
         "47",
         "9",
         "39.0316",
         "12.6257",
         "15.0694",
         "14.2253",
         "13.0367",
         "0.2889",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "281",
         "zH6zBoktYO",
         "8000",
         "1695493297402",
         "['~Neel_Jain1', '~Khalid_Saifullah1', '~Yuxin_Wen2', '~John_Kirchenbauer1', '~Manli_Shu1', '~Aniruddha_Saha1', '~Micah_Goldblum1', '~Jonas_Geiping1', '~Tom_Goldstein1']",
         "Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models",
         "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set, which can lead to misleading evaluations. To alleviate the issues in traditional evaluation, we propose a complementary framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-sensitivity and human-supervised evaluations. The self-sensitivity paradigm complements current evaluation strategies that rely on labeled data.",
         "Reviewer_AbSH",
         "1699916249271",
         "1699916404107",
         "3",
         "4",
         "2",
         "3",
         "2",
         "The paper presents a self-supervised evaluation approach for toxicity classifiers. The paper cites that due to training data leakage, toxicity classifiers may have an inflated reported performance. Using the proposed approach where inputs are modified using negation and other techniques, the robustness of content classifiers is evaluated. The paper has the following strengths.\n\nFirst, it is well-written. The paper motivates the problem well, experiments are described clearly. Related work descriptions are reasonable (although the paper missed some key citations, e.g., Gröndahl et al.). \n\nSecond, the motivation for building a domain-specific toxicity classifier is well-received. The key weakness of the paper is:\n\n1. The modifications it is suggesting are too simplistic (e.g., F-bombing). There are many known modifications that have tripped content classifiers before (e.g., All You Need is \"Love\": Evading Hate Speech Detection by Gröndahl et al.) or examples of real-world examples tripping content classifiers (e.g., Are Chess Discussions Racist? An Adversarial Hate Speech Data Set by Sarkar and KhudaBukhsh). Instead of using obfuscation techniques well-grounded in literature, the paper adopts simplistic techniques to modify inputs.  \n\n2. The second weakness of the paper is it relies on Perspective API. Perspective API's toxic scores are not reliable. Recent research indicates that. Hence, an API that itself has calibration issues cannot be very useful for calibrating other systems. My questions are how would the authors respond to my two weaknesses listed above?",
         "230",
         "0",
         "2",
         "0.7940",
         "-0.05675",
         "0.7675612569",
         "51",
         "0",
         "39.1619",
         "10.3942",
         "13.3992",
         "12.0793",
         "11.4429",
         "0.30110000000000003",
         "82",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "292",
         "zEOnlJaRKp",
         "167",
         "1694772573802",
         "['~Jianan_Zhou1', '~Yaoxin_Wu2', '~Zhiguang_Cao1', '~Wen_Song1', '~Jie_Zhang9']",
         "Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems",
         "While enjoying desirable efficiency and less dependence on domain expertise, existing neural methods for vehicle routing problems (VRPs) are vulnerable to adversarial attacks -- their performance drops drastically on adversarial instances, i.e., clean instances with crafted perturbations. To enhance the robustness, we propose a Collaborative Neural Framework (CNF) w.r.t the adversarial defense of neural methods for VRPs, which is crucial yet underexplored in literature. Given a neural method, we adversarially train multiple models in a collaborative manner to synergistically promote the robustness against attacks, while maintaining (or even boosting) the standard generalization on clean instances. A neural router is designed to elegantly distribute instances to each model, which improves load balancing and collaborative performance. Extensive experiments verify the effectiveness and versatility of CNF to defend against various attacks for different neural methods. Notably, our trained models also achieve decent out-of-distribution generalization performance on real-world benchmark instances.",
         "Reviewer_4zRf",
         "1698726633349",
         "1700725165287",
         "6",
         "4",
         "3",
         "4",
         "2",
         "This paper presents a systematic study of the adversarial training of neural network solvers for TSP and CVRP. The methodology part extends the adversarial training pipeline by ensembling multiple models, leading to the so-called CNF approach in this paper. Experiments are conducted on TSP and CVRP, with adversarial samples mainly generated by (Zhang et al., 2022). * This paper is well-written and easy to follow. I could see the efforts of the authors in the organization and the figures.\n* Robustness in solving routing problems is an important measure and worth studying.\n* The experiment study seems extensive and in general seems sound. * The authors believe that model degeneration on clean data is an important issue, and propose the Collaborative Neural Framework to solve it. However, the motivation for developing such a collaborative framework is not clear. The authors only mentioned that collaboration will mitigate existing issues in adversarial training, but do not explain why. From my side, the reason for the improvements brought by \"collaboration\" is quite straightforward and trivial: \"collaboration\" in this paper means training multiple models in adversarial training and using all of them to predict on the same problem instance. Since we are studying an optimization problem where solution evaluation is very fast, we can easily generate multiple predictions using multiple models and pick the best one. Therefore, it is not surprising that \"collaborated\" models are way better than standalone AT models. \n* One step further on the previous point, it is not surprising to see that the performance of Collaborative Neural Framework is kept on clean instances after adversarial training. One can achieve similar results in Figure 1 by simply freezing one model on the clean data and doing adversarial training on the other models. The \"collaborated\" model will never degenerate on the clean data.\n* The improvements brought by the interesting neural router module seem only marginal. As read from Table 1, there are significant performance improvements when 1) from POMO to POMO_AT (add adversarial training), and 2) from POMO_AT (1) to POMO_AT (3) (use 3 models together, i.e., collaboration). Adversarial training seems not an original contribution in this paper; Collaboration, as discussed above, is not surprising to bring a significant improvement. While with the only technically sound module, the improvement from POMO_AT (3) to CNF (3) is not that significant.\n* The authors made the claim on Page 2 that \"simply increasing the model capacity\" will not help Adversarial Training to generalize better, but I do not find any experimental evidence to support that in the main paper.\n### Minor Points\n* In the title: in combinatorial optimization's convention, VRP is usually considered different from TSP. However, in this paper, the authors seem to call both TSP and CVRP \"subsets of VRP\". I believe it will cause confusion and would suggest changing the naming to \"routing problems\".\n* Please explain \"OOD\" in Section 4.3 to make it self-contained.\n* Not sure if it is proper to call all Reinforcement Learning methods as \"REINFORCE\" in Eq (1) because the RL algorithms deployed nowadays usually integrate many more tricks than the vanilla form in Eq (1). * The authors mentioned three papers on the adversarial robustness of CO, and based the major experiment study in the main paper on (Zhang et al. 2022). From my understanding, the other two papers (Geisler et al., 2022) and (Lu et al., 2023) considered the \"hardness\" of the CO problem itself (i.e., there are some guarantees on the optimal objective), while (Zhang et al., 2022) only considered the objective score solved by an existing solver. Can the author justify the reason of selecting (Zhang et al., 2022) as the main experiment protocol?\n* Do the neural network know the behavior of the attacker during training? I.e., are the adversarial data points generated by the attacker in the test dataset?",
         "641",
         "5",
         "1",
         "0.7954",
         "0.1382103825",
         "0.8802164197000001",
         "68",
         "23",
         "41.9616",
         "11.6231",
         "13.9229",
         "13.4172",
         "11.7013",
         "0.426",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "293",
         "zEOnlJaRKp",
         "167",
         "1694772573802",
         "['~Jianan_Zhou1', '~Yaoxin_Wu2', '~Zhiguang_Cao1', '~Wen_Song1', '~Jie_Zhang9']",
         "Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems",
         "While enjoying desirable efficiency and less dependence on domain expertise, existing neural methods for vehicle routing problems (VRPs) are vulnerable to adversarial attacks -- their performance drops drastically on adversarial instances, i.e., clean instances with crafted perturbations. To enhance the robustness, we propose a Collaborative Neural Framework (CNF) w.r.t the adversarial defense of neural methods for VRPs, which is crucial yet underexplored in literature. Given a neural method, we adversarially train multiple models in a collaborative manner to synergistically promote the robustness against attacks, while maintaining (or even boosting) the standard generalization on clean instances. A neural router is designed to elegantly distribute instances to each model, which improves load balancing and collaborative performance. Extensive experiments verify the effectiveness and versatility of CNF to defend against various attacks for different neural methods. Notably, our trained models also achieve decent out-of-distribution generalization performance on real-world benchmark instances.",
         "Reviewer_APh6",
         "1698806483129",
         "1699635942254",
         "5",
         "3",
         "2",
         "3",
         "2",
         "To solve vehicle routing problems’ (VRPs) vulnerability to adversarial examples and existing adversarial training methods do not strike a good balance between generalization (on clean instances) and robustness (on adversarial instances). The Collaborative Neural Framework (CNF) is proposed by the authors, but some descriptions in the paper are not very accurate and clear. The novelty is also limited. The following are some of my doubts and suggestions for the paper, hoping to improve the quality of the paper. The content of this paper is practical and valuable. The experiment of the paper is relatively sufficient. (1) This paper describes adversarial examples in the field of image processing, but does not give a formal definition of adversarial examples in the field of VRPS, and suggests adding a formal definition of adversarial examples in the field of VRPS.\n\n(2) When the number of trained models is listed in Figure 1, it is only increased to 5. Perhaps when the number of models increases, the traditional adversarial training method can exceed the method proposed in the paper. Therefore, it is suggested to increase the number of trained models to demonstrate the effectiveness of the method. \n\n(3) The basis for selecting an attacker is not elaborated, and it is suggested to prove the generality of the selected attacker.\n\n(4) At the end of the paper, experiments are conducted on the out of distribution data, but the relationship between OOD data’s performance and the adversarial robustness is not explained in detail, so it is suggested to elaborate. (1) During the Outer Minimization of CNF, there are three instance types, namely \"ori\", \"local attack\" and \"global attack\". How to prove that the instance of \"global attack\" improves the effectiveness of the method? It is suggested to add experiments in this part or give theoretical explanations.\n(2) In the Outer Minimization stage of CNF, a neural router is trained. Will training a neural router seriously increase the training time? It is suggested to clarify in the paper.",
         "330",
         "0",
         "0",
         "0.6622",
         "0.0738705739",
         "0.9385450482000001",
         "56",
         "9",
         "39.023",
         "12.3709",
         "14.9697",
         "13.985",
         "12.2858",
         "0.088",
         "89",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "294",
         "zEOnlJaRKp",
         "167",
         "1694772573802",
         "['~Jianan_Zhou1', '~Yaoxin_Wu2', '~Zhiguang_Cao1', '~Wen_Song1', '~Jie_Zhang9']",
         "Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems",
         "While enjoying desirable efficiency and less dependence on domain expertise, existing neural methods for vehicle routing problems (VRPs) are vulnerable to adversarial attacks -- their performance drops drastically on adversarial instances, i.e., clean instances with crafted perturbations. To enhance the robustness, we propose a Collaborative Neural Framework (CNF) w.r.t the adversarial defense of neural methods for VRPs, which is crucial yet underexplored in literature. Given a neural method, we adversarially train multiple models in a collaborative manner to synergistically promote the robustness against attacks, while maintaining (or even boosting) the standard generalization on clean instances. A neural router is designed to elegantly distribute instances to each model, which improves load balancing and collaborative performance. Extensive experiments verify the effectiveness and versatility of CNF to defend against various attacks for different neural methods. Notably, our trained models also achieve decent out-of-distribution generalization performance on real-world benchmark instances.",
         "Reviewer_8oTe",
         "1699464036344",
         "1699635942134",
         "5",
         "3",
         "2",
         "3",
         "3",
         "In this paper, the authors focused on enchance the robustness and generalization of vehicle routing problems. The proposed Collaborative Neural Framework (CNF) enhances robustness by adversarially training multiple models to work together, thus improving defense against attacks and potentially increasing generalization on clean instances. This approach is supported by experimental evidence showing that CNF effectively defends against a range of attacks and also performs well on real-world benchmark instances. 1. The exploration of robustness within the context of vehicle routing problems represents a critical area of research that has received limited attention in prior studies. This paper makes a commendable contribution to the field by addressing this gap.\n\n2. The proposed method CNF stands out for its novelty. It builds upon the established principles of min-max optimization, fundamental to adversarial training, which ostensibly enhances the robustness of the model. The efficacy of CNF is further substantiated by the empirical results presented within the study. 1. It seems that the adversarial attack introduced in this model has no attack budget. While acknowledging the distinctions between Vehicle Routing Problems (VRPs) and image-based tasks, it is important to note that the intrinsic discreteness of VRPs does not preclude the assignment of an attack budget, as demonstrated in adversarial settings pertinent to GNNs. The reviewer posits that evaluating the model's performance across various attack budgets is crucial for addressing the balance between clean accuracy and robust accuracy.\n\n2. In the context of graph-based tasks, the absence of constraints on an adversary typically facilitates a significant degradation in performance, often to levels below random chance. Nevertheless, according to Table 1, the vanilla model's performance does not seem to be significantly compromised. Could the authors elucidate the factors that might be contributing to this unexpected resilience?\n\n3. A considerable volume of literature \\[1-5\\] suggests that adversarial data augmentation can bolster generalization capabilities, particularly when the adversarial perturbations involved are small. Should the CNF enhance generalization as well, would this imply that the adversarial attack delineated within this study is potentially suboptimal in terms of its strength?\n\n\\[1\\] Xie et al. Adversarial examples improve image recognition. CVPR 2020.\n\n\\[2\\] Herrmann et al. Pyramid adversarial training improves vit performance. CVPR 2022.\n\n\\[3\\] Wen et al. Adversarial cross-view disentangled graph contrastive learning. 2022\n\n\\[4\\] Kong et al. Robust optimization as data augmentation for large-scale graphs. CVPR 2022.\n\n\\[5\\] Cheng et al. Advaug: Robust adversarial augmentation for neural machine translation. 2020 See weaknesses",
         "403",
         "5",
         "17",
         "0.8363",
         "0.0853918651",
         "0.9295349717",
         "56",
         "1",
         "23.115",
         "13.7433",
         "16.3922",
         "14.5546",
         "14.3981",
         "0.1041",
         "94",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "295",
         "zEOnlJaRKp",
         "167",
         "1694772573802",
         "['~Jianan_Zhou1', '~Yaoxin_Wu2', '~Zhiguang_Cao1', '~Wen_Song1', '~Jie_Zhang9']",
         "Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems",
         "While enjoying desirable efficiency and less dependence on domain expertise, existing neural methods for vehicle routing problems (VRPs) are vulnerable to adversarial attacks -- their performance drops drastically on adversarial instances, i.e., clean instances with crafted perturbations. To enhance the robustness, we propose a Collaborative Neural Framework (CNF) w.r.t the adversarial defense of neural methods for VRPs, which is crucial yet underexplored in literature. Given a neural method, we adversarially train multiple models in a collaborative manner to synergistically promote the robustness against attacks, while maintaining (or even boosting) the standard generalization on clean instances. A neural router is designed to elegantly distribute instances to each model, which improves load balancing and collaborative performance. Extensive experiments verify the effectiveness and versatility of CNF to defend against various attacks for different neural methods. Notably, our trained models also achieve decent out-of-distribution generalization performance on real-world benchmark instances.",
         "Reviewer_ko2G",
         "1699594966148",
         "1700712381908",
         "6",
         "4",
         "2",
         "3",
         "3",
         "This paper proposed a novel adversarial training based framework (CNF) on VRP tasks by generating global adversarial examples on a set of collaborative formed models, and distributing these samples through a well-designed attention-based neural router to perform effective joint adversarial training. The proposed method, CNF, is claimed to achieve better performance on both accuracy and robustness perspective. Experiments has been conducted by comparing CNF with various baselines on TSP and CVRP tasks. Results looks promising - CNF (3) achieves much better vanilla accuracy and robustness with large gap compared with existing baselines. Extensive ablation studies and analysis has been well presented to show the effectiveness of CNF. The whole paper contains enough experimental details and the overall writing is clear. - The overall novelty is okay but it is interesting to see when it is applied to VRP tasks.\n- Impressive experimental results - proposed CNF is better than other AT baslines by a quite large margin on TSP task.\n- Detailed experimental setup and solid experimental analysis. I really love reading the Section 4.3 OOD generalization part - most of the robust training algorithm do not consider such scenario.\n- The whole paper is well-written. Especially for Section 3, it is well-organized for reader to follow the exact CNF pipeline. - No training efficiency was discussed while compared with other baselines. According to Algorithm 1, the training cost is largely relied on n, k and for neural router, its inference time is also heavily relied on K. We should have a column showing the exact training time for CNF and other baselines to achieve the table numbers.\n- Notation is quite unclear: in Algorithm 1, n refers to the iterating variable from 1 to B and for later sections, n refers to the total number of generated samples. In Section 3.2, the captital N was introduced to refer the total number of instances. Also k refers to the attack steps while the capital K refers to the topK samples selected for neural router. However, in Section 4.2, the calligraphic K is also used to refer the topK parameter. This makes reader get confused while checking the experimental details. - (Included in Weakness part) Can you provide the total training time for both CNF and other baselines shown in Table 2? \n- You include the diversity-enhanced ensemble training methods (GAL) as one of baseline methods. However, it has been proved to be not that strong compared with other recent robust ensemble training methods, such as ADP, DVERGE, TRS. Especially for DVERGE, it also claimed to have well-balance between benign accuracy and robust accuracy by crafting adversarial examples on each submodels vulnerability region and reducing adversarial transferability between submodels. It would be interesting to see how DVERGE would perform on the VRP tasks.\n- I'm still quite confused about your inference setup. Given M models you have, it looks unfair to just report the best gap among all models on each instance as the actual robustness: attacker should have the prior information of each models' vulnerability to the attack instance so you should report the worst gap instead. From your side, you do not have the information about the ground-truth so you cannot always choose the best performed model against the unseen attack instances.\n\n\n=============================================================\n\nUpdates:\n\nI thank authors for conducting additional experiments and further clarifying paper notations. These new results and experimental details largely addressed my major concerns. However, I'm still quite confused about the inference reporting metric (Q.3): considering the white-box attack setting, attacker should have all information about your routing strategy and generate adv instances for the whole system instead of the best-performed model. Author should elaborate more on this. I will keep my score but raise my confidence to 4.",
         "623",
         "0",
         "0",
         "0.8047",
         "0.1379129204",
         "0.7871162891",
         "68",
         "12",
         "43.2301",
         "11.3253",
         "13.2175",
         "12.8439",
         "12.0945",
         "0.7458",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "345",
         "z7usV2BlEE",
         "7016",
         "1695451488958",
         "['~Peiyi_Wang1', '~Lei_Li14', '~Liang_Chen10', '~Feifan_Song1', '~Binghuai_Lin1', '~Yunbo_Cao3', '~Tianyu_Liu3', '~Zhifang_Sui1']",
         "Making Large Language Models Better Reasoners with Alignment",
         "Reasoning is a cognitive process of using evidence to reach a sound conclusion.\nThe reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent.\nRecent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. \nHowever, we find that the fine-tuned LLMs suffer from an \\textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities.\nIn this paper, we introduce an \\textit{Alignment Fine-Tuning (AFT)} paradigm with a novel \\textit{Constrained Alignment Loss} to alleviate the assessment misalignment problem.\nSpecifically, the proposed loss has two objectives:\na) Alignment, which guarantees the  scores of high-quality COTs surpass that of subpar ones;\nb) Constraint, which keeps the subpar scores confined to a reasonable range to prevent the model degradation.\nExtensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.\nAFT also performs well in multi-task and out-of-distribution situations.\nFurthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance.",
         "Reviewer_9VoV",
         "1697570161673",
         "1700585835418",
         "5",
         "4",
         "3",
         "3",
         "2",
         "The paper addresses reasoning problems using LLMs and Chain-of-Thought (CoT).\nThe paper proposes to sample multiple chains of thought of the same training question from a pretrained model, and finetune the model to prefer the solutions that lead to the correct final answer. This results in improvements on several reasoning benchmarks, compared to the baseline which was only finetuned on the training set without this augmentation. * The proposed approach is simple\n* The paper focuses on a class of important problems\n* The approach results in gains across multiple popular benchmarks 1. The proposed approach is very similar to \\[LARGE LANGUAGE MODELS CAN SELF-IMPROVE (Huang et al., 2022)\\](https://arxiv.org/pdf/2210.11610.pdf), which came out a year ago. Since the authors did not cite it, I assume that they were not aware of it, but in terms of novelty there is a significant overlap. \n\n2. Motivation - The motivation in Table 1 is unclear. T-Accuracy is ~40% but ~A-Accuracy is ~70% - Is it a surprising result?\nThe paper says that:\n>These results show that the assessment ability of VFT-LLMs is far from expected, as they cannot\naccurately discern the quality of various COTs of previously learned questions.\n\nI'm not sure I agree. What other results would the authors expect?\n\n3. Over-mathematical - I think that there are large complicated parts in the paper that are not necessarily needed, and the paper can be significantly simplified. Since \"Detached Constraint\" (Section 4.3.1) and \"Boundary Constraint\" (Section 4.3.2) perform almost the same, while none of them consistently outperforms the other, why do we need both of them? ### Questions\n1. The paper says that:\n>We discover that LLMs fine-tuned by the vanilla fine-tuning ... frequently assign lower scores to high-quality COTs compared to low-quality ones\n\nWhich is correct, but isn't it trivial? Isn't it the case with any machine learning model - sometimes the model assigns higher probability to the wrong output and low probability to the correct output? Isn't this the source of any kind of mistake in any machine learning model?\n\n### Comments\n1. While terms such as \"serve as the brain of the artificial general intelligence\" (appearing twice) are unfortunately popular in media, have no scientific basis, and I suggest avoiding them in a research paper.\n2. Figure 1 is confusing, or there is a mistake in the text that refers to it:  the second paragraph of the Introduction says: \n\n>As a result, they struggle to assess the quality of other answers and tend to assign lower perplexity (higher score) to\nincorrect Candidate Answer 1 compared to the correct Candidate Answers 2.\n\nHowever, Answer 1 **is the correct answer**, and Answer 2 is the incorrect.\n\n3. There are some claims that are inaccurate. For example:\n> Intuitively, the MLE objective seeks to exclusively allocate probability mass to the reference COT\n\nI wouldn't say that it *exclusively* allocates probability mass to the reference COT, since a lot of mass remains for other possible CoT. As evidence, their probability is not zero.\n\nAs another example:\n>As demonstrated by our pilot experiment, VFT-LLMs fail to give reasonable scores to COTs in GP and GN.\n\nWhat are \"reasonable scores\"? What scores did the authors expect?\n\n4. Figure 2 is visually nice, important, and extensive, but unfortunately impossible to read because the fonts are too tiny.\n5.  The experiments were performed across multiple benchmarks (which is great), using the 7B and 13B versions of LLama 1 and 2. However, I think that these models were only pretrained, without instruction tuning or RLHF. It would be great if the authors could also experiment with the \"Chat\" version of Llama 2 (of the same sizes).\n\n### Summary\nI appreciate the authors' efforts and extensive analysis, but I think that the main approach is too similar to a previous work that came out a year ago (and was not cited). This fact severely hurts the paper in terms of novelty. I thus vote for rejection at this time, unless convinced that there is a significant difference that I have missed.",
         "670",
         "2",
         "8",
         "0.7781",
         "0.08167044600000001",
         "0.8811685443",
         "59",
         "34",
         "49.0402",
         "10.9599",
         "13.2686",
         "13.0239",
         "11.6104",
         "0.8056000000000001",
         "100",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "346",
         "z7usV2BlEE",
         "7016",
         "1695451488958",
         "['~Peiyi_Wang1', '~Lei_Li14', '~Liang_Chen10', '~Feifan_Song1', '~Binghuai_Lin1', '~Yunbo_Cao3', '~Tianyu_Liu3', '~Zhifang_Sui1']",
         "Making Large Language Models Better Reasoners with Alignment",
         "Reasoning is a cognitive process of using evidence to reach a sound conclusion.\nThe reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent.\nRecent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. \nHowever, we find that the fine-tuned LLMs suffer from an \\textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities.\nIn this paper, we introduce an \\textit{Alignment Fine-Tuning (AFT)} paradigm with a novel \\textit{Constrained Alignment Loss} to alleviate the assessment misalignment problem.\nSpecifically, the proposed loss has two objectives:\na) Alignment, which guarantees the  scores of high-quality COTs surpass that of subpar ones;\nb) Constraint, which keeps the subpar scores confined to a reasonable range to prevent the model degradation.\nExtensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.\nAFT also performs well in multi-task and out-of-distribution situations.\nFurthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance.",
         "Reviewer_MzKF",
         "1698829141476",
         "1700728897251",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This work identified an Assessment Misalignment problem in pre-trained Large Language Models (LLMs), where these models cannot well distinguish subpar Chain of Thought (COT) reasoning processes from good COT reasoning processes. The paper then proposed an Alignment Fine-Tuning (AFT) paradigm to address this Assessment Misalignment problem. AFT addresses this by a three-step process: fine-tuning LLMs with COT data, generating multiple COT responses per question, and calibrating the scores using their proposed constraint alignment loss. The AFT method is validated through extensive experiments, showing improved performance in reasoning tasks across various benchmarks​.\n\n====After authors' discussion===\nI have read through the authors' response, and I think they have addressed my concerns. Therefore, I keep my score that this is a work marginally above the acceptance threshold. \\[+\\] The paper identified an important problem that may be overlooked in existing literature -- the misaligned assessment on different COT reasoning process\n\n\\[+\\] The proposed method achieved empirical improvement over vanilla finetuning and other baselines on several datasets \\[-\\] The improvements over existing methods seem a little bit incremental.\n\n\\[-\\] see questions - It would be great if the authors could provide some intuitions on their designed losses to address the corresponding constraint\n- It would be great if the authors could explain why the performance drop for other baseline methods when comparing to vanilla finetuning\n- I also wonder how the quality of LLM-generated COTs impact the performance of AFT. For example, how large is the variance using 3 generated examples?",
         "247",
         "0",
         "0",
         "0.8377",
         "0.1744419643",
         "0.9130199552",
         "61",
         "21",
         "27.3179",
         "16.0462",
         "19.9946",
         "17.6314",
         "19.059",
         "0.1262",
         "82",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "347",
         "z7usV2BlEE",
         "7016",
         "1695451488958",
         "['~Peiyi_Wang1', '~Lei_Li14', '~Liang_Chen10', '~Feifan_Song1', '~Binghuai_Lin1', '~Yunbo_Cao3', '~Tianyu_Liu3', '~Zhifang_Sui1']",
         "Making Large Language Models Better Reasoners with Alignment",
         "Reasoning is a cognitive process of using evidence to reach a sound conclusion.\nThe reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent.\nRecent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. \nHowever, we find that the fine-tuned LLMs suffer from an \\textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities.\nIn this paper, we introduce an \\textit{Alignment Fine-Tuning (AFT)} paradigm with a novel \\textit{Constrained Alignment Loss} to alleviate the assessment misalignment problem.\nSpecifically, the proposed loss has two objectives:\na) Alignment, which guarantees the  scores of high-quality COTs surpass that of subpar ones;\nb) Constraint, which keeps the subpar scores confined to a reasonable range to prevent the model degradation.\nExtensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.\nAFT also performs well in multi-task and out-of-distribution situations.\nFurthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance.",
         "Reviewer_rVEU",
         "1698832681688",
         "1699636822014",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper proposes an improved fine-tuning procedure for LLMs to keep high chain of thought reasoning capabilities. The authors therefore propose a constrained alignment loss based on a constrastive loss function and constraints for the gradients of negative examples. The approach is evaluated on three reasoning datasets - GSM8K, AQUARAT, ECQA and a self-created extension of GSM8K. The chosen baselines are RFT, RRHF, PRO and vanilla fine-tuning. The results are on-par or superior to the baselines. The authors propose a sensible approach to do fine-tuning. The proposed fine-tuning loss including the constraints for negative examples is sufficiently introduced and defined. The method is also easily applicable to other problems, given that negative samples are identified. Also, the authors provide runnable code for the review, backing up the clarity and quality of their work.\n\nThe evaluation results are promising as well. The approach is mostly better than the chosen baselines, thereby showing improved reasoning capabilites. Here, the chosen baselines are quite sensible, as they include one approach tailored for mathematical reasoning (RFT) as well as general fine-tuning results (RRHF, PRO). Given the larger related work, it remains open what the current SoTA results are.\n\nIn a similar vein, it is quite clear from the paper where the loss design differences to the baselines of the evaluation lie, but originality wrt to some referenced works is more difficult to assess from the paper alone. The related work for preference alignment a tad vague: Although it includes the a variety of strongly related and relevant works, the focus of the discussion could/should be more on the diverse strategies of the LLMs tuned for mathematical reasoning tasks. Referenced works could thus be better introduced and compared to based on the respective losses/techniques. This would make clear how innovative/novel the proposed technique is.\n\nThere is no clear argumentation why other mathematical datasets are not used /or referenced in order to back up the design decision for the chosen datasets. It would be good/important to introduce a clear argumentation or reference why these datasets have been chosen, as there are other/more datasets in this field.\n\nThere is no evaluation against some of the direct competitors, such as the referenced Li et al., 2023. It would important to argument why these models have not been chosen for comparison - maybe it is not required. Otherwise it is difficult to understand for the reader if the proposed approach supersedes the current State-of-the-Art. As the approach of the paper can be applied to other/general fine-tuning problems, the added value could also be shown by comparing on more general datasets. Did you compare your methods to other approaches focussed on chain-of-though reasoning for mathematical tasks? \n\nWhy are the chosen evaluation datasets sufficient for your claims? Are these the main datasets of other related works in the field or other reasoning datasets \"easier\" than the chosen ones?\n\nAre the empirical results on-par with other referenced works in the field, such as Li et al., 2023?\n\nHow would standard RLHF perform here? It would be an interesting baseline, as no constrains on the ranking loss are put and it is simpler than PRO.\n\nHow difficult is it to set hyperparameter $B$ and what implications does it have on the results?",
         "538",
         "0",
         "0",
         "0.7659",
         "0.0453846154",
         "0.8569500446",
         "48",
         "9",
         "44.1227",
         "11.5437",
         "14.9079",
         "14.0682",
         "12.5766",
         "0.1163",
         "82",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "348",
         "z7usV2BlEE",
         "7016",
         "1695451488958",
         "['~Peiyi_Wang1', '~Lei_Li14', '~Liang_Chen10', '~Feifan_Song1', '~Binghuai_Lin1', '~Yunbo_Cao3', '~Tianyu_Liu3', '~Zhifang_Sui1']",
         "Making Large Language Models Better Reasoners with Alignment",
         "Reasoning is a cognitive process of using evidence to reach a sound conclusion.\nThe reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent.\nRecent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. \nHowever, we find that the fine-tuned LLMs suffer from an \\textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities.\nIn this paper, we introduce an \\textit{Alignment Fine-Tuning (AFT)} paradigm with a novel \\textit{Constrained Alignment Loss} to alleviate the assessment misalignment problem.\nSpecifically, the proposed loss has two objectives:\na) Alignment, which guarantees the  scores of high-quality COTs surpass that of subpar ones;\nb) Constraint, which keeps the subpar scores confined to a reasonable range to prevent the model degradation.\nExtensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.\nAFT also performs well in multi-task and out-of-distribution situations.\nFurthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance.",
         "Reviewer_voWS",
         "1698845846567",
         "1699636821917",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The authors propose a method to improve the chain-of-thought reasoning training by adding a loss function that imposes additional constraints such that sampled generated outputs that reach the correct answer are consistently favored over those with incorrect answer.\nThe method is evaluated on several reasoning datasets and is shown to outperform existing methods. Overall the paper is easy to read and the presentation of the main ideas is clear.\n\nThe proposed method seems novel and is well-motivated. The empirical results are convincing. Although the intention is to improve the \"reasoning\" capability of the model, the additional loss function makes use of the slightly risky assumption that generated outputs with the correct final answer should be assigned higher score than those with the wrong final answer. One  could argue that the chain of thoughts itself is perhaps more important than the final answer and some negative examples should still be scored higher than positive examples with \"wrong\" reasoning steps. Obviously this cannot be done without additional annotation and the proposed approach seems to work fine despite the risk.\n\nAs in label smoothing, one wonders whether a simple entropy penalty can already help improve the \"overly high confidence\" problem in the first place. See above.",
         "203",
         "0",
         "1",
         "0.7540",
         "0.1143434343",
         "0.8051519394000001",
         "48",
         "9",
         "37.6623",
         "13.6096",
         "15.918800000000001",
         "14.7122",
         "15.5092",
         "0.1041",
         "105",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "357",
         "z6KS9D1dxt",
         "872",
         "1694939062755",
         "['~Simin_Li5', '~Jun_Guo6', '~Jingqiao_Xiu1', '~Ruixiao_Xu1', '~Xin_Yu7', '~Jiakai_Wang1', '~Aishan_Liu1', '~Yaodong_Yang1', '~Xianglong_Liu3']",
         "Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game",
         "In this study, we explore the robustness of cooperative multi-agent reinforcement learning (c-MARL) against Byzantine failures, where any agent can enact arbitrary, worst-case actions due to malfunction or adversarial attack. To address the uncertainty that any agent can be adversarial, we propose a Bayesian Adversarial Robust Dec-POMDP (BARDec-POMDP) framework, which views Byzantine adversaries as nature-dictated types, represented by a separate transition. This allows agents to learn policies grounded on their posterior beliefs about the type of other agents, fostering collaboration with identified allies and minimizing vulnerability to adversarial manipulation. We define the optimal solution to the BARDec-POMDP as an ex interim robust Markov perfect Bayesian equilibrium, which we proof to exist and the corresponding policy weakly dominates previous approaches as time goes to infinity. To realize this equilibrium, we put forward a two-timescale actor-critic algorithm with almost sure convergence under specific conditions. Experiments on matrix game, Level-based Foraging and StarCraft II indicate that, our method successfully acquires intricate micromanagement skills and adaptively aligns with allies under worst-case perturbations, showing resilience against non-oblivious adversaries, random allies, observation-based attacks, and transfer-based attacks.",
         "Reviewer_UzHb",
         "1698041520105",
         "1700544258549",
         "8",
         "4",
         "3",
         "2",
         "3",
         "The paper addresses Byzantine failures in multi-agent reinforcement learning (MARL), where agents can adopt malicious behavior due to malfunction caused by hardware/software faults. First, a new problem setting, called Bayesian Adversarial Robust Dec-POMDP (BARDec-POMDP), is proposed to model adversarial intervention as a transition, where originally cooperative joint actions are modified before being executed in the actual environment. The setting is inspired by Bayesian games, where agents have types that need to be inferred by other agents through their beliefs. The goal is to learn a more fine-grained solution than prior work, where policies are able to collaborate with functional agents, while being robust against adversaries therefore finding a better cooperation-robustness trade-off. Ex post mixed-strategy robust Bayesian Markov perfect equilibrium is proposed as a solution concept for BARDec-POMDPs, which is claimed to be weakly dominant over equilibria that were pursued in previous works.\n\nBased on this setting, a two-timescale actor-critic is proposed based on the robust Harsanyi-Bellman equation, defining the maximin value according to the ideal case (before any adversarial modification) and the adversarial case. The policy gradient uses the value of the adversarial case as critic. The approach is evaluated in a variety of games, including a matrix game, a gridworld game, and a map of SMAC. It is also evaluated against different attacker types. The paper addresses a very important problem, which is often neglected in the MARL community.\n\nThe proposed setting (BARDec-POMDP) can model realistic scenarios, where agents can behave adversarially due to malfunctioning.\n\nWhile most works on robust MARL focus on defenses against any kind of adversarial attack, which leads to conservative policies, the paper aims to find a trade-off between collaborating with actual functional agents and robustness against actual adversaries, which is a more desirable goal for real-world applications. Bayesian games provide a neat framework to discern between these types of agents, which is a convincing proposal.\n\nThe solution concept seems valid.\n\nI like the evaluation, which first starts with a small toy problem before scaling up to larger benchmarks like SMAC. I also appreciate the evaluation with different adversarial strategies. My main concern with the paper is the lack of self-containment: The paper excessively references the appendix, which hurts readability (it is not convenient to peek into the appendix for almost every paragraph of the main paper).\n\nThe paper needs a clear prioritization of what is really important and what can be safely left in the appendix. For example, important proofs can be sketched informally with little space, but delegating them to the appendix completely is not acceptable.\n\nBefore checking, if I can raise my score, I need a revised version of the paper that is more self-contained, e.g., where the number of appendix references is significantly reduced and proofs are at least sketched such that the reader is not forced to switch documents all the time.\n\n**Minor Comments**\n- In Dec-POMDPs (Section 2.1), policies select their actions by the history of past observations and actions. Conditioning only on observations is insufficient since they are not Markovian. The definition in Section 2.2 is correct, though.\n- Line 119: “was replaced” - “**is** replaced”\n- Line 277: “four type of threats” - “four type**s** of threats”\n- The text size in Figure 2 is too small for printed versions. 1. Why do adversaries condition on observations despite them not being Markovian (in contrast to the non-adversarial policies)? Is this intentional or a mistake?\n2. Do you have any intuition on why M3DDPG performs so poorly in the presence of an adversary compared to the standard MAPPO without any robustness mechanism in Figure 4?",
         "597",
         "0",
         "2",
         "0.7926",
         "0.1150439394",
         "0.8859655261",
         "64",
         "28",
         "34.8172",
         "13.2971",
         "15.5957",
         "14.6021",
         "14.3921",
         "0.7021000000000001",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "358",
         "z6KS9D1dxt",
         "872",
         "1694939062755",
         "['~Simin_Li5', '~Jun_Guo6', '~Jingqiao_Xiu1', '~Ruixiao_Xu1', '~Xin_Yu7', '~Jiakai_Wang1', '~Aishan_Liu1', '~Yaodong_Yang1', '~Xianglong_Liu3']",
         "Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game",
         "In this study, we explore the robustness of cooperative multi-agent reinforcement learning (c-MARL) against Byzantine failures, where any agent can enact arbitrary, worst-case actions due to malfunction or adversarial attack. To address the uncertainty that any agent can be adversarial, we propose a Bayesian Adversarial Robust Dec-POMDP (BARDec-POMDP) framework, which views Byzantine adversaries as nature-dictated types, represented by a separate transition. This allows agents to learn policies grounded on their posterior beliefs about the type of other agents, fostering collaboration with identified allies and minimizing vulnerability to adversarial manipulation. We define the optimal solution to the BARDec-POMDP as an ex interim robust Markov perfect Bayesian equilibrium, which we proof to exist and the corresponding policy weakly dominates previous approaches as time goes to infinity. To realize this equilibrium, we put forward a two-timescale actor-critic algorithm with almost sure convergence under specific conditions. Experiments on matrix game, Level-based Foraging and StarCraft II indicate that, our method successfully acquires intricate micromanagement skills and adaptively aligns with allies under worst-case perturbations, showing resilience against non-oblivious adversaries, random allies, observation-based attacks, and transfer-based attacks.",
         "Reviewer_EssV",
         "1699329370678",
         "1700457812183",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper addresses the robustness of multi-agent reinforcement learning against Byzantine failures. A Bayesian Adversarial Robust\nDec-POMDP (BARDec-POMDP) framework is proposed.  The theoretical formulation of the problem is one of the contributions of the\npaper and an actor-critic algorithm that produces convergence under some conditions.  Convergence is not ensured but experimentally\nthe approach shows great resilience against a spectrum of adversaries.\n\nThe paper makes some strong assumptions, like the fact that in each episode there is only one attacker. Other assumptions are consistency and sequential rationality, which are used to form an ex interim robust Markov perfect Bayesian equilibrium (RMPBE). With some additional assumptions, the existence of ex ante and ex interim RMPBE are guaranteed. For the ex interim equilibrium, the Q function can be written using the Bellman-type equation for the two Q functions, which the paper calls \"the robust Harsanyi-Bellman equation.\" With a few more assumptions, updating the value function via the Bayes rule guarantees convergence to the optimal value of Q.\n\nThe algorithm proposed is applied to different problems, a toy metrics game and some map problems. For the attacks, four types of threats are considered: non-oblivious adversaries, random agents, noisy observations, and transferred adversaries. The experimental results cover robustness over non-oblivious attacks and various types of attacks. The novelty of the paper is in the theoretical formulation of the problem and in the actor-critic algorithm that produces convergence\nunder some conditions.  Convergence is not ensured but experimentally the approach shows great resilience against a spectrum of adversaries. - The fact that convergence cannot be guaranteed despite the assumptions made is a weakness of the paper. The method proposed is complex, and the assumptions are strong, yet there is no guarantee of convergence\n- The proofs are all in the Appendix, which makes the paper quite long, too long for a conference paper, and that makes it appear incomplete.  Even the analysis of two of the environments used for the experiments is in the Appendix. Expecting the reviewers to read a paper of 36 pages is too much for a conference.  Without the Appendices the paper is incomplete.\n- The paper is hard to read, it assumes significant knowledge of the field and is full of acronyms and citations that break the flow of the text.\n\nAfter the discussion and the changes made to the paper, I reduced my criticism about convergence and increased the rating I gave for contribution. However, the presentation needs more work.  Many of the corrections made to the paper have grammar errors, like mismatches of singular/plural. I understand the rush of making the changes, but the writing is not where it should be.  I also still object to the length of the paper. If you were to write a paper that fits in the page limits, would you include some of the material from the Appendices and drop some of the material currently in the paper or leave the paper unchanged?  I am wondering what you think are the most important parts needed to present the work without exceeding the page limits.",
         "510",
         "0",
         "0",
         "0.7209",
         "0.16693548390000001",
         "0.9243630767000001",
         "63",
         "13",
         "43.1045",
         "11.912",
         "15.4007",
         "14.341",
         "12.8111",
         "0.5533",
         "86",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 3835
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>4303</td>\n",
       "      <td>1695343783421</td>\n",
       "      <td>[~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Reviewer_BcRN</td>\n",
       "      <td>1698598642014</td>\n",
       "      <td>1699636398632</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0004</td>\n",
       "      <td>15.6607</td>\n",
       "      <td>14.5546</td>\n",
       "      <td>14.5263</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>4303</td>\n",
       "      <td>1695343783421</td>\n",
       "      <td>[~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Reviewer_hJxN</td>\n",
       "      <td>1698648844616</td>\n",
       "      <td>1699636398538</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.7030</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>12.2047</td>\n",
       "      <td>12.4388</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>4303</td>\n",
       "      <td>1695343783421</td>\n",
       "      <td>[~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Reviewer_8Cdu</td>\n",
       "      <td>1698863097320</td>\n",
       "      <td>1699636398427</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14.8293</td>\n",
       "      <td>18.2521</td>\n",
       "      <td>15.9032</td>\n",
       "      <td>16.8967</td>\n",
       "      <td>0.1939</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>4303</td>\n",
       "      <td>1695343783421</td>\n",
       "      <td>[~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Reviewer_Q843</td>\n",
       "      <td>1699416352034</td>\n",
       "      <td>1699636398331</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>9.6210</td>\n",
       "      <td>12.2299</td>\n",
       "      <td>12.2310</td>\n",
       "      <td>10.3101</td>\n",
       "      <td>0.4364</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>zt8bb6vC4m</td>\n",
       "      <td>4003</td>\n",
       "      <td>1695329721281</td>\n",
       "      <td>[~Jianyu_Xu1, ~Yu-Xiang_Wang1]</td>\n",
       "      <td>Pricing with Contextual Elasticity and Heteros...</td>\n",
       "      <td>We study an online contextual dynamic pricing ...</td>\n",
       "      <td>Reviewer_6Reb</td>\n",
       "      <td>1698589805767</td>\n",
       "      <td>1699636362362</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9542</td>\n",
       "      <td>14.0176</td>\n",
       "      <td>13.1874</td>\n",
       "      <td>11.7498</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27974</th>\n",
       "      <td>09iOdaeOzp</td>\n",
       "      <td>4531</td>\n",
       "      <td>1695351755791</td>\n",
       "      <td>[~Mengzhou_Xia1, ~Tianyu_Gao1, ~Zhiyuan_Zeng3,...</td>\n",
       "      <td>Sheared LLaMA: Accelerating Language Model Pre...</td>\n",
       "      <td>The popularity of LLaMA (Touvron et al., 2023a...</td>\n",
       "      <td>Reviewer_qt4Y</td>\n",
       "      <td>1698822664319</td>\n",
       "      <td>1699636430275</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>11.5371</td>\n",
       "      <td>13.9291</td>\n",
       "      <td>13.4191</td>\n",
       "      <td>13.1220</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27975</th>\n",
       "      <td>09iOdaeOzp</td>\n",
       "      <td>4531</td>\n",
       "      <td>1695351755791</td>\n",
       "      <td>[~Mengzhou_Xia1, ~Tianyu_Gao1, ~Zhiyuan_Zeng3,...</td>\n",
       "      <td>Sheared LLaMA: Accelerating Language Model Pre...</td>\n",
       "      <td>The popularity of LLaMA (Touvron et al., 2023a...</td>\n",
       "      <td>Reviewer_wgpN</td>\n",
       "      <td>1698839708409</td>\n",
       "      <td>1699636430183</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0944</td>\n",
       "      <td>13.2245</td>\n",
       "      <td>12.5486</td>\n",
       "      <td>13.4303</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28002</th>\n",
       "      <td>030cjlZm4a</td>\n",
       "      <td>9267</td>\n",
       "      <td>1695548092232</td>\n",
       "      <td>[~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...</td>\n",
       "      <td>Learning Predictive Checklists with Probabilis...</td>\n",
       "      <td>Checklists have been widely recognized as effe...</td>\n",
       "      <td>Reviewer_SxKf</td>\n",
       "      <td>1698683826765</td>\n",
       "      <td>1700488544114</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8921</td>\n",
       "      <td>11.5486</td>\n",
       "      <td>11.5339</td>\n",
       "      <td>8.5000</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28003</th>\n",
       "      <td>030cjlZm4a</td>\n",
       "      <td>9267</td>\n",
       "      <td>1695548092232</td>\n",
       "      <td>[~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...</td>\n",
       "      <td>Learning Predictive Checklists with Probabilis...</td>\n",
       "      <td>Checklists have been widely recognized as effe...</td>\n",
       "      <td>Reviewer_Ucnh</td>\n",
       "      <td>1698794126465</td>\n",
       "      <td>1699637167426</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9360</td>\n",
       "      <td>15.0476</td>\n",
       "      <td>14.0682</td>\n",
       "      <td>13.3413</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28004</th>\n",
       "      <td>030cjlZm4a</td>\n",
       "      <td>9267</td>\n",
       "      <td>1695548092232</td>\n",
       "      <td>[~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...</td>\n",
       "      <td>Learning Predictive Checklists with Probabilis...</td>\n",
       "      <td>Checklists have been widely recognized as effe...</td>\n",
       "      <td>Reviewer_eMqU</td>\n",
       "      <td>1698839690002</td>\n",
       "      <td>1700668054185</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5123</td>\n",
       "      <td>12.1707</td>\n",
       "      <td>11.9908</td>\n",
       "      <td>11.2335</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3835 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "15       zxPDdw8koz               4303             1695343783421   \n",
       "16       zxPDdw8koz               4303             1695343783421   \n",
       "17       zxPDdw8koz               4303             1695343783421   \n",
       "18       zxPDdw8koz               4303             1695343783421   \n",
       "48       zt8bb6vC4m               4003             1695329721281   \n",
       "...             ...                ...                       ...   \n",
       "27974    09iOdaeOzp               4531             1695351755791   \n",
       "27975    09iOdaeOzp               4531             1695351755791   \n",
       "28002    030cjlZm4a               9267             1695548092232   \n",
       "28003    030cjlZm4a               9267             1695548092232   \n",
       "28004    030cjlZm4a               9267             1695548092232   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "15     [~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...   \n",
       "16     [~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...   \n",
       "17     [~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...   \n",
       "18     [~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...   \n",
       "48                        [~Jianyu_Xu1, ~Yu-Xiang_Wang1]   \n",
       "...                                                  ...   \n",
       "27974  [~Mengzhou_Xia1, ~Tianyu_Gao1, ~Zhiyuan_Zeng3,...   \n",
       "27975  [~Mengzhou_Xia1, ~Tianyu_Gao1, ~Zhiyuan_Zeng3,...   \n",
       "28002  [~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...   \n",
       "28003  [~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...   \n",
       "28004  [~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "15     CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "16     CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "17     CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "18     CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "48     Pricing with Contextual Elasticity and Heteros...   \n",
       "...                                                  ...   \n",
       "27974  Sheared LLaMA: Accelerating Language Model Pre...   \n",
       "27975  Sheared LLaMA: Accelerating Language Model Pre...   \n",
       "28002  Learning Predictive Checklists with Probabilis...   \n",
       "28003  Learning Predictive Checklists with Probabilis...   \n",
       "28004  Learning Predictive Checklists with Probabilis...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "15     Contrastive language image pretraining (CLIP) ...  Reviewer_BcRN   \n",
       "16     Contrastive language image pretraining (CLIP) ...  Reviewer_hJxN   \n",
       "17     Contrastive language image pretraining (CLIP) ...  Reviewer_8Cdu   \n",
       "18     Contrastive language image pretraining (CLIP) ...  Reviewer_Q843   \n",
       "48     We study an online contextual dynamic pricing ...  Reviewer_6Reb   \n",
       "...                                                  ...            ...   \n",
       "27974  The popularity of LLaMA (Touvron et al., 2023a...  Reviewer_qt4Y   \n",
       "27975  The popularity of LLaMA (Touvron et al., 2023a...  Reviewer_wgpN   \n",
       "28002  Checklists have been widely recognized as effe...  Reviewer_SxKf   \n",
       "28003  Checklists have been widely recognized as effe...  Reviewer_Ucnh   \n",
       "28004  Checklists have been widely recognized as effe...  Reviewer_eMqU   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "15     1698598642014           1699636398632              3  ...   \n",
       "16     1698648844616           1699636398538              3  ...   \n",
       "17     1698863097320           1699636398427              3  ...   \n",
       "18     1699416352034           1699636398331              8  ...   \n",
       "48     1698589805767           1699636362362              6  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "27974  1698822664319           1699636430275              8  ...   \n",
       "27975  1698839708409           1699636430183              5  ...   \n",
       "28002  1698683826765           1700488544114              8  ...   \n",
       "28003  1698794126465           1699637167426              3  ...   \n",
       "28004  1698839690002           1700668054185              6  ...   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "15                  13.0004      15.6607     14.5546   \n",
       "16                  10.7030      12.5661     12.2047   \n",
       "17                  14.8293      18.2521     15.9032   \n",
       "18                   9.6210      12.2299     12.2310   \n",
       "48                  10.9542      14.0176     13.1874   \n",
       "...                     ...          ...         ...   \n",
       "27974               11.5371      13.9291     13.4191   \n",
       "27975               11.0944      13.2245     12.5486   \n",
       "28002                8.8921      11.5486     11.5339   \n",
       "28003               12.9360      15.0476     14.0682   \n",
       "28004               10.5123      12.1707     11.9908   \n",
       "\n",
       "       automated_readability_index politeness_score  hedge_C  hedge_D  \\\n",
       "15                         14.5263           0.0364       94        0   \n",
       "16                         12.4388           0.0720       94        0   \n",
       "17                         16.8967           0.1939       80        0   \n",
       "18                         10.3101           0.4364       93        0   \n",
       "48                         11.7498           0.1041       94        0   \n",
       "...                            ...              ...      ...      ...   \n",
       "27974                      13.1220           0.1392       87        0   \n",
       "27975                      13.4303           0.1450       72        0   \n",
       "28002                       8.5000           0.0291       89        1   \n",
       "28003                      13.3413           0.0485       96        0   \n",
       "28004                      11.2335           0.1262       99        0   \n",
       "\n",
       "       hedge_E hedge_I  hedge_N  \n",
       "15           0       0        0  \n",
       "16           0       0        0  \n",
       "17           0       0        0  \n",
       "18           0       0        0  \n",
       "48           0       0        0  \n",
       "...        ...     ...      ...  \n",
       "27974        1       0        0  \n",
       "27975        0       0        0  \n",
       "28002        1       0        1  \n",
       "28003        0       0        0  \n",
       "28004        0       0        0  \n",
       "\n",
       "[3835 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Randomly select 1000 unique submission_number values\n",
    "selected_submission_numbers = random.sample(df['submission_number'].unique().tolist(), 1000)\n",
    "\n",
    "# Filter rows with the selected submission_number values\n",
    "df_1000 = df[df['submission_number'].isin(selected_submission_numbers)]\n",
    "\n",
    "# Display the new dataframe\n",
    "df_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000.to_json('/home/ali/Review_Quality_Benchmark/data/processed/iclr2024_1000_papers.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
